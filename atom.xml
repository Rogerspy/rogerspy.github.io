<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Rogerspy&#39;s Home</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://rogerspy.gitee.io/"/>
  <updated>2021-09-15T15:36:16.765Z</updated>
  <id>https://rogerspy.gitee.io/</id>
  
  <author>
    <name>Rogerspy</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>深入理解 einsum：实现多头注意力机制</title>
    <link href="https://rogerspy.gitee.io/2021/09/12/einsum-mhsa/"/>
    <id>https://rogerspy.gitee.io/2021/09/12/einsum-mhsa/</id>
    <published>2021-09-12T02:45:06.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/einsum-attention.png" alt></p><p>Einsum 表示法是对张量的复杂操作的一种优雅方式，本质上是使用特定领域的语言。 一旦理解并掌握了 einsum，可以帮助我们更快地编写更简洁高效的代码。</p><a id="more"></a><p>Einsum 是爱因斯坦求和（Einstein summation）的缩写，是一种求和的方法，在处理关于坐标的方程式时非常有效。在 numpy、TensorFlow 和 Pytorch 中都有相关实现，本文通过 Pytorch 实现 Transformer 中的多头注意力来介绍 einsum 在深度学习模型中的应用。</p><h1 id="1-矩阵乘法"><a href="#1-矩阵乘法" class="headerlink" title="1. 矩阵乘法"></a>1. 矩阵乘法</h1><p>假设有两个矩阵：</p><script type="math/tex; mode=display">A = \left[\begin{matrix}1 & 2 & 3 \\4 & 5 & 6\end{matrix} \right],\quadB = \left[\begin{matrix}7 & 8  \\9 & 10 \\11 & 12\end{matrix} \right]</script><p>我们想求两个矩阵的乘积。</p><ul><li>第一步：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210912131703.png" style="zoom:67%;"></p><ul><li>第二步：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210912132039.png" style="zoom:67%;"></p><ul><li>第三步：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210912132541.png" style="zoom:67%;"></p><ul><li>第四步：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210912132929.png" style="zoom:67%;"></p><h1 id="2-Einstein-Notation"><a href="#2-Einstein-Notation" class="headerlink" title="2. Einstein Notation"></a>2. Einstein Notation</h1><p>爱因斯坦标记法又称爱因斯坦求和约定（Einstein summation convention），基本内容是：</p><blockquote><p>当两个变量具有相同的角标时，则遍历求和。在此情况下，求和号可以省略。</p></blockquote><p>比如，计算两个向量的乘积， $\color{red}{a}, \color{blue}{b} \in \mathbb{R}^I$：</p><script type="math/tex; mode=display">\color{green}{c} = \sum_i \color{red}{a_i}\color{blue}{b_i}=\color{red}{a_i}\color{blue}{b_i}</script><p>计算两个矩阵的乘积， <font color="red">$A$</font> $\in \mathbb{R}^{I\times K}$，<font color="blue">$B$</font> $\in \mathbb{R}^{K\times J}$。用爱因斯坦求和符号表示，可以写成：</p><script type="math/tex; mode=display">\color{green}{c}_{ij} \color{black}= \sum_k\color{red}{A_{ik}}\color{blue}{B_{kj}}=\color{red}{A_{ik}}\color{blue}{B_{kj}}</script><p>在深度学习中，通常使用的是更高阶的张量之间的变换。比如在一个 batch 中包含 $N$ 个训练样本的，最大长度是 $T$，词向量维度为 $K$ 的张量，即 $\color{red}{\mathcal{T}}\in \mathbb{R}^{N\times T \times K}$，如果想让词向量的维度映射到 $Q$ 维，则定义一个 $\color{blue}{W} \in \mathbb{R}^{K\times Q}$:</p><script type="math/tex; mode=display">\color{green}{C_{ntq}} = \sum_k\color{red}{\mathcal{T}_{ntk}}\color{blue}{W_{kq}}=\color{red}{\mathcal{T}_{ntk}}\color{blue}{W_{kq}}</script><p>在图像处理中，通常在一个 batch 的训练样本中包含 $N$ 张图片，每张图片长为 $T$，宽为 $K$，颜色通道为 $M$，即 $\color{red}{\mathcal{T}}\in \mathbb{R}^{N\times T \times K \times M}$ 是一个 4d 张量。如果我想进行三个操作：</p><ul><li>将 $K$ 投影成 $Q$ 维；</li><li>对 $T$ 进行求和；</li><li>将 $M$ 和 $N$ 进行转置。</li></ul><p>用爱因斯坦标记法可以表示成：</p><script type="math/tex; mode=display">\color{green}{C_{mqn}}=\sum_t \sum_k \color{red}{\mathcal{T}_{ntkm}} \color{blue}{W_{kq}} = \color{red}{\mathcal{T}_{ntkm}} \color{blue}{W_{kq}}</script><p>需要注意的是，爱因斯坦标记法是一种书写约定，是为了将复杂的公式写得更加简洁。它本身并不是某种运算符，具体运算还是要回归到各种算子上。</p><h1 id="3-einsum"><a href="#3-einsum" class="headerlink" title="3. einsum"></a>3. einsum</h1><ul><li>Numpy：<code>np.einsum</code></li><li>Pytorch：<code>torch.einsum</code></li><li>TensorFlow：<code>tf.einsum</code></li></ul><p>以上三种 <code>einsum</code> 都有相同的特性 <code>einsum(equation, operands)</code>：</p><ul><li><code>equation</code>：字符串，用来表示爱因斯坦求和标记法的；</li><li><code>operands</code>：一些列张量，要运算的张量。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210912232701.png" alt></p><p>其中 <code>口</code> 是一个占位符，代表的是张量维度的字符。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.einsum(&apos;ij,jk-&gt;ik&apos;, A, B)</span><br></pre></td></tr></table></figure><p><code>A</code> 和 <code>B</code> 是两个矩阵，将 <code>ij,jk-&gt;ik</code> 分成两部分：<code>ij, jk</code> 和 <code>ik</code>，那么 <code>ij</code> 代表的是输入矩阵 <code>A</code> 的第 <code>i</code> 维和第 <code>j</code> 维，<code>jk</code> 代表的是 <code>B</code> 第 <code>j</code> 维和第 <code>k</code> 维，<code>ik</code> 代表的是输出矩阵的第 <code>i</code> 维和第 <code>k</code> 维。注意 <code>i, j, k</code> 可以是任意的字符，但是必须保持一致。换句话说，<code>einsum</code> 实际上是直接操作了矩阵的维度（角标）。上例中表示的是， <code>A</code> 和 <code>B</code> 的乘积。</p><p><img src="https://obilaniu6266h16.files.wordpress.com/2016/02/einsum-matrixmul.png?w=676" alt></p><h2 id="3-1-矩阵转置"><a href="#3-1-矩阵转置" class="headerlink" title="3.1 矩阵转置"></a>3.1 矩阵转置</h2><script type="math/tex; mode=display">B_{ji} = A_{ij}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.arange(<span class="number">6</span>).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">torch.einsum(<span class="string">'ij-&gt;ji'</span>, [a])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[ <span class="number">0.</span>,  <span class="number">3.</span>],</span><br><span class="line">        [ <span class="number">1.</span>,  <span class="number">4.</span>],</span><br><span class="line">        [ <span class="number">2.</span>,  <span class="number">5.</span>]])</span><br></pre></td></tr></table></figure><h2 id="3-2-求和"><a href="#3-2-求和" class="headerlink" title="3.2 求和"></a>3.2 求和</h2><script type="math/tex; mode=display">b = \sum_i\sum_j A_{ij}=A_{ij}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">6</span>).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">torch.einsum(<span class="string">'ij-&gt;'</span>, [a])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor(<span class="number">15.</span>)</span><br></pre></td></tr></table></figure><h2 id="3-3-列求和"><a href="#3-3-列求和" class="headerlink" title="3.3 列求和"></a>3.3 列求和</h2><script type="math/tex; mode=display">b_j=\sum_iA_{ij}=A_{ij}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">6</span>).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">torch.einsum(<span class="string">'ij-&gt;j'</span>, [a])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([ <span class="number">3.</span>,  <span class="number">5.</span>,  <span class="number">7.</span>])</span><br></pre></td></tr></table></figure><h2 id="3-4-行求和"><a href="#3-4-行求和" class="headerlink" title="3.4 行求和"></a>3.4 行求和</h2><script type="math/tex; mode=display">b_i=\sum_jA_{ij}=A_{ij}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">6</span>).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">torch.einsum(<span class="string">'ij-&gt;i'</span>, [a])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([  <span class="number">3.</span>,  <span class="number">12.</span>])</span><br></pre></td></tr></table></figure><h2 id="3-5-矩阵-向量乘积"><a href="#3-5-矩阵-向量乘积" class="headerlink" title="3.5 矩阵-向量乘积"></a>3.5 矩阵-向量乘积</h2><script type="math/tex; mode=display">c_i=\sum_kA_{ik}b_k=A_{ik}b_k</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">6</span>).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">b = torch.arange(<span class="number">3</span>)</span><br><span class="line">torch.einsum(<span class="string">'ik,k-&gt;i'</span>, [a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([  <span class="number">5.</span>,  <span class="number">14.</span>])</span><br></pre></td></tr></table></figure><h2 id="3-6-矩阵-矩阵乘积"><a href="#3-6-矩阵-矩阵乘积" class="headerlink" title="3.6 矩阵-矩阵乘积"></a>3.6 矩阵-矩阵乘积</h2><script type="math/tex; mode=display">C_{ij}=\sum_kA_{ik}B_{kj}=A_{ik}B_{kj}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">6</span>).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">b = torch.arange(<span class="number">15</span>).reshape(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">torch.einsum(<span class="string">'ik,kj-&gt;ij'</span>, [a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">tensor([[  <span class="number">25.</span>,   <span class="number">28.</span>,   <span class="number">31.</span>,   <span class="number">34.</span>,   <span class="number">37.</span>],</span><br><span class="line">        [  <span class="number">70.</span>,   <span class="number">82.</span>,   <span class="number">94.</span>,  <span class="number">106.</span>,  <span class="number">118.</span>]])</span><br></pre></td></tr></table></figure><h2 id="3-7-点积"><a href="#3-7-点积" class="headerlink" title="3.7 点积"></a>3.7 点积</h2><script type="math/tex; mode=display">c = \sum_ia_ib_i=a_ib_i</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">3</span>)</span><br><span class="line">b = torch.arange(<span class="number">3</span>, <span class="number">6</span>)</span><br><span class="line">torch.einsum(<span class="string">'i,i-&gt;'</span>, [a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">tensor(<span class="number">14.</span>)</span><br></pre></td></tr></table></figure><h2 id="3-8-Hardamard-积"><a href="#3-8-Hardamard-积" class="headerlink" title="3.8 Hardamard 积"></a>3.8 Hardamard 积</h2><script type="math/tex; mode=display">C_{ij} = A_{ij}B_{ij}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">6</span>).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">b = torch.arange(<span class="number">6</span>,<span class="number">12</span>).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">torch.einsum(<span class="string">'ij,ij-&gt;ij'</span>, [a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">tensor([[  <span class="number">0.</span>,   <span class="number">7.</span>,  <span class="number">16.</span>],</span><br><span class="line">        [ <span class="number">27.</span>,  <span class="number">40.</span>,  <span class="number">55.</span>]])</span><br></pre></td></tr></table></figure><h2 id="3-9-外积"><a href="#3-9-外积" class="headerlink" title="3.9 外积"></a>3.9 外积</h2><script type="math/tex; mode=display">C_{ij}=a_ib_j</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">3</span>)</span><br><span class="line">b = torch.arange(<span class="number">3</span>, <span class="number">7</span>)</span><br><span class="line">torch.einsum(<span class="string">'i, j-&gt;ij'</span>, [a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">tensor([[  <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>,   <span class="number">0.</span>],</span><br><span class="line">        [  <span class="number">3.</span>,   <span class="number">4.</span>,   <span class="number">5.</span>,   <span class="number">6.</span>],</span><br><span class="line">        [  <span class="number">6.</span>,   <span class="number">8.</span>,  <span class="number">10.</span>,  <span class="number">12.</span>]])</span><br></pre></td></tr></table></figure><h2 id="3-10-Batch-矩阵乘积"><a href="#3-10-Batch-矩阵乘积" class="headerlink" title="3.10 Batch 矩阵乘积"></a>3.10 Batch 矩阵乘积</h2><script type="math/tex; mode=display">C_{ijl}=\sum_kA_{ijk}B_{ikl}=A_{ijk}B_{ikl}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">3</span>,<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">b = torch.randn(<span class="number">3</span>,<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">torch.einsum(<span class="string">'ijk, jkl-&gt;ijl'</span>, [a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">tensor([[[ <span class="number">1.0886</span>,  <span class="number">0.0214</span>,  <span class="number">1.0690</span>],</span><br><span class="line">         [ <span class="number">2.0626</span>,  <span class="number">3.2655</span>, <span class="number">-0.1465</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">-6.9294</span>,  <span class="number">0.7499</span>,  <span class="number">1.2976</span>],</span><br><span class="line">         [ <span class="number">4.2226</span>, <span class="number">-4.5774</span>, <span class="number">-4.8947</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">-2.4289</span>, <span class="number">-0.7804</span>,  <span class="number">5.1385</span>],</span><br><span class="line">         [ <span class="number">0.8003</span>,  <span class="number">2.9425</span>,  <span class="number">1.7338</span>]]])</span><br></pre></td></tr></table></figure><h2 id="3-11-张量收缩"><a href="#3-11-张量收缩" class="headerlink" title="3.11 张量收缩"></a>3.11 张量收缩</h2><p>假设有两个张量 $\mathcal{A}\in \mathbb{R}^{I_1\times \dots\times I_n}$ 和 $\mathcal{B} \in \mathbb{R}^{J_1\times \dots \times J_m}$。比如 $n=4, m=5$，且 $I_2=J_3$ 和 $I_3=J_5$。我们可以计算两个张量的乘积，得到新的张量 $\mathcal{C}\in\mathbb{R}^{I_1\times I_4 \times J_1 \times J_2 \times J_4}$：</p><script type="math/tex; mode=display">C_{pstuv}=\sum_q\sum_r A_{pqrs}B_{tuqvr} = A_{pqrs}B_{tuqvr}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>)</span><br><span class="line">b = torch.randn(<span class="number">11</span>,<span class="number">13</span>,<span class="number">3</span>,<span class="number">17</span>,<span class="number">5</span>)</span><br><span class="line">torch.einsum(<span class="string">'pqrs,tuqvr-&gt;pstuv'</span>, [a, b]).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">13</span>, <span class="number">17</span>])</span><br></pre></td></tr></table></figure><h2 id="3-12-双线性变换"><a href="#3-12-双线性变换" class="headerlink" title="3.12 双线性变换"></a>3.12 双线性变换</h2><script type="math/tex; mode=display">D_{ij}=\sum_k\sum_lA_{ik}B_{jkl}C_{il} = A_{ik}B_{jkl}C_{il}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.randn(<span class="number">5</span>,<span class="number">3</span>,<span class="number">7</span>)</span><br><span class="line">c = torch.randn(<span class="number">2</span>,<span class="number">7</span>)</span><br><span class="line">torch.einsum(<span class="string">'ik,jkl,il-&gt;ij'</span>, [a, b, c])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">tensor([[ <span class="number">3.8471</span>,  <span class="number">4.7059</span>, <span class="number">-3.0674</span>, <span class="number">-3.2075</span>, <span class="number">-5.2435</span>],</span><br><span class="line">        [<span class="number">-3.5961</span>, <span class="number">-5.2622</span>, <span class="number">-4.1195</span>,  <span class="number">5.5899</span>,  <span class="number">0.4632</span>]])</span><br></pre></td></tr></table></figure><h1 id="4-einops"><a href="#4-einops" class="headerlink" title="4. einops"></a>4. einops</h1><p>尽管 <code>einops</code> 是一个通用的包，这里哦我们只介绍 <code>einops.rearrange</code> 。同 <code>einsum</code> 一样，<code>einops.rearrange</code> 也是操作矩阵的角标的，只不过函数的参数正好相反，如下图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210914003018.png" alt></p><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • NOTE            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            如果 <code>rearrange</code> 传入的参数是一个张量列表，那么后面字符串的第一维表示列表的长度。        </div>        </div>    </div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">qkv = torch.rand(<span class="number">2</span>,<span class="number">128</span>,<span class="number">3</span>*<span class="number">512</span>) <span class="comment"># dummy data for illustration only</span></span><br><span class="line"><span class="comment"># We need to decompose to n=3 tensors q, v, k</span></span><br><span class="line"><span class="comment"># rearrange tensor to [3, batch, tokens, dim] and cast to tuple</span></span><br><span class="line">q, k, v = tuple(rearrange( qkv , <span class="string">'b t (d n) -&gt; n b t d '</span>, n=<span class="number">3</span>))</span><br></pre></td></tr></table></figure><h1 id="5-Scale-dot-product-self-attention"><a href="#5-Scale-dot-product-self-attention" class="headerlink" title="5. Scale dot product self-attention"></a>5. Scale dot product self-attention</h1><ul><li><p><strong>第一步</strong>：创建一个线性投影。给定输入 $X\in \mathbb{R}^{b\times t\times d}$，其中 $b$ 表示 $\text{batch size}$，$t$ 表示 $\text{sentence length}$，$d$ 表示 $\text{word dimension}$。</p><script type="math/tex; mode=display">Q=XW_Q, \quad K=XW_K, \quad V=XW_V</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">to_qvk = nn.Linear(dim, dim * <span class="number">3</span>, bias=<span class="literal">False</span>) <span class="comment"># init only</span></span><br><span class="line"><span class="comment"># Step 1</span></span><br><span class="line">qkv = to_qvk(x)  <span class="comment"># [batch, tokens, dim*3 ]</span></span><br><span class="line"><span class="comment"># decomposition to q,v,k</span></span><br><span class="line">q, k, v = tuple(rearrange(qkv, <span class="string">'b t (d k) -&gt; k b t d '</span>, k=<span class="number">3</span>))</span><br></pre></td></tr></table></figure></li><li><p><strong>第二步</strong>：计算点积，mask，最后计算 softmax。</p><script type="math/tex; mode=display">\text{dot_score} = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}} \right)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Step 2</span></span><br><span class="line"><span class="comment"># Resulting shape: [batch, tokens, tokens]</span></span><br><span class="line">scaled_dot_prod = torch.einsum(<span class="string">'b i d , b j d -&gt; b i j'</span>, q, k) * self.scale_factor</span><br><span class="line"><span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">assert</span> mask.shape == scaled_dot_prod.shape[<span class="number">1</span>:]</span><br><span class="line">    scaled_dot_prod = scaled_dot_prod.masked_fill(mask, -np.inf)</span><br><span class="line">attention = torch.softmax(scaled_dot_prod, dim=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure></li><li><p><strong>第三步</strong>：计算注意力得分与 $V$ 的乘积。</p><script type="math/tex; mode=display">\text{Attention}(Q,K,V)=\text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}} \right)V</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.einsum(<span class="string">'b i j , b j d -&gt; b i d'</span>, attention, v)</span><br></pre></td></tr></table></figure></li></ul><p>将上面三步综合起来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SelfAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implementation of plain self attention mechanism with einsum operations</span></span><br><span class="line"><span class="string">    Paper: https://arxiv.org/abs/1706.03762</span></span><br><span class="line"><span class="string">    Blog: https://theaisummer.com/transformer/</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dim)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            dim: for NLP it is the dimension of the embedding vector</span></span><br><span class="line"><span class="string">            the last dimension size that will be provided in forward(x),</span></span><br><span class="line"><span class="string">            where x is a 3D tensor</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        <span class="comment"># for Step 1</span></span><br><span class="line">        self.to_qvk = nn.Linear(dim, dim * <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># for Step 2</span></span><br><span class="line">        self.scale_factor = dim ** <span class="number">-0.5</span>  <span class="comment"># 1/np.sqrt(dim)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask=None)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> x.dim() == <span class="number">3</span>, <span class="string">'3D tensor must be provided'</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1</span></span><br><span class="line">        qkv = self.to_qvk(x)  <span class="comment"># [batch, tokens, dim*3 ]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># decomposition to q,v,k</span></span><br><span class="line">        <span class="comment"># rearrange tensor to [3, batch, tokens, dim] and cast to tuple</span></span><br><span class="line">        q, k, v = tuple(rearrange(qkv, <span class="string">'b t (d k) -&gt; k b t d '</span>, k=<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2</span></span><br><span class="line">        <span class="comment"># Resulting shape: [batch, tokens, tokens]</span></span><br><span class="line">        scaled_dot_prod = torch.einsum(<span class="string">'b i d , b j d -&gt; b i j'</span>, q, k) * self.scale_factor</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">assert</span> mask.shape == scaled_dot_prod.shape[<span class="number">1</span>:]</span><br><span class="line">            scaled_dot_prod = scaled_dot_prod.masked_fill(mask, -np.inf)</span><br><span class="line"></span><br><span class="line">        attention = torch.softmax(scaled_dot_prod, dim=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3</span></span><br><span class="line">        <span class="keyword">return</span> torch.einsum(<span class="string">'b i j , b j d -&gt; b i d'</span>, attention, v)</span><br></pre></td></tr></table></figure><h1 id="6-Multi-Head-Self-Attention"><a href="#6-Multi-Head-Self-Attention" class="headerlink" title="6. Multi-Head Self-Attention"></a>6. Multi-Head Self-Attention</h1><ul><li><p><strong>第一步</strong>：为每一个头创建一个线性投影 $Q, K, V$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">to_qvk = nn.Linear(dim, dim_head * heads * <span class="number">3</span>, bias=<span class="literal">False</span>) <span class="comment"># init only</span></span><br><span class="line">qkv = self.to_qvk(x)</span><br></pre></td></tr></table></figure></li><li><p><strong>第二步</strong>：将 $Q, K, V$ 分解，并分配给每个头。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Step 2</span></span><br><span class="line"><span class="comment"># decomposition to q,v,k and cast to tuple</span></span><br><span class="line"><span class="comment"># [3, batch, heads, tokens, dim_head]</span></span><br><span class="line">q, k, v = tuple(rearrange(qkv, <span class="string">'b t (d k h) -&gt; k b h t d '</span>, k=<span class="number">3</span>, h=self.heads))</span><br></pre></td></tr></table></figure></li><li><p><strong>第三步</strong>：计算注意力得分</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Step 3</span></span><br><span class="line"><span class="comment"># resulted shape will be: [batch, heads, tokens, tokens]</span></span><br><span class="line">scaled_dot_prod = torch.einsum(<span class="string">'b h i d , b h j d -&gt; b h i j'</span>, q, k) * self.scale_factor</span><br><span class="line"><span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">assert</span> mask.shape == scaled_dot_prod.shape[<span class="number">2</span>:]</span><br><span class="line">    scaled_dot_prod = scaled_dot_prod.masked_fill(mask, -np.inf)</span><br><span class="line">attention = torch.softmax(scaled_dot_prod, dim=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure></li><li><p><strong>第四步</strong>：注意力得分与 $V$ 相乘</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Step 4. Calc result per batch and per head h</span></span><br><span class="line">out = torch.einsum(<span class="string">'b h i j , b h j d -&gt; b h i d'</span>, attention, v)</span><br></pre></td></tr></table></figure></li><li><p><strong>第五步</strong>：将所有的头合并</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out = rearrange(out, <span class="string">"b h t d -&gt; b t (h d)"</span>)</span><br></pre></td></tr></table></figure></li><li><p><strong>第六步</strong>：线性变换</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.W_0 = nn.Linear( _dim, dim, bias=<span class="literal">False</span>) <span class="comment"># init only</span></span><br><span class="line"><span class="comment"># Step 6. Apply final linear transformation layer</span></span><br><span class="line">self.W_0(out)</span><br></pre></td></tr></table></figure></li></ul><p>最终实现 MHSA：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> einops <span class="keyword">import</span> rearrange</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadSelfAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dim, heads=<span class="number">8</span>, dim_head=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Implementation of multi-head attention layer of the original transformer model.</span></span><br><span class="line"><span class="string">        einsum and einops.rearrange is used whenever possible</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            dim: token's dimension, i.e. word embedding vector size</span></span><br><span class="line"><span class="string">            heads: the number of distinct representations to learn</span></span><br><span class="line"><span class="string">            dim_head: the dim of the head. In general dim_head&lt;dim.</span></span><br><span class="line"><span class="string">            However, it may not necessary be (dim/heads)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.dim_head = (int(dim / heads)) <span class="keyword">if</span> dim_head <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> dim_head</span><br><span class="line">        _dim = self.dim_head * heads</span><br><span class="line">        self.heads = heads</span><br><span class="line">        self.to_qvk = nn.Linear(dim, _dim * <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.W_0 = nn.Linear( _dim, dim, bias=<span class="literal">False</span>)</span><br><span class="line">        self.scale_factor = self.dim_head ** <span class="number">-0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask=None)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> x.dim() == <span class="number">3</span></span><br><span class="line">        <span class="comment"># Step 1</span></span><br><span class="line">        qkv = self.to_qvk(x)  <span class="comment"># [batch, tokens, dim*3*heads ]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2</span></span><br><span class="line">        <span class="comment"># decomposition to q,v,k and cast to tuple</span></span><br><span class="line">        <span class="comment"># the resulted shape before casting to tuple will be:</span></span><br><span class="line">        <span class="comment"># [3, batch, heads, tokens, dim_head]</span></span><br><span class="line">        q, k, v = tuple(rearrange(qkv, <span class="string">'b t (d k h) -&gt; k b h t d '</span>, k=<span class="number">3</span>, h=self.heads))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3</span></span><br><span class="line">        <span class="comment"># resulted shape will be: [batch, heads, tokens, tokens]</span></span><br><span class="line">        scaled_dot_prod = torch.einsum(<span class="string">'b h i d , b h j d -&gt; b h i j'</span>, q, k) * self.scale_factor</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">assert</span> mask.shape == scaled_dot_prod.shape[<span class="number">2</span>:]</span><br><span class="line">            scaled_dot_prod = scaled_dot_prod.masked_fill(mask, -np.inf)</span><br><span class="line"></span><br><span class="line">        attention = torch.softmax(scaled_dot_prod, dim=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4. Calc result per batch and per head h</span></span><br><span class="line">        out = torch.einsum(<span class="string">'b h i j , b h j d -&gt; b h i d'</span>, attention, v)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 5. Re-compose: merge heads with dim_head d</span></span><br><span class="line">        out = rearrange(out, <span class="string">"b h t d -&gt; b t (h d)"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 6. Apply final linear transformation layer</span></span><br><span class="line">        <span class="keyword">return</span> self.W_0(out)</span><br></pre></td></tr></table></figure><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><p><a href="https://obilaniu6266h16.wordpress.com/2016/02/04/einstein-summation-in-numpy/" target="_blank" rel="noopener">Einstein Summation in Numpy</a>, <em>OLEXA BILANIUK</em></p></li><li><p><a href="https://ajcr.net/Basic-guide-to-einsum/" target="_blank" rel="noopener">A basic introduction to NumPy’s einsum</a>, <em>Alex Riley</em></p></li><li><a href="https://rockt.github.io/2018/04/30/einsum" target="_blank" rel="noopener">EINSUM IS ALL YOU NEED - EINSTEIN SUMMATION IN DEEP LEARNING</a>, <em>Tim Rocktäschel</em> </li><li><a href="https://theaisummer.com/einsum-attention/" target="_blank" rel="noopener">Understanding einsum for Deep learning: implement a transformer with multi-head self-attention from scratch</a>, <em>Nikolas Adaloglou</em></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/einsum-attention.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;Einsum 表示法是对张量的复杂操作的一种优雅方式，本质上是使用特定领域的语言。 一旦理解并掌握了 einsum，可以帮助我们更快地编写更简洁高效的代码。&lt;/p&gt;
    
    </summary>
    
      <category term="博客转载" scheme="https://rogerspy.gitee.io/categories/%E5%8D%9A%E5%AE%A2%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="einsum" scheme="https://rogerspy.gitee.io/tags/einsum/"/>
    
      <category term="MHSA" scheme="https://rogerspy.gitee.io/tags/mhsa/"/>
    
  </entry>
  
  <entry>
    <title>预训练语言模型：context2vec</title>
    <link href="https://rogerspy.gitee.io/2021/09/09/ptm-context2vec/"/>
    <id>https://rogerspy.gitee.io/2021/09/09/ptm-context2vec/</id>
    <published>2021-09-09T15:31:32.000Z</published>
    <updated>2021-09-15T15:36:17.312Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210909234144.png" alt></p><p>上下文的向量表示在许多 NLP 任务中都有至关重要的作用，比如词义消歧、命名实体识别、指代消解等等。以前的方法多是直接用离散上下文词向量组合，缺乏对上下文整体的优化表示方法。本文提出一种双向 LSTM 模型，有效学习句子上下文表征。</p><a id="more"></a><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>通常词向量能获得单个词的语义语法信息，在训练词向量的时候是通过优化与任务无关的目标函数。为了推理出一个具体的词，好的上下文向量表示也是必须的。比如：</p><blockquote><p>我找不到【星期五】了。</p></blockquote><p>其中【星期五】可能是个人，可能是一个宠物等等。我们必须借助“我找不到【】了”才能确定“星期五”并不是一个表示日期的词。</p><p>通常上下文的表示有两种方式：</p><ol><li>无监督。使用上下文的词向量组成一个序列输入到模型，或者直接使用上下文词向量相加求平均。这种方式缺乏对上下文整体表征的优化。</li><li>监督学习。通过标注数据根据具体的任务训练上下文表征。这种方式有两个缺点：① 依赖标注数据，通常标注数据是很难得的；② 训练出来的上下文表征依赖具体的任务，很可能并没有学习到目标词与上下文的依赖关系。</li></ol><p>context2vec 通过在大规模的无标注数据上训练神经网络模型，直接对整个上下文和目标词进行编码，能够获得他们的依赖关系。将训练好的模型应用于下游的任务也获得了很好的表现。</p><h1 id="2-Context2vec-模型"><a href="#2-Context2vec-模型" class="headerlink" title="2. Context2vec 模型"></a>2. Context2vec 模型</h1><table><tr>    <td><img width="600" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210910000919.png"></td>    <td><img width="600" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210910000943.png"></td></tr></table>            <p>Context2vec 的主要目标是学习一个通用的与任务无关嵌入模型，用来表示目标词上下文的变长序列向量表示。我们借鉴了 word2vec 的 CBOW 模型，利用上下文来预测目标词。与 CBOW 不同的是，我们将原来的上下文向量求平均操作替换成了双向 LSTM 模型，如上右图所示。</p><blockquote><p>John [submitted] a paper</p></blockquote><ol><li><p>用双向 LSTM 作为特征抽取器；</p></li><li><p>一个 LSTM 输入句子序列是从左向右；另一个 LSTM 输入序列是从右向左；</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210911121347.png" style="zoom:67%;"></p></li><li><p>将目标词左侧（“John”）的 left-to-right 特征与目标词右侧（“a paper”）的 right-to-left 特征拼接起来；</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210911122227.png" style="zoom:67%;"></p></li><li><p>将拼接后的特征输入到 MLP 中，我们的目标是让 MLP 的输出等于 [submitted] 的向量。</p></li><li><p>采用 Word2vec 中的负采样方法训练神经网络参数，这样就能学到上下文向量和目标词向量。</p></li></ol><h1 id="3-形式化分析"><a href="#3-形式化分析" class="headerlink" title="3. 形式化分析"></a>3. 形式化分析</h1><p>定义：lLS 表示 left-to-right LSTM，rLS 表示 right-to-left LSTM。给定句子 $w_{1:n}$ 和目标词 $w_i$，那么双向 LSTM 的输出为：</p><script type="math/tex; mode=display">biLS(w_{1:n}, i)=\text{lLS}(l_{1:i-1})\oplus\text{rLS}(r_{n:i+1})</script><p>其中 $l$ 和 $r$ 分别表示句子中从左到右和从右到左的词向量。注意在本模型中句子的第 $0$ 个位置和第 $n+1$ 个位置分别表示 $\text{BOS}$ 和 $\text{EOS}$。我们并没有将目标词传入到 LSTM 中去。接下来：</p><script type="math/tex; mode=display">\text{MLP}(x) = L_2(\text{ReLU}(L_1(x)))</script><p>其中 $\text{ReLU}$ 表示激活函数，$L<em>i$  表示线性变换。令 $c=(w_1, …, w</em>{i-1}, w_{i+1}, …, w_n)$ 表示句子的上下文词向量。</p><script type="math/tex; mode=display">\vec{c}=\text{MLP}(\text{biLS}(w_{1:n}, i))</script><p>令目标词 $w_i$ 的词向量为 $\vec{t}$：</p><script type="math/tex; mode=display">S=\sum_{t,c}\left( \log\sigma(\vec{t}\cdot \vec{c})+\sum_{i=1}^k\log\sigma(-\vec{t}\cdot\vec{c})\right)</script><p>其中 $\sum_{c,t}$ 表示对训练语料中的每个 $(t,c)$  对求和，$t_1, …, t_k$ 表示负采样的样本。负采样的概率分布为：</p><script type="math/tex; mode=display">p_\alpha(t) \propto (\#t)^\alpha</script><p>$0\le\alpha\le1$ 表示一个平滑系数，$\alpha$ 越大越容易采样到罕见词。$#$ 表示统计个数。</p><p><a href="https://proceedings.neurips.cc/paper/2014/file/feab05aa91085b7a8012516bc3533958-Paper.pdf" target="_blank" rel="noopener">Levy &amp; Goldberg (2014)</a> 证明了将上式用于单字上下文时是可以优化的，当</p><script type="math/tex; mode=display">\vec{t}\cdot\vec{c}=\text{PMI}_\alpha(t,c)-\log(k)</script><p>其中 $\text{PMI}(t,c)=\log\frac{p(t,c)}{p_\alpha(t)p(c)}$ 表示目标词 $t$ 与 上下文 $c$ 的点互信息。 Levy &amp; Goldberg (2014) 的分析适用于两个随机变量的共现矩阵。在我们这里，上下文不是单字而是一个目标词的完整句子表达。据此，我们可以将模型得到的上下文向量视作所有可能的目标词与可能句子上下文的 $\text{PMI}$ 的矩阵分解。</p><p>最终我们注意到 $\alpha$ 越大，则目标词越偏向罕见词。</p><h1 id="4-模型验证"><a href="#4-模型验证" class="headerlink" title="4. 模型验证"></a>4. 模型验证</h1><p>为了验证模型的质量，我们提出三种相似度矩阵：</p><ol><li>target-to-context</li><li>context-to-context</li><li>target-to-target</li></ol><p>所有的相似度都用 $\cos(\cdot)$ 计算。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210911134102.png" style="zoom:67%;"></p><h2 id="4-1-target-to-context"><a href="#4-1-target-to-context" class="headerlink" title="4.1 target-to-context"></a>4.1 target-to-context</h2><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210911134426.png" alt></p><p>当 $\alpha$ 取不同的值的时候，目标词的结果：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210911134541.png" alt></p><h2 id="4-2-context-to-context"><a href="#4-2-context-to-context" class="headerlink" title="4.2 context-to-context"></a>4.2 context-to-context</h2><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210911134650.png" alt></p><h2 id="4-3-target-to-target"><a href="#4-3-target-to-target" class="headerlink" title="4.3 target-to-target"></a>4.3 target-to-target</h2><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210911134743.png" alt></p><h1 id="5-与语言模型的关系"><a href="#5-与语言模型的关系" class="headerlink" title="5. 与语言模型的关系"></a>5. 与语言模型的关系</h1><p>从我们对模型的介绍，以及 target-to-context 实验结果的分析可以看出，我们的模型和基于 LSTM 的语言模型很像。主要的区别在于 LSTM 语言模型给定目标词，优化模型的联合概率。然而 context2vec 的目标是学习通用的向量表示。我们采用了 Word2vec 的学习框架，但是我们利用 $\vec{t}\cdot\vec{v}$ 近似点互信息，而不是 $\log p(t|c)$。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://aclanthology.org/K16-1006.pdf" target="_blank" rel="noopener">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>, <em>Oren Melamud, Jacob Goldberger, Ido Dagan. 2016</em></li><li><a href="https://proceedings.neurips.cc/paper/2014/file/feab05aa91085b7a8012516bc3533958-Paper.pdf" target="_blank" rel="noopener">Neural Word Embedding as Implicit Matrix Factorization</a>, <em>Omer Levy, Yoav Goldberg. 2014</em> </li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210909234144.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;上下文的向量表示在许多 NLP 任务中都有至关重要的作用，比如词义消歧、命名实体识别、指代消解等等。以前的方法多是直接用离散上下文词向量组合，缺乏对上下文整体的优化表示方法。本文提出一种双向 LSTM 模型，有效学习句子上下文表征。&lt;/p&gt;
    
    </summary>
    
      <category term="语言模型" scheme="https://rogerspy.gitee.io/categories/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="context2vec" scheme="https://rogerspy.gitee.io/tags/context2vec/"/>
    
  </entry>
  
  <entry>
    <title>预训练语言模型-Semi-supervised Sequence Learning</title>
    <link href="https://rogerspy.gitee.io/2021/09/07/ptm-semi-supervised-sequence-learning/"/>
    <id>https://rogerspy.gitee.io/2021/09/07/ptm-semi-supervised-sequence-learning/</id>
    <published>2021-09-07T15:01:19.000Z</published>
    <updated>2021-09-15T15:36:17.312Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210907233207.png" alt></p><p>之前我们介绍了 Word Embedding，将词转换成稠密向量。词向量中包含了大量的自然语言中的先验知识，word2vec 的成功证明了我们可以通过无监督学习获得这些先验知识。随后很多工作试图将句子、段落甚至文档也表示成稠密向量。其中比较有代表性的，比如：</p><a id="more"></a><ul><li>有监督学习<ol><li><a href="https://www.researchgate.net/publication/336156611_Convolutional_Recurrent_Neural_Networks_for_Text_Classification" target="_blank" rel="noopener">Recurrent Convolutional Neural Networks for Text Classification</a> </li><li><a href="https://arxiv.org/pdf/1408.5882.pdf" target="_blank" rel="noopener">Convolutional Neural Networks for Sentence Classification</a> </li></ol></li><li>无监督学习<ol><li><a href="https://arxiv.org/pdf/1405.4053.pdf" target="_blank" rel="noopener">Distributed Representations of Sentences and Documents</a></li><li><a href="https://www.researchgate.net/publication/279068396_Skip-Thought_Vectors" target="_blank" rel="noopener">Skip-Thought</a> 、<a href="https://arxiv.org/pdf/1803.02893.pdf" target="_blank" rel="noopener">Quick-thoughts</a>、<a href="https://rogerspy.github.io/2020/10/13/ptm-introduction/" target="_blank" rel="noopener">InferSent</a> </li></ol></li></ul><p>等等。纯粹的有监督学习是通过分类任务去学习网络参数，最终得到句子向量表示。纯粹的无监督学习是通过预测上下文，比如 skip-thought 利用了 word2vec  的思想，通过预测上下文句子来学习句子表示。</p><p>本文要介绍的这篇论文则是首先尝试使用大规模无标注数据进行预训练，然后将整个句子的向量序列作为有监督任务的初始化值的方法。该方法开创了后来的与训练语言模型+微调下游任务的 NLP 模型训练模式。</p><h1 id="1-Sequence-autoencoders"><a href="#1-Sequence-autoencoders" class="headerlink" title="1.  Sequence autoencoders"></a>1.  Sequence autoencoders</h1><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210907233207.png" alt></p><p>序列自编码器与机器翻译的 seq2seq 架构很相似，主要有两点不同：</p><ol><li>seq2seq 是有监督模型，序列自编码器是无监督模型</li><li>seq2seq 输出是目标语言序列，而序列自编码器输出是输入的句子本身，所以叫做自编码器。</li></ol><p>这个模型中，编码器（绿色部分）和解码器（红色部分）的权重是一样的。</p><p>序列自编码器的一个重要性质就是可以使用大量无标注的数据训练语言模型，这对有限标注数据任务非常有帮助。</p><h1 id="2-Recurrent-language-models"><a href="#2-Recurrent-language-models" class="headerlink" title="2. Recurrent language models"></a>2. Recurrent language models</h1><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210908002430.png" alt></p><p>将序列自编码器，去掉编码器我们就可以得到 LSTM。在我们的任务中，我们使用序列自编码器对 LSTM 的权重进行初始化，我们将使用语言模型初始化后的 LSTM 称之为 LM-LSTM。</p><p>我们再将 LM-LSTM 用于下游的分类任务。通常情况下，LSTM 使用最后一个隐层的输出来预测输入的标签。但是在我们的实验中也尝试了使用 LSTM 每一步输出线性递增组合的方式预测标签，这样我们可以将梯度传递到更靠前的位置上，减轻梯度消失带来的问题。</p><p>另外，我们还尝试了将序列自编码器和下游监督学习模型一起训练的方法，称之为“联合训练”。</p><h1 id="3-Experiments"><a href="#3-Experiments" class="headerlink" title="3. Experiments"></a>3. Experiments</h1><ul><li><p>IMDB 数据集实验结果</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210908005116.png" alt></p></li><li><p>Rotten Tomatoes 数据集实验结果</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210908004411.png" alt></p></li><li><p>20 newsgroups 数据集实验结果</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210908004438.png" alt></p></li><li><p>DBpedia character level classification</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210908004455.png" alt></p></li><li><p>CIFAR-10 object classification</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210908004510.png" alt></p></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://arxiv.org/pdf/1511.01432.pdf" target="_blank" rel="noopener">Semi-supervised Sequence Learning</a>, <em>Andrew M. Dai, Quoc V. Le, 2015, arxiv:1511.01432</em></li><li><a href="https://zhuanlan.zhihu.com/p/21313501" target="_blank" rel="noopener">Semi-supervised Sequence Learning</a>, <em>PaperWeekly, Zhihu</em> </li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210907233207.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;之前我们介绍了 Word Embedding，将词转换成稠密向量。词向量中包含了大量的自然语言中的先验知识，word2vec 的成功证明了我们可以通过无监督学习获得这些先验知识。随后很多工作试图将句子、段落甚至文档也表示成稠密向量。其中比较有代表性的，比如：&lt;/p&gt;
    
    </summary>
    
      <category term="语言模型" scheme="https://rogerspy.gitee.io/categories/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="半监督语言模型" scheme="https://rogerspy.gitee.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法：双端队列（deque）</title>
    <link href="https://rogerspy.gitee.io/2021/09/05/ds-deque/"/>
    <id>https://rogerspy.gitee.io/2021/09/05/ds-deque/</id>
    <published>2021-09-04T17:12:57.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png" alt></p><p>本文介绍双端队列，并用 Python 实现。</p><a id="more"></a><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>双端队列（deque），顾名思义指的是队列的前端和后端都可以进行插入和删除。因此，它不遵循 FIFO 原则。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905144730.png" alt></p><p>双端队列有两种：</p><ul><li>输入限制型双端队列：这种队列中输入被限制在一端，而删除则可以两端同时进行；</li><li>输出限制型双端队列：这种队列只能在一端进行删除，而插入元素则可以两端同时进行。</li></ul><h1 id="2-双端队列的基本操作"><a href="#2-双端队列的基本操作" class="headerlink" title="2. 双端队列的基本操作"></a>2. 双端队列的基本操作</h1><p>下面我们以循环队列实现的双端队列为例尽心介绍。在循环队列中，如果队列是满的，那么我们就从头开始。</p><p>但是，用线性队列实现的双端队列中，如果队列是满的，队列就不允许再往里插入元素了。</p><p>展示双端队列基本操作之前，我们有一些预备工作：</p><ol><li>设置队列的大小 <code>n</code>；</li><li>定义两个指针 <code>FRONT=-1</code> 和 <code>REAR=0</code>。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905150638.png" alt></p><h2 id="2-1-在头部插入元素"><a href="#2-1-在头部插入元素" class="headerlink" title="2.1 在头部插入元素"></a>2.1 在头部插入元素</h2><ol><li><p>检查前端位置</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905181644.png" alt></p></li><li><p>如果 <code>FRONT &lt; 1</code>，重置 <code>FRONT=n-1</code>（最后一个索引）</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905181844.png" alt></p></li></ol><ol><li><p>否则， <code>FRONT-1</code></p></li><li><p>在 <code>FRONT</code> 的位置添加新元素</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905193549.png" alt></p></li></ol><h2 id="2-2-在尾部添加元素"><a href="#2-2-在尾部添加元素" class="headerlink" title="2.2 在尾部添加元素"></a>2.2 在尾部添加元素</h2><ol><li><p>检查队列是否是满队列</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905193906.png" alt></p></li><li><p>如果队列是满的，重置 <code>REAR=0</code></p></li><li><p>否则，<code>REAR=REAR+1</code></p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905194245.png" alt></p></li><li><p>在 <code>REAR</code> 的位置添加新元素</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905194423.png" alt></p></li></ol><h2 id="2-3-从头部删除元素"><a href="#2-3-从头部删除元素" class="headerlink" title="2.3 从头部删除元素"></a>2.3 从头部删除元素</h2><ol><li><p>检查队列是否为空</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905194650.png" alt></p></li><li><p>如果队列是空（即 <code>FRONT=-1</code>），不能删除元素。</p></li><li><p>如果队列只有一个元素（即 <code>FRONT=REAR</code>），设置 <code>FRONT=-1</code> 以及 <code>REAR=-1</code>。</p></li><li><p>否则如果 <code>FORNT=n-1</code>，则令 <code>FRONT</code>去到首位，即令 <code>FRONT=0</code>。</p></li><li><p>否则 <code>FRONT=FORNT+1</code>。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905195221.png" alt></p></li></ol><h2 id="2-4-从尾部删除元素"><a href="#2-4-从尾部删除元素" class="headerlink" title="2.4 从尾部删除元素"></a>2.4 从尾部删除元素</h2><ol><li><p>检查队列是否为空。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905195459.png" alt></p></li><li><p>如果队列为空（<code>FRONT=-1</code>），不能删除元素。</p></li><li><p>如果队列只有一个元素（即 <code>FRONT=REAR</code>），设置 <code>FRONT=-1</code> 以及 <code>REAR=-1</code>。</p></li><li><p>如果 <code>REAR</code> 在前面（<code>REAR=0</code>），则令 <code>REAR=n-1</code>。</p></li><li><p>否则 <code>REAR=REAR-1</code>。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905195900.png" alt></p></li></ol><h2 id="2-5-检查队列是否为空"><a href="#2-5-检查队列是否为空" class="headerlink" title="2.5 检查队列是否为空"></a>2.5 检查队列是否为空</h2><p>检查 <code>FRONT=-1</code>，如果为真则队列为空。</p><h2 id="2-6-检查队列是否为满"><a href="#2-6-检查队列是否为满" class="headerlink" title="2.6 检查队列是否为满"></a>2.6 检查队列是否为满</h2><p>如果 <code>FRONT=0</code> 以及 <code>REAR=n-1</code> 或者 <code>FRONT=REAR+1</code> 则队列为满。</p><h1 id="3-Python-实现双端队列"><a href="#3-Python-实现双端队列" class="headerlink" title="3. Python 实现双端队列"></a>3. Python 实现双端队列</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Deque implementaion in python</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Deque</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.items = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isEmpty</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.items == []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addRear</span><span class="params">(self, item)</span>:</span></span><br><span class="line">        self.items.append(item)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addFront</span><span class="params">(self, item)</span>:</span></span><br><span class="line">        self.items.insert(<span class="number">0</span>, item)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeFront</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.items.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeRear</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.items.pop()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">size</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.items)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">d = Deque()</span><br><span class="line">print(d.isEmpty())</span><br><span class="line">d.addRear(<span class="number">8</span>)</span><br><span class="line">d.addRear(<span class="number">5</span>)</span><br><span class="line">d.addFront(<span class="number">7</span>)</span><br><span class="line">d.addFront(<span class="number">10</span>)</span><br><span class="line">print(d.size())</span><br><span class="line">print(d.isEmpty())</span><br><span class="line">d.addRear(<span class="number">11</span>)</span><br><span class="line">print(d.removeRear())</span><br><span class="line">print(d.removeFront())</span><br><span class="line">d.addFront(<span class="number">55</span>)</span><br><span class="line">d.addRear(<span class="number">45</span>)</span><br><span class="line">print(d.items)</span><br></pre></td></tr></table></figure><h1 id="4-时间复杂度"><a href="#4-时间复杂度" class="headerlink" title="4. 时间复杂度"></a>4. 时间复杂度</h1><p>上述操作的时间复杂度为 $O(1)$。</p><h1 id="5-双端队列的应用"><a href="#5-双端队列的应用" class="headerlink" title="5. 双端队列的应用"></a>5. 双端队列的应用</h1><ol><li>软件的撤销操作</li><li>浏览器存储浏览历史</li><li>用来实现队列和栈</li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.programiz.com/dsa/deque" target="_blank" rel="noopener">Deque Data Structure</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;本文介绍双端队列，并用 Python 实现。&lt;/p&gt;
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://rogerspy.gitee.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据结构" scheme="https://rogerspy.gitee.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="queue" scheme="https://rogerspy.gitee.io/tags/queue/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法：优先队列（priority queue）</title>
    <link href="https://rogerspy.gitee.io/2021/09/05/ds-priority-queue/"/>
    <id>https://rogerspy.gitee.io/2021/09/05/ds-priority-queue/</id>
    <published>2021-09-04T17:12:16.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png" alt></p><p>本文介绍优先队列，并用 Python 实现。</p><a id="more"></a><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>优先队列是一种特殊的队列类型，队列中每个元素都包含一个优先级值。每个元素根据优先级的大小进行处理，即优先级越高，对应的元素越早处理。</p><p>但是，如果两个元素的优先级一样的话，根据他们在队列中的先后进行处理。</p><h2 id="1-1-分配优先级"><a href="#1-1-分配优先级" class="headerlink" title="1.1 分配优先级"></a>1.1 分配优先级</h2><p>通常情况下，元素值本身就是优先级。比如，元素值越高则优先级越高，或者元素值越低优先级越高。当然，我们也可以根据具体需要来设置优先级。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905125711.png" alt></p><h2 id="1-2-优先队列与常规队列的区别"><a href="#1-2-优先队列与常规队列的区别" class="headerlink" title="1.2 优先队列与常规队列的区别"></a>1.2 优先队列与常规队列的区别</h2><p>在常规队列中，遵守先进先出规则；而在优先队列中，根据优先级删除值，首先删除优先级最高的元素。</p><h2 id="1-3-优先队列的实现方式"><a href="#1-3-优先队列的实现方式" class="headerlink" title="1.3 优先队列的实现方式"></a>1.3 优先队列的实现方式</h2><p>优先队列的实现有多种方式，比如数组、链表、堆以及二叉树等。其中堆更加高效，所以下面我们以堆实现的优先队列为例进行介绍。因此，在此之前需要先了解堆数据结构：<a href="https://www.programiz.com/dsa/heap-sort#heap" target="_blank" rel="noopener">max-heap and mean-heap</a>。</p><p>不同实现方式的复杂度对比：</p><div class="table-container"><table><thead><tr><th>Operations</th><th>peek</th><th>insert</th><th>delete</th></tr></thead><tbody><tr><td>Linked List</td><td><code>O(1)</code></td><td><code>O(n)</code></td><td><code>O(1)</code></td></tr><tr><td>Binary Heap</td><td><code>O(1)</code></td><td><code>O(log n)</code></td><td><code>O(log n)</code></td></tr><tr><td>Binary Search Tree</td><td><code>O(1)</code></td><td><code>O(log n)</code></td><td><code>O(log n)</code></td></tr></tbody></table></div><h1 id="2-优先队列的基本操作"><a href="#2-优先队列的基本操作" class="headerlink" title="2. 优先队列的基本操作"></a>2. 优先队列的基本操作</h1><p>优先队列的基本操作包括：插入、删除、查询。</p><h2 id="2-1-插入"><a href="#2-1-插入" class="headerlink" title="2.1 插入"></a>2.1 插入</h2><p>通过下面的步骤向优先队列中插入元素（max-heap）:</p><ul><li><p>在树的末尾插入元素</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905131519.png" alt></p></li><li><p>将树进行<a href="https://www.programiz.com/dsa/heap-data-structure#heapify" target="_blank" rel="noopener">堆化</a></p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905131744.png" alt></p><p>在优先队列中（max-heap）插入元素的算法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">If there is no node, </span><br><span class="line">  create a newNode.</span><br><span class="line">else (a node is already present)</span><br><span class="line">  insert the newNode at the end (last node from left to right.)</span><br><span class="line">  </span><br><span class="line">heapify the array</span><br></pre></td></tr></table></figure><p>对于 Min heap，上面的算法中 <code>parentNode</code> 永远小于 <code>newNode</code>。</p></li></ul><h2 id="2-2-删除"><a href="#2-2-删除" class="headerlink" title="2.2 删除"></a>2.2 删除</h2><p>通过下面的步骤从优先队列中删除元素（max heap）：</p><ul><li><p>选择要删除的元素</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905132805.png" alt></p></li><li><p>与最后一个元素位置进行交换</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905132935.png" alt></p></li><li><p>删除最后一个元素</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905133111.png" alt></p></li><li><p>将树进行堆化</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905133211.png" alt></p></li></ul><p>从优先队列中删除元素的算法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">If nodeToBeDeleted is the leafNode</span><br><span class="line">  remove the node</span><br><span class="line">Else swap nodeToBeDeleted with the lastLeafNode</span><br><span class="line">  remove noteToBeDeleted</span><br><span class="line">   </span><br><span class="line">heapify the array</span><br></pre></td></tr></table></figure><p>对于 Min Heap，上面算法中的 <code>childNodes</code> 一直 <code>currentNode</code>。</p><h2 id="2-3-查询"><a href="#2-3-查询" class="headerlink" title="2.3 查询"></a>2.3 查询</h2><p>对于 Max heap，返回最大元素；对于 Min heap，返回最小值。</p><p>对于 Max heap 和 Min heap 来说，都是返回根节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">return rootNode</span><br></pre></td></tr></table></figure><h2 id="2-4-选取最大值最小值"><a href="#2-4-选取最大值最小值" class="headerlink" title="2.4 选取最大值最小值"></a>2.4 选取最大值最小值</h2><p>抽取最大值返回从最大堆中删除后具有最大值的节点，而抽取最小值则返回从最小堆中删除后具有最小值的节点。</p><h1 id="3-Python-实现优先队列"><a href="#3-Python-实现优先队列" class="headerlink" title="3. Python 实现优先队列"></a>3. Python 实现优先队列</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"># Priority Queue implementation in Python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Function to heapify the tree</span><br><span class="line">def heapify(arr, n, i):</span><br><span class="line">    # Find the largest among root, left child and right child</span><br><span class="line">    largest = i</span><br><span class="line">    l = 2 * i + 1</span><br><span class="line">    r = 2 * i + 2</span><br><span class="line"></span><br><span class="line">    if l &lt; n and arr[i] &lt; arr[l]:</span><br><span class="line">        largest = l</span><br><span class="line"></span><br><span class="line">    if r &lt; n and arr[largest] &lt; arr[r]:</span><br><span class="line">        largest = r</span><br><span class="line"></span><br><span class="line">    # Swap and continue heapifying if root is not largest</span><br><span class="line">    if largest != i:</span><br><span class="line">        arr[i], arr[largest] = arr[largest], arr[i]</span><br><span class="line">        heapify(arr, n, largest)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Function to insert an element into the tree</span><br><span class="line">def insert(array, newNum):</span><br><span class="line">    size = len(array)</span><br><span class="line">    if size == 0:</span><br><span class="line">        array.append(newNum)</span><br><span class="line">    else:</span><br><span class="line">        array.append(newNum)</span><br><span class="line">        for i in range((size // 2) - 1, -1, -1):</span><br><span class="line">            heapify(array, size, i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Function to delete an element from the tree</span><br><span class="line">def deleteNode(array, num):</span><br><span class="line">    size = len(array)</span><br><span class="line">    i = 0</span><br><span class="line">    for i in range(0, size):</span><br><span class="line">        if num == array[i]:</span><br><span class="line">            break</span><br><span class="line"></span><br><span class="line">    array[i], array[size - 1] = array[size - 1], array[i]</span><br><span class="line"></span><br><span class="line">    array.remove(size - 1)</span><br><span class="line"></span><br><span class="line">    for i in range((len(array) // 2) - 1, -1, -1):</span><br><span class="line">        heapify(array, len(array), i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">arr = []</span><br><span class="line"></span><br><span class="line">insert(arr, 3)</span><br><span class="line">insert(arr, 4)</span><br><span class="line">insert(arr, 9)</span><br><span class="line">insert(arr, 5)</span><br><span class="line">insert(arr, 2)</span><br><span class="line"></span><br><span class="line">print (&quot;Max-Heap array: &quot; + str(arr))</span><br><span class="line"></span><br><span class="line">deleteNode(arr, 4)</span><br><span class="line">print(&quot;After deleting an element: &quot; + str(arr))</span><br></pre></td></tr></table></figure><h1 id="5-优先队列的应用"><a href="#5-优先队列的应用" class="headerlink" title="5. 优先队列的应用"></a>5. 优先队列的应用</h1><ul><li>Dijkstra 算法</li><li>实现栈结构</li><li>操作系统中的负载平衡和中断处理</li><li>Huffman 编码的数据压缩</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.programiz.com/dsa/priority-queue" target="_blank" rel="noopener">Priority Queue</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;本文介绍优先队列，并用 Python 实现。&lt;/p&gt;
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://rogerspy.gitee.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据结构" scheme="https://rogerspy.gitee.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="queue" scheme="https://rogerspy.gitee.io/tags/queue/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法：循环队列（circular-queue）</title>
    <link href="https://rogerspy.gitee.io/2021/09/05/ds-circular-queue/"/>
    <id>https://rogerspy.gitee.io/2021/09/05/ds-circular-queue/</id>
    <published>2021-09-04T16:00:33.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png" alt></p><p>本文介绍循环队列，并用 Python 实现循环队列。</p><a id="more"></a><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>循环队列是常规队列（简单队列）的变种，是将队列中最后一个元素与第一个元素相连。因此，循环队列看起来像下图的样子：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210905000636.png" alt></p><p>循环队列是为了解决简单队列的限制。在常规队列中，经过一系列的出队入队操作之后，会有一些空位置。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210904230231.png" alt></p><p>上图中 0 和 1 的位置会被空置，除非等到队列重置。</p><h1 id="2-循环队列的基本操作"><a href="#2-循环队列的基本操作" class="headerlink" title="2. 循环队列的基本操作"></a>2. 循环队列的基本操作</h1><p>循环队列通过循环递增的方式工作，即当我们递增指针并到达队列的末尾时，我们又从队列的开头开始。其中递增是通过模除队列的尺寸，即：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if REAR + 1 == 5 (overflow!), REAR = (REAR + 1)%5 = 0 (start of queue)</span><br></pre></td></tr></table></figure><p>具体过程如下：</p><ul><li>两个指针 <code>FRONT</code> 和 <code>REAR</code></li><li><code>FRONT</code> 追踪队列中第一个元素</li><li><code>REAR</code> 追踪队列中最后一个元素</li><li>初始化 <code>FRONT</code> 和 <code>REAR</code> 为 -1</li></ul><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/circular-queue-program.png" style="zoom:50%;"></p><h2 id="2-1-Enqueue"><a href="#2-1-Enqueue" class="headerlink" title="2.1 Enqueue"></a>2.1 Enqueue</h2><ul><li>检查队列是否是满队列</li><li>对于第一个元素，设置 <code>FRONT</code> 的值为 0</li><li>循环增加 <code>REAR</code> ，如果 <code>REAR</code> 到末尾，下一步就从头开始</li><li>在 <code>REAR</code> 指向的位置添加新元素</li></ul><h2 id="2-2-Dequeue"><a href="#2-2-Dequeue" class="headerlink" title="2.2 Dequeue"></a>2.2 Dequeue</h2><ul><li>检查队列是否为空</li><li>返回 <code>FRONT</code> 指向的值</li><li><code>FRONT</code> 循环加 1</li><li>对于最后一个元素，重置 <code>FRONT</code> 和 <code>REAR</code> 为 -1</li></ul><p>然而，检查满队列的时候，有一个新问题：</p><ul><li>第一种情况：<code>FRONT=0</code> &amp;&amp; <code>REAR=size-1</code></li><li>第二种情况：<code>FRONT=REAR+1</code></li></ul><p>第二种情况下，<code>REAR</code> 因为循环递增而从 0  开始，并且其值只比 <code>FRONT</code> 时，队列已满。</p><h1 id="3-Python实现循环队列"><a href="#3-Python实现循环队列" class="headerlink" title="3. Python实现循环队列"></a>3. Python实现循环队列</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Circular Queue implementation in Python</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCircularQueue</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k)</span>:</span></span><br><span class="line">        self.k = k</span><br><span class="line">        self.queue = [<span class="literal">None</span>] * k</span><br><span class="line">        self.head = self.tail = <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Insert an element into the circular queue</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">enqueue</span><span class="params">(self, data)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ((self.tail + <span class="number">1</span>) % self.k == self.head):</span><br><span class="line">            print(<span class="string">"The circular queue is full\n"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> (self.head == <span class="number">-1</span>):</span><br><span class="line">            self.head = <span class="number">0</span></span><br><span class="line">            self.tail = <span class="number">0</span></span><br><span class="line">            self.queue[self.tail] = data</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.tail = (self.tail + <span class="number">1</span>) % self.k</span><br><span class="line">            self.queue[self.tail] = data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Delete an element from the circular queue</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dequeue</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> (self.head == <span class="number">-1</span>):</span><br><span class="line">            print(<span class="string">"The circular queue is empty\n"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> (self.head == self.tail):</span><br><span class="line">            temp = self.queue[self.head]</span><br><span class="line">            self.head = <span class="number">-1</span></span><br><span class="line">            self.tail = <span class="number">-1</span></span><br><span class="line">            <span class="keyword">return</span> temp</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            temp = self.queue[self.head]</span><br><span class="line">            self.head = (self.head + <span class="number">1</span>) % self.k</span><br><span class="line">            <span class="keyword">return</span> temp</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">printCQueue</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span>(self.head == <span class="number">-1</span>):</span><br><span class="line">            print(<span class="string">"No element in the circular queue"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> (self.tail &gt;= self.head):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.head, self.tail + <span class="number">1</span>):</span><br><span class="line">                print(self.queue[i], end=<span class="string">" "</span>)</span><br><span class="line">            print()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.head, self.k):</span><br><span class="line">                print(self.queue[i], end=<span class="string">" "</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, self.tail + <span class="number">1</span>):</span><br><span class="line">                print(self.queue[i], end=<span class="string">" "</span>)</span><br><span class="line">            print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Your MyCircularQueue object will be instantiated and called as such:</span></span><br><span class="line">obj = MyCircularQueue(<span class="number">5</span>)</span><br><span class="line">obj.enqueue(<span class="number">1</span>)</span><br><span class="line">obj.enqueue(<span class="number">2</span>)</span><br><span class="line">obj.enqueue(<span class="number">3</span>)</span><br><span class="line">obj.enqueue(<span class="number">4</span>)</span><br><span class="line">obj.enqueue(<span class="number">5</span>)</span><br><span class="line">print(<span class="string">"Initial queue"</span>)</span><br><span class="line">obj.printCQueue()</span><br><span class="line"></span><br><span class="line">obj.dequeue()</span><br><span class="line">print(<span class="string">"After removing an element from the queue"</span>)</span><br><span class="line">obj.printCQueue()</span><br></pre></td></tr></table></figure><h1 id="4-循环队列时间复杂度"><a href="#4-循环队列时间复杂度" class="headerlink" title="4. 循环队列时间复杂度"></a>4. 循环队列时间复杂度</h1><p>基于数组实现的循环队列，其 enqueue 和 dequeue 时间复杂度都是 $O(1)$。</p><h1 id="5-循环队列的应用"><a href="#5-循环队列的应用" class="headerlink" title="5. 循环队列的应用"></a>5. 循环队列的应用</h1><ul><li>CPU 任务调度</li><li>内存管理</li><li>任务堵塞管理</li></ul><h1 id="Refernece"><a href="#Refernece" class="headerlink" title="Refernece"></a>Refernece</h1><p><a href="https://www.programiz.com/dsa/circular-queue" target="_blank" rel="noopener">Circular Queue Data Structure</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;本文介绍循环队列，并用 Python 实现循环队列。&lt;/p&gt;
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://rogerspy.gitee.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据结构" scheme="https://rogerspy.gitee.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="queue" scheme="https://rogerspy.gitee.io/tags/queue/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法：队列（queue）</title>
    <link href="https://rogerspy.gitee.io/2021/09/04/ds-queue/"/>
    <id>https://rogerspy.gitee.io/2021/09/04/ds-queue/</id>
    <published>2021-09-04T14:21:26.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png" alt></p><p>本文介绍队列数据结构，并用 Python 代码实现。</p><a id="more"></a><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>队列是一个非常有用的数据结构。它与电影院外排队买票是一样的，先排先买。队列也是如此，遵循先进先出（First In First Out，FIFO）原则。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210904222908.png" alt></p><p>如上图所示，1 排在 2 前面，也会在 2 之前被删除。</p><p>在编程的术语中，将元素添加进队列中的操作叫做 “<em>enqueue</em>”，从队列中删除的操作叫做 “<em>dequeue</em>”。</p><h1 id="2-队列的基本操作"><a href="#2-队列的基本操作" class="headerlink" title="2. 队列的基本操作"></a>2. 队列的基本操作</h1><ul><li><strong>Enqueue</strong>：向队列中添加元素</li><li><strong>Dequeue</strong>：从队列中删除元素</li><li><strong>IsEmpty</strong>：判断队列是否为空</li><li><strong>IsFull</strong>：判断队列是否为满队列</li><li><strong>Peek</strong>：获取队列最前面的元素而不删除该元素</li></ul><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/Queue-program-enqueue-dequeue.png" style="zoom: 50%;"></p><ol><li>定义两个指针 <code>FRONT</code> 和 <code>REAR</code></li><li><code>FRONT</code> 追踪队列中第一个元素</li><li><code>REAR</code> 追踪队列中最后一个元素 </li><li>初始化 <code>FRONT</code> 和 <code>REAR</code> 都为 -1</li></ol><h2 id="2-1-Enqueue-操作"><a href="#2-1-Enqueue-操作" class="headerlink" title="2.1 Enqueue 操作"></a>2.1 Enqueue 操作</h2><ul><li>检查队列是否为满序列</li><li>对于第一个元素，设置 <code>FRONT</code> 为 0</li><li><code>REAR</code> 索引加 1</li><li>在 <code>REAR</code> 指向的位置处添加新元素</li></ul><h2 id="2-2-Dequeue"><a href="#2-2-Dequeue" class="headerlink" title="2.2 Dequeue"></a>2.2 Dequeue</h2><ul><li>检查队列是否为空</li><li>返回 <code>FRONT</code> 指向的元素</li><li><code>FRONT</code> 的索引加 1</li><li>对于最后一个元素，重新设置 <code>FRONT</code> 和 <code>REAR</code> 为  -1</li></ul><h1 id="3-Python-实现队列"><a href="#3-Python-实现队列" class="headerlink" title="3. Python 实现队列"></a>3. Python 实现队列</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Queue implementation in Python</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Queue</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.queue = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add an element</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">enqueue</span><span class="params">(self, item)</span>:</span></span><br><span class="line">        self.queue.append(item)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove an element</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dequeue</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> len(self.queue) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> self.queue.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Display  the queue</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">display</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(self.queue)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">size</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.queue)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">q = Queue()</span><br><span class="line">q.enqueue(<span class="number">1</span>)</span><br><span class="line">q.enqueue(<span class="number">2</span>)</span><br><span class="line">q.enqueue(<span class="number">3</span>)</span><br><span class="line">q.enqueue(<span class="number">4</span>)</span><br><span class="line">q.enqueue(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">q.display()</span><br><span class="line"></span><br><span class="line">q.dequeue()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"After removing an element"</span>)</span><br><span class="line">q.display()</span><br></pre></td></tr></table></figure><h1 id="4-队列的限制"><a href="#4-队列的限制" class="headerlink" title="4. 队列的限制"></a>4. 队列的限制</h1><p>如下图所示，经过一系列的入队和出队，队列的尺寸减小了。但是我们只能在队列重置（所有的元素都出队）的时候设置 0 和 1 索引。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210904230231.png" alt></p><p>对于队列的一种变种——循环队列来说，由于入队时尾指针向前追赶头指针；出队时头指针向前追赶尾指针，造成队空和队满时头尾指针均相等。因此，无法通过条件front==rear来判别队列是”空”是”满”。</p><h1 id="5-队列的时间复杂度"><a href="#5-队列的时间复杂度" class="headerlink" title="5. 队列的时间复杂度"></a>5. 队列的时间复杂度</h1><p>Enqueue 和 dequeue 操作在使用数组实现的队列中复杂度都是 $O(1)$。如果你用python中的 <code>pop(n)</code> 方法，那时间复杂度可能是 $O(n)$，取决于你要删除的元素的位置。</p><h1 id="6-队列的应用"><a href="#6-队列的应用" class="headerlink" title="6. 队列的应用"></a>6. 队列的应用</h1><ul><li>CPU  调度，硬盘调度。</li><li>当两个进程之间异步传输数据时，队列用于消息同步。</li><li>处理实时系统的中断。</li><li>呼叫中心电话系统使用队列将呼叫他们的人按顺序排列。</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.programiz.com/dsa/queue" target="_blank" rel="noopener">Queue Data Structure</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;本文介绍队列数据结构，并用 Python 代码实现。&lt;/p&gt;
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://rogerspy.gitee.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据结构" scheme="https://rogerspy.gitee.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法：队列类型</title>
    <link href="https://rogerspy.gitee.io/2021/09/04/ds-types-queue/"/>
    <id>https://rogerspy.gitee.io/2021/09/04/ds-types-queue/</id>
    <published>2021-09-04T05:15:12.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png" alt></p><p>本文介绍不同类型的队列数据结构。</p><a id="more"></a><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>队列就像排队买票，先到先得。有四种不同的队列：</p><ul><li>简单队列（simple queue）</li><li>循环队列（circular queue）</li><li>优先队列（priority queue）</li><li>双端队列（double ended queue，deque）</li></ul><h1 id="2-简单队列"><a href="#2-简单队列" class="headerlink" title="2. 简单队列"></a>2. 简单队列</h1><p>在一个简单的队列中，插入发生在后面，移除发生在前面。 它严格遵循 FIFO（先进先出）规则。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210904233021.png" alt></p><p>更详细内容，查看 <a href="https://rogerspy.github.io//2021/09/05/ds-queue/" target="_blank" rel="noopener">数据结构与算法：队列（queue）</a>。</p><h1 id="3-循环队列"><a href="#3-循环队列" class="headerlink" title="3. 循环队列"></a>3. 循环队列</h1><p>循环队列是指，最后一个元素指向第一个元素，形成一个循环链。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210904233239.png" alt></p><p>与简单队列相比，循环队列的主要优点是更好的内存利用率。 如果最后一个位置已满而第一个位置为空，我们可以在第一个位置插入一个元素。 此操作在简单队列中是不可能的。</p><p>更详细的内容，查看 <a href="https://rogerspy.github.io/2021/09/05/ds-circular-queue/" target="_blank" rel="noopener">数据结构与算法：循环队列（circular-queue）</a>。</p><h1 id="4-优先队列"><a href="#4-优先队列" class="headerlink" title="4. 优先队列"></a>4. 优先队列</h1><p>优先级队列是一种特殊类型的队列，其中每个元素都与一个优先级相关联，并根据其优先级进行处理。 如果出现具有相同优先级的元素，则按照它们在队列中的顺序进行处理。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210904233542.png" alt></p><p>更详细的内容，查看 <a href="https://rogerspy.github.io/2021/09/05/ds-priority-deque/" target="_blank" rel="noopener">数据结构与算法：优先队列（priority queue）</a>。</p><h1 id="5-双端队列"><a href="#5-双端队列" class="headerlink" title="5. 双端队列"></a>5. 双端队列</h1><p>在双端队列中，可以从前面或后面执行元素的插入和删除。 因此，它不遵循 FIFO（先进先出）规则。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210904235805.png" alt></p><p>更详细的内容，查看 <a href="https://rogerspy.github.io/2021/09/05/ds-deque/" target="_blank" rel="noopener">数据结构与算法：双端队列（deque）</a>。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.programiz.com/dsa/types-of-queue" target="_blank" rel="noopener">Types of Queues</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;本文介绍不同类型的队列数据结构。&lt;/p&gt;
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://rogerspy.gitee.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据结构" scheme="https://rogerspy.gitee.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="queue" scheme="https://rogerspy.gitee.io/tags/queue/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法：栈（stack）</title>
    <link href="https://rogerspy.gitee.io/2021/09/04/ds-stack/"/>
    <id>https://rogerspy.gitee.io/2021/09/04/ds-stack/</id>
    <published>2021-09-04T04:16:52.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png" alt></p><p>本文介绍栈（stack）数据结构，并用 python 代码实现。</p><a id="more"></a><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>栈是一个线性数据结构，遵循后进先出（Last In First Out，LIFO）的原则。这就意味着最后插入的元素会先被删除。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210904122325.png" style="zoom:80%;"></p><p>就像叠盘子一样，</p><ul><li>你可以在最上面放一个新盘子</li><li>拿盘子的时候也是从最上面开始拿</li></ul><p>如果想要最下面的盘子，你就必须先把上面所有的盘子先拿走。这就是栈的基本工作方式。</p><h1 id="2-栈的-LIFO-原则"><a href="#2-栈的-LIFO-原则" class="headerlink" title="2. 栈的 LIFO 原则"></a>2. 栈的 LIFO 原则</h1><p>用编程的术语来说，在栈最上面放置一个元素称之为 “<em>push</em>”，删除元素叫做 “<em>pop</em>”。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210904122919.png" style="zoom: 80%;"></p><h1 id="3-栈的基本操作"><a href="#3-栈的基本操作" class="headerlink" title="3. 栈的基本操作"></a>3. 栈的基本操作</h1><ul><li><strong>push</strong>：在栈上面添加一个元素 </li><li><strong>pop</strong>：从栈中删除一个元素</li><li><strong>isEmpty</strong>：判断栈是否为空</li><li><strong>isFull</strong>：判断栈是否是一个满栈</li><li><strong>peek</strong>：获取栈最上层的元素而不删除它</li></ul><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210904124034.png" alt></p><ol><li>用 <code>TOP</code> 指针来追踪栈中最上层的元素</li><li>初始化栈的时候，我们设置设置指针为 -1，这样我们就可以通过判断 <code>TOP==-1</code> 来检查栈是否为空</li><li>当往栈里 push 数据的时候，我峨嵋你增加 <code>TOP</code> 的值，将新元素放置在 <code>TOP</code> 指定的位置</li><li>删除元素的时候，返回 <code>TOP</code> 指向的值，然后减小 <code>TOP</code> 值</li><li>向栈 push 数据的时候应该先检查栈是否已满</li><li>删除数据的时候，应该检查栈是否为空</li></ol><h1 id="4-用-Python-实现栈"><a href="#4-用-Python-实现栈" class="headerlink" title="4. 用 Python 实现栈"></a>4. 用 Python 实现栈</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Stack implementation in python</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Creating a stack</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_stack</span><span class="params">()</span>:</span></span><br><span class="line">    stack = []</span><br><span class="line">    <span class="keyword">return</span> stack</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Creating an empty stack</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_empty</span><span class="params">(stack)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> len(stack) == <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Adding items into the stack</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(stack, item)</span>:</span></span><br><span class="line">    stack.append(item)</span><br><span class="line">    print(<span class="string">"pushed item: "</span> + item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Removing an element from the stack</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(stack)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> (check_empty(stack)):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"stack is empty"</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> stack.pop()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">stack = create_stack()</span><br><span class="line">push(stack, str(<span class="number">1</span>))</span><br><span class="line">push(stack, str(<span class="number">2</span>))</span><br><span class="line">push(stack, str(<span class="number">3</span>))</span><br><span class="line">push(stack, str(<span class="number">4</span>))</span><br><span class="line">print(<span class="string">"popped item: "</span> + pop(stack))</span><br><span class="line">print(<span class="string">"stack after popping an element: "</span> + str(stack))</span><br></pre></td></tr></table></figure><h1 id="5-栈的时间复杂度"><a href="#5-栈的时间复杂度" class="headerlink" title="5. 栈的时间复杂度"></a>5. 栈的时间复杂度</h1><p>对于基于数组的栈实现，push 和 pop 操作都是常数时间，即 $O(1)$。</p><h1 id="6-栈的应用"><a href="#6-栈的应用" class="headerlink" title="6. 栈的应用"></a>6. 栈的应用</h1><p>尽管栈是非常简单的数据结构，但是它非常有用，最常见的应用如：</p><ul><li>词倒置。将词中的每个字符方法栈中，然后一个一个删除就可以了。因为栈是 LIFO 的，删除的时候就可以将词中的字符倒置过来。</li><li>编译器中，计算比如 <code>2+4/5*(7-9)</code> 的表达式的时候，用栈将表达式转化成前缀或者后缀的形式。</li><li>浏览器中，后退按钮用栈存储了所有你浏览过的网址（URL），每次你浏览一个新的网站的时候，它就会被加入到栈中，当你回退的时候，现在的网页就会被删除，然后回到倒数第二个页面。</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.programiz.com/dsa/stack" target="_blank" rel="noopener">Stack Data Structure</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;本文介绍栈（stack）数据结构，并用 python 代码实现。&lt;/p&gt;
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://rogerspy.gitee.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据结构" scheme="https://rogerspy.gitee.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="stack" scheme="https://rogerspy.gitee.io/tags/stack/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识建模（三）RDFS/OWL 词汇表</title>
    <link href="https://rogerspy.gitee.io/2021/08/26/kg-rdf-vocabulary/"/>
    <id>https://rogerspy.gitee.io/2021/08/26/kg-rdf-vocabulary/</id>
    <published>2021-08-26T14:11:35.000Z</published>
    <updated>2021-09-15T15:36:17.312Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/kgicon.png" alt></p><p>前面的文章介绍了知识建模，我们提到知识建模使用的是 RDF 知识表示法，而 RDFS 本质上是一个标准化语义词汇表。所以本文总结一些常用的 RDFS/OWL 的语义词汇。</p><a id="more"></a><h1 id="0-絮絮叨叨"><a href="#0-絮絮叨叨" class="headerlink" title="0. 絮絮叨叨"></a>0. 絮絮叨叨</h1><h2 id="0-1-RDF-XML"><a href="#0-1-RDF-XML" class="headerlink" title="0.1 RDF/XML"></a>0.1 RDF/XML</h2><p>在正式介绍 RDFS/OWL 词汇之前，相信很多小伙伴在看知识建模的时候就会有很多疑问。为什么一定要用 RDF？XML 好像也能胜任这份工作，RDF 和 XML 的区别是什么？RDF 标榜的让计算机理解语义体现在哪里？等等一系列的疑问。当然回答这些问题并不是本文的目的，本文只是总结 RDFS/OWL 的词汇。要想弄明白 RDF 到底是怎么一回事，这里推荐一些必读的书籍/文献，希望能帮助到有疑问的人。</p><ul><li><a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=08AF5BC897E861F62FE3800830B02E22?doi=10.1.1.91.8164&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener"> Where are the Semantics in the Semantic Web?</a>, <em>Michael Uschold</em></li><li><a href="https://www.w3.org/DesignIssues/RDF-XML.html" target="_blank" rel="noopener">Why RDF model is different from the XML model</a>, <em>Tim Berners-Lee</em></li><li><a href="https://www.researchgate.net/publication/279393307_A_Developer%27s_Guide_to_the_Semantic_Web" target="_blank" rel="noopener">A developer’s guide to semantic web</a>, <em>Liyang Yu</em></li><li><a href="http://www-900.ibm.com/developerWorks/cn/xml/x-xmlrdf/index.shtml#authorname" target="_blank" rel="noopener">XML+RDF——实现Web数据基于语义的描述</a>, <em>周竞涛、王明微</em></li></ul><h2 id="0-2-IRI-URI-URL-URN-的区别"><a href="#0-2-IRI-URI-URL-URN-的区别" class="headerlink" title="0.2 IRI, URI, URL, URN 的区别"></a>0.2 IRI, URI, URL, URN 的区别</h2><ul><li><p>URL</p><p><strong>Uniform Resource Locator</strong>，统一资源定位符。是用于在网络中传播和访问互联网资源的一个地址，只有通过特定的地址才能够访问的指定的资源或者网页，简而言之就是我们所说的网址，当然这样有些不太恰当，但是确实最容易被理解的，就如你必须通过 <code>https://www.baidu.com</code> 才能访问百度搜索页面，通过其他的链接都是不行的，这个地址就被称之为 URL。</p></li><li><p>URI</p><p><strong>Uniform Resource Identifier</strong>，统一资源标识符。也可以理解为标识、定位资源的字符串。字符集仅限于 US-ASCII 中（额外加一个百分号 %）， 不包括某些保留字符。URI 可用作定位器、名称或两者。 如果 URI 是定位器，则它描述了资源的主要访问机制。 如果一个 URI 是一个名称，它通过给它一个唯一的名称来标识一个资源。 许多人容易将 URL 和 URI 两者混淆，其实两者非常相似，但是也有所不同。URL 包含相对地址和绝对地址，URI 就属于绝对地址，所以 URL 包含 URI，简单的举例就是很多的网站可能都有 <code>/about</code> 这个路径，但是不同的域名或者 IP 访问到的就是不同的资源页面，所以这就只是一个标识，并不能标识其具体未知或者唯一性。</p></li><li><p>IRI</p><p><strong>Internationalized Resource Identifier</strong>，国际化资源标识符。和 URI 类似，区别在于 URI 使用的字符集有限制，所以没有办法兼容不同的文字语言，所以 IRI 就引入了 Unicode 字符来解决这个兼容问题，最后就有了国际化资源标识符（IRI）。</p></li><li><p>URN</p><p><strong>Uniform Resource Name</strong>，统一资源名称。旨在用作持久的，与位置无关的资源标识符。URN 可以提供一种机制，用于查找和检索定义特定命名空间的架构文件。尽管普通的 URL 可以提供类似的功能，但是在这方面，URN 更加强大并且更容易管理，因为 URN 可以引用多个 URL。子凡举个最简单的例子大家就明白了，那就是：磁力链接，它就是 URN 的一种实现，可以持久化的标识一个 BT 资源，资源分布式的存储在 P2P 网络中，无需中心服务器用户即可找到并下载它。</p></li></ul><p>总结一下：</p><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • SUMMARY            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            • IRI ⊃ URI <br>            • URI ⊃ URL <br>            • URI ⊃ URN <br>            • URL ∩ URN = ∅         </div>        </div>    </div><p>下面就进入今天的正题——RDFS/OWL 词汇表。本文摘自 <em>《语义网技术体系》 [瞿裕忠，胡伟，程龚 编著] 2015年版</em> 这本书。想查看完整版词汇表，可前往这两个网页：</p><ul><li><a href="https://www.w3.org/TR/rdf-schema/" target="_blank" rel="noopener">RDF Schema 1.1</a> </li><li><a href="https://www.w3.org/TR/2004/REC-owl-ref-20040210/" target="_blank" rel="noopener">OWL Web Ontology Language</a></li></ul><p>再啰嗦一句，除了以上两个 RDF 词汇表，还有一个 <a href="http://xmlns.com/foaf/spec/" target="_blank" rel="noopener">FOAF</a> 词汇表在对人物进行建模的时候通常会用到。但是这里就不再介绍，想了解更多可自行前往。</p><h1 id="1-序言"><a href="#1-序言" class="headerlink" title="1. 序言"></a>1. 序言</h1><p>RDF Schema（下文简称 RDFS） 是 RDF 词汇表的一个扩展版本（RDF 本身是一个知识表示模型，但同时也是一个词汇表）。RDFS 承认有许多技术可以用来描述类和属性的含义，例如 OWL。</p><p>本文中定义的语言由一组 RDF 资源组成，这些资源可用于在特定于应用程序的 RDF 词汇表中描述其他 RDF 资源。核心词汇 <code>rdfs</code> 非正式地称为命名空间中定义。该命名空间由 IRI 标识：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.w3.org/2000/01/rdf-schema#</span><br></pre></td></tr></table></figure><p>并且通常与前缀相关联 <code>rdfs:</code>。本规范还使用前缀 <code>rdf:</code>来指代 RDF 命名空间：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.w3.org/1999/02/22-rdf-syntax-ns#</span><br></pre></td></tr></table></figure><p>为了方便和可读性，本规范使用缩写形式来表示 IRI。形式 <code>prefix:suffix</code> 的名称应该被解释为一个 IRI，它由与后缀连接的前缀相关联的 IRI 组成。</p><h1 id="2-RDFS"><a href="#2-RDFS" class="headerlink" title="2. RDFS"></a>2. RDFS</h1><p>资源可以被分成不同的组，这些组称之为“类”（classes）。每个类别下包含的成员称之为“实例”。比如“人”是一个类，“张三”是一个“人”的实例。通常我们把 RDF 和 RDFS 合写成 RDF(S) 或 RDF/S。</p><p>下面分别介绍 RDF(S) 的核心词汇。</p><h2 id="2-1-Classes"><a href="#2-1-Classes" class="headerlink" title="2.1 Classes"></a>2.1 Classes</h2><p>资源可以分成不同的组，这些组就称之为“类”，组内的成员就称之为类的“实例”。我们用 IRI 来标识类，然后用 RDF 属性来描述类。两个不同的类可能有相同的实例，比如“张三”既可以是“导演”这个类，也可以是“演员”这个类。一个类也可能是他自己的实例。</p><blockquote><p>名词解释：“类的外延”</p><p>与一个类别相关的集合，我们称之为类的外延。类的外延集合中的每个成员都是类的实例。举个例子：</p><p>类：食物</p><p>类的外延：a = {鸡，鸭，鱼，肉}</p><p>类的实例：鸡，鸭，鱼，肉</p><p>例子中，“食物”作为一个类别，表示一个抽象概念。跟这个类别相关的一个集合 a 表示“食物”的外延，相对类来说类的外延是具体的概念。但是要注意 a 作为一个集合整体出现。而 a 中的每一个元素称之为实例。</p><p>当我们说“鸡肉是一种食物”的时候，实际上是表明“鸡肉”是“食物”这个概念的外延集合中的一员。</p><script type="math/tex; mode=display">\text{instance} \in a \rightarrow class</script></blockquote><h3 id="2-1-1-rdf-Resource"><a href="#2-1-1-rdf-Resource" class="headerlink" title="2.1.1 rdf:Resource"></a>2.1.1 rdf:Resource</h3><p>所有 RDF 描述的事物都是资源，即都是 <code>rdfs:Resource</code> 的实例。这是所有事物的类，其他所有类都是它的子类。<code>rdfs:Resource</code> 也是 <code>rdfs:Class</code> 的实例。</p><h3 id="2-1-2-rdf-Class"><a href="#2-1-2-rdf-Class" class="headerlink" title="2.1.2 rdf:Class"></a>2.1.2 rdf:Class</h3><p>对应“类”的概念，即资源的类。当定义一个新类的时候，表示该类的资源必须有一个 <code>rdf:type</code> 属性，属性值是 <code>rdfs:Class</code>。比如定义“导演”是一个新类，那么我们必须定义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">导演 rdf:type rdfs:Class</span><br></pre></td></tr></table></figure><p>注意，如上所述，一个实例可能属于多个类，所以类成员是不互斥的。<code>rdfs:Class</code> 是 <code>rdfs:Class</code> 是实例。</p><h3 id="2-1-3-rdf-Literal"><a href="#2-1-3-rdf-Literal" class="headerlink" title="2.1.3 rdf:Literal"></a>2.1.3 rdf:Literal</h3><p><code>rdf:Literal</code> 表示类或属性的字面量类型，比如数字、字符串等。<code>rdfs:Literal</code> 是 <code>rdfs:Class</code> 的实例，同时也是 <code>rdfs:Resource</code> 的子类。</p><h3 id="2-1-4-rdfs-Property"><a href="#2-1-4-rdfs-Property" class="headerlink" title="2.1.4 rdfs:Property"></a>2.1.4 rdfs:Property</h3><p><code>rdfs:Property</code> 是 RDF 属性类，同时也是 <code>rdfs:Class</code> 的实例。</p><h2 id="2-2-Properties"><a href="#2-2-Properties" class="headerlink" title="2.2.  Properties"></a>2.2.  Properties</h2><p>在 RDF 中，RDF 属性表示 subject 资源和 object 资源之间的关系。为了下文解释方便，我们这里写下三元组的一般形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">subject predicate object</span><br></pre></td></tr></table></figure><h2 id="2-2-1-rdfs-range"><a href="#2-2-1-rdfs-range" class="headerlink" title="2.2.1 rdfs:range"></a>2.2.1 rdfs:range</h2><p><code>rdfs:range</code> 是 <code>rdfs:Property</code> 的一个实例，用来指明一个属性的值域。例如三元组：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p rdfs:range c</span><br></pre></td></tr></table></figure><p>表示 p 是 <code>rdfs:range</code> 的一个实例， c 是 <code>rdfs:Class</code>  的一个实例。上面的三元组描述的是一个 predicate 是 p 的 object 是 c 的实例。</p><h3 id="2-2-2-rdfs-domain"><a href="#2-2-2-rdfs-domain" class="headerlink" title="2.2.2 rdfs:domain"></a>2.2.2 rdfs:domain</h3><p><code>rdfs:domain</code> 是 <code>rdfs:Property</code> 的一个实例，用来指明一个属性的定义域。例如三元组：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p rdfs:domain c</span><br></pre></td></tr></table></figure><p>表示 p 是 <code>rdfs:Property</code> 的一个实例，c 是 <code>rdfs:Class</code> 的实例。上面的三元组描述的是一个 predicate 是 p 的 subject 是 c 的实例。</p><p>其中，如果 p 有不止一个 <code>rdfs:domain</code> ，那么其对应的所有 subject 都是 c 的实例。</p><p>举个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">人 吃 食物  </span><br><span class="line"></span><br><span class="line">吃 rdf:type rdfs:Property</span><br><span class="line">吃 rdfs:domain 人</span><br><span class="line">吃 rdfs:range 食物</span><br></pre></td></tr></table></figure><p>翻译过来就是，“吃”表示一种属性（关系），它的主语是“人”，宾语是“食物”。</p><h3 id="2-2-3-rdf-type"><a href="#2-2-3-rdf-type" class="headerlink" title="2.2.3 rdf:type"></a>2.2.3 rdf:type</h3><p><code>rdf:type</code> 是 <code>rdf:Property</code> 的一个实例，用于描述一个资源是类的实例，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">R rdf:type C</span><br></pre></td></tr></table></figure><p>表示 C 是 <code>rdfs:Class</code> 的子类，并且 R 是 C 的实例。用一句通俗易懂的话就是，R 是一种 C，比如 <code>人 rdf:type 生物</code> 表示“人是一种动物”。实际上 <code>rdf:type</code> 表示 “is-a” 的关系，可以简写成 <code>a</code>。</p><h3 id="2-2-4-rdfs-subClassOf"><a href="#2-2-4-rdfs-subClassOf" class="headerlink" title="2.2.4 rdfs:subClassOf"></a>2.2.4 rdfs:subClassOf</h3><p><code>rdfs:subClassOf</code> 是 <code>rdfs:Property</code>  的一个实例，用来指明一个类的所有实例也是另一个类的实例，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C1 rdfs:subClassOf C2</span><br></pre></td></tr></table></figure><p>描述的是，C1 是 <code>rdfs:Class</code> 的一个实例，C2 是 <code>rdfs:Class</code> 的一个实例，并且 C1 是 C2 的一个子类。<code>rdfs:subClassOf</code> 是可传递的，即如果 a 是 b 的子类，b 是 c 的子类，那么 a 也是 c 的子类。</p><p><code>rdfs:subClassOf</code> 的 <code>rdfs:domain</code> 是 <code>rdfs:Class</code>。<code>rdfs:subClassOf</code> 的 <code>rdfs:range</code> 是 <code>rdfs:Class</code>。</p><h3 id="2-2-5-rdfs-subPropertyOf"><a href="#2-2-5-rdfs-subPropertyOf" class="headerlink" title="2.2.5 rdfs:subPropertyOf"></a>2.2.5 rdfs:subPropertyOf</h3><p><code>rdfs:subPropertyOf</code> 是 <code>rdfs:Property</code> 的一个实例，用来指明与一个资源相关的所有属性也与另一个资源相关，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">P1 rdfs:subPropertyOf P2</span><br></pre></td></tr></table></figure><p>描述了 P1 是 <code>rdfs:Property</code> 的一个实例，P2 也是 <code>rdfs:Property</code> 的一个实例，并且 P1 是 P2 的一个子属性。<code>rdfs:subPropertyOf</code> 是可传递性的。</p><p><code>rdfs:subPropertyOf</code> 的 <code>rdfs:domain</code> 是 <code>rdf:Property</code>。<code>rdfs:subPropertyOf</code> 的 <code>rdfs:range</code> 是 <code>rdf:Property</code>。</p><p>除了上面介绍的词之外， RD(S) 还有很多其他有用的词汇，这里不一一列举。下图展示了 RDF(S) 各个词汇之间的关系：</p><p> <img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210830172323.png" alt></p><h3 id="2-2-6-RDFS-词汇总结"><a href="#2-2-6-RDFS-词汇总结" class="headerlink" title="2.2.6 RDFS 词汇总结"></a>2.2.6 RDFS 词汇总结</h3><h4 id="2-2-6-1-Classes"><a href="#2-2-6-1-Classes" class="headerlink" title="2.2.6.1 Classes"></a>2.2.6.1 Classes</h4><div class="table-container"><table><thead><tr><th>Class name</th><th>comment</th></tr></thead><tbody><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_resource" target="_blank" rel="noopener">rdfs:Resource</a></td><td>The class resource, everything.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_literal" target="_blank" rel="noopener">rdfs:Literal</a></td><td>The class of literal values, e.g. textual strings and integers.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_langstring" target="_blank" rel="noopener">rdf:langString</a></td><td>The class of language-tagged string literal values.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_html" target="_blank" rel="noopener">rdf:HTML</a></td><td>The class of HTML literal values.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_xmlliteral" target="_blank" rel="noopener">rdf:XMLLiteral</a></td><td>The class of XML literal values.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_class" target="_blank" rel="noopener">rdfs:Class</a></td><td>The class of classes.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_property" target="_blank" rel="noopener">rdf:Property</a></td><td>The class of RDF properties.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_datatype" target="_blank" rel="noopener">rdfs:Datatype</a></td><td>The class of RDF datatypes.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_statement" target="_blank" rel="noopener">rdf:Statement</a></td><td>The class of RDF statements.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_bag" target="_blank" rel="noopener">rdf:Bag</a></td><td>The class of unordered containers.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_seq" target="_blank" rel="noopener">rdf:Seq</a></td><td>The class of ordered containers.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_alt" target="_blank" rel="noopener">rdf:Alt</a></td><td>The class of containers of alternatives.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_container" target="_blank" rel="noopener">rdfs:Container</a></td><td>The class of RDF containers.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_containermembershipproperty" target="_blank" rel="noopener">rdfs:ContainerMembershipProperty</a></td><td>The class of container membership properties, rdf:_1, rdf:_2, …, all of which are sub-properties of ‘member’.</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_list" target="_blank" rel="noopener">rdf:List</a></td><td>The class of RDF Lists.</td></tr></tbody></table></div><h4 id="2-2-6-2-Properties"><a href="#2-2-6-2-Properties" class="headerlink" title="2.2.6.2 Properties"></a>2.2.6.2 Properties</h4><div class="table-container"><table><thead><tr><th>Property name</th><th>comment</th><th>domain</th><th>range</th></tr></thead><tbody><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_type" target="_blank" rel="noopener">rdf:type</a></td><td>The subject is an instance of a class.</td><td>rdfs:Resource</td><td>rdfs:Class</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_subclassof" target="_blank" rel="noopener">rdfs:subClassOf</a></td><td>The subject is a subclass of a class.</td><td>rdfs:Class</td><td>rdfs:Class</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_subpropertyof" target="_blank" rel="noopener">rdfs:subPropertyOf</a></td><td>The subject is a subproperty of a property.</td><td>rdf:Property</td><td>rdf:Property</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_domain" target="_blank" rel="noopener">rdfs:domain</a></td><td>A domain of the subject property.</td><td>rdf:Property</td><td>rdfs:Class</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_range" target="_blank" rel="noopener">rdfs:range</a></td><td>A range of the subject property.</td><td>rdf:Property</td><td>rdfs:Class</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_label" target="_blank" rel="noopener">rdfs:label</a></td><td>A human-readable name for the subject.</td><td>rdfs:Resource</td><td>rdfs:Literal</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_comment" target="_blank" rel="noopener">rdfs:comment</a></td><td>A description of the subject resource.</td><td>rdfs:Resource</td><td>rdfs:Literal</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_member" target="_blank" rel="noopener">rdfs:member</a></td><td>A member of the subject resource.</td><td>rdfs:Resource</td><td>rdfs:Resource</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_first" target="_blank" rel="noopener">rdf:first</a></td><td>The first item in the subject RDF list.</td><td>rdf:List</td><td>rdfs:Resource</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_rest" target="_blank" rel="noopener">rdf:rest</a></td><td>The rest of the subject RDF list after the first item.</td><td>rdf:List</td><td>rdf:List</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_seealso" target="_blank" rel="noopener">rdfs:seeAlso</a></td><td>Further information about the subject resource.</td><td>rdfs:Resource</td><td>rdfs:Resource</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_isdefinedby" target="_blank" rel="noopener">rdfs:isDefinedBy</a></td><td>The definition of the subject resource.</td><td>rdfs:Resource</td><td>rdfs:Resource</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_value" target="_blank" rel="noopener">rdf:value</a></td><td>Idiomatic property used for structured values.</td><td>rdfs:Resource</td><td>rdfs:Resource</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_subject" target="_blank" rel="noopener">rdf:subject</a></td><td>The subject of the subject RDF statement.</td><td>rdf:Statement</td><td>rdfs:Resource</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_predicate" target="_blank" rel="noopener">rdf:predicate</a></td><td>The predicate of the subject RDF statement.</td><td>rdf:Statement</td><td>rdfs:Resource</td></tr><tr><td><a href="https://www.w3.org/TR/rdf-schema/#ch_object" target="_blank" rel="noopener">rdf:object</a></td><td>The object of the subject RDF statement.</td><td>rdf:Statement</td><td>rdfs:Resource</td></tr></tbody></table></div><h1 id="3-OWL"><a href="#3-OWL" class="headerlink" title="3. OWL"></a>3. OWL</h1><p>由于 RDFS 的表达能力较弱，W3C 2004 年又发布了 Web Ontology Language（OWL）进一步提供更加丰富的知识表示和推理能力。OWL 以描述逻辑为理论基础，可以将概念和属于用结构化的形式表示出来。通过 RDF 中的链接可以是本体分布在不同的系统中，充分体现了其标准化，开放性，扩展性以及适应性。现在 OWL 已经是 W3C 推荐的本体建模标准。OWL 的命名空间是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.w3.org/2002/07/owl#</span><br></pre></td></tr></table></figure><p>OWL 提供 3 中表达能力不同的子语言：OWL Full，OWL DL，OWL Lite。其中任意一个都可以映射成一个完整的 RDF 图。</p><ul><li>OWL Full。完全兼容 RDFS，但超出经典一阶逻辑的范畴。与 OWL Full 相关的推理工具现在还在探索中。</li><li>OWL DL。是 OWL Full 的一个子集，表达能力相对较强，可以有效的支持逻辑推理，但不是完全兼容 RDFS。</li><li>OWL Lite。在 OWL DL 的基础上对允许使用公理做了进一步的限制。</li></ul><p>到了 2012 年，W3C 对原先版本的 OWL 进行了修订，发布新的 OWL 版本——OWL 2。OWL 2 对 OWL 向后兼容，包含了 3 个指定的概图：</p><ul><li>OWL 2 EL。允许以高效的多项式时间算法对类型的可满足性检查、分类和实例检查并进行推理，特别适合使用含有大量属性或类本体的应用。</li><li>OWL 2 QL。允许使用传统的关系数据库实现查询问答，特别适合使用大量实例数据并且以查询问答作为主要推理任务的应用。</li><li>OWL 2 RL。允许以一种比较直接的方式，使用基于规则的推理引擎，在不牺牲太多的表达能力的情况下实现大规模推理。</li></ul><h2 id="3-1-OWL-Document"><a href="#3-1-OWL-Document" class="headerlink" title="3.1 OWL Document"></a>3.1 OWL Document</h2><p>一般情况下，描述本体的文档都包含本体本身的信息。一个本体是一个资源，可以采用 OWL 和其他命名空间属性进行描述。这些描述被称为本体头部，通常位于本体文档的开始部分。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;rdf:RDF xmlns=&quot;http://www.semanticweb.org/qiuji/ontologies/2017/9/untitled-ontology-2#&quot;</span><br><span class="line">     xml:base=&quot;http://www.semanticweb.org/qiuji/ontologies/2017/9/untitled-ontology-2&quot;</span><br><span class="line">     xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;</span><br><span class="line">     xmlns:owl=&quot;http://www.w3.org/2002/07/owl#&quot;</span><br><span class="line">     xmlns:xml=&quot;http://www.w3.org/XML/1998/namespace&quot;</span><br><span class="line">     xmlns:untitled-ontology-22=&quot;http://www.semanticweb.org/ontologies/2017/9/untitled-ontology-2#&quot;</span><br><span class="line">     xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema#&quot;</span><br><span class="line">     xmlns:untitled-ontology-2=&quot;http://www.semanticweb.org/qiuji/ontologies/2017/9/untitled-ontology-2#&quot;</span><br><span class="line">     xmlns:rdfs=&quot;http://www.w3.org/2000/01/rdf-schema#&quot;&gt;</span><br><span class="line">    &lt;owl:Ontology rdf:about=&quot;http://www.semanticweb.org/ontologies/2017/9/untitled-ontology-2&quot;/&gt;</span><br></pre></td></tr></table></figure><h3 id="3-1-1-owl-imports"><a href="#3-1-1-owl-imports" class="headerlink" title="3.1.1 owl:imports"></a>3.1.1 owl:imports</h3><p>允许引用另一个包含定义的 OWL 本体，并将其含义作为定义本体的一部分。每个引用都包含一个 URI，它指向被导入的本体。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@prefix : &lt;http://example.com/pwl/families/&gt; .</span><br><span class="line">@prefix otherOnt: &lt;http/example.org/otherOntologies/families/&gt; .</span><br><span class="line">@prefix owl: &lt;http://www.w3.org/2002/07/owl#&gt; .</span><br><span class="line">@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .</span><br><span class="line">@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;</span><br><span class="line"></span><br><span class="line">&lt;http://example.com/pwl/families/&gt;</span><br><span class="line">    rdf:type owlOntology ;</span><br><span class="line">    owl:imports &lt;http/example.org/otherOntologies/families.owl&gt; .</span><br></pre></td></tr></table></figure><p>另外，还可以在本体头部添加有关版本的一些信息。相关属性包括：<code>owl:versionInfo</code>，<code>owl:priorVersion</code>，<code>owl:backwardCompatibleWith</code>，<code>owl:incompatibleWith</code> 等等。</p><h2 id="3-2-OWL-Classes"><a href="#3-2-OWL-Classes" class="headerlink" title="3.2 OWL Classes"></a>3.2 OWL Classes</h2><p>与 RDFS 类似， OWL 也有“类”的概念，也是表示我们对资源的分组，也有“类的外延”等概念。需要注意的是，在OWL 中，类的外延中的元素称之为个体（individual），和在 Protege 建模工具菜单栏中的 individual 是同一概念，都表示实例。</p><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • NOTE            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            OWL DL 和 OWL DL 中的资源不能同时是个体（individual）和类（class），即 class 和 individual 是互斥的。            另外，rdfs:Class 和 rdfs:Property 是被禁止使用的。        </div>        </div>    </div><p>从上面的介绍来看，OWL 被设计出来主要是对 RDFS  的逻辑推理能力进行补强。要进行推理我们首先要有一些公理。在 OWL 中采用“类描述”对 OWL 类进行解释描述，然后将 OWL 组合成类公理。</p><h3 id="3-2-1-类描述（class-description）"><a href="#3-2-1-类描述（class-description）" class="headerlink" title="3.2.1 类描述（class description）"></a>3.2.1 类描述（class description）</h3><p>类描述通过类名或通过指定未命名匿名类的类外延来描述 OWL 类。OWL 中有 6 中不同的类描述：</p><ol><li>类标识符（URI）</li><li>穷举组成一个类的个体（enumeration）</li><li>属性限制（property restriction）</li><li>多个类描述的交集（intersection）</li><li>多个类描述的并集（union）</li><li>一个类描述的补集（complement）</li></ol><p>类标识符相当于通过类名（URI）来描述一个类；穷举表示一个类包含可穷举的个体；一个类中的所有个体都要满足特定的属性限制。对于 4、5、6 来说，可以认为是逻辑与（AND）或（OR）非（NOT）操作。</p><h4 id="3-2-1-1-owl-Class"><a href="#3-2-1-1-owl-Class" class="headerlink" title="3.2.1.1 owl:Class"></a>3.2.1.1 owl:Class</h4><p><code>owl:Class</code> 表示一个明明资源是一个类别，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ex：Human rdf:type owl:Class .</span><br></pre></td></tr></table></figure><p>其中 <code>ex</code> 表示本体的命名空间。下面的例子我们都用 RDF/XML 语法进行举例，所以上面的例子改写成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Class rdf:ID=&quot;Human&quot;/&gt;</span><br></pre></td></tr></table></figure><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • NOTE            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            OWL Lite 和 OWL DL 中 <code>owl:Class</code> 必须用在所有的类描述上。        </div>        </div>    </div><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • NOTE            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            在 OWL Lite 和 OWL DL 中<code>owl:Class</code> 是 <code>rdfs:Class</code> 的子类。这个关系说明            在 RDFS 中，并不是所有的类在 OWL DL(Lite) 都是合法的。但是在 OWL Full 中二者是等价的。        </div>        </div>    </div><p>OWL 类标识符是预先定义好的，即 <code>owl:Thing</code> / <code>owl:Nothing</code>。<code>owl:Thing</code> 是所有 OWL 类的父类，而 <code>owl:Nothing</code> 是所有类的子类（可以认为就是空集）。</p><h4 id="3-2-1-2-owl-oneOf"><a href="#3-2-1-2-owl-oneOf" class="headerlink" title="3.2.1.2 owl:oneOf"></a>3.2.1.2 owl:oneOf</h4><p><code>owl:oneOf</code> 用来表示类描述中的穷举，它的值必须是类的实例。为了方便，我们可以用 <code>rdfs:parseType=&quot;Collection&quot;</code> ，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Class&gt;</span><br><span class="line">  &lt;owl:oneOf rdf:parseType=&quot;Collection&quot;&gt;</span><br><span class="line">    &lt;owl:Thing rdf:about=&quot;#Eurasia&quot;/&gt;</span><br><span class="line">    &lt;owl:Thing rdf:about=&quot;#Africa&quot;/&gt;</span><br><span class="line">    &lt;owl:Thing rdf:about=&quot;#NorthAmerica&quot;/&gt;</span><br><span class="line">    &lt;owl:Thing rdf:about=&quot;#SouthAmerica&quot;/&gt;</span><br><span class="line">    &lt;owl:Thing rdf:about=&quot;#Australia&quot;/&gt;</span><br><span class="line">    &lt;owl:Thing rdf:about=&quot;#Antarctica&quot;/&gt;</span><br><span class="line">  &lt;/owl:oneOf&gt;</span><br><span class="line">&lt;/owl:Class&gt;</span><br></pre></td></tr></table></figure><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • NOTE            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            OWL Lite 没有穷举。        </div>        </div>    </div><h4 id="3-2-1-3-owl-Restriction"><a href="#3-2-1-3-owl-Restriction" class="headerlink" title="3.2.1.3 owl:Restriction"></a>3.2.1.3 owl:Restriction</h4><p>属性限制是一类特殊的类描述。它用来描述所有个体都满足一定限制条件的匿名类。OWL 有两种属性限制：值限制和基数限制。</p><ul><li>所谓值限制指的是，限制属性的值域。</li><li>所谓基数限制指的是，限制属性的个数。</li></ul><p>OWL 还提供了全局基数限制：<code>owl:FunctionalProperty</code> 和 <code>owl:InverseFunctionalProperty</code>。</p><p><code>owl:Restriction</code> 是 <code>owl:Class</code> 的子类。一个限制类应该有一个三元组用 <code>owl:onProperty</code> 来连接属性和限制。</p><ul><li><p><strong>值限制</strong></p><ol><li><p><code>owl:allValuesFrom</code>：用来限制一个类的所有个体是否在指定的值域内。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Restriction&gt;</span><br><span class="line">  &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt;</span><br><span class="line">  &lt;owl:allValuesFrom rdf:resource=&quot;#Human&quot;  /&gt;</span><br><span class="line">&lt;/owl:Restriction&gt;</span><br></pre></td></tr></table></figure></li><li><p><code>owl:someValuesFrom</code>：用来限制一个类的所有个体中，至少有一个个体来源于指定的值域。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Restriction&gt;</span><br><span class="line">  &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt;</span><br><span class="line">  &lt;owl:someValuesFrom rdf:resource=&quot;#Physician&quot; /&gt;</span><br><span class="line">&lt;/owl:Restriction&gt;</span><br></pre></td></tr></table></figure></li><li><p><code>owl:hasValue</code>：用来限制一个类的所有个体中，至少有一个（语义上）等于指定的值。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Restriction&gt;</span><br><span class="line">  &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt;</span><br><span class="line">  &lt;owl:hasValue rdf:resource=&quot;#Clinton&quot; /&gt;</span><br><span class="line">&lt;/owl:Restriction&gt;</span><br></pre></td></tr></table></figure><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • NOTE            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            “语义上等价于”的意思是，V 不一定是指定的值，但是 V 和指定的值 V1 之间有一个 <code>owl:sameAs</code>的关系。        </div>        </div>    </div></li></ol></li><li><p><strong>基数限制</strong></p><ol><li><p><code>owl:maxCardinality</code>：用来限制一个类包含了最多 N 个语义不同的个体，其中 N 就是基数限制的值。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Restriction&gt;</span><br><span class="line">  &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt;</span><br><span class="line">  &lt;owl:maxCardinality rdf:datatype=&quot;&amp;xsd;nonNegativeInteger&quot;&gt;2&lt;/owl:maxCardinality&gt;</span><br><span class="line">&lt;/owl:Restriction&gt;</span><br></pre></td></tr></table></figure></li><li><p><code>owl:minCardinality</code>：用来限制一个类至少包含 N 个语义不同的个体，其中 N 就是基数限制的值。</p><p>比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Restriction&gt;</span><br><span class="line">  &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt;</span><br><span class="line">  &lt;owl:minCardinality rdf:datatype=&quot;&amp;xsd;nonNegativeInteger&quot;&gt;2&lt;/owl:minCardinality&gt;</span><br><span class="line">&lt;/owl:Restriction&gt;</span><br></pre></td></tr></table></figure><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • NOTE            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            一个类中的所有实例都要有 N 个属性。        </div>        </div>    </div></li><li><p><code>owl:cardinality</code>：用来限制一个类必须要有 N 个语义不同的个体，不能多也不能少。其中 N 就是基数限制的值。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Restriction&gt;</span><br><span class="line">  &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt;</span><br><span class="line">  &lt;owl:cardinality rdf:datatype=&quot;&amp;xsd;nonNegativeInteger&quot;&gt;2&lt;/owl:cardinality&gt;</span><br><span class="line">&lt;/owl:Restriction&gt;</span><br></pre></td></tr></table></figure></li></ol></li></ul><h4 id="3-2-1-4-Intersection-union-and-complement"><a href="#3-2-1-4-Intersection-union-and-complement" class="headerlink" title="3.2.1.4 Intersection, union and complement"></a>3.2.1.4 Intersection, union and complement</h4><ul><li><p><code>owl:intersectionOf</code>：连接一个类和一个类描述的列表，表示这个类的外延中的个体同时也是列表中所有类描述的外延成员。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Class&gt;</span><br><span class="line">  &lt;owl:intersectionOf rdf:parseType=&quot;Collection&quot;&gt;</span><br><span class="line">    &lt;owl:Class&gt;</span><br><span class="line">      &lt;owl:oneOf rdf:parseType=&quot;Collection&quot;&gt;</span><br><span class="line">        &lt;owl:Thing rdf:about=&quot;#Tosca&quot; /&gt;</span><br><span class="line">        &lt;owl:Thing rdf:about=&quot;#Salome&quot; /&gt;</span><br><span class="line">      &lt;/owl:oneOf&gt;</span><br><span class="line">    &lt;/owl:Class&gt;</span><br><span class="line">    &lt;owl:Class&gt;</span><br><span class="line">      &lt;owl:oneOf rdf:parseType=&quot;Collection&quot;&gt;</span><br><span class="line">        &lt;owl:Thing rdf:about=&quot;#Turandot&quot; /&gt;</span><br><span class="line">        &lt;owl:Thing rdf:about=&quot;#Tosca&quot; /&gt;</span><br><span class="line">      &lt;/owl:oneOf&gt;</span><br><span class="line">    &lt;/owl:Class&gt;</span><br><span class="line">  &lt;/owl:intersectionOf&gt;</span><br><span class="line">&lt;/owl:Class&gt;</span><br></pre></td></tr></table></figure><p><code>owl:intersectionOf</code> 可以看成逻辑连词。</p></li><li><p><code>owl:unionOf</code>：表示一个个体至少会出现在列表中的一个类中。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Class&gt;</span><br><span class="line">  &lt;owl:unionOf rdf:parseType=&quot;Collection&quot;&gt;</span><br><span class="line">    &lt;owl:Class&gt;</span><br><span class="line">      &lt;owl:oneOf rdf:parseType=&quot;Collection&quot;&gt;</span><br><span class="line">        &lt;owl:Thing rdf:about=&quot;#Tosca&quot; /&gt;</span><br><span class="line">        &lt;owl:Thing rdf:about=&quot;#Salome&quot; /&gt;</span><br><span class="line">      &lt;/owl:oneOf&gt;</span><br><span class="line">    &lt;/owl:Class&gt;</span><br><span class="line">    &lt;owl:Class&gt;</span><br><span class="line">      &lt;owl:oneOf rdf:parseType=&quot;Collection&quot;&gt;</span><br><span class="line">        &lt;owl:Thing rdf:about=&quot;#Turandot&quot; /&gt;</span><br><span class="line">        &lt;owl:Thing rdf:about=&quot;#Tosca&quot; /&gt;</span><br><span class="line">      &lt;/owl:oneOf&gt;</span><br><span class="line">    &lt;/owl:Class&gt;</span><br><span class="line">  &lt;/owl:unionOf&gt;</span><br><span class="line">&lt;/owl:Class&gt;</span><br></pre></td></tr></table></figure></li><li><p><code>owl:complementOf</code>：连接一个类和一个类描述，表示类外延中的个体不属于类描述的外延。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Class&gt;</span><br><span class="line">  &lt;owl:complementOf&gt;</span><br><span class="line">    &lt;owl:Class rdf:about=&quot;#Meat&quot;/&gt;</span><br><span class="line">  &lt;/owl:complementOf&gt;</span><br><span class="line">&lt;/owl:Class&gt;</span><br></pre></td></tr></table></figure></li></ul><h3 id="3-2-2-类公理"><a href="#3-2-2-类公理" class="headerlink" title="3.2.2 类公理"></a>3.2.2 类公理</h3><p>类描述通过类公理组合在一起用来定义一个类。这句话说起来很拗口，其实描述的道理很简单。就相当于我们要炒一盘菜，需要一些原材料（类描述），然后通过一些原则（类公理）将这些原料组合在一起形成一盘菜（类）。</p><p>OWL 提供了 3 个词汇，将类描述组合起来：</p><ul><li><code>rdfs:subClassOf</code></li><li><code>owl:equivalentClass</code></li><li><code>owl:disjointWith</code></li></ul><h4 id="3-2-2-1-rdfs-subClassOf"><a href="#3-2-2-1-rdfs-subClassOf" class="headerlink" title="3.2.2.1 rdfs:subClassOf"></a>3.2.2.1 rdfs:subClassOf</h4><script type="math/tex; mode=display">class\ description \quad \text{rdfs:subClassOf} \quad class\ description</script><p>这里的 <code>rdfs:subClassOf</code> 和 RDFS 中的一样。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Class rdf:ID=&quot;Opera&quot;&gt;</span><br><span class="line">  &lt;rdfs:subClassOf rdf:resource=&quot;#MusicalWork&quot; /&gt;</span><br><span class="line">&lt;/owl:Class&gt;</span><br></pre></td></tr></table></figure><h4 id="3-2-2-2-owl-equivalentClass"><a href="#3-2-2-2-owl-equivalentClass" class="headerlink" title="3.2.2.2 owl:equivalentClass"></a>3.2.2.2 owl:equivalentClass</h4><script type="math/tex; mode=display">class\ description\quad \text{owl:equivalentClass}\quad class\ description</script><p><code>owl:equivalentClass</code> 表示两个类描述有相同的类外延。最简单的形式是，两个命名类别是等价的。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Class rdf:about=&quot;#US_President&quot;&gt;</span><br><span class="line">  &lt;equivalentClass rdf:resource=&quot;#PrincipalResidentOfWhiteHouse&quot;/&gt;</span><br><span class="line">&lt;/owl:Class&gt;</span><br></pre></td></tr></table></figure><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • NOTE            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            <code>owl:equivalentClass</code> 的两个类并不表示两个类是等价的。        </div>        </div>    </div><p>比如上例中，“美国总统” 这个概念和“白宫的主要居民”这个概念并不一样。真正的语义等价应该用 <code>owl:sameAs</code>。</p><h4 id="3-2-2-3-owl-disjointWith"><a href="#3-2-2-3-owl-disjointWith" class="headerlink" title="3.2.2.3 owl:disjointWith"></a>3.2.2.3 owl:disjointWith</h4><script type="math/tex; mode=display">class\ description\quad \text{owl:disjointWith}\quad class\ description</script><p><code>owl:disjointWith</code> 表示两个类描述没有公共的个体，或者说两个类描述是互斥的。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:Class rdf:about=&quot;#Man&quot;&gt;</span><br><span class="line">  &lt;owl:disjointWith rdf:resource=&quot;#Woman&quot;/&gt;</span><br><span class="line">&lt;/owl:Class&gt;</span><br></pre></td></tr></table></figure><h2 id="3-3-Properties"><a href="#3-3-Properties" class="headerlink" title="3.3 Properties"></a>3.3 Properties</h2><p> OWL 有两种属性：对象属性（object property）和数据类型属性（datatype property）。对象属性用来连接两个实例，而数据类型属性连接一个实例和寿哥数据类型的字面量。换成比较容易理解的话就是，对象属性表示两个实体之间的关系，数据类型属性就是实体和属性之间的关系。比如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">小明 父亲 大明</span><br><span class="line">小明 生日 1990/1/1</span><br></pre></td></tr></table></figure><p>其中“父亲”就是对象属性，“生日”就是数据类型属性。</p><p>OWL 中支持的属性机构包括：</p><ul><li>RDFS ：<code>rdfs:subPropertyOf</code>, <code>rdfs:domain</code> 和 <code>rdfs:range</code></li><li>与其他属性相关的： <code>owl:equivalentProperty</code> 和 <code>owl:inverseOf</code></li><li>全局基数限制：<code>owl:FunctionalProperty</code> 和 <code>owl:InverseFunctionalProperty</code></li><li>逻辑属性： <code>owl:SymmetricProperty</code> 和 <code>owl:TransitiveProperty</code></li></ul><h3 id="3-3-1-owl-equivalentProperty"><a href="#3-3-1-owl-equivalentProperty" class="headerlink" title="3.3.1 owl:equivalentProperty"></a>3.3.1 owl:equivalentProperty</h3><p><code>owl:equivalentProperty</code> 表示两个属性有相同的属性外延。类似 <code>owl:equivalentClass</code>。</p><h3 id="3-3-2-owl-inverseOf"><a href="#3-3-2-owl-inverseOf" class="headerlink" title="3.3.2 owl:inverseOf"></a>3.3.2 owl:inverseOf</h3><p>属性是有方向的，从定义域指向值域。<code>owl:inverseOf</code> 表示反向属性，即原属性的定义域和值域互换。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:ObjectProperty rdf:ID=&quot;hasChild&quot;&gt;</span><br><span class="line">  &lt;owl:inverseOf rdf:resource=&quot;#hasParent&quot;/&gt;</span><br><span class="line">&lt;/owl:ObjectProperty&gt;</span><br></pre></td></tr></table></figure><h3 id="3-3-3-owl-FunctionalProperty"><a href="#3-3-3-owl-FunctionalProperty" class="headerlink" title="3.3.3 owl:FunctionalProperty"></a>3.3.3 owl:FunctionalProperty</h3><p><code>owl:FunctionalProperty</code> 表示对于实例 $x$ 来说，只有唯一的 $y$ 值。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:ObjectProperty rdf:ID=&quot;husband&quot;&gt;</span><br><span class="line">  &lt;rdfs:domain rdf:resource=&quot;#Woman&quot; /&gt;</span><br><span class="line">  &lt;rdfs:range  rdf:resource=&quot;#Man&quot; /&gt;</span><br><span class="line">&lt;/owl:ObjectProperty&gt;</span><br><span class="line"></span><br><span class="line">&lt;owl:FunctionalProperty rdf:about=&quot;#husband&quot; /&gt;</span><br></pre></td></tr></table></figure><h3 id="3-3-4-owl-InverseFunctionalProperty"><a href="#3-3-4-owl-InverseFunctionalProperty" class="headerlink" title="3.3.4 owl:InverseFunctionalProperty"></a>3.3.4 owl:InverseFunctionalProperty</h3><p><code>owl:InverseFunctionalProperty</code> 表示与 <code>owl:FunctionalProperty</code> 相反的意思，即对于值 $y$ 只能有一个 实例 $x$ 与之对应。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:InverseFunctionalProperty rdf:ID=&quot;biologicalMotherOf&quot;&gt;</span><br><span class="line">  &lt;rdfs:domain rdf:resource=&quot;#Woman&quot;/&gt;</span><br><span class="line">  &lt;rdfs:range rdf:resource=&quot;#Human&quot;/&gt;</span><br><span class="line">&lt;/owl:InverseFunctionalProperty&gt;</span><br></pre></td></tr></table></figure><h3 id="3-3-5-owl-TransitiveProperty"><a href="#3-3-5-owl-TransitiveProperty" class="headerlink" title="3.3.5 owl:TransitiveProperty"></a>3.3.5 owl:TransitiveProperty</h3><p><code>owl:TransitiveProperty</code> 表示属性的可传递性。如果 $(x,y)$ 是 P 的实例，$(y,z)$ 也是 P 的实例，那么 $(x,z)$ 也是 P 的实例。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:TransitiveProperty rdf:ID=&quot;subRegionOf&quot;&gt;</span><br><span class="line">  &lt;rdfs:domain rdf:resource=&quot;#Region&quot;/&gt;</span><br><span class="line">  &lt;rdfs:range  rdf:resource=&quot;#Region&quot;/&gt;</span><br><span class="line">&lt;/owl:TransitiveProperty&gt;</span><br></pre></td></tr></table></figure><h3 id="3-3-6-owl-SymmetricProperty"><a href="#3-3-6-owl-SymmetricProperty" class="headerlink" title="3.3.6 owl:SymmetricProperty"></a>3.3.6 owl:SymmetricProperty</h3><p><code>owl:SymmetricProperty</code> 表示如果 $(x,y)$ 是 P 的实例，那么 $(y,x)$ 也是 P 的实例。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:SymmetricProperty rdf:ID=&quot;friendOf&quot;&gt;</span><br><span class="line">  &lt;rdfs:domain rdf:resource=&quot;#Human&quot;/&gt;</span><br><span class="line">  &lt;rdfs:range  rdf:resource=&quot;#Human&quot;/&gt;</span><br><span class="line">&lt;/owl:SymmetricProperty&gt;</span><br></pre></td></tr></table></figure><h2 id="3-4-Individuals"><a href="#3-4-Individuals" class="headerlink" title="3.4 Individuals"></a>3.4 Individuals</h2><p>个体分为两种：</p><ol><li>类的成员和个体的属性值</li><li>个体身份</li></ol><h3 id="3-4-1-类的成员和个体属性值"><a href="#3-4-1-类的成员和个体属性值" class="headerlink" title="3.4.1 类的成员和个体属性值"></a>3.4.1 类的成员和个体属性值</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;Opera rdf:ID=&quot;Tosca&quot;&gt;</span><br><span class="line">  &lt;hasComposer rdf:resource=&quot;#Giacomo_Puccini&quot;/&gt;</span><br><span class="line">  &lt;hasLibrettist rdf:resource=&quot;#Victorien_Sardou&quot;/&gt;</span><br><span class="line">  &lt;hasLibrettist rdf:resource=&quot;#Giuseppe_Giacosa&quot;/&gt;</span><br><span class="line">  &lt;hasLibrettist rdf:resource=&quot;#Luigi_Illica&quot;/&gt;</span><br><span class="line">  &lt;premiereDate rdf:datatype=&quot;&amp;xsd;date&quot;&gt;1900-01-14&lt;/premiereDate&gt;</span><br><span class="line">  &lt;premierePlace rdf:resource=&quot;#Roma&quot;/&gt;</span><br><span class="line">  &lt;numberOfActs rdf:datatype=&quot;&amp;xsd;positiveInteger&quot;&gt;3&lt;/numberOfActs&gt; </span><br><span class="line">&lt;/Opera&gt;</span><br></pre></td></tr></table></figure><h3 id="3-4-2-个体身份"><a href="#3-4-2-个体身份" class="headerlink" title="3.4.2 个体身份"></a>3.4.2 个体身份</h3><p>通常我们会给不同的事物取不同的名字，但是我们并不能保证不重名。比如“苹果”既可以是电子产品，也可以是水果。为了对个体的身份进行区分或合并，OWL 也设计了一套词汇：</p><ul><li><code>owl:sameAs</code>：表明是相同的个体，只是名字不同</li><li><code>owl:differentFrom</code>：表明是两个不同的个体</li><li><code>owl:AllDifferent</code>：表明列表中所有的个体都不相同</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;rdf:Description rdf:about=&quot;#William_Jefferson_Clinton&quot;&gt;</span><br><span class="line">  &lt;owl:sameAs rdf:resource=&quot;#BillClinton&quot;/&gt;</span><br><span class="line">&lt;/rdf:Description&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;Opera rdf:ID=&quot;Don_Giovanni&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;Opera rdf:ID=&quot;Nozze_di_Figaro&quot;&gt;</span><br><span class="line">  &lt;owl:differentFrom rdf:resource=&quot;#Don_Giovanni&quot;/&gt;</span><br><span class="line">&lt;/Opera&gt;</span><br><span class="line"></span><br><span class="line">&lt;Opera rdf:ID=&quot;Cosi_fan_tutte&quot;&gt;</span><br><span class="line">  &lt;owl:differentFrom rdf:resource=&quot;#Don_Giovanni&quot;/&gt;</span><br><span class="line">  &lt;owl:differentFrom rdf:resource=&quot;#Nozze_di_Figaro&quot;/&gt;</span><br><span class="line">&lt;/Opera&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;owl:AllDifferent&gt;</span><br><span class="line">  &lt;owl:distinctMembers rdf:parseType=&quot;Collection&quot;&gt;</span><br><span class="line">    &lt;Opera rdf:about=&quot;#Don_Giovanni&quot;/&gt;</span><br><span class="line">    &lt;Opera rdf:about=&quot;#Nozze_di_Figaro&quot;/&gt;</span><br><span class="line">    &lt;Opera rdf:about=&quot;#Cosi_fan_tutte&quot;/&gt;</span><br><span class="line">    &lt;Opera rdf:about=&quot;#Tosca&quot;/&gt;</span><br><span class="line">    &lt;Opera rdf:about=&quot;#Turandot&quot;/&gt;</span><br><span class="line">    &lt;Opera rdf:about=&quot;#Salome&quot;/&gt;</span><br><span class="line">  &lt;/owl:distinctMembers&gt;</span><br><span class="line">&lt;/owl:AllDifferent&gt;</span><br></pre></td></tr></table></figure><h1 id="4-结语"><a href="#4-结语" class="headerlink" title="4. 结语"></a>4. 结语</h1><p>关于 RDFS 和 OWL 的词汇总结我们就介绍这么多。当然，这些都只是一小部分，要想看完整版的推荐看 w3c 的官方文档。我们总结出来的这些词汇是比较常用的，同时也是有助于帮助不了解本体，不了解知识建模的同学对这些东西有一个大体的概念。其实本体建模就是在构建一套逻辑体系，这套逻辑体系帮助计算机进行逻辑推理。而无论是 RDFS 还是 OWL 亦或是其他众多我们没有介绍的词汇表都是在尝试将这样一个逻辑体系进行标准化。先阶段计算机的逻辑推理能力仍然处于很弱的阶段，说明我们现在的工作仍然很初级。我们这里总结的相关内容也许在不久的将来就会过期，失效甚至被推翻。但是了解这些知识也有助于我们对未来的发展有一个清晰的认知。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.w3.org/TR/rdf-schema/" target="_blank" rel="noopener">RDF Schema 1.1</a></li><li><a href="https://www.w3.org/TR/2004/REC-owl-ref-20040210/" target="_blank" rel="noopener">OWL Web Ontology Language</a> </li><li><a href="https://fusion.cs.uni-jena.de/fusion/blog/2016/11/18/iri-uri-url-urn-and-their-differences/" target="_blank" rel="noopener">IRI, URI, URL, URN and their differences</a>, <em>JAN MARTIN KEIL</em> </li><li><a href="https://zhangzifan.com/t/7393.html" target="_blank" rel="noopener">浅谈什么是 URL、URI、IRI、URN 及之间的区别</a>, <em>张子凡</em> </li><li>语义网技术体系 [瞿裕忠，胡伟，程龚 编著] 2015年版</li><li><a href="https://www.jianshu.com/p/9e2bfa9a5a06" target="_blank" rel="noopener">知识图谱-浅谈RDF、OWL、SPARQL</a>, <em>吕不韦</em> </li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/kgicon.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;前面的文章介绍了知识建模，我们提到知识建模使用的是 RDF 知识表示法，而 RDFS 本质上是一个标准化语义词汇表。所以本文总结一些常用的 RDFS/OWL 的语义词汇。&lt;/p&gt;
    
    </summary>
    
      <category term="知识图谱" scheme="https://rogerspy.gitee.io/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="KG" scheme="https://rogerspy.gitee.io/tags/kg/"/>
    
      <category term="knowledge-modelling" scheme="https://rogerspy.gitee.io/tags/knowledge-modelling/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识建模（二）构建本体的方法论</title>
    <link href="https://rogerspy.gitee.io/2021/08/23/kg-build-ontology-method/"/>
    <id>https://rogerspy.gitee.io/2021/08/23/kg-build-ontology-method/</id>
    <published>2021-08-23T02:52:56.000Z</published>
    <updated>2021-09-15T15:36:17.312Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/kgicon.png" alt></p><h1 id="1-什么是本体？"><a href="#1-什么是本体？" class="headerlink" title="1. 什么是本体？"></a>1. 什么是本体？</h1><p>“本体”（<em>ontology</em>）的概念来源于哲学对本体论的研究。随着人工智能（AI）的发展，科学家们将“本体”这一概念引入到计算机领域。不同的文献对本体有着不同的定义，甚至有些定义是相互矛盾的。为了方便起见，我们将本体定义为：<strong>本体是一系列词汇，这些词汇包括机器可读的概念定义和概念之间的关系</strong>。</p><a id="more"></a><ul><li><em>Classes</em>： 类别，或者概念（<em>concepts</em>）表示具体领域内的一些抽象概念，比如“酒”，“人”等。<em>Class</em> 是本体的核心。</li><li><em>Subclasses</em>：表示，大类别下面的子类。比如“酒”的子类包括“白酒”、“红酒”等。</li><li><em>Instances</em>：实例，表示抽象概念下的具体事物。比如“白酒”的实例包括“红星二锅头”、“飞天茅台”等。</li><li><em>Properties</em>：属性，表示的是概念的不同特征和属性。<em>OWL</em> 中的 <em>property</em> 实际上表示的就是关系。主要包括两种关系：<em>object property</em> 和 <em>data property</em> 。<em>Object property</em> 表示两个实体之间的关系，比如小明和小红是兄妹关系，其中“兄妹”就是“小明”和“小红”两个实体的 <em>object property</em>；<em>data property</em> 表示实体属性，比如小明的年龄是12岁，其中“姓名”就是“小明”这个实体的 <em>data property</em>。除此以外， W3C 还规定了一种标注属性（<em>annotation property</em>），它表示一些实体的注释元信息，用来对实体进行注释说明。</li><li><em>slots</em>：槽，可以认为就是实体具体属性，比如“小明的年龄是12岁”，其中 “年龄” 就是一个 <em>slot</em>，而 “12岁” 就是 <em>slot value</em>。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/image-20210729171714117.png" alt></p><p>总结一下，本体需要包含以下要素：</p><ul><li>定义本体类别</li><li>构建各类别之间的层级关系（父类 -&gt; 子类）</li><li>定义 <em>slot</em> 以及可接受的值，比如年龄 <em>slot</em> 必须是数字</li><li>在实例中对 <em>slot</em> 进行填充</li></ul><h1 id="2-为什么需要本体？"><a href="#2-为什么需要本体？" class="headerlink" title="2. 为什么需要本体？"></a>2. 为什么需要本体？</h1><ul><li>共享人类或者计算机理解的信息结构。假设多个的网页包含不同的医疗信息，如果这些网页能够共享相同的本体，那么计算机可以轻易从这些网页抽取有用信息提供给用户。不仅如此，计算机还可以聚合不同来源的信息，准确回答用户的问题。</li><li>领域知识的复用。举个例子，很多地方都会需要时间信息，包括时间段、时间点、相对时间等等。如果有人能够构建一个关于时间的本体，那么其他人就可以轻易将这个本体应用到自己的领域。另外，当我们自己构建本体的时候，也可以使用已有的本体知识在上面进行扩充或者缩减等。</li><li>明确领域假设。相当于我们将某一领域内的知识点利用一些假设关系相互串联起来，使我们对整个领域有更加清晰准确的认识，尤其是对一些新人。</li><li>将领域知识与可操作性的知识分离。这就有点类似于我们在设计一款产品的时候，我们将具体的产品和组件分离开来（模块化）。比如手机，多年前的手机充电器，基本上是一个品牌甚至同一个品牌的不同型号手机就有一个充电器，充电器不同共用，相当于手机和充电器是深度绑定的。后来为了解决这种深度绑定带来的各种问题，业内开始制定统一标准实现充电器与手机分离，一个充电器可以使用不同的充电器，而一个充电器可以给不同的手机充电。其中充电器标准就可以认为是领域知识本体，而手机就是可操作数据。</li><li>领域知识分析。当我们要复用和扩展领域知识的时候，这些领域知识元素就会变得非常有价值，说白了其实还是避免重复造轮子。</li></ul><p>通常定义领域的本体并不是我们的最终目的。开发本体类似于定义一组数据及其结构以供其他程序使用。 解决问题的方法、独立于领域的应用程序和软件代理使用从本体构建的本体和知识库作为数据。 例如，在本文中，我们开发了葡萄酒和食物的本体以及葡萄酒与膳食的适当组合。 然后，该本体可以用作一套餐厅管理工具中某些应用程序的基础：一个应用程序可以为当天的菜单创建葡萄酒建议或回答服务员和顾客的查询。 另一个应用程序可以分析酒窖的库存清单，并建议扩展哪些葡萄酒类别以及为即将到来的菜单或食谱购买哪些特定的葡萄酒。</p><h1 id="3-如何构建本体？"><a href="#3-如何构建本体？" class="headerlink" title="3. 如何构建本体？"></a>3. 如何构建本体？</h1><p>现实中，并没有一个标准的、统一的本体构建方法。本文只是讨论一种比较通用的方法：先构建比较粗糙、大粒度的本体，然后不断的迭代细化。</p><p>在详细介绍构建本体的流程之前，我们先强调本体设计时的一些规则，虽然看起来有些教条，但是在很多情况下这些规则确实能帮助我们。</p><ul><li>没有一个标准的、统一的本体构建方法。最好的方法就是根据实际业务需求去构建。</li><li>本体构建是一个需要不断迭代的过程</li><li>本体中的概念和关系必须是一些比较相近的对象（无论是物理上还是逻辑上）。这些对象可能是某领域内描述性句子中的名词或者动词。</li></ul><p>接下来，我们以构建酒类和食物领域的本体为例，介绍构建本体的方法。</p><h2 id="3-1-第一步、确定本体的领域和范围"><a href="#3-1-第一步、确定本体的领域和范围" class="headerlink" title="3.1 第一步、确定本体的领域和范围"></a>3.1 第一步、确定本体的领域和范围</h2><p>构建本体的第一步是确定领域和范围，因此我们需要回答下面几个问题：</p><blockquote><ul><li>我们要构建什么领域的本体？</li><li>这些本体用来做什么？</li><li>这些本体可以回答什么问题？</li><li>谁会使用这些本体？</li></ul></blockquote><p>在本体设计过程中，这些问题的答案可能会发生变化，但是任何时候这些问题都可以帮助我们限定本体范围。</p><p>考虑酒类和食物的例子。首先我们已经确定要构建酒类和食物的本体了，我们的目的是用这些本体来推荐一些好的食物和酒的搭配。</p><p>那么显然，不同酒类的概念，食物类型的概念，以及酒和食物的搭配就必须包含在我们的本体中。同时，在我们的本体中不太可能包括管理酒厂库存或餐厅员工的概念，即使这些概念与酒和食物的概念有些相关。</p><p>如果我们的本体是用来帮助酒类杂志文章进行自然语言处理，那么词性、同义词等自然语言信息可能就会变得非常重要。如果本体用于帮助餐厅顾客决定订购哪种酒，我们需要包括零售定价信息。如果用于酒品买家储存酒窖，则可能需要批发定价和可用性信息。如果本体描述语言不同于本体用户语言，我们可能需要提供语言之间的映射。</p><h3 id="能力问题（competency-questions）"><a href="#能力问题（competency-questions）" class="headerlink" title="能力问题（competency questions）"></a>能力问题（competency questions）</h3><p>确定本体范围的方法之一就是勾勒出基于本体的知识库能够回答的问题（<a href="https://www.semanticscholar.org/paper/Methodology-for-the-Design-and-Evaluation-of-Gruninger/497abc0ddace6a7772a5f5a3edb3d7b751476755" target="_blank" rel="noopener">Gruninger and Fox 1995</a>）。这些问题能帮助我们确定我们是否有足够的信息去回答这些问题，本体粒度都不够，覆盖的范围全不全。只需要一些大致的问题即可，无需穷举。</p><p>在我们的例子中，我们可能包含以下能力问题：</p><blockquote><ul><li>当我挑选酒品的时候应该考虑什么？</li><li>Cabernet Sauvignon 适合搭配海鲜吗？</li><li>什么酒与烤肉最配？</li><li>酒类的哪些特点会影响与食物的搭配？</li><li>特定的酒的香气或者酒本身会随着时间发生变化吗？</li><li>Napa Zinfandel 最好的年份？</li></ul></blockquote><p>从上面的问题中可以总结出，在我们的本体中石少应该包含：不同酒的特点、酒的类型、年份（及其品质的好坏）、食物分类以及酒和食物的搭配。</p><h2 id="3-2-第二步、现有本体的复用"><a href="#3-2-第二步、现有本体的复用" class="headerlink" title="3.2 第二步、现有本体的复用"></a>3.2 第二步、现有本体的复用</h2><p>程序员的圣经之一就是“不要重复造轮子”。查找已有的可用本体是一件非常重要的事情。网上有很多相关的资源，下面列举一些比较重要的资源（大多是英文的资源，中文开放本体资源目前还比较少）：</p><blockquote><ul><li><p>OpenKG</p><p>OpenKG是最大的中文开放知识图谱库，其中包含了很多本体。</p><p>地址：<a href="http://openkg.cn/home" target="_blank" rel="noopener">http://openkg.cn/home</a></p></li><li><p>Protege Ontology Library</p><p>地址：<a href="https://protegewiki.stanford.edu/wiki/Protege_Ontology_Library" target="_blank" rel="noopener">https://protegewiki.stanford.edu/wiki/Protege_Ontology_Library</a></p></li><li><p>Ontolingua ontology library</p><p>地址：<a href="http://www.ksl.stanford.edu/software/ontolingua/" target="_blank" rel="noopener">http://www.ksl.stanford.edu/software/ontolingua/</a></p></li><li><p>DAML ontology library</p><p>地址：<a href="http://www.daml.org/ontologies/" target="_blank" rel="noopener">http://www.daml.org/ontologies/</a></p></li><li><p>UNSPSC</p><p>地址：<a href="https://www.unspsc.org" target="_blank" rel="noopener">https://www.unspsc.org</a></p></li><li><p>RosettaNet</p><p>地址：<a href="https://www.rosettanet.org" target="_blank" rel="noopener">https://www.rosettanet.org</a></p></li><li><p>DMOZ</p><p>地址：<a href="https://www.dmoz.org" target="_blank" rel="noopener">https://www.dmoz.org</a></p></li></ul></blockquote><p>实际上现在确实有酒类开放实体可用，但是我们假设不存在，从头构建一个酒类本体。</p><h2 id="3-3-第三步、枚举本体中的重要对象"><a href="#3-3-第三步、枚举本体中的重要对象" class="headerlink" title="3.3 第三步、枚举本体中的重要对象"></a>3.3 第三步、枚举本体中的重要对象</h2><p>当提到一个对象的时候你会讨论些什么？这些对象有什么属性？关于这个对象你会说些什么？思考这些问题对我们构建本体是非常有用的。我们可以把这些对象写成一个列表记录下来，比如提到“酒”，你会想到“葡萄”、“酿酒厂”、“原产地”、“酒的颜色”、“口感”、“含糖量”、“酒精含量”等等。而提到“食物”，我们通常会想到“鱼”、“虾“、”肉“、”蛋“、”奶“等等。起初，对于对象的一个综合理解更重要，无需过于关注概念和关系之间的相互覆盖。</p><h2 id="3-4-第四步、定义类和类的层级结构"><a href="#3-4-第四步、定义类和类的层级结构" class="headerlink" title="3.4 第四步、定义类和类的层级结构"></a>3.4 第四步、定义类和类的层级结构</h2><p>有几种不同的方法定义类的层级结构（<a href="https://www.cambridge.org/core/journals/knowledge-engineering-review/article/abs/ontologies-principles-methods-and-applications/2443E0A8E5D81A144D8C611EF20043E6" target="_blank" rel="noopener">Uschold &amp; Gruninger 1996</a>）：</p><ul><li><strong>自上而下</strong>的方法是先定义领域内最通用的顶层概念，然后依次向下扩展。比如，我们先定义两个类别：“酒”和“食物”。然后定义酒的子类：白酒、红酒、玫瑰酒等等。然后对红酒进一步分类：<em>Syrah</em>，<em>Red Burgundy</em>，<em>Cabernet Sauvignon</em> 等等。对“食物”也是如此。</li><li><strong>自下而上</strong>的方法是先定义一些具体的类别，然后讲这些类别聚合成更加通用的类别。比如“衡水老白干”和“红星二骨头”可以聚合成“白酒”。另外，“拉菲”，“桃乐丝”可以聚合成“红酒”。而“白酒”和“红酒”可以聚合成“酒”。</li><li><strong>上下结合</strong>的方法是先定义一些比较重要的类，然后向上聚合和向下扩展。相当于将上面两种方法结合在一起。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/image-20210802113435286.png" alt></p><p>这三种方法中，没有一种是一定比其他两种更好的方法。最终采取哪种方法取决于开发人对领域的认知。如果开发人员对领域有着系统性的了解，那么采取自上而下的方法应该是首选。通常对于大多数的开发人员来说，上下结合的方法是比较适合的，因为多数人对领域都是有一定的了解而又了解不深。所以可以通过先构建一些比较通用的本体，然后再从实例中进行总结向上补充的方法会比较合适。</p><p>比如，多数人都知道酒可以分成“白酒”、“红酒”、“鸡尾酒”等，经常看广告也可以知道“白酒”有“酱香型”、“浓香型”对于其他的香型不太了解。而对于具体的酒进行总结归类，就可以发现，原来“酒鬼酒”是馥郁香型的，那么我们就可以将“馥郁香型”补充到酒类香型的层级上去。</p><p>无论是那种方法，都是从定义类开始的。第三步中，我们列举出了一些对象，现在我们可以从列表中的选择那些用于描述独立存在的对象作为类别，以这些对象作为锚点构建层级关系。一个重要的假设如下：</p><blockquote><p>  <em>如果类别 A 是类别 B 的父类，那么属于 B 类的所有实例也同样是类别 A 的实例。</em></p></blockquote><h2 id="3-5-第五步、定义类的属性——slots"><a href="#3-5-第五步、定义类的属性——slots" class="headerlink" title="3.5 第五步、定义类的属性——slots"></a>3.5 第五步、定义类的属性——<em>slots</em></h2><p>单纯的类别不足以为回答能力问题提供足够的信息，一旦我们用以上的方法定义了类别之后，需要为这些类别提供额外的信息，比如酒的颜色、口感、含糖量、产地等。这些信息就是类别的属性。</p><p>通常，一下集中类型的对象可以成为本体的属性：</p><ul><li>内秉属性，比如：颜色、口感、含糖量等；</li><li>外部属性，比如：产地、酒名等；</li><li>子结构，如果一个对象是结构化的，那么它的实体结构和抽象结构都可以成为它的属性；</li><li>与其他对象的关系。比如，酒的厂家、酒的原料等。</li></ul><p>所有子类都要继承父类的属性。比如“酒”的属性包括“厂家”、“颜色”、“口感”、“含糖量”、“产地”等，那么“酒”的子类“白酒”也要继承这些属性。因此，定义 <em>slots</em> 的时候通常是附加在具有该属性的最顶级类别上。</p><h2 id="3-6-第六步、定义-slots-的刻面"><a href="#3-6-第六步、定义-slots-的刻面" class="headerlink" title="3.6 第六步、定义 slots 的刻面"></a>3.6 第六步、定义 <em>slots</em> 的刻面</h2><p><em>slots</em> 的刻面包括 <em>slots</em> 基数、数据类型、定义域和值域等。比如酒的名称（<em>name</em>）是一个字符串类型的数据，酒厂生产（<em>produces</em>）酒，这些酒是具体的酒的实例，因此其对应的数据类型应该是实例（<em>instance</em>）。</p><ul><li><p>基数（<em>cardinality</em>）</p><p><em>slot</em> 基数定义了一个 <em>slot</em> 可以有多少个值。有些 <em>slot</em> 只能至多有一个值，而有些则可以有多个值。比如一种酒只能有一种颜色，却可以有多个产地。</p><p>有些系统会规定 <em>slot</em> 基数的最大值和最小值。最小值 <em>N</em> 表明该 <em>slot</em> 至少有 <em>N</em> 个值，比如葡萄酒的原料葡萄 <em>slot</em> 最小值为 1，表明该种葡萄酒的原料中至少包含一种葡萄。最大值 <em>M</em> 表明该 <em>slot</em> 最多有 <em>M</em> 个值。比如葡萄酒的原料葡萄 <em>slot</em> 最大值为 2，表明该种葡萄酒最多有两种不同品种的葡萄酿制而成。如果最大值最小值都是 1，说明这种葡萄酒就是 1 种葡萄酿制而成的。所有时候将最大值设置成 0 也是非常有用的，表明对于某些特定的子类没有任何值满足条件。</p></li><li><p>数据类型</p><p>数据类型定义了 <em>slot</em> 的数据类型。</p><ul><li>字符串（<em>string</em>）：最简单，最常用的数据类型。</li><li>数字（<em>number</em>）：数值类型的 <em>slot</em>，比如年龄、价格等。</li><li>布尔型（<em>boolean</em>）：<em>yes</em> 或者 <em>no</em>，<em>true</em> 或者 <em>false</em> 等</li><li>可枚举（<em>enumerated</em>）：给定 <em>slot</em> 可取到的值的列表，比如酒的口味可以是 [“重”，“中等”，“清淡”] 中的任意一种，而不能超过这三种的范围。</li><li>实例类型（<em>instance</em>）：<em>slot</em> 允许定义两个单独实体的关系，但是必须定义清楚哪些类别的实体是可以作为 <em>slot</em> 的值。比如“酒”这个类别，可以作为 “<em>produces</em>” 的值。</li></ul></li><li><p>定义域和值域</p><p>允许使用实例类型作为 <em>slot</em> 的类别称之为值域，比如 “酒” 作为 “<em>produces</em>” 的 <em>slot</em> 值，“酒” 就是  “<em>produces</em>” 的值域。简单来说，就是 $x \rightarrow y$，其中 $y$ 的所有实例数据类型的取值就是值域。</p><p>而定义域就是 <em>slot</em> 描述的对象。比如 “酿酒厂”，“<em>produces</em>”，“酒”，其中 “酿酒厂” 就是定义域。是简单来说，就是 $x \rightarrow y$，其中 $x$​ 的取值范围就是定义域。</p><p>确定定义域和值域的规则是相似的：</p><blockquote><ul><li>找到最通用的类或者最具代表性的类别；</li><li>另一方面，不要将定义域和值域定义得范围太大，定义域中所有的值都可以被 <em>slot</em> 描述，值域中的所有值应该是 <em>slot</em> 的潜在填充值。不要选择过于笼统的类别，而是应该选择涵盖所有填充值的类别。</li></ul></blockquote><p>比如，“酿酒厂”，“<em>produces</em>” 的值域不应该是所有“酒” 的子类（“白酒”，“啤酒”，“红酒”等），而直接就是“酒”。同时，也不应该将“酒”进一步泛化到 “<em>THING</em>”。</p><p>具体来讲：</p><blockquote><p>  <em>如果 slot 的值域或者定义域包括一个类别以及该类别下的子类，那么将其子类全部删掉</em></p></blockquote><p>比如，一个 <em>slot</em> 的值域包括“酒”和“红酒”，那么应该将“红酒”删掉，因为“红酒”是“酒”的子类。</p><blockquote><p>  <em>如果 slot 的值域或者定义域包含了 A 类的所有子类，但不包含 A 类本身，那么值域应该只包含 A 类本身而不包括其子类。</em></p></blockquote><p>比如，一个 <em>slot</em> 的值域是“白酒”、“红酒”、“啤酒”等，我们可以将值域设为“酒”本身。</p><blockquote><p>  <em>如果 slot 的值域或者定义域包含类别 A 中除少数子类以外的所有子类，那么我们应该考虑将类别 A 本身进行重新定义。</em></p></blockquote><p>将一个 <em>slot</em> 挂在到一个类别上，和将该类别设为 <em>slot</em> 的定义域是完全等价的。一方面，我们应该尽可能泛化，另一方面我们应该保证 <em>slot</em> 对应的类别确实有相应的属性。总之一句话，我们既要一个都不差，也要避免张冠李戴。</p></li></ul><h2 id="3-7-第七步、构建实例"><a href="#3-7-第七步、构建实例" class="headerlink" title="3.7 第七步、构建实例"></a>3.7 第七步、构建实例</h2><p>最后一步就是根据我们建立的类别层级结构构建实例。定义一个实例需要：</p><ol><li>选择一个类别；</li><li>创建该类的单一实例</li><li>填充 <em>slot</em> 值</li></ol><p>比如，我们创建一个 <em>飞天茅台</em> 的实体用来表示 “白酒” 的实例。它的属性如下：</p><blockquote><p>  酒精度：53%</p><p>  颜色：无色透明</p><p>  香气：幽雅细腻</p><p>  口味：回味悠长</p><p>  产地：贵州省仁怀市</p><p>  生产商：贵州茅台酒股份有限公司</p></blockquote><h1 id="4-定义类别和类别层级结构"><a href="#4-定义类别和类别层级结构" class="headerlink" title="4. 定义类别和类别层级结构"></a>4. 定义类别和类别层级结构</h1><p>本节讨论定义类别和类别层级结构时需要注意的点和容易出现的错误。对于任意领域来说都没有一个唯一正确的层级结构。我们所定义的层级结构依赖于我们要怎样使用本体，应用中必要的细节，个人喜好以及有时候可能还需要与其他模型进行兼容。但是我们还是要讨论一些开发层级结构时的一些指南，当我们开发完新的层级结构以后，回过头重新审视我们的定义是否满足这些指南，可以帮助我们避免很多错误。</p><h2 id="4-1-保证类别层级结构的正确性"><a href="#4-1-保证类别层级结构的正确性" class="headerlink" title="4.1 保证类别层级结构的正确性"></a>4.1 保证类别层级结构的正确性</h2><ul><li><p>“is-a” 关系</p><p>如果类别 A 中的所有实例同时也是类别 B 的实例，此时我们就说类别 A 是类别 B 的子类，我们就可以定义关系（A，is-a，B）。比如，（“茅台酒”，“is-a”，“白酒”）。另一个也可以表示这种关系的是 “kind-of”，（“茅台酒” ，“kind-of”，“白酒”），（“肉”，“kind-of”，“食物”）等等。</p></li><li><p>单一的酒不是所有酒的子类</p><p>一个常见的错误是，在层级结构中包含同一个概念的单数版本和复数版本，然后令单数版本是复数版本的子类。比如，定义 “<em>wine</em>” 是 “<em>wines</em>” 的子类。然而这种关系是错误的。为了避免这种情况发生，在给类别命名的时候最好都采用单数形式或者都采用复数形式（第六节中讨论类别命名）。</p></li><li><p>层级关系的可传递性</p><p>满足以下条件的关系是可传递的：</p><blockquote><p>  <em>如果 B 是 A 的子类，C 是 B 的子类，那么 C 也是 A 的子类。</em></p></blockquote><p>比如，我们定义一个类别是 “酒”，然后定义 “白酒” 是 “酒” 的子类。然后再定义 “茅台酒” 是 “白酒” 的子类。那么可传递性表示 “茅台酒” 也是 “酒” 的一个子类。有时候我们会区分直接子类和间接子类。直接子类表示在层级结构中两个类别之间没有其他子类，即某一类别与其父类直接相连。而间接子类就是需要一个中间子类再与父类相连。实际上该子类也是中间父类的直接子类。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/image-20210803104950521.png" alt></p></li><li><p>类别层级结构的演化</p><p>随着定义域的变化，要维护一个不变的层级结构可能会是一件很困难的事。比如通常我们见到的 “茅台酒” 是无色透明的，所以我们将 “茅台酒” 定义为 “白酒” 的子类。但是有可能在未来的某一天，酒厂发明了一种新的酿酒技术使得酒变成了黄色或者红色。此时，我们再将 “茅台酒” 归类到 “白酒” 里面可能就不太合适了。（这个例子实际上并不是很典型，一个比较典型的例子是组织结构的本体。组织结构的变动是很频繁的，一些部门今天还在，明天可能就取消了。）</p></li><li><p>类别及其名字的区别</p><p>区分类别和它的名字是至关重要的，通常也很难被注意到。</p><blockquote><p>  类别代表的是某一领域内的概念本身，而不是代表这个概念的几个单词。</p></blockquote><p>我们选择的术语不同，其类别名就会发生变化，但实际上不同的术语表示的是同一个概念。比如 “克劳修斯表述”，“开尔文表述”，“熵增定律” 等等虽然名字不同，但都表示 “热力学第二定律” 这一概念。只是各自的名字不同罢了。再比如 “飞人乔丹”，“乔帮主” 都可以表示 “迈克尔·乔丹” 这个概念。</p><p>现实情况下，我们应该遵循以下规则：</p><blockquote><p>  <em>表示相同概念的同义词不可代表不同的类别</em></p></blockquote><p>同义词仅仅是相同概念的不同术语而已，因此，我们不能使用同义词来命名不同的类别。很多本体系统允许将同义词与表示类别名称相关联。比如，我们可以定义 “<em>same_as</em>” 关系，将“熵增定律”、“克劳修斯表述”和“开尔文表述”都关联到“热力学第二定律”上。如果不允许这种关联，则应该在类别文档中列出同义词。</p></li><li><p>避免类别套娃</p><p>类别层级结构中的循环指的是，类别 A 是类别 B 的子类的同时，类别 B 又是 类别 A 的子类，即两个类别互为子类和父类。是在构建层级结构的时候，我们应该避免出现这种情况。一旦出现这种情况就说明 A 和 B 是等价的：A 的所有实例也是 B 的实例，同时 B 的所有实例也是 A 的实例。</p></li></ul><h2 id="4-2-分析同级类别"><a href="#4-2-分析同级类别" class="headerlink" title="4.2 分析同级类别"></a>4.2 分析同级类别</h2><ul><li><strong>层次结构中的同级类别</strong></li></ul><p>同级类别（<em>siblings</em>）指的是具有相同直接父类的类别。</p><blockquote><p>  除了根节点，所有同级类别必须处于同一层。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/image-20210803143900031.png" alt></p><p>如图所示，“红酒”、“白酒”、“玫瑰酒” 同级别，“五粮液”、“鸭溪窖酒”、“贵阳大曲” 是同级别。</p><ul><li><strong>多少是太多？多少是太少？</strong></li></ul><p>并没有一个硬性指标规定一个类别至少应该有多少个直接子类。但是很多结构比较规范的本体中的类别通常有 2 个到 12 个直接子类。因此，我们可以有以下经验：</p><blockquote><p>  <em>如果一个给定类别只有一个直接子类，可能是本体建模有问题，或者本体不完全</em>；</p><p>  <em>如果一个给定类别的子类过多（超过 12 个），可能需要一些中间类别重新归类</em></p></blockquote><p>比如上图，如果我们构建的本体，“酒” 只有 “白酒” 一个直接子类，说明我们丢了 “红酒”、“玫瑰酒”等其他酒品。而如果把所有白酒都挂到 “白酒” 下面可能说明，我们对 “白酒” 的分类过于粗糙。因此，我们可以对 “白酒” 再进一步细分成 “酱香型”、“浓香型”、“清香型”等等。然后，再将对应的白酒挂上去。</p><h2 id="4-3-多继承"><a href="#4-3-多继承" class="headerlink" title="4.3 多继承"></a>4.3 多继承</h2><p>大多数知识表示系统都允许多继承：一个类别可以同时是多个类别的子类。比如，“啤酒”既可以是 “酒” 的直接子类，也可以是 “食物” 本体中 “调味料” 的直接子类。因此，“啤酒” 可以有两个父类：“酒” 和 “调味料”。“啤酒” 的所有实例同时也是 “酒” 和 “调味料” 的实例。当然，“啤酒” 也会同时继承 “酒” 和 “调味料” 的一些属性。</p><h2 id="4-4-什么时候应该（不应该）引入新的类别？"><a href="#4-4-什么时候应该（不应该）引入新的类别？" class="headerlink" title="4.4 什么时候应该（不应该）引入新的类别？"></a>4.4 什么时候应该（不应该）引入新的类别？</h2><p>本体构建最难的部分应该就是什么时候引入新的类别，或者什么时候通过不同的属性值加以区分。也就是说，对于一个新的对象，我们是把它归到已有的类别然后给予不同的属性，还是新建一个类别？如果新建过多类别，会造成类别过多，甚至会出现彼此嵌套。而如果是新加属性加以区分的话 ，又会造成属性过于复杂。如何找到一个平衡点并不容易。</p><p>为了寻找这样一个平衡点，我们可以设定一些规则：</p><blockquote><p>  一个子类通常需要满足以下条件之一：</p><ol><li>有一些父类不具备的属性；</li><li>与父类的限制条件不同；</li><li>与父类参与的关系类型不同</li></ol></blockquote><p>比如，“烤肉” 有一个属性 “几分熟”，但是其父类 “肉” 通常不会有这个属性。或者 “白酒” 的颜色限制为 “无色透明”（或者 “微黄透明”），而 “酒” 没有这个限制。换句话说，当我们想要描述的对象无法通过父类来描述的时候，就需要定义新的子类。</p><p>实际情况下，每个子类都应该有新的 <em>slot</em>，或者有新的 <em>slot</em> 值，又或者要覆盖原有的继承自父类的刻面。</p><p>有时候，没有新的属性的时候也可以引入新子类：</p><blockquote><p>  <em>术语层级结构不需要引入新的属性</em></p></blockquote><p>比如，电子病历系统基础的本体可以包括对各种疾病的分类。这个分类可能只是没有属性（或者有相同属性集）的术语层级结构。比如，“糖尿病”、“心脏病”、“高血压” 都是不带属性的，但是我们还是应该将这些术语分成不同的类，而不应该看成属性。</p><p>另一个无新增属性而要新建类别的情况是——约定俗成。某些领域内的对象，在领域专家眼中通常是区分对待的，我们构建的本体系统应该反映出领域专家对该领域的看法。因此，这种情况下，还是需要新增子类。</p><p>最后，我们不应该为每个附加的限制创建一个子类。比如，我们可以构建 “红酒”、“白酒”、“玫瑰酒” 的分类，但是不能构建 “扬州酒”、“贵州酒”、“法国酒” 等，单独根据产地属性的类别。</p><h2 id="4-5-新的类别或者属性值？"><a href="#4-5-新的类别或者属性值？" class="headerlink" title="4.5 新的类别或者属性值？"></a>4.5 新的类别或者属性值？</h2><p>当我们对一个领域进行建模的时候，通常需要考虑将某些对象定义为属性还是类别的问题。</p><p>我们是要定义 “白酒”、“红酒” 作为 “酒” 的子类，还是要将 “白酒”、“红酒” 作为 “酒” 的 “颜色” 属性值？这通常取决于我们构建的本体的范围。“白酒” 在你的领域内重要性如何？如果 “白酒” 只是为我们提供一些边缘信息，或者与其他对象没有很重要的关系，那么我们就不应该将 “白酒” 作为一个类别来对待。</p><blockquote><p>  <em>如果有不同 slot 的概念会变成其他类别的不同 slot 的限制，那么我们应该新建一个类别。否则我们就在属性中加以区分即可。</em></p><p>  换句话说就是，如果 slot 的值发生了变，会使得类别也发生变化的话，那么我们应该新建一个类别。 </p></blockquote><p>比如，“红啤”、“白啤”、“黑啤” 等，这几种酒确实不是同一种酒。</p><blockquote><p>  <em>如果领域内对对象的区分非常重要，并且我们将具有不同值的对象视为不同种类的对象，那么我们应该创建一个新类</em></p></blockquote><p>同时我们还应该注意：</p><blockquote><p>  <em>一个实例所属的类别不应该时常发生变动</em></p></blockquote><p>通常情况下，当我们用外部属性而不是内秉属性来划分类别的时候，实例所属的类别经常会发生变化。比如，“热牛奶” 和 “常温牛奶” 并不应该分成两个类别，而是应该把温度设置成 “牛奶” 的属性。</p><p>另外，数字、颜色、地点通常应该是属性而不是类别。但是，对于 “酒” 来说，颜色应该是一个很重要的分类标准，所以在 “酒” 的分类中颜色应该属于类别而不是属性。</p><p>另一个人体解剖学本体的例子。当我们表示 “肋骨” 的时候，是否应该将肋骨分成 “左侧第一根肋骨”、“左侧第二根肋骨” 等？或者我们将肋骨的顺序和位置当成属性？如果在我们的本体中每根肋骨承载的信息非常不同的话，我们么确实应该为每根肋骨构建一个类别。比如，如果我们想要对肋骨不同位置的邻接信息建模，以及运动过程中每根肋骨所起的作用，或者不同肋骨保护的不同器官等等，这时候我们就需要对每根肋骨新建一个类别。如果我们只是对人体解剖学进行大致建模，那么我们只需要构建一个 “肋骨” 的类别，然后把 “位置” 和 “顺序” 作为属性即可。</p><h2 id="4-6-实例还是类别？"><a href="#4-6-实例还是类别？" class="headerlink" title="4.6 实例还是类别？"></a>4.6 实例还是类别？</h2><p>决定一个对象是类别还是实例，还是取决于我们构建的本体的潜在应用场景。类别结束实例开始的位置决定了本体的细节粒度。比如，“酸奶” 应该算是一个类别，还是实例？如果作为类别，它下面还有 “成都老酸奶”、“青海老酸奶” 等更细粒度的类别，如果 “酸奶” 作为实例，那么就不需要区分 “成都老酸奶” 和 “青海老酸奶”了。</p><p>要确定本体的细节粒度，可以回到本体构建步骤的第一步——我们想要利用这个本体回答什么问题？</p><blockquote><p>  知识库中，单实例是粒度最细的概念。</p></blockquote><p>比如，如果我们关心的是是否易消化，那么 “酸奶”、“纯牛奶” 就可以作为实例，而如果还要考察 “酸奶” 的制作工艺，口味特点等。那么 “酸奶” 就需要成为一个类别。</p><p>另外，如果满足以下条件，则可以将实例转化成类别：</p><blockquote><p>  <em>如果一个概念天然有层级结构，那么我们应该把它当成类别。</em></p></blockquote><p>比如，“地球有七个大洲”，我们可以把 “七大洲”（“亚洲”，“欧洲”，…） 当成 “地球” 的实例，但是 “七大洲” 是由不同国家组成的。因此，通常我们把每个大洲作为类别，而不是实例。</p><p>需要注意的是，只有类别有值域。在知识表示系统中，不存在 “subinstance” 的概念。因此，如果我们还想对一个概念进行细分，即使概念本身没有任何实例，也要把它当成类别，而不是实例。</p><h2 id="4-7-限制本体范围"><a href="#4-7-限制本体范围" class="headerlink" title="4.7 限制本体范围"></a>4.7 限制本体范围</h2><blockquote><p>  <em>本体系统不需要包括领域内所有的信息：我们不需要细化或者泛化超过实际需求的本体。</em></p></blockquote><p>比如，如果我们的用处是酒和食物的单配，那么我们就不需要知道如何酿酒和如何烹饪。</p><blockquote><p>  <em>本体系统不需要包含所有的属性以及不同类别之间的区别。</em></p><p>  <em>本体系统不需要包含所有的关系</em></p></blockquote><h2 id="4-8-无交集子类"><a href="#4-8-无交集子类" class="headerlink" title="4.8 无交集子类"></a>4.8 无交集子类</h2><p>如果两个类别的实例中没有公共实例，我们就认为这两个类别是无交集类别。比如 “红酒” 和 “白酒” 就是无交集类别：没有一种酒即是红酒又是白酒。在构建本体系统的时候，我们可以指定两个类别是无交集类别。指定无交集类别的好处是可以使本体更好进行验证——如果不指定的话，我们要看两个类别是否有交集还要将两个类别的实例全部读取出来，然后求交集看是否为空。不仅浪费空间还浪费时间。</p><p>同时，如果我们指定 “红酒” 和 “白酒” 是无交集类别的话，在进行建模的时候，如果创建了一个多继承子类，父类中包括了 “红酒” 和 “白酒”，那么系统可以很快识别出建模错误。</p><h1 id="5-定义属性——更多细节"><a href="#5-定义属性——更多细节" class="headerlink" title="5. 定义属性——更多细节"></a>5. 定义属性——更多细节</h1><p>本节主要讨论可逆属性和属性默认值。</p><h2 id="5-1-互逆属性（slot）"><a href="#5-1-互逆属性（slot）" class="headerlink" title="5.1 互逆属性（slot）"></a>5.1 互逆属性（slot）</h2><p>一个 <em>slot</em> 的值可能依赖于另一个 <em>slot</em> 的值。比如，（<em>wine</em>，<em>produced_by</em>，<em>winery</em>）和（<em>winery</em>，<em>produces</em>，<em>wine</em>）这两个关系就是互逆关系。如果在本体系统中将两个关系都存下来，会显得整个本体冗杂。当我们知道某种酒的生产厂家是某某某的时候，我们就可以推断出某某某厂家生产了某种酒。从知识获取的角度来说，明确这种互逆关系对知识获取来说是很方便的。知识获取系统可以自动填写互逆关系的值，以确保知识库的一致性。</p><p>比如，当我们明确了 “<em>produced_by</em>” 和 “<em>produces</em>” 是互逆关系之后，当我们填写了 “茅台酒 <em>produced_by</em> 贵州茅台酒股份有限公司” 以后，系统可以自动填写 “贵州茅台酒股份有限公司 <em>produces</em> 茅台酒”。</p><h2 id="5-2-默认属性值（slot-value）"><a href="#5-2-默认属性值（slot-value）" class="headerlink" title="5.2 默认属性值（slot value）"></a>5.2 默认属性值（slot value）</h2><p>许多基于框架的系统允许指定默认属性值。如果多数实例的特定属性是相同的，那么我们可以给这个属性指定一个默认值。然后，每次往该类别下添加有该属性的实例的时候，系统可以自动填充属性值。如果我们默认的属性值与该实例的实际属性值不符，我们还可以手动修改。</p><p>比如，如果多数白酒都是 53° 的，那么我们在 “酒精度数” 中可以默认为 53°。如果有些白酒不是 53°，还可以手动改成其他度数。</p><p>需要注意的是，默认属性值与属性值是不同的，默认属性值是可以修改的，而属性值是不可修改的。即如果我们定义了 “白酒” 的酒精度是 53°，那么所有 “白酒” 的子类和实例的酒精度都是 53°，这个度数在任意子类和实例中都不可修改。</p><h1 id="6-名字包含什么？"><a href="#6-名字包含什么？" class="headerlink" title="6. 名字包含什么？"></a>6. 名字包含什么？</h1><blockquote><p>  本节讨论对概念命名规则，主要集中在英文名称中会出现的一些问题，比如大小写、分隔符、单复数等。这些问题在中文中都基本不会出现。但是就个人而言，还是建议使用英文进行知识建模。众所周知，现在很多系统对中文的支持并不是十分友好，使用中文建模的话很可能出现各种意想不到的问题，因此，能用英文建模的就尽量使用英文建模吧。</p></blockquote><p>为本体中的概念设定一些命名规则，不仅可以使本体更容易理解，还能够帮助我们避免一些常见的建模错误。命名方法有很多，实际应用的时候可以选择合适的方法。但是，我们要：</p><blockquote><p>  <em>定义一种类别和属性的命名规范，然后遵守它。</em></p></blockquote><p>在知识表示系统中，我们可以考虑以下特征用于对概念进行命名：</p><ul><li>本体中是否存在同名的类别、属性、实例？比如 “酿酒厂” 既是类别又是属性？</li><li>本体系统大小写敏感吗？比如，系统是否人为 “<em>Wine</em>” 和 “<em>wine</em>” 是同一个概念？</li><li>名称中允许出现什么样的分隔符？空格、逗号、星号等等？</li></ul><h2 id="6-1-大小写与分隔符"><a href="#6-1-大小写与分隔符" class="headerlink" title="6.1 大小写与分隔符"></a>6.1 大小写与分隔符</h2><p>首先，如果我们在本体中保证概念名称的大小写一致性能够大幅提升本体的可读性。比如，通常的做法是大写类别名称，小写属性名称（假设大小写敏感）。</p><p>当概念名称中有不止一个词的时候，我们需要在词与词之间添加分隔符。通常分隔符有以下几种选择：</p><ul><li>空格</li><li>词与词之间没有分隔符，而是将每个词的首字母大写，比如 “MealCourse”</li><li>使用下划线或者连接符，比如 “meal_course”，“meal-course” 等</li></ul><p>在使用空格的时候，需要考虑你所使用的本体建模工具是否支持空格，以及你构建出来的本体是否会与其他本体系统交互使用，如果有交互，需要交互的本体系统是否支持空格。因此，虽然用空格作为分隔符更符合人类的习惯，但是需要考虑的因素比较多，更建议使用后两种方案。</p><h2 id="6-2-单数还是复数？"><a href="#6-2-单数还是复数？" class="headerlink" title="6.2 单数还是复数？"></a>6.2 单数还是复数？</h2><p>一个类别的名称代表的是一些列对象的集合。所以，建议使用复数作为类别的名称。但是无论使用单数还是复数，都要在整个本体中保持一致，不要出现在这里是单数，淡了另一处就变成了复数。甚至有些本体建模工具会要求用户指定概念名称的单复数。</p><h2 id="6-3-前缀和后缀的规则"><a href="#6-3-前缀和后缀的规则" class="headerlink" title="6.3 前缀和后缀的规则"></a>6.3 前缀和后缀的规则</h2><p>有些知识库会建议使用前缀或者后缀还区分类别名和属性名。属性名中常用的两种前缀或者后缀：“has-” 或者 “-of”。比如 “<em>has-maker</em>” 或者 “<em>*maker-of</em>”。通过这种方式区分类别名和属性名可以提高可读性。</p><h2 id="6-4-命名中的一些其他考量"><a href="#6-4-命名中的一些其他考量" class="headerlink" title="6.4 命名中的一些其他考量"></a>6.4 命名中的一些其他考量</h2><ul><li>不要在概念名称中出现 “<em>class</em>”、“<em>property</em>”、“<em>slot</em>” 等词汇</li><li>避免使用缩写</li><li>对直接子类进行命名的时候，要么所有子类都包含父类的名称，要么都不包含父类的名称。不要出现有些子类包含父类有些不包含的情况。比如 “<em>red wine</em>” 和 “<em>*white</em>”</li></ul><h1 id="7-其他可参考资料"><a href="#7-其他可参考资料" class="headerlink" title="7. 其他可参考资料"></a>7. 其他可参考资料</h1><ol><li><a href="https://dl.acm.org/doi/10.1006/ijhc.1999.0366" target="_blank" rel="noopener">WonderTools? A comparative study of ontological engineering tools</a>, <em>Duineveld, A.J., Stoter, R., Weiden, M.R., Kenepa, B. and Benjamins, V.R. (2000).</em></li><li>Knowledge sharing and reuse. <em>Gómez-Pérez, A. (1998).</em></li><li><a href="https://www.cambridge.org/core/journals/knowledge-engineering-review/article/abs/ontologies-principles-methods-and-applications/2443E0A8E5D81A144D8C611EF20043E6" target="_blank" rel="noopener">Ontologies: Principles, Methods and Applications</a>, <em>Uschold, M. and Gruninger, M. (1996).</em></li><li><a href="http://www.ksl.stanford.edu/software/ontolingua/tutorial.pdf" target="_blank" rel="noopener">Ontolingua tutorial</a>. <em>Farquhar, A. (1997).</em></li><li><a href="https://www.researchgate.net/publication/profile/Richard_Fikes/publication/221393548_An_Environment_for_Merging_and_Testing_Large_Ontologies/links/564d604f08ae4988a7a44137/An-Environment-for-Merging-and-Testing-Large-Ontologies.pdf" target="_blank" rel="noopener">An Environment for Merging and Testing Large Ontologies</a>. <em>McGuinness, D.L., Fikes, R., Rice, J. and Wilder, S. (2000).</em></li></ol><h1 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h1><p>本文描述了构建本体的方法和步骤。讨论了构建过程中需要注意的问题。但是我们需要记住一点：</p><p><strong>对于任意领域来说都没有一个唯一正确的方法</strong></p><p>本体的构建是一个创造的过程，即使是以相同的目的和应用场景构建相同领域的本体，不同的人都会得到不同的本体。主要能满足我们的需求，就是好的本体。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://protege.stanford.edu/publications/ontology_development/ontology101.pdf" target="_blank" rel="noopener">Ontology Development 101: A Guide to Creating Your First Ontology</a>. <em>Natalya F. Noy and Deborah L. McGuinness</em> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/kgicon.png&quot; alt&gt;&lt;/p&gt;
&lt;h1 id=&quot;1-什么是本体？&quot;&gt;&lt;a href=&quot;#1-什么是本体？&quot; class=&quot;headerlink&quot; title=&quot;1. 什么是本体？&quot;&gt;&lt;/a&gt;1. 什么是本体？&lt;/h1&gt;&lt;p&gt;“本体”（&lt;em&gt;ontology&lt;/em&gt;）的概念来源于哲学对本体论的研究。随着人工智能（AI）的发展，科学家们将“本体”这一概念引入到计算机领域。不同的文献对本体有着不同的定义，甚至有些定义是相互矛盾的。为了方便起见，我们将本体定义为：&lt;strong&gt;本体是一系列词汇，这些词汇包括机器可读的概念定义和概念之间的关系&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="知识图谱" scheme="https://rogerspy.gitee.io/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="KG" scheme="https://rogerspy.gitee.io/tags/kg/"/>
    
      <category term="ontology" scheme="https://rogerspy.gitee.io/tags/ontology/"/>
    
  </entry>
  
  <entry>
    <title>双数组前缀树</title>
    <link href="https://rogerspy.gitee.io/2021/08/16/double_array_trie/"/>
    <id>https://rogerspy.gitee.io/2021/08/16/double_array_trie/</id>
    <published>2021-08-16T12:34:43.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p>前缀树（trie）又叫字典树，顾名思义通过字符串的前缀进行查找、匹配的数据结构。Trie 树的应用场景主要包括：分词、词频统计、字符串查询和模糊匹配、字符串排序等。Trie 树大幅降低重复字符串的比较，所以执行效率非常高。</p><a id="more"></a><h1 id="1-Trie-树简介"><a href="#1-Trie-树简介" class="headerlink" title="1. Trie 树简介"></a>1. Trie 树简介</h1><p>前缀树是将字符串存储在一棵树结构内，该树是将字符串的公共前缀作为父节点。以下图为例：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210816213207.png" alt></p><p>假设有三个词，分别是“茶叶”、“茶树”、“走廊”。将这三个词存储在 Trie 树里如上图所示。“茶树”和“茶叶”有公共前缀“茶”，所以“茶”作为“叶”和“树”的父节点。而“走廊”和前两个词无公共前缀，所以独立成一个分支。另外 <code>root</code> 节点表示根节点，所有词的匹配、查找都是从根节点开始的。而 <code>null</code> 为叶节点表示从根节点 <code>root</code> 到 叶子节点 <code>null</code> 的路径组成一个完整的词。Trie 树具有以下几个特点：</p><ul><li>具有相同前缀的词必须位于同一个路径下。“叶”和“树”要共用一个父节点“茶”。</li><li>Trie 树中的词只可共用前缀，不可共用词的其他部分。比如，现在有一个新词“卖茶”，虽然都有“茶”，但是它并不是“卖茶”的前缀，所以“卖茶”要与“茶叶”和“茶树”在不同的分支上。</li><li>Trie 树中任何一个完整的词，都必须是从根节点开始至叶子节点结束，这意味着对一个词进行检索也必须从根节点开始，至叶子节点才算结束。</li></ul><h1 id="2-搜索-Trie-树的时间复杂度"><a href="#2-搜索-Trie-树的时间复杂度" class="headerlink" title="2. 搜索 Trie 树的时间复杂度"></a>2. 搜索 Trie 树的时间复杂度</h1><p>在 Trie 树中搜索一个字符串，会从根节点出发，沿着某条路径向下逐字比对字符串的每个字符，直到抵达底部的叶子节点才能确认字符串为该词，这种检索方式具有以下两个优点：</p><ol><li><p>公共前缀的词都位于同一个串内，查词范围因此被大幅缩小（比如首字不同的字符串，都会被排除）。</p></li><li><p>Trie 树实质是一个有限状态自动机（Deterministic Finite Automaton, DFA），这就意味着从 Trie 树 的一个节点（状态）转移到另一个节点（状态）的行为完全由状态转移函数控制，而 <strong>状态转移函数本质上是一种映射</strong>，这意味着：<strong>逐字搜索 Trie 树时，从一个字符到下一个字符比对是不需要遍历该节点的所有子节点的。</strong></p><blockquote><p>确定的有限自动机 M 是一个五元组：</p><script type="math/tex; mode=display">M = (\Sigma, Q, \delta, q_0, F)</script><p>其中，</p><ul><li><p>$\Sigma$ 是输入符号的有穷集合；</p></li><li><p>$Q$ 是状态的有限集合；</p></li><li><p>$\delta$ 是 $Q$ 与 $\Sigma$ 的直积 $Q × \Sigma$ 到 $Q$ (下一个状态) 的映射。它支配着有限状态控制的行为，有时也称为状态转移函数。</p></li><li><p>$q_0 \in Q$ 是初始状态；</p></li><li><p>$F$ 是终止状态集合，$F \subseteq Q$；</p></li></ul><p>可以把 DFA 想象成一个单放机，插入一盘磁带，随着磁带的转动，DFA 读取一个符号，依靠状态转移函数改变自己的状态，同时磁带转到下一个字符。</p></blockquote></li></ol><p>这两个优点相结合可以最大限度地减少无谓的字符比较，使得搜索的时间复杂度理论上仅与检索词的长度有关：$O(m)$，其中 $m$ 为检索词的长度。</p><h1 id="3-Trie-树的缺点"><a href="#3-Trie-树的缺点" class="headerlink" title="3. Trie 树的缺点"></a>3. Trie 树的缺点</h1><p>综上可知， Trie 树主要是利用词的公共前缀缩小查词范围、通过状态间的映射关系避免了字符的遍历，从而达到高效检索的目的。这一思想有赖于字符在词中的前后位置能够得到表达，因此其设计哲学是典型的“<strong>以信息换时间</strong>”，当然，这种优势同样是需要付出代价的：</p><ol><li>由于结构需要记录更多的信息，因此 Trie 树的实现稍显复杂。好在这点在大多数情况下并非不可接受。</li><li>Trie 型词典不仅需要记录词，还需要记录字符之间、词之间的相关信息，因此字典构建时必须对每个词和字逐一进行处理，而这无疑会减慢词典的构建速度。对于强调实时更新的词典而言，这点可能是致命的，尤其是采用双数组实现的 Trie 树，更新词典很大概率会造成词典的全部重构，词典构建过程中还需处理各种冲突，因此重构的时间非常长，这导致其大多用于离线；不过也有一些 Trie 可以实现实时更新，但也需付出一定的代价，这个缺点一定程度上影响了 Trie 树的应用范围。</li><li>公共前缀虽然可以减少一定的存储空间，但 Trie 树相比普通字典还需表达词、字之间的各种关系，其实现也更加复杂，因此实际空间消耗相对更大（大多少，得根据具体实现而定）。尤其是早期的“Array Trie”，属于典型的以空间换时间的实现，（其实 Trie 本身的实现思想是是以信息换时间，而非以空间换时间，这就给 Trie 树的改进提供了可能），然而 Trie 树现今已经得到了很好的改进，总体来说，对于类似词典这样的应用，Trie 是一个优秀的数据结构。</li></ol><h1 id="4-Trie-树的几种实现"><a href="#4-Trie-树的几种实现" class="headerlink" title="4. Trie 树的几种实现"></a>4. Trie 树的几种实现</h1><p>Trie 树实现:一般的链表指针方式，三数组实现，双数组实现，HAT，burst trie 等。</p><ul><li><p><strong>链表指针方式</strong></p><p>即每个节点对应一个字符，并有多个指针指向子节点，查找和插入从根节点按照指针的指向向下查询。这种方案，实现较为简单，但指针较多，较为浪费空间；树形结构，指针跳转，对缓存不够友好，节点数目上去之后，效率不够高。</p></li><li><p><strong>Hash Trie 树以及 Burst trie</strong></p><p>是将 trie 树和其他数据结构，比如 HashMap，结合起来，提高效率。但主要用于键值查找，对于给定一个字符串匹配其前缀这种场景不适用。</p></li><li><p><strong>三数组实现</strong></p><p>利用三个数组（分别叫做 base, next, check）来实现状态的转移，将前缀树压缩到三个数据里，能够较好的节省内存；数组的方式也能较好的利用缓存。</p></li><li><p><strong>双数组实现</strong></p><p>是在三数组的基础上，将 base 数组重用为 next 数组，节省了一个数组，并没有增加其他开销。与三数组相比，内存使用和效率进一步提升。</p></li></ul><p>综上，双数组 trie（Double Array trie，简称为 DATrie）的实现有明显的优势，以下讨论 DATrie 的细节（只介绍构造和查询，删除节点不常用，而且比较复杂，暂时略过）。</p><h1 id="5-Double-Array-Trie-树"><a href="#5-Double-Array-Trie-树" class="headerlink" title="5. Double-Array Trie 树"></a>5. Double-Array Trie 树</h1><h2 id="5-1-DATrie-构造方法"><a href="#5-1-DATrie-构造方法" class="headerlink" title="5.1 DATrie 构造方法"></a>5.1 DATrie 构造方法</h2><ol><li><p>数组表示 trie 树的状态转移，父节点跳转到子节点转化为父状态跳转到子状态。</p></li><li><p>利用两个数组 <code>base</code>, <code>check</code>表示状态的转移：</p><ul><li><code>base</code> 数组的索引用来表示状态</li><li><code>base</code> 数组里存的数据称为 offset</li><li><code>check</code> 数组里存的数据是父状态的索引</li><li><code>check</code> 与<code>base</code> 大小相同，一一对应，用于保存父状态，以及解决冲突</li></ul></li><li><p>状态 S 接收到字符 c 后转移到状态 T:</p><script type="math/tex; mode=display">S \overset{c}{\to} T</script><p>满足：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">check[base[S] + c] = S</span><br><span class="line">base[S] + c = T</span><br><span class="line">base[T] = base[S]</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/trie1.png" alt></p><ul><li><code>base</code> 数组的索引为 0，1，…, base[s], …, S, …, T，均表示 trie 树的状态</li><li>从 S 状态接收到 c 跳转到 T, 则表示为 base 数组索引为 S 的内容 base[S] 为基地址，加上跳转偏移 c，得到下一个 T 状态在 base 的索引 <code>T=base[S] + C</code></li><li><code>check</code> 数组对应 T 的内容 check[T] 为跳转过来的父状态，即 S。</li></ul></li></ol><h2 id="5-2-DATrie-查询"><a href="#5-2-DATrie-查询" class="headerlink" title="5.2 DATrie 查询"></a>5.2 DATrie 查询</h2><ol><li>从 <code>base</code> 数组索引 0 开始，初始状态为 S=base[0]，其中偏移的基地址为 base[S]</li><li>接受到 c，则跳转到 <code>base</code> 数组索引 T=base[S] + c，检查此时 <code>check</code> 数组的 check[T] == S，为真跳转到 3，否则匹配失败。</li><li>如果 <code>base[T] == LEAF_VALUE</code> （这里 <code>LEAF_VALUE</code> 用来表示叶子节点的特殊值），则匹配完成；否则，令 S = T, 跳转到 2。</li></ol><p>状态更新的伪码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">T := base[S] + c</span><br><span class="line"></span><br><span class="line">if check[T] = S then</span><br><span class="line">    next state := T</span><br><span class="line">else</span><br><span class="line">    fail</span><br><span class="line">endif</span><br></pre></td></tr></table></figure><h2 id="5-3-举个例子"><a href="#5-3-举个例子" class="headerlink" title="5.3 举个例子"></a>5.3 举个例子</h2><ul><li><p>假定输入两个前缀为 ‘ab’ ,  ‘ad’ ，将字母 a-z 映射为数字 1，2，3,…, 26.</p></li><li><p>这里用 -1 代表数组元素为空，-2 代表叶子节点，-3 代表根节点</p></li><li><p>状态如下：</p><ol><li><p>初始状态</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/dat_example1.png" alt></p></li><li><p>输入 ‘a’ （’ab’）</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/dat_example2.png" alt></p><p><code>base[0]+a</code>，由状态 0 跳转到状态 2。<code>check[2]</code> 为 -1，说明为空，更新为父状态 0；<code>base[2]</code>更新为跳转过来的 <code>base</code>, 即 <code>base[0]</code> 的值 1。</p></li><li><p>输入 ‘b’ （’ab’）</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/dat_example3.png" alt></p><p><code>base[2]+b</code>，由状态 2 跳转到状态 3，<code>check[3]</code>为 -1，说明为空，更新为父状态 2；由于字符串结束，将 <code>base[3]</code> 更新为 -2，代表叶节点。</p></li><li><p>输入 ‘a’（’ad’）</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/dat_example4.png" alt></p><p>图中 <code>base</code> 和 <code>check</code> 的状态不会变化。 根据 <code>base[0]+a</code>，从状态 0 跳转到 2。<code>check[2]</code> 不为空，但<code>check[2]</code> 的值 0 与其父状态 S=0 相等，则无需更新，进入状态 2，等待输入下一个字符。这个过程相当于一个查询过程。</p></li><li><p>输入 ‘d’ （’ad’）</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/dat_example5.png" alt></p><p><code>base[2]+d</code>，由状态 2 跳转到状态 5，<code>check[5]</code> 为 -1，说明为空，更新为父状态 2；由于字符串结束，将 <code>base[5]</code> 更新为 -2，代表叶节点。</p></li></ol></li></ul><h2 id="5-4-解决冲突"><a href="#5-4-解决冲突" class="headerlink" title="5.4 解决冲突"></a>5.4 解决冲突</h2><p>DATrie 不可避免会出现冲突。仍以上面的例子说明，继续插入 ‘ca’：</p><ul><li><p>输入 ‘c’（’ca’）</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/dat_example6.png" alt></p><p>状态由 0 跳转到状态 4，<code>check[4]</code> 空闲，将 <code>check[4]</code> 赋值为 0，<code>base[4]</code> 赋值为1。</p></li><li><p>输入 ‘a’ （’ca’）</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/dat_example7.png" alt></p><p>根据 <code>base[4]+4</code> 状态从4跳转到2， 但是 <code>check[2]</code> 非空，并且 <code>check[2]=0</code> 不等于父状态 4，此时发生冲突。</p></li><li><p>解决冲突</p><ol><li><p>挪动以 4 为父状态状态转移，查找对应 <code>base</code>，<code>check</code> 的连续的空闲空间以放入状态。这里只有最新的输入 ‘a’ 带来的状态转移以 4 为父状态。<code>base[6]</code>, <code>check[6]</code> 有空闲。</p></li><li><p>修改 <code>base[4]</code>, 使其能够根据输入跳转到空闲空间，即 <code>base[4] = 6 - a = 5</code>。</p></li><li><p>重新插入 ‘a’，如下图</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/dat_example8.png" alt></p></li></ol></li></ul><h1 id="6-Trie-树的压缩"><a href="#6-Trie-树的压缩" class="headerlink" title="6. Trie 树的压缩"></a>6. Trie 树的压缩</h1><p>双数组 Trie 树虽然大幅改善了经典 Trie 树的空间浪费，但是由于冲突发生时，程序总是向后寻找空地址，导致数组不可避免的出现空置，因此空间上还是会有些浪费。另外， 随着节点的增加，冲突的产生几率也会越来越大，字典构建的时间因此越来越长，为了改善这些问题，有人想到对双数组 Trie 进行尾缀压缩，具体做法是：将非公共前缀的词尾合并为一个节点（tail 节点），以此大幅减少节点总数，从而改善树的构建速度；同时将合并的词尾单独存储在另一个数组之中（Tail array）， 并通过 tail 节点的 base 值指向该数组的相应位置，以 <code>{baby, bachelor, badge, jar}</code> 四词为例，其实现示意图如下:</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/dat_example9.png" alt></p><ul><li>速度：减少了 <code>base</code>， <code>check</code> 的状态数，以及冲突的概率，提高了插入的速度。</li><li>内存：状态数的减少的开销大于存储 tail 的开销，节省了内存。</li><li>删除：能很方便的实现删除，只需将 tail 删除即可。</li></ul><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><ol><li>Trie 树是一种以信息换时间的数据结构，其查询的复杂度为 $O(m)$。</li><li>Trie 的单数组实现能够达到最佳的性能，但是其空间利用率极低，是典型的以空间换时间的实现。</li><li>Trie 树的哈希实现可以很好的平衡性能需求和空间开销，同时能够实现词典的实时更新。</li><li>Trie 树的双数组实现基本可以达到单数组实现的性能，同时能够大幅降低空间开销；但是其难以做到词典的实时更新。</li><li>对双数组 Trie 进行 tail 改进可以明显改善词典的构建速度，同时进一步减少空间开销。</li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://segmentfault.com/a/1190000008877595" target="_blank" rel="noopener">小白详解 Trie 树</a>, <em>xu_zhoufeng</em></li><li><a href="https://www.iteye.com/blog/huangwei1024-813697" target="_blank" rel="noopener">Double-Array Trie（双数组字典树）</a>, <em>huangwei1024</em></li><li><a href="https://turbopeter.github.io/2013/09/02/prefix-match/" target="_blank" rel="noopener">前缀树匹配(Double Array Trie)</a>, <em>minzhan’s blog</em></li><li><a href="https://zhuanlan.zhihu.com/p/35193582" target="_blank" rel="noopener">双数组前缀树（Double-Array Trie）</a>, <em>两片</em> </li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前缀树（trie）又叫字典树，顾名思义通过字符串的前缀进行查找、匹配的数据结构。Trie 树的应用场景主要包括：分词、词频统计、字符串查询和模糊匹配、字符串排序等。Trie 树大幅降低重复字符串的比较，所以执行效率非常高。&lt;/p&gt;
    
    </summary>
    
      <category term="博客转载" scheme="https://rogerspy.gitee.io/categories/%E5%8D%9A%E5%AE%A2%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="数据结构" scheme="https://rogerspy.gitee.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="双数组前缀树" scheme="https://rogerspy.gitee.io/tags/%E5%8F%8C%E6%95%B0%E7%BB%84%E5%89%8D%E7%BC%80%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>预训练语言模型：Word Embedding</title>
    <link href="https://rogerspy.gitee.io/2021/08/11/ptm-word-embedding/"/>
    <id>https://rogerspy.gitee.io/2021/08/11/ptm-word-embedding/</id>
    <published>2021-08-11T13:27:18.000Z</published>
    <updated>2021-09-15T15:36:17.312Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://aylien.com/images/uploads/general/tumblr_inline_o8tinsmw081u37g00_540.png" alt></p><p>词嵌入（word embedding）是一种用稠密向量来表示词义的方法，其中每个词对应的向量叫做词向量（word vector）。词嵌入通常是从语言模型中学习得来的，其中蕴含着词与词之间的语义关系，比如 “猫” 和 “狗” 的语义相似性大于 “猫” 和 “计算机” 。这种语义相似性就是通过向量距离来计算的。</p><a id="more"></a><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><h2 id="1-1-词表示法简史"><a href="#1-1-词表示法简史" class="headerlink" title="1.1 词表示法简史"></a>1.1 词表示法简史</h2><p>自然语言文本在很长时间里并没有一个统一的表示法，用于计算机进行计算。通常人们给每个词分配一个 id，将词作为离散符号输入计算机系统。</p><ul><li><p><strong>查字典</strong></p><p>最直接的方法是创建一个词表，每个词分配一个唯一的 ID，比如：</p><blockquote><p>  我， 0</p><p>  是， 1</p><p>  谁， 2</p><p>  …</p></blockquote></li><li><p><strong>One-hot 编码</strong></p><p>同样是先建立一个词表，然后给词表中的每个词分配一个大小为词表大小的向量来表示词。每个词对应的向量中，只有一个位置的数字为 1，其他位置上的数字全部是 0。词与词的 one-hot 向量两两正交。整个词表就是一个 $1\times (N+1)$ 的矩阵，其中 $N$ 表示词表大小，额外的 1 表示 <em>UNK</em> ，即不在词表中的词的统一标识。比如：</p><blockquote><p>  我，[1, 0, 0, 0, …]</p><p>  是，[0, 1, 0, 0, …]</p><p>  谁，[0, 0, 1, 0, …]</p><p>  …</p></blockquote></li><li><p><strong>Distributional 表示法</strong></p><p>以上两种方法存在着一下几个问题：</p><ol><li>正交。词与词之间的语义丢失，我们没有办法从向量表示中得到词与词之间的关联性，</li><li>维度爆炸。通常一个词表会有几万个词，如果用 one-hot 表示，那么整个词表的 one-hot 就是一个几万乘几万的矩阵，极大地消耗了计算机资源。</li><li>矩阵稀疏。one-hot 矩阵中，除了特定位置上的数字是 1， 其余位置全部是 0，造成整个矩阵极端稀疏化，运算过程中极大地浪费了算力，</li></ol><p>因此，人们提出了分布式表示法，希望通过稠密向量来获得词嵌入矩阵。而得到稠密向量的方法就是我们下面要介绍的。</p></li></ul><h2 id="1-2-发展里程碑"><a href="#1-2-发展里程碑" class="headerlink" title="1.2 发展里程碑"></a>1.2 发展里程碑</h2><div class="timeline"><div class="timenode"><div class="meta"><p></p><p>2003 年 —— 前馈神经网络语言模型</p><p></p></div><div class="body"><p>2003 年 <em>Bengio</em> 等人提出前馈神经网络语言模型（FFNNLM），该模型的一个重要副产物就是词向量。相当于提出了一种利用语言模型训练词向量的方法，同样为后来的 Word2vec 打下了基础。</p></div></div><div class="timenode"><div class="meta"><p></p><p>2005 年 —— 层级 Softmax</p><p></p></div><div class="body"><p><em>Morin &amp; Bengio</em> 提出层级 softmax 思想。给定大小为 $V$ 的词表，通过一棵二叉树计算输出词的概率分布，将计算复杂度从 $O(V)$ 降到 $O(\log(V))$。这一思想成为后来 word2vec 模型的重要组成部分。</p></div></div><div class="timenode"><div class="meta"><p></p><p>2010 年 —— Noise Contrastive Estimation</p><p></p></div><div class="body"><p><em>Gutmann &amp; Hyvarinen</em> 提出噪声对比估计（NCE）方法。其基本思想是：一个好的模型可以利用<strong>逻辑回归</strong>从噪声中识别有用数据。后来 NCE 被 <em>Mnih &amp;Teh</em> 用于语言模型。后来 Word2vec 中的负采样技术就是 NCE 的简化版。</p></div></div><div class="timenode"><div class="meta"><p></p><p>2013 年 —— word2vec</p><p></p></div><div class="body"><p><em>Mikolov</em> 等人提出 word2vec 模型，使得大规模训练词向量成为现实。Word2vec 包含两个模型：<em>skip-gram</em> 和 <em>CBOW</em>。为了加速计算，word2vec 将 softmax 替换成层级 softmax，二叉树用的是哈夫曼树（Huffman tree）。</p></div></div><div class="timenode"><div class="meta"><p></p><p>2013 年 —— 负采样</p><p></p></div><div class="body"><p><em>Mikolov</em> 等人对原来的 word2vec 模型进行了优化，提出负采样的方法。负采样是噪声对比估计的简化版，比层级 softmax 更简单、更快。</p></div></div><div class="timenode"><div class="meta"><p></p><p>2014 年 —— GloVe</p><p></p></div><div class="body"><p><em>Pennington</em> 等人基于词共现的方法，提出另一种训练词向量的方法：Glove。与 word2vec 相比，两个模型表现相差不大，而 GloVe 更容易并行化训练。</p></div></div></div><p>接下来我们介绍两种主要的训练词嵌入的方法：</p><ul><li><strong>Context-based</strong>：给定上下文，设计模型预测中心词。</li><li><strong>Count-based</strong>：统计文本中词的共现矩阵，然后利用矩阵分解的方法对矩阵进行降维。</li></ul><h1 id="2-Context-based-Word2Vec"><a href="#2-Context-based-Word2Vec" class="headerlink" title="2. Context-based: Word2Vec"></a>2. Context-based: Word2Vec</h1><p>2013 年 <a href="http://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="noopener">Mikolov</a> 等人提出一种模型 —— Word2Vec。该模型包含两种架构：<em>Continuous Bag-of-Words（CBOW）</em> 和  <em>Continuous Skip-gram（Skip-gram）</em>，然后在随后的文章中提出了两种模型训练的优化方法：<em>hierarchical softmax（层级 softmax）</em> 和 <em>negative sampling（负采样）</em>。Mikolov 等人不是第一个提出连续向量表示词的人，但是他们提出的 word2vec 模型是第一个能应用在大规模语料上的模型，具有非常重要的意义。</p><p>假设有一个固定大小的滑动窗口，沿着句子从头到尾滑动取片段，每个窗口中中心词即为目标词（target），其他的词为上下文（context）。举个例子（假设已经分词）：</p><blockquote><p>  天才 就是 百分之一 的 灵感 加 百分之九十九 的 汗水。</p></blockquote><div class="table-container"><table><thead><tr><th>滑动窗口（size=5）</th><th>target</th><th>context</th></tr></thead><tbody><tr><td>[<font color="red">天才</font>, 就是, 百分之一]</td><td>天才</td><td>就是, 百分之一</td></tr><tr><td>[天才, <font color="red">就是</font>, 百分之一, 的]</td><td>就是</td><td>天才, 百分之一,的</td></tr><tr><td>[天才, 就是, <font color="red">百分之一</font>, 的, 灵感]</td><td>百分之一</td><td>天才, 就是, 的, 灵感</td></tr><tr><td>…</td><td>…</td><td>…</td></tr><tr><td>[灵感, 加, <font color="red">百分之九十九</font>, 的, 汗水]</td><td>百分之九十九</td><td>灵感, 加, 的, 汗水</td></tr><tr><td>[加, 百分之九十九, <font color="red">的</font>, 汗水]</td><td>的</td><td>加, 百分之九十九, 汗水</td></tr><tr><td>[百分之九十九, 的, <font color="red">汗水</font>]</td><td>汗水</td><td>百分之九十九, 的</td></tr></tbody></table></div><h2 id="2-1-Skip-Gram-Model"><a href="#2-1-Skip-Gram-Model" class="headerlink" title="2.1 Skip-Gram Model"></a>2.1 Skip-Gram Model</h2><p>Skip-gram 模型的核心思想是通过<strong>中心词</strong>预测<strong>上下文</strong>，即：</p><script type="math/tex; mode=display">p(w_{i-2}, w_{i-1}, w_{i+1}, w_{i+2}|w_i)</script><p>Skip-gram 模型采用的是一个浅层神经网络来计算这个概率分布。该一共只有三层：输入层、投影层（隐藏层）、输出层。模型结构如下图：</p><p><img width="500" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210811213240.jpg"></p><p>假设上下文中的词相互独立，则：</p><script type="math/tex; mode=display">p(w_{i-2}, w_{i-1}, w_{i+1}, w_{i+2}|w_i) = p(w_{i-2}|w_i)\cdot p(w_{i-1}|w_i) \cdot p(w_{i+1}|w_i)\cdot p(w_{i+2}|w_i)</script><p>相当于训练样本的（target，context）对拆解成 $2m$个（target，context word）对，其中 $m$ 表示滑动窗口除中心词外一半大小（很多地方会直接把 $m$ 定义为窗口大小），context word 表示上下文中每个词。例如，中心词为 “百分之九十九”，那么训练样本就是：</p><blockquote><p>  （百分之九十九，灵感）</p><p>  （百分之九十九，加）</p><p>  （百分之九十九， 的）</p><p>  （百分之九十九， 汗水）</p></blockquote><p>此时，上面的模型结构则等效于下图：</p><p><img width="500" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210811213223.jpg"></p><p>模型的输入是中心词，输出是上下文词之一。</p><p>假设词表 $\mathcal{V}$​​​​​ 的大小为 $V=|\mathcal{V}|$​​​​​，中心词在词典中的索引为 $i$​​​​​，上下文对应的词在词表中的索引为 $j$， $N$ 表示词向量 $\boldsymbol{v}_i$ 的维度，即 $\boldsymbol{v}_i \in \mathbb{R}^N$​​​​​。</p><p>关于模型的一些细节：</p><ul><li><p>$\boldsymbol{x}$​​​ 和 $\boldsymbol{y}$​​​ 都是 one-hot 编码，编码中 $i$​ 和 $j$​ 对应的位置为 1，其余位置全部为 0，$\boldsymbol{x},\boldsymbol{y} \in \mathbb{R}^{1\times V}$​。​​​</p></li><li><p>首先，将输入 $\boldsymbol{x}$​​ 与一个 $\boldsymbol{W}$​​ 矩阵相乘得到隐藏层 $\boldsymbol{h}$​​，其中 $\boldsymbol{W}\in \mathbb{R}^{V\times N}$​​​​​​​ ，则 $\boldsymbol{h}\in \mathbb{R}^{1\times N}$​​。实际上 $\boldsymbol{h}$​ 相当于 $\boldsymbol{W}$​ 的第 $i$​ 行：</p><script type="math/tex; mode=display">[0, ..., 1, ..., 0] \times \left[\begin{matrix}w_{00}, w_{01}, ..., w_{0N} \\\\\vdots \\\\w_{i0}, w_{i1}, ..., w_{iN} \\\\\vdots \\\\w_{V0}, w_{V1}, ..., w_{VN}\end{matrix}\right] = \left[w_{i0}, ...,w_{ii}, ..., w_{iN}\right]</script></li><li><p>用 $\boldsymbol{h}$​ 与另一个矩阵 $\boldsymbol{W’}\in \mathbb{R}^{N\times V}$​​ 相乘得到一个 $1\times V$ 的向量 $\boldsymbol{h’}$。</p></li><li><p>将 $\boldsymbol{h’}$ 进行归一化即可得到 $\boldsymbol{y}$​ 的 one-hot 概率分布：</p><script type="math/tex; mode=display">\boldsymbol{y} = \mathrm{softmax}(\boldsymbol{h'})</script></li><li><p>$\boldsymbol{y}$ 中概率最大的位置 $j$ 即对应词表第 $j$ 个词：</p><script type="math/tex; mode=display">w_j = \mathcal{V}_{j=\arg \max (\boldsymbol{y})}</script><p>比如：</p><blockquote><p>  假设 $\mathcal{V}=[我，的，灵感，天才，…]$</p><p>  $\boldsymbol{y} = [0.1, 0.2, 0.3, 0.2, 0.15, 0.05]$</p><p>  $\boldsymbol{y}$​ 中最大概率为 0.3，对应的索引是 2，即 $j=2$​​，</p><p>  则 $w_j = \mathcal{V}_2 = 灵感$​。</p></blockquote></li><li><p>模型中有两个矩阵 $\boldsymbol{W}$ 和 $\boldsymbol{W’}$​，非别对应着中心词的向量编码和上下文的向量编码。在自然语言处理应用中，一般使用中心词向量作为词的表征向量，即 $\boldsymbol{W}$ 就是我们最终得到的 word embedding。</p></li></ul><h2 id="2-2-CBOW-Model"><a href="#2-2-CBOW-Model" class="headerlink" title="2.2 CBOW Model"></a>2.2 CBOW Model</h2><p>连续词袋模型（CBOW）模型与 skip-gram 模型正相反，CBOW 是利用<strong>上下文</strong>来预测<strong>中心词</strong>，即：</p><script type="math/tex; mode=display">p(w_i|w_{i-2},w_{i-1},w_{i_1},w_{i+1})</script><p>模型结构如下图所示：</p><p><img width="500" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210811213150.png"></p><p>由于 CBOW 模型的输入有多个，所以我们将得到的 context 向量取平均，然后使用和 skip-gram 一样的方法来计算中心词的概率分布。</p><script type="math/tex; mode=display">\boldsymbol{h} = \frac{1}{2m}\sum \boldsymbol{x}_i \cdot \boldsymbol{W}</script><h2 id="2-3-Loss-object-Functions"><a href="#2-3-Loss-object-Functions" class="headerlink" title="2.3 Loss/object Functions"></a>2.3 Loss/object Functions</h2><p>无论是 skip-gram 模型还是 CBOW 模型，模型参数就是中心词向量和上下文词向量对应的嵌入矩阵 $\boldsymbol{W}$​​​​ 和 $\boldsymbol{W’}$​​​。给定输入词 $w_I$​​​ ，其在 $\boldsymbol{W}$​​​ 中对应的向量为 $\boldsymbol{v}_I$​​​​（即 $\boldsymbol{h}$​​）。$\boldsymbol{W’}$​​ 中每一列对应的词向量为 $\boldsymbol{v’}_j$​​​​​​。输出词 $w_O$​​ 对应的词向量为 $\boldsymbol{v’}_o$​​。</p><p>通过最小化损失函数对模型进行训练，下面以 skip-gram 为例介绍一些常用的损失/目标函数。</p><h3 id="2-3-1-标准-Softmax（Full-Softmax）"><a href="#2-3-1-标准-Softmax（Full-Softmax）" class="headerlink" title="2.3.1 标准 Softmax（Full Softmax）"></a>2.3.1 标准 Softmax（Full Softmax）</h3><p>用数学语言来描述上面的模型，即对于单个样本我们的目标函数为：</p><script type="math/tex; mode=display">p(w_O|w_I) = \frac{\exp(\boldsymbol{v'}_O^\mathsf{T} \cdot \boldsymbol{v}_I)}{\sum_{j=1}^V\exp(\boldsymbol{v'}_j^\mathsf{T} \cdot \boldsymbol{v}_I)}</script><p>从上式可以看出，对于任意单一样本，我们都需要对全词表进行指数求和，然而当 $V$ 非常大的时候（实际情况下 $V$​ 通常会有几万到几十万），计算将会变得非常复杂，根据 2.3.3 节关于交叉熵损失函数的介绍中，我们也可以看出进行后向传播的时候，计算过程同样是需要计算完整词表。因此，<a href="https://www.iro.umontreal.ca/~lisa/pointeurs/hierarchical-nnlm-aistats05.pdf" target="_blank" rel="noopener">Morin and Bengio</a> 等人在 2005 年的时候，提出了层级 Softmax，采用二叉树来加速计算。</p><h3 id="2-3-2-层级-Softmax（Hierarchical-Softmax）"><a href="#2-3-2-层级-Softmax（Hierarchical-Softmax）" class="headerlink" title="2.3.2 层级 Softmax（Hierarchical Softmax）"></a>2.3.2 层级 Softmax（Hierarchical Softmax）</h3><p><img width="500" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210811213210.png"></p><p>由于标准的 softmax 的计算复杂度较高，所以人们就不断思考对其进行优化。2001 年 <a href="https://arxiv.org/abs/cs/0108006" target="_blank" rel="noopener"><em>Goodman</em></a> 提出基于分类思想的加速方案。简单来说，假设我们词表中有 10000 个词，在传统的方法是在这 10000 个词上做 <em>softmax</em> 获得每个词的概率分布，然后取出概率最大的词，这样我们需要计算 10000 次。如果我们将这 10000 个词进行分类，假设分成 100 个类别，每个类别 100 个词。这个时候我们的计算过程是，先用一个 <em>softmax</em> 计算下一个词是属于什么类别，然后再用一个 <em>softmax</em> 计算概率最大的类别中的词的概率分布，这样我们只需要两个 100 次的计算量，计算速度直接提升 50 倍。</p><p>基于这个思想，<a href="https://www.iro.umontreal.ca/~lisa/pointeurs/hierarchical-nnlm-aistats05.pdf" target="_blank" rel="noopener"><em>Morin &amp; Bengio</em></a> 于 2005 年提出层级 softmax 的方法：使用平衡二叉树来构建这种分类关系，能够将计算复杂度降到 $O(\log_2(|\mathcal{V}|))$。由于他们利用的是先验知识（wordnet 中的 is-a 关系）来构建二叉树，最终的而效果并不理想。随后 <em>Mnih &amp; Hinton</em> 采用 boostrapping 的方法，从一个随机树开始自动学习一棵平衡二叉树。</p><p>直到 2013 年 <em>Mikolov</em> 等人提出使用 Huffman 树来代替平衡二叉树，使得层级 softmax 在效果和效率上都达到了新的高度。</p><h4 id="2-3-2-1-Huffman-树"><a href="#2-3-2-1-Huffman-树" class="headerlink" title="2.3.2.1 Huffman 树"></a>2.3.2.1 Huffman 树</h4><p>Huffman 树是一个用于数据压缩的算法。计算机中所有的数据都是以 0 和 1 进行存储的，最简单的数据编码方式是 <strong>等长编码</strong>。假设我们的数据中有 6 个字母，那么我们要将这些字母区分开，就至少需要三位二进制数来表示，$2^3=8&gt;6$，如果数据中的字符数更多，那就需要更长的二进制数进行编码。然而我们希望用尽可能少的二进制数对数据进行编码，尤其是实际生活中，有些字符使用频率非常高，另一些字符很少使用。我们希望使用频率高的字符编码长度更短，这样就可以节省存储空间了。所以这里就涉及到 <strong>变长编码</strong>。</p><p>比如，给定一个字符串 <code>aabacdab</code>，包含了 8 个字符，我们发现这个这个字符串中包含了 4 个不同的字符 <code>a</code>、<code>b</code>、<code>c</code>、<code>d</code>，分别对应的频率为 4、2、1、1。由于 <code>a</code> 的频率大于 <code>b</code>，<code>b</code> 的频率大于 <code>c</code> 和 <code>d</code>。所以，我们可以给 <code>a</code> 分配一个 1 位的编码长度，<code>b</code> 分配 2 位的编码长度，<code>c</code> 和 <code>d</code> 分配 3 位的编码长度：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a: 0</span><br><span class="line">b: 11</span><br><span class="line">c: 100</span><br><span class="line">d: 011</span><br></pre></td></tr></table></figure><p>所以，<code>aabacdab</code> 就被编码成了 <code>00110100011011</code>（<code>0|0|11|0|100|011|0|11</code>）。但是这个编码会有问题，那就是歧义性。因为我们不仅需要编码，还需要解码。当我们把数据存储到计算机以后，还需要从计算机中将数据读取出来。读取数据的过程就是解码的过程。如果我们用上面的编码进行存储解码的时候，会出现不同的解码方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0|011|0|100|011|0|11    adacdab</span><br><span class="line">0|0|11|0|100|0|11|011   aabacabd</span><br><span class="line">0|011|0|100|0|11|0|11   adacabab</span><br><span class="line">…</span><br></pre></td></tr></table></figure><p>为了避免解码歧义，我们需要保证编码满足 “<strong>前缀规则</strong>”：任意编码不能是其他编码的前缀。在上例中，<code>0</code> 是 <code>011</code> 的前缀，所以才会出现解码歧义性问题。</p><p>Huffman 树就是用来做这种变长编码的数据结构，构造过程如下：</p><ol><li><p>计算字符频率</p><p><img width="250" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/hf-character-frequency.png"></p></li><li><p>根据词频对字符进行排序，并按升序进行排列，得到序列 <code>Q</code>：</p><p><img width="250" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/hf-character-frequency-sorted.png"></p></li><li><p>创建一个空节点 <code>z</code>。节点 <code>z</code> 的左子节点是频率最低的字符，右子节点是频率第二低的字符。节点 <code>z</code> 的频率为左右子节点字符频率之和</p><p><img width="200" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/hf-encoding-1.png"></p></li><li><p>从 <code>Q</code> 中删除两个上一步中两个频率最低的字符，然后将两者频率之和添加到 <code>Q</code> 中。</p></li><li><p>重复 3-4 两步</p><table><tr>    <td><center><img width="250" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/hf-encoding-2.png"></center></td>    <td><center><img width="250" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/hf-encoding-3.png"></center></td></tr></table>            </li><li><p>将左侧的边赋值为 0，右侧的边为 1。</p><p><img width="250" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/hf-encoding-4.png"></p></li></ol><p>这样就构建好了一棵 Huffman 树。Huffman 编码就是找到从根节点到对应的字符之间的路径，然后将路径上的边对应的值拼接在一起。比如，上例中的 <code>A</code>、<code>B</code>、<code>C</code>、<code>D</code> 的编码分别为：<code>11</code>、<code>100</code>、<code>0</code>、<code>101</code>。</p><p>解码过程就是按照编码找到相应的路径：</p><p><img width="250" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/hf-decoding.png"></p><h4 id="2-3-2-2-基于-Huffman-树的层级-softmax"><a href="#2-3-2-2-基于-Huffman-树的层级-softmax" class="headerlink" title="2.3.2.2 基于 Huffman 树的层级 softmax"></a>2.3.2.2 基于 Huffman 树的层级 softmax</h4><p>Word2vec 中是预先统计语料中的词频，根据词频构建起一棵 Huffman 树。</p><blockquote><p>Huffman 树的每个叶子节点是词表中的一个词，每个除叶子节点和根节点以外的节点都表示一个二分类的概率，这个概率用来决定去往左右子节点的路径。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210811213210.png" alt></p><p>如上图所示，每个叶子结点（白圈）表示一个词表中的词 $w_i$，每个非叶子节点（灰圈）表示该路径上的概率。每个词都有一条唯一可达的路径，$n(w_i, j)$ 表示 $w_i$ 的路径上 第 $j$ 个节点。比如 $w_2$ 的路径就是 $n(w_2,1)n(w_2,2)n(w_2,3)w_2$。这条路径就对应 Huffman 编码。$w_2$ 的概率就是这条路径上每个节点的概率累积：</p><script type="math/tex; mode=display">p(w_O \vert w_I) = \prod_{j-1}^{L(w_O)-1} p(n(w_O,j))</script><p>其中 $L(w_O)$  表示 $w_O$ 的路径长度（Huffman 编码长度）。由于这是一个二叉树，相当于 $p(n(w_O,j))$ 是一个二分类，所以可以使用 $\sigma$ 函数进行计算：</p><script type="math/tex; mode=display">p(w_O \vert w_I) = \prod_{j=1}^{L(w_O)-1} \sigma({\mathbb{I}_{\text{turn}} \cdot\boldsymbol{v'}_{n(w_O, j)}}^{\top} \cdot \boldsymbol{v}_{w_I})</script><p>其中 $v’<em>{n(w_O,j)}$ 表示 $n(w</em>,j)$ 节点对应的向量，$\mathbb{I}<em>{\text{turn}}$ 表示特殊的标识函数：如果 $n(w_O,j+1)$ 是 $n(w_O,j)$ 的左子节点，则 $\mathbb{I}</em>{\text{turn}}=1$ ，否则为 $\mathbb{I}_{\text{turn}}=-1$。比如，上图中，我们要计算 $w_2$ 的概率：</p><script type="math/tex; mode=display">P(w_2 \mid w_I) = \sigma(\boldsymbol{v'}_{n(w_2,1)}^\top \boldsymbol{v}_I) \cdot \sigma(\boldsymbol{v'}_{n(w_2,2)}^\top \boldsymbol{v}_I) \cdot \sigma(-\boldsymbol{v'}_{n(w_2,3)}^\top \boldsymbol{v}_I)</script><p>内部节点的向量 $\boldsymbol{v’}_{n(w_i, j)}$ 可以通过训练得到。由 $\sigma(\cdot)$ 的定义：</p><script type="math/tex; mode=display">\sigma(z) = \frac{1}{1+\exp(-z)}</script><p>可知，整个概率的计算都无需遍历整个词表，只需计算 $\log_2(V)$ 次 $\sigma(\cdot)$ 即可，相当于将计算复杂度降低到了 $\log_2(V)$，大幅提升了计算效率。</p><p>由于 $\sigma(x)+\sigma(-x)=1$，给定中心词 $w_I$，生成词典 $\mathcal{V}$ 中任意词的体哦阿健概率之和也满足：</p><script type="math/tex; mode=display">\sum_{w\in \mathcal{V}} p(w|w_I)=1</script><p>由于 Huffman 树是用来对数据进行压缩编码的，其主要思想是高频的词距离根节点越近，那么它的路径就会越短，所需要计算的 $\sigma(\cdot)$ 函数的次数也会越少。所以相比平衡二叉树，Huffman 树的计算更有效率。</p><p>需要注意的是，我们在训练过程中，由于已知我们需要预测的词是哪一个，所以只需要计算对应的词的概率，然后进行优化即可。但是在推理过程中，我们并不知道哪个词是最优解，所以还是需要遍历整个词表。所以基于 Huffman 树的 word2vec 加速了训练过程而没有加速推理过程。</p><h3 id="2-3-3-交叉熵（Cross-Entropy）"><a href="#2-3-3-交叉熵（Cross-Entropy）" class="headerlink" title="2.3.3 交叉熵（Cross Entropy）"></a>2.3.3 交叉熵（Cross Entropy）</h3><p>交叉熵用于度量两个概率（$p$ 和 $q$​​）分布间的差异性信息的一个指标。计算公式如下：</p><script type="math/tex; mode=display">H(p, q) = -\sum_xp(x)\log q(x)</script><p>当交叉熵用于损失函数的时候，我们需要度量的是真实标签概率分布（$\boldsymbol{y}<em>{true}$）和模型输出标签概率分布（$\boldsymbol{y}</em>{pred}$）之间的差异，即：</p><script type="math/tex; mode=display">H(\boldsymbol{y}_{true}, \boldsymbol{y}_{pred}) = -\sum \boldsymbol{y}_{true}\cdot \log(\boldsymbol{y}_{pred})</script><p>在我们的情况下，$\boldsymbol{y}<em>{true}$​ 中只有 $y</em>{i=O}=1$​，其余位置 $y<em>j$​ 全部是 0，$\boldsymbol{y}</em>{pred} = p(w_i|w_I)$​。也就是说，我们只需要计算 $w_i=w_O$​ 位置的交叉熵即可，如下图所示。 </p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210813001314.jpg" alt></p><script type="math/tex; mode=display">\mathcal{L}_{\theta} = H(y_i, w_i) = -\sum_{i=1}^{V}y_i\log p(w_i|w_I) \overset{i=O}{=} -\log p(w_O|w_I)</script><p>式中 $\theta$ 表示我们需要训练的参数。如上面介绍的，交叉熵是用来度量两个分布的差异性的指标。对于我们的模型来说，当然是 $\boldsymbol{y}<em>{ture}$ 和 $\boldsymbol{y}</em>{pred}$​ 的差异越小越好。所以我们模型训练最终的目的是<strong>最小化交叉熵</strong>。</p><p>将 $p(w_O|w_I)$ 的 full softmax 公式代入交叉熵损失函数中得到：</p><script type="math/tex; mode=display">\mathcal{L}_{\theta} = -\log \frac{\exp(\boldsymbol{v'}_{O}^\mathsf{T} \cdot \boldsymbol{v}_I)}{\sum_{j=1}^V\exp(\boldsymbol{v'}_{j}^\mathsf{T} \cdot \boldsymbol{v}_I)}=-\boldsymbol{v'}_{O}^\mathsf{T} \cdot \boldsymbol{v}_I + \log \sum_{j=1}^V \exp(\boldsymbol{v'}_{j}^\mathsf{T} \cdot \boldsymbol{v}_I)</script><p>使用随机梯度下降算法对模型开始训练，需要计算损失函数的梯度。为了简化，我们令 $z<em>{IO}=\boldsymbol{v’}</em>{O}^\mathsf{T} \cdot \boldsymbol{v}<em>I$​ 及 $z</em>{Ij}=\boldsymbol{v’}_{j}^\mathsf{T} \cdot \boldsymbol{v}_I$​。</p><script type="math/tex; mode=display">\begin{equation} \nonumber\begin{aligned}\nabla_\theta \mathcal{L}_\theta &= \nabla_\theta(-z_{IO}+\log\sum_{j=1}^V\exp(z_{Ij}))\\\\                                 &= -\nabla_\theta z_{IO} + \nabla_\theta(\log \sum_{j=1}^V \exp(z_{Ij})) \\\\                                 &= -\nabla_\theta z_{IO} + \frac{1}{\sum_{j=1}^V\exp(z_{Ij})} \sum_{j=1}^V \exp(z_{Ij}) \cdot \nabla_\theta z_{Ij} \\\\                                 &= -\nabla_\theta z_{IO} + \sum_{j=1}^V \frac{\exp(z_{Ij})}{\sum_{j=1}^V\exp(z_{Ij})} \cdot \nabla_\theta z_{Ij} \\\\                                 &= -\nabla_\theta z_{IO} + \sum_{j=1}^V p(w_j|w_I) \cdot \nabla_\theta z_{Ij} \\\\                                 &= -\nabla_\theta z_{IO} + \mathbb{E}_{w_j \sim Q(\bar{w})} \cdot \nabla_\theta z_{Ij}\end{aligned}\end{equation}</script><p>将 $z<em>{IO}$ 和 $z</em>{Ij}$ 代回原式，根据下面两式：</p><script type="math/tex; mode=display">\nabla_\theta z_{IO} =  \frac{\partial (\boldsymbol{v'}_{O}^\mathsf{T} \cdot \boldsymbol{v}_I)}{\partial \boldsymbol{v}_I} = \boldsymbol{v'}_{O} ,\quad\nabla_\theta z_{Ij} = \frac{\partial (\boldsymbol{v'}_{j}^\mathsf{T} \cdot \boldsymbol{v}_I)}{\partial \boldsymbol{v}_I} = \boldsymbol{v'}_{j} \\\\</script><p>可得：</p><script type="math/tex; mode=display">\nabla_\theta \mathcal{L}_\theta = -\boldsymbol{v'}_{O} + \mathbb{E}_{w_j \sim Q(\tilde{w})} \cdot \boldsymbol{v'}_{j}</script><p>上式中 $Q(\tilde{w})$​ 表示噪声概率分布。根据上式，输出词的词向量越大，损失越小；而其他词的词向量越小，则损失越小。因此，交叉熵损失函数会使模型将正确的输出更加凸显，而对错误的输出进行压制，从而使参数达到最优。</p><h3 id="2-3-4-Noise-Contrastive-Estimation"><a href="#2-3-4-Noise-Contrastive-Estimation" class="headerlink" title="2.3.4 Noise Contrastive Estimation"></a>2.3.4 Noise Contrastive Estimation</h3><p>噪声对比估计（NCE）是通过简单的逻辑回归来区分目标词和非目标词的。</p><p>给定输入词 $w_I$，正确的输出词是 $w_O$。同时，我们可以从噪声词分布 $Q(\tilde{w})$ 中进行采样得到 $N$ 个负样本词：</p><script type="math/tex; mode=display">\tilde{w}_1,\tilde{w}_2,\dots,\tilde{w}_N \sim Q(\tilde{w})</script><p>此时，我们的样本就成了 $w_O$  为正样本，$\tilde{w}_1,\tilde{w}_2,\dots,\tilde{w}_N$ 为负样本，然后再用一个二分类器进行分类：</p><script type="math/tex; mode=display">\mathcal{L}_\theta = - \left[ \log p(d=1 \vert w_O, w_I) + \sum_{i=1, \tilde{w}_i \sim Q}^N \log p(d=0|\tilde{w}_i, w_I) \right]</script><p>$d$ 表示二分类器的输出标签。</p><p>当 $N$ 足够大时，根据<a href="https://en.wikipedia.org/wiki/Law_of_large_numbers" target="_blank" rel="noopener">大数定理</a>可得:</p><script type="math/tex; mode=display">\mathcal{L}_\theta = - \left[ \log p(d=1 \vert w_O, w_I) + N\mathbb{E}_{\tilde{w}_i \sim Q} \log p(d=0|\tilde{w}_i, w_I) \right]</script><p>为了计算概率分布 $p(d=1 \vert w<em>O, w_I)$，我们可以从联合概率 $p(d, w_j \vert w_I), w_j \in [w_O, \tilde{w}_1, \tilde{w}_2, \dots, \tilde{w}_N]$。我们有 $1/(N+1)$ 的概率得到 $w_j=w_O$，这个概率是一个条件概率 $p(w_j=w_O\vert w_I)$，同时我们有 $N/(N+1)$ 的概率得到噪声词 $q(\tilde{w}</em>{1:N})$。</p><script type="math/tex; mode=display">p(d, w_j | w_I) = \begin{cases} \frac{1}{N+1} p(w_O \vert w_I) & \text{if } d=1 \\\\ \frac{N}{N+1} q(\tilde{w}_{1:N}) & \text{if } d=0 \end{cases}</script><p>然后我们可以计算 $p(d=1 \vert w, w_I)$ 和 $p(d=0 \vert w, w_I)$：</p><script type="math/tex; mode=display">\begin{equation} \nonumber\begin{aligned} p(d=1 \vert w, w_I) &= \frac{p(d=1, w \vert w_I)}{p(d=1, w \vert w_I) + p(d=0, w \vert w_I)} \\\\                     &\overset{贝叶斯公式}{=} \frac{p(w \vert w_I)}{p(w \vert w_I) + Nq(\tilde{w})}\end{aligned}\end{equation}</script><script type="math/tex; mode=display">\begin{equation} \nonumber\begin{aligned}p(d=0 \vert w, w_I) &= \frac{p(d=0, w \vert w_I)}{p(d=1, w \vert w_I) + p(d=0, w \vert w_I)}\\\\ &\overset{贝叶斯公式}{=} \frac{Nq(\tilde{w})}{p(w \vert w_I) + Nq(\tilde{w})} \end{aligned}\end{equation}</script><p>最后，NCE 二分类器的损失函数为：</p><script type="math/tex; mode=display">\begin{equation} \nonumber\begin{aligned} \mathcal{L}_\theta & = - \left[ \log p(d=1 \vert w, w_I) + \sum_{\substack{i=1 \\\\ \tilde{w}_i \sim Q}}^N \log p(d=0|\tilde{w}_i, w_I) \right] \\\\                    & = - \left[ \log \frac{p(w \vert w_I)}{p(w \vert w_I) + Nq(\tilde{w})} + \sum_{\substack{i=1 \\ \tilde{w}_i \sim Q}}^N \log \frac{Nq(\tilde{w}_i)}{p(w \vert w_I) + Nq(\tilde{w}_i)} \right] \end{aligned}\end{equation}</script><p>然而，我们会发现公式中仍然有 $p(w \vert w_I)$ ，即仍然要对整个词表进行求和。为了方便，令 $Z(w_I)$ 为 $p(w\vert w_I)$ 的分母。NCE 对于 $Z(w_I)$ 的处理有两种假设：</p><ol><li><p>将 $Z(w_I)$ 视作常数。<a href="https://www.cs.toronto.edu/~amnih/papers/ncelm.pdf" target="_blank" rel="noopener">Mnih &amp; Teh, 2012</a> 证明对于参数量很大的神经网络模型来说，将 $Z(w_I)$ 固定为 1 对每个 $w_I$ 仍是成立的。此时，上面的损失函数可以简化成：</p><script type="math/tex; mode=display">\mathcal{L}_\theta = - \left[ \log \frac{\exp({v'_w}^{\top}{v_{w_I}})}{\exp({v'_w}^{\top}{v_{w_I}}) + Nq(\tilde{w})} + \sum_{\substack{i=1 \\ \tilde{w}_i \sim Q}}^N \log \frac{Nq(\tilde{w}_i)}{\exp({v'_w}^{\top}{v_{w_I}}) + Nq(\tilde{w}_i)}\right]</script><ul><li><p>这种情况下，我们可以证明，当 $N \to \infty$ 时，$\nabla<em>\theta \mathcal{L}</em>{NCE}=\nabla<em>\theta\mathcal{L}</em>{entrpy}$。证明过程可参看 <a href="https://www.cs.toronto.edu/~amnih/papers/ncelm.pdf" target="_blank" rel="noopener">Mnih &amp; Teh, 2012</a>。所以 NCE 的优化目标和交叉熵是一样的。作者还发现，当 $N=25$ 时，效果就已经与标准 softmax 效果差不多了，但是速度提升了 45 倍。</p></li><li><p>实际上 $Z(w_I)$ 到底取值是多少，不同作者都有过不同的尝试。但是从表现来看，不同点只是开始的时候收敛速度不同，最终的结果相差不大。</p></li><li><p>噪声分布 $Q(\tilde{w})$ 是一个可调参数，在选择 $Q$ 的分布的时候应该考虑两点：</p><p>① 接近真实数据分布；</p><p>② 容易采样</p></li></ul></li><li><p>将 $Z(w_I)$ 看作一个可训练的参数。</p></li></ol><p>从实践来看，当训练语料比较小的时候，$Z(w_I)$ 直接设置为常数效果更好。当有足够语料的时候，$Z(w_I)$ 作为可训练的一个参数效果更好。</p><p>NCE 处理似乎是故意绕开了标准 Softmax 计算量最大的分母，但其背后有充分的理论推导和证明。如果直接在最大似然估计上用这两种假设（之一）是否可行？</p><p>答案还真是不行。两种情况：</p><ol><li>如果最大似然估计中的 $Z(w<em>I)$ 为常数，那么 $\mathcal{L}</em>\theta$ 的第二项 $\log Z(w<em>I)$ 就是常数，这就意味着 $\mathcal{L}</em>\theta$ 的导数的第二项就为 0。也就是噪声词的词向量缺少约束，模型只需要让目标词的概率变大即可，最坏情况下预测所有词的概率为 1 即可。</li><li>如果 $Z(w_I)$ 为可训练的一个参数，这个参数没有和数据产生任何联系，只需要简单的变小，就可以让似然概率变大，得到一个完全与数据无关的结果，所以也不可行。</li></ol><h3 id="2-3-5-Negative-Sampling"><a href="#2-3-5-Negative-Sampling" class="headerlink" title="2.3.5 Negative Sampling"></a>2.3.5 Negative Sampling</h3><p><em><a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">Mikolov</a></em> 等人 2013 年提出的负采样方法是 NCE 的一个简化版变种。因为 word2vec 的目标是训练高质量的词向量，而不是对自然语言中的词进行建模。所以，<em>Mikolov</em> 等人在 NCE 的基础上进一步简化。</p><p>在 NCE 假设 $Z(w_I)=1$ 的基础上，进一步令 $N q(\tilde{w})=1$，则</p><script type="math/tex; mode=display">\begin{equation} \nonumber\begin{aligned}p(d=1\vert w, w_I) &= \frac{p(w \vert w_I)}{p(w \vert w_I)+1} \\\\                   &= \sigma({v'_{w}}^\top v_{w_I}) \\\\p(d=0\vert w, w_I) &= \frac{1}{p(w \vert w_I) + 1} \\\\                    &= 1 - \sigma({v'_{w}}^\top v_{w_I}) \\\\                   &= \sigma(-{v'_{w}}^\top v_{w_I})\end{aligned}\end{equation}</script><p>那么负采样的损失函数为：</p><script type="math/tex; mode=display">\mathcal{L}_\theta =  - \left[ \log \sigma({v'_{w}}^\top v_{w_I}) + \sum_{\substack{i=1 \\ \tilde{w}_i \sim Q}}^N \log \sigma(-{v'_{\tilde{w}_i}}^\top v_{w_I}) \right]</script><p>因为 $Nq(\tilde{w})=1$，所以 $q(\tilde{w})=1/N$ 是一个均匀分布。这里的均匀采样并不是每个词采样概率相同，而是在总的语料中进行均匀采样。这就意味着，它实际上是按照每个词本身的词频来进行采样的，词频越高，采样的概率就越高。这种情况下，模型最终拟合的实际是词的互信息。详细解答看这里：<a href="https://spaces.ac.cn/archives/5617" target="_blank" rel="noopener">“噪声对比估计”杂谈：曲径通幽之妙</a>。互信息与条件概率的区别就类似：条件概率反映“我认识周杰伦，周杰伦却不认识我”，而互信息反映的是“你认识我，我也认识你”。所以，通常负采样的效果比层次 softmax 要好一些。</p><h2 id="2-4-一些小技巧"><a href="#2-4-一些小技巧" class="headerlink" title="2.4 一些小技巧"></a>2.4 一些小技巧</h2><ul><li><p><strong>Soft slide window</strong>。利用滑动窗口构建输入词和输出词样本对的时候，我们可以给距离较远的词更低的权重。比如，设置窗口就最大值 $s<em>{\text{max}}$，然后每次训练时的真实窗口大小是从 $[1, s</em>{\text{max}}]$ 中进行随机采样。因此，每个上下文词都有 $1/(d)$ 的概率被取到，其中 $d$ 表示到中心词的距离。</p></li><li><p><strong>下采样高频词</strong>。极端高端的词可能由于太常见而无法得以区分（比如停用词）。而低频词可能会带有很重要的信息。为了平衡高频词和低频词，<em>Mikolov</em> 等人提出采样时对每个词施加一个采样概率 $1-\sqrt{t/f(w)}$。其中 $f(w)$ 表示词频，$t$ 表示相关性阈值，通常取值为 $10^{-5}$。</p></li><li><p><strong>先学词组</strong>。词组表示一个有意义的概念单元，而非简单的独立单词的组合。先学习这些词组将他们作为一个词单元来处理可以提升词向量的质量。比如基于 unigram 和 bigram 统计：</p><script type="math/tex; mode=display">s_{\text{phrase}} = \frac{C(w_i w_j) - \delta}{ C(w_i)C(w_j)}</script><p>其中 $C(\cdot)$ 表示 unigram $w<em>i$ 或 bigram $w_iw_j$ 的数量，$\delta$ 表示衰减阈值，防止过高频的词或词组。$s</em>{\text{phrase}}$ 得分越高则采样几率越高。为了形成长于两个单词的短语，我们可以随着分数截止值的降低多次扫描词汇表。</p></li></ul><h1 id="3-Count-based-GloVe"><a href="#3-Count-based-GloVe" class="headerlink" title="3. Count-based: GloVe"></a>3. Count-based: GloVe</h1><p>GloVe（<em>The Global Vector</em>）是 <a href="http://www.aclweb.org/anthology/D14-1162" target="_blank" rel="noopener">Pennington</a> 等人于 2014 年提出的模型。 GloVe 结合了 矩阵分解和 skip-gram 模型。</p><p>众所周知，统计数量和共现可以表示词义。为了区分上下文的词嵌入 $p(w_O \vert w_I)$，我们定义共现概率：</p><script type="math/tex; mode=display">p_{\text{co}}(w_k \vert w_i) = \frac{C(w_i, w_k)}{C(w_i)}</script><p>$C(w_i, w_k)$ 表示 $w_i$ 和 $w_k$ 的共现频率。假设有两个词 $w_i=”ice”$ 和 $w_j=”steam”$，第三个词 $\tilde{w}_k=”solid”$ 与 $”ice”$ 相关，但是与 $”steam”$ 无关，我们希望：</p><script type="math/tex; mode=display">p_{\text{co}}(\tilde{w}_k \vert w_i) > p_{\text{co}}(\tilde{w}_k \vert w_j)</script><p>因此 $\frac{p<em>{\text{co}}(\tilde{w}_k \vert w_i)}{p</em>{\text{co}}(\tilde{w}<em>k \vert w_j)}$ 会非常大。而如果 $\tilde{w}_k=”water”$ 与 $”ice”$ 和 $”steam”$ 都有关系，或者 $\tilde{w}_k=”fashion”$ 与两者都没有关系，$\frac{p</em>{\text{co}}(\tilde{w}<em>k \vert w_i)}{p</em>{\text{co}}(\tilde{w}_k \vert w_j)}$ 会接近 1。</p><p>以上描述给我们的直观感受就是，词义是通过共现概率分布的比例得到的，而非共现概率本身。所以，GloVe 模型是将第三个词的向量取决于另两个词之间的关系：</p><script type="math/tex; mode=display">F(w_i, w_j, \tilde{w}_k) = \frac{p_{\text{co}}(\tilde{w}_k \vert w_i)}{p_{\text{co}}(\tilde{w}_k \vert w_j)}</script><p>确定 $F$ 的函数形式过程如下：</p><ol><li><p>$F(w_i, w_j, \tilde{w}_k)$ 是考察 $i, j, k$ 三个词的相似关系，不妨单独考察 $i, j$ 两个词。在线性空间中，两个向量的相似性最简单的就是欧氏距离 $v_i, v_j$，所以 $F$ 可以是</p><script type="math/tex; mode=display">F(w_i-w_j, \tilde{w}_k) = \frac{p_{\text{co}}(\tilde{w}_k \vert w_i)}{p_{\text{co}}(\tilde{w}_k \vert w_j)}</script></li><li><p>$\frac{p<em>{\text{co}}(\tilde{w}_k \vert w_i)}{p</em>{\text{co}}(\tilde{w}_k \vert w_j)}$ 是一个标量，而 $F$ 是作用在两个向量上的，向量与矢量之间的关系自然就可以想到内积，所以进一步确定 $F$ 的形式：</p><script type="math/tex; mode=display">F((w_i-w_j) \top \tilde{w}_k) = F(w_i\top \tilde{w}_k-w_j \top \tilde{w}_k) = \frac{p_{\text{co}}(\tilde{w}_k \vert w_i)}{p_{\text{co}}(\tilde{w}_k \vert w_j)}</script></li><li><p>上式中，左边是差，右边是商。可以通过 $\exp(\cdot)$ 函数将两者结合在一起：</p><script type="math/tex; mode=display">\exp(w_i\top \tilde{w}_k-w_j \top \tilde{w}_k) = \frac{\exp(w_i \top \tilde{w}_k)}{\exp(w_j \top \tilde{w}_k)} = \frac{p_{\text{co}}(\tilde{w}_k \vert w_i)}{p_{\text{co}}(\tilde{w}_k \vert w_j)}</script></li><li><p>现在只要让分子分母分别相等，上式就可以成立：</p><script type="math/tex; mode=display">\exp(w_i \top \tilde{w}_k) = p_{co}(\tilde{w}_k \vert w_i) \\\\\exp(w_j \top \tilde{w}_k) = p_{co}(\tilde{w}_k \vert w_j)</script></li><li><p>只需要满足：</p><script type="math/tex; mode=display">{w_i}^\top \tilde{w}_k = \log p_{\text{co}}(\tilde{w}_k \vert w_i) = \log \frac{C(w_i, \tilde{w}_k)}{C(w_i)} = \log C(w_i, \tilde{w}_k) - \log C(w_i)</script></li><li><p>由于 $w_i$ 和 $\tilde{w}_k$ 是向量，所以 $\tilde{w}_k \top w_i = w_i \top \tilde{w}_k$ ，这就意味着上式中 $i, k$ 是顺序不敏感的，但是右边交换 $i,k$ 的顺序结果就会不同。为了解决这个对称性问题，模型引入两个偏置项 $b_i, b_k$，则模型变成：</p><script type="math/tex; mode=display">\log C(w_i, \tilde{w}_k) = w_i \top \tilde{w}_k + b_i +\tilde{b}_k</script></li><li><p>上面的公式只是理想状态下，实际上左右只能无限接近，所以损失函数定义为：</p><script type="math/tex; mode=display">\mathcal{L}_\theta = \sum_{i=1, k=1}^V ({w_i}^\top \tilde{w}_k + b_i + \tilde{b}_k - \log C(w_i, \tilde{w}_k))^2</script></li><li><p>根据经验，如果两个词共现次数越多，那么两个词在损失函数中的影响就应该越大，所以可以根据两个词共现的次数设计一个权重来对损失函数进行加权：</p><script type="math/tex; mode=display">\mathcal{L}_\theta = \sum_{i=1, j=1}^V f(C(w_i,\tilde{w}_k)) ({w_i}^\top \tilde{w}_k + b_i + \tilde{b}_k - \log C(w_i, \tilde{w}_k))^2</script><p>权重函数 $f(\cdot)$ 应该有以下性质：</p><p>① $f(0)=0$，即如果两个词没有共现过，那么权重为 0；</p><p>② $f(x)$ 必须是一个单调递增的函数。两个词共现次数越多，反而权重越小违反了设置权重项的初衷；</p><p>③ $f(x)$ 对于共现次数过多的词对，不能有太大的值，比如停用词。</p><p>有了这三个性质，可以将 $f(x)$ 定义为：</p><script type="math/tex; mode=display">f(x) = \begin{cases}(\frac{x}{x_{\text{max}}})^\alpha,\quad & \text{if}\quad x<x_{\text{max}}\\\\1, \quad & \text{otherwise}\end{cases}</script><p>根据经验 GloVe 作者认为 $x_\text{max}=100, \alpha=3/4$ 是一个比较好的选择。</p></li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><p><a href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/" target="_blank" rel="noopener">The amazing power of word vectors</a>, <em>Adrian Colyer</em></p></li><li><p><a href="https://lilianweng.github.io/lil-log/2017/10/15/learning-word-embedding.html#glove-global-vectors" target="_blank" rel="noopener">Learning Word Embedding</a>, <em>Lilian Weng</em></p></li><li><p><a href="https://jalammar.github.io/illustrated-word2vec/" target="_blank" rel="noopener">Illustrated word2vec</a>, <em>Jay Alammar</em></p></li><li><p><a href="https://zh.d2l.ai/chapter_natural-language-processing/word2vec.html" target="_blank" rel="noopener">Dive into deep learning: word2vec</a></p></li><li><p><a href="https://zh.d2l.ai/chapter_natural-language-processing/glove.html" target="_blank" rel="noopener">Dive into deep learning: GloVe</a></p></li><li><p><a href="http://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="noopener">Efficient Estimation of Word Representations in Vector Space</a> <em>Mikolov et al. 2013</em></p></li><li><p><a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">Distributed Representations of Words and Phrases and their Compositionality</a> <em>Mikolov et al. 2013</em></p></li><li><p><a href="http://www.aclweb.org/anthology/N13-1090" target="_blank" rel="noopener">Linguistic Regularities in Continuous Space Word Representations</a> <em>Mikolov et al. 2013</em></p></li><li><p><a href="http://arxiv.org/pdf/1411.2738v3.pdf" target="_blank" rel="noopener">word2vec Parameter Learning Explained</a> <em>Rong 2014</em></p></li><li><p><a href="http://arxiv.org/pdf/1402.3722v1.pdf" target="_blank" rel="noopener">word2vec Explained: Deriving Mikolov et al’s Negative Sampling Word-Embedding Method</a> <em>Goldberg and Levy 2014</em></p></li><li><p><a href="https://nlp.stanford.edu/pubs/glove.pdf" target="_blank" rel="noopener">GloVe: Global Vectors for Word Representation</a>, <em>Jeffrey Pennington et al. 2014</em></p></li><li><p><a href="https://www.gavagai.io/text-analytics/a-brief-history-of-word-embeddings/" target="_blank" rel="noopener">A Brief History of Word Embeddings</a>, <em>gavagai</em></p></li><li><p><a href="https://licor.me/post/word-representation/" target="_blank" rel="noopener">Word Representation</a>, <em>Chuanrong Li</em></p></li><li><p>Devopedia. 2020. “Word2vec.” Version 4, September 5. Accessed 2021-03-28. <a href="https://devopedia.org/word2vec" target="_blank" rel="noopener">https://devopedia.org/word2vec</a></p></li><li><p><a href="https://www.cnblogs.com/peghoty/p/3857839.html" target="_blank" rel="noopener">word2vec 中的数学原理详解</a>, <em>peghoty</em></p></li><li><p><a href="https://www.techiedelight.com/huffman-coding/" target="_blank" rel="noopener">Huffman Coding Compression Algorithm</a> </p></li><li><p><a href="https://www.programiz.com/dsa/huffman-coding" target="_blank" rel="noopener">Huffman Coding</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/368939108" target="_blank" rel="noopener">噪声对比估计 Noise Contrastive Estimation</a>, <em>码农要术</em></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/42073620" target="_blank" rel="noopener">(十五）通俗易懂理解——Glove算法原理</a>, <em>梦里寻梦</em> </p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://aylien.com/images/uploads/general/tumblr_inline_o8tinsmw081u37g00_540.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;词嵌入（word embedding）是一种用稠密向量来表示词义的方法，其中每个词对应的向量叫做词向量（word vector）。词嵌入通常是从语言模型中学习得来的，其中蕴含着词与词之间的语义关系，比如 “猫” 和 “狗” 的语义相似性大于 “猫” 和 “计算机” 。这种语义相似性就是通过向量距离来计算的。&lt;/p&gt;
    
    </summary>
    
      <category term="语言模型" scheme="https://rogerspy.gitee.io/categories/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="词向量" scheme="https://rogerspy.gitee.io/tags/%E8%AF%8D%E5%90%91%E9%87%8F/"/>
    
  </entry>
  
  <entry>
    <title>算法与数据结构（Python）：array</title>
    <link href="https://rogerspy.gitee.io/2021/08/09/ds-array/"/>
    <id>https://rogerspy.gitee.io/2021/08/09/ds-array/</id>
    <published>2021-08-09T14:21:24.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p>数组是一个容器，它容纳的元素应该是相同的数据类型。数组有两个重要概念：</p><ul><li><strong>元素</strong> —— 存储的数组中的数据称为元素。</li><li><strong>索引</strong> —— 数组中每个元素所在的位置。</li></ul><a id="more"></a><h1 id="1-数组的表示"><a href="#1-数组的表示" class="headerlink" title="1. 数组的表示"></a>1. 数组的表示</h1><p><img src="https://codingdict.com/static/assets/tutorials/python/ds/array_declaration.jpg" alt></p><ul><li><code>int</code>  表示数组中数字的类型为整型</li><li><code>array</code> 表示数组的名字</li><li><code>[10]</code> 表示数组的尺寸，即数组中有多少个元素</li><li><code>{35, 33, 42, ...}</code> 表示数组存储的数据</li></ul><p><img src="https://codingdict.com/static/assets/tutorials/python/ds/array_representation.jpg" alt></p><ul><li>索引从 0 开始</li><li>数组的尺寸是 10，表示它可以存储 10 个元素</li><li>每个元素可以通过索引访问</li></ul><h1 id="2-基本操作"><a href="#2-基本操作" class="headerlink" title="2. 基本操作"></a>2. 基本操作</h1><p>数组的基本操作包括：</p><ul><li><strong>遍历</strong> —— 逐个获得数组中的元素</li><li><strong>插入</strong> —— 在指定的位置（索引）处添加一个元素</li><li><strong>删除</strong> —— 删除指定位置（索引）处的元素</li><li><strong>搜索</strong> —— 搜索指定位置（索引）处的元素</li><li><strong>更新</strong> —— 更新指定位置（索引）处的元素</li></ul><p><code>python</code> 内置的 <code>array</code> 模块可以用来创建数组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> array <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">arrayName = array(typecode, [Initializerss])</span><br></pre></td></tr></table></figure><p>其中 <code>typecode</code> 用于定义数组中元素的数据类型，一些常用的 <code>typecode</code> 如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">typecode</th><th style="text-align:left">表示</th></tr></thead><tbody><tr><td style="text-align:center">b</td><td style="text-align:left">大小为1字节/ td&gt;的有符号整数</td></tr><tr><td style="text-align:center">B</td><td style="text-align:left">大小为1字节的无符号整数</td></tr><tr><td style="text-align:center">C</td><td style="text-align:left">大小为1字节的字符</td></tr><tr><td style="text-align:center">i</td><td style="text-align:left">大小为2个字节的带符号整数</td></tr><tr><td style="text-align:center">I</td><td style="text-align:left">大小为2个字节的无符号整数</td></tr><tr><td style="text-align:center">F</td><td style="text-align:left">大小为4字节的浮点</td></tr><tr><td style="text-align:center">d</td><td style="text-align:left">大小为8个字节的浮点</td></tr></tbody></table></div><p>举个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> array <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">array1 = array(<span class="string">'i'</span>, [<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>,<span class="number">50</span>])</span><br></pre></td></tr></table></figure><h2 id="2-1-遍历"><a href="#2-1-遍历" class="headerlink" title="2.1 遍历"></a>2.1 遍历</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> array1:</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">10</span></span><br><span class="line"><span class="number">20</span></span><br><span class="line"><span class="number">30</span></span><br><span class="line"><span class="number">40</span></span><br><span class="line"><span class="number">50</span></span><br></pre></td></tr></table></figure><h2 id="2-2-搜索"><a href="#2-2-搜索" class="headerlink" title="2.2 搜索"></a>2.2 搜索</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方法一</span></span><br><span class="line">print(array1[<span class="number">0</span>])</span><br><span class="line">print(array1[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法二</span></span><br><span class="line">print(array1.index(<span class="number">40</span>))</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">10</span></span><br><span class="line"><span class="number">30</span></span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure><h2 id="2-3-插入"><a href="#2-3-插入" class="headerlink" title="2.3 插入"></a>2.3 插入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array1.insert(<span class="number">1</span>,<span class="number">60</span>)</span><br><span class="line">print(array1)</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array(<span class="string">'i'</span>, [<span class="number">10</span>, <span class="number">60</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>])</span><br></pre></td></tr></table></figure><h2 id="2-4-删除"><a href="#2-4-删除" class="headerlink" title="2.4 删除"></a>2.4 删除</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array1.remove(<span class="number">40</span>)</span><br><span class="line">print(array1)</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array(<span class="string">'i'</span>, [<span class="number">10</span>, <span class="number">60</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">50</span>])</span><br></pre></td></tr></table></figure><h2 id="2-5-更新"><a href="#2-5-更新" class="headerlink" title="2.5 更新"></a>2.5 更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array1[<span class="number">2</span>] = <span class="number">80</span></span><br><span class="line">print(array1)</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array(<span class="string">'i'</span>, [<span class="number">10</span>, <span class="number">60</span>, <span class="number">80</span>, <span class="number">30</span>, <span class="number">50</span>])</span><br></pre></td></tr></table></figure><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://codingdict.com/article/4830" target="_blank" rel="noopener">Python-数组</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数组是一个容器，它容纳的元素应该是相同的数据类型。数组有两个重要概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;元素&lt;/strong&gt; —— 存储的数组中的数据称为元素。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;索引&lt;/strong&gt; —— 数组中每个元素所在的位置。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://rogerspy.gitee.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数组" scheme="https://rogerspy.gitee.io/tags/%E6%95%B0%E7%BB%84/"/>
    
  </entry>
  
  <entry>
    <title>ROC-AUC原理及计算方法</title>
    <link href="https://rogerspy.gitee.io/2021/07/29/roc-auc/"/>
    <id>https://rogerspy.gitee.io/2021/07/29/roc-auc/</id>
    <published>2021-07-29T15:26:19.000Z</published>
    <updated>2021-09-15T15:36:17.312Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转载自知乎用户<strong>码农要术</strong>的文章 <a href="https://zhuanlan.zhihu.com/p/141266017" target="_blank" rel="noopener">衡量指标篇：ROC-AUC</a>。</p></blockquote><h1 id="1-历史起源"><a href="#1-历史起源" class="headerlink" title="1. 历史起源"></a>1. 历史起源</h1><p>1941年，日军偷袭珍珠港，太平洋战争由此爆发。美军的雷达操作员（Radar operator）开始忙碌了起来，他们要识别出雷达屏幕上的光点是不是日本的战机。</p><a id="more"></a><p><img width="300" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/radar.jpg"></p><p>因为光点也有可能是我方军舰，也有可能是噪声。为了衡量识别的性能，研究者们设计了ROC曲线（Receiver operating characteristic curve）。所谓 Receiver 就是雷达接收器，operating characteristic 则是表明雷达操作员（Radar operator）的识别能力。</p><p>后来，ROC曲线被应用到了医学领域，还有机器学习领域。虽然名字比较奇怪，但是从诞生之初，ROC 曲线的目的就是衡量分类的性能。AUC 是 ROC 曲线下的面积（ <strong>A</strong>rea <strong>U</strong>nder the ROC <strong>C</strong>urve），有一些优雅的性质，我们后面再说。</p><p>想讲清楚 ROC曲线，先要讲一下混淆矩阵。</p><h1 id="2-混淆矩阵"><a href="#2-混淆矩阵" class="headerlink" title="2. 混淆矩阵"></a>2. 混淆矩阵</h1><p>先从两类开始说起，Positive 和 Negative，医学上叫阳性和阴性，机器学习称之为正例和负例。经过分类器的决策后，一般情况下，正例预测的有对有错，负例预测的也有对有错。这样数据会被划分成4部分：<strong>正例预测对（True Positive），正例预测错（False Negtative），负例预测对（True Negative），负例预测错（False Positive）。</strong></p><p><img width="600" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/confusion_matrix1.jpg"></p><h1 id="3-如何衡量分类器的好坏？"><a href="#3-如何衡量分类器的好坏？" class="headerlink" title="3. 如何衡量分类器的好坏？"></a>3. 如何衡量分类器的好坏？</h1><p>如何衡量一个分类器是有效的，而不是随机结果？还是以雷达识别敌舰这个场景来说明。</p><h2 id="3-1-两个假设"><a href="#3-1-两个假设" class="headerlink" title="3.1 两个假设"></a>3.1 两个假设</h2><ul><li><p>正负例等比例分布 </p></li><li><p>分类器输出是离散值, 也就是 label 的集合</p></li></ul><p>此时预测为正的结果可以划分成两部分：$TP$ 和 $FP$。比较两者关系，有如下结论：</p><ol><li>如果分类器是随机抽样，那么模型的输出和正负例比例一致。也就是 $TP=FP$。这个时候向识别出来的敌舰(预测为正的样本)开炮就是无差别攻击。</li><li>如果 $TP&gt;FP$, 可以说分类器有一定的甄别能力，战争中可以做到伤敌一千，自损八百。</li><li>如果是 $TP&lt;FP$ ,则说明分类器太差了，都不如随机抽样。用在战争中可以做到伤敌八百，自损一千。</li></ol><h2 id="3-2-一个假设"><a href="#3-2-一个假设" class="headerlink" title="3.2 一个假设"></a>3.2 一个假设</h2><blockquote><p>分类器输出是离散值, 也就是 label 的集合</p></blockquote><p>这个时候在用TP和FP的绝对值做对比就显得不公平, 举个例子，我方军舰10艘，敌方军舰100艘。预测并且击沉我方军舰 8 艘，敌方军舰 9 艘.绝对数量上确实是占优势，但是我方基本全军覆没，敌方绝大多数战力仍然保留。样本不均衡时，就得做归一化，看相对值。</p><p>这里引入两个概念：$TPR$ （True Positive Rate），$FPR$（False Positive Rate）</p><script type="math/tex; mode=display">TPR = \frac{TP}{TP+FN} \\\\FPR = \frac{\mathrm{FP}}{FP+TN}</script><p>$TPR$ 就是正例中预测正确的比率。$FPR$ 就是负例预测错的比例。</p><p>$TPR$ 和 $FPR$，比较两者关系，有如下结论：</p><ol><li>如果分类器是随机抽样，那么模型的输出和正负例比例一致。也就是 $TPR=FPR$。这个时候向识别出来的敌舰(预测为正的样本)开炮就是无差别攻击。</li><li>如果 $TPR&gt;FPR$, 可以说分类器有一定的甄别能力，战争中伤敌的比率高于自损的比率。</li><li>如果是 $TPR&lt;FPR$ ,则说明分类器太差，不如随机抽样。战争中伤敌的比率低于自损的比率。</li></ol><p>把 $TPR$ 和 $FPR$ 可视化，在 “<em>分类器输出是离散值, 也就是 label</em>“ 的假设下，$TPR$ 和 $FPR$ 是确定的，在二维坐标系上就是一个点。这个点就是 ROC 曲线的雏形。如下图：</p><p><img width="300" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/roc-auc8.jpg"></p><p>图中，E 点就是随机抽样 （$TPR=FPR$）。A，B，D点表示分类器有一定的甄别能力（$TPR&gt;FPR$）。其中 A 点对应的是一个完美的分类器，所有的正例被识别正确（$TPR=1$），所有的负例没有识别错误（$FPR=0$）。F 点就是分类器太差（$TPR&lt;FPR$），不如随机抽样。</p><h2 id="3-3-另一个假设"><a href="#3-3-另一个假设" class="headerlink" title="3.3 另一个假设"></a>3.3 另一个假设</h2><blockquote><p> 分类器输出连续值</p></blockquote><p>此时需要确定一个阈值来决定混淆矩阵和 $TPR$，$FPR$。</p><p>$TPR$ 的计算如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/roc-auc1.gif" alt></p><p>$FPR$ 的计算如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/roc-auc2.gif" alt></p><p>对于同一个分类器，不同的阈值对应不同的 $TPR$ 和 $FPR$，遍历阈值，即可得到 ROC 曲线。如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/roc-auc3.gif" alt></p><p>对于一个分类器，固定阈值，则得到一条 ROC 曲线。不同分类器会使预测的数据分布不同，在固定阈值的情况下，ROC 曲线变化如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/roc-auc4.gif" alt></p><p>直观来看，分类器的区分度越好，ROC 曲线则越往左上角靠拢。AUC 就越大。怎么解释？</p><h1 id="4-AUC-的概率解释"><a href="#4-AUC-的概率解释" class="headerlink" title="4. AUC 的概率解释"></a>4. AUC 的概率解释</h1><p>如果把 ROC 曲线看成是 $TPR$ 对 $FPR$ 的函数，$TPR=F(x)$ 我们对这个函数进行积分。如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/roc-auc5.jpg" alt></p><script type="math/tex; mode=display">AUC = \int_{0}^1F(x)dx</script><p>假设样本标签为 $y$，模型预测得分为 $s$，阈值为 $t$，正例的概率密度函数为 $f_1(s)$，负例的概率密度函数为 $f_0(s)$，则有</p><script type="math/tex; mode=display">TPR = F(x) = \int_t^\infty f_1(s)ds = P(s>t|y=1) \\\\FPR = x = \int_t^\infty f_0(s)ds = 1-\int_{-\infty}^t f_0(s)ds</script><p>$x$ 是 $t$ 的积分上限函数，根据积分上限函数的性质，得到</p><script type="math/tex; mode=display">\frac{dx}{dt} = \frac{d}{dt}(1-\int_{-\infty}^t f_0(s)ds) = -f_0(t) \\\\dx = -f_0(t)dt = -P(s'=t|y'=0)dt</script><p>则有</p><script type="math/tex; mode=display">\begin{equation} \nonumber\begin{aligned}AUC &= \int_0^1F(x)dx \\\\    &= \int_{\infty}^{-\infty} F(x)(-f_0(t))dt \\\\    &= \int_{-\infty}^{\infty} F(x)f_0(t)dt \\\\    &= \int_{-\infty}^{\infty} P(s>t|y=1)f_0(t)dt \\\\    &= \int_{-\infty}^{\infty} P(s>t|y=1)\times P(s/=t|y'=0)dt \\\\    &= \int_{-\infty}^{\infty} P(s>s'\ \&\ s'=t|y=1\ \&\ y'=0)dt \\\\    &= P(s>s'|y=1\ \&\ y'=1)\end{aligned}\end{equation}</script><p>上面推导需要解释一下：</p><ol><li>第二行，因为 $FPR$ 的取值范围从 0 到 1，对应着阈值是从大到小的变化。可以从动图中看出，只不过动图中阈值是从小到大，$FPR$ 是从 1 到 0。</li><li>第五行，$f_0(t)$ 的含义就是该样本为负例，得分为 $t$ 的概率。加引号是为了和正例区分。</li><li>第七行，该积分相当于是遍历阈值 $t$，同时负例得分和 $t$ 相同，也就是负例遍历所有可能的得分情况。</li></ol><p>最终得到这么一个结论：</p><blockquote><p><strong><em>AUC 的值，就是从样本中任意取一个正例和一个负例，正例得分大于负例得分的概率。</em></strong></p></blockquote><h1 id="5-AUC-的一些性质"><a href="#5-AUC-的一些性质" class="headerlink" title="5. AUC 的一些性质"></a>5. AUC 的一些性质</h1><p>从公式可以看出，$TPR$ 的计算只局限在正例中，$FPR$ 的计算只局限在负例中。正例（或负例）如果同分布的增加或者减小，对于 ROC 曲线来说没有区别，因为在正例（或负例）内部已经做了归一化。如下图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/roc-auc6.gif" alt></p><p>但如果正例（或负例）的比例在变化的同时，分布也发生了变化，那么 ROC 和 AUC 也会随之变化。如下图</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/roc-auc7.gif" alt></p><p>AUC 使用时，有几点需要注意：</p><ol><li>AUC 只关注预测的正负例的顺序关系，对于和 label 的拟合情况则不关注。比如正例得分都是 0.2，负例得分都是 0.1，AUC 很完美，但是 loss 就会比较大。</li><li>在非常不均衡的样本上，AUC 表现可能很好，但 precision 可能比较差。比如 $TP=80$，$FN=20$，$FP=200$，$TN=8000$，此时从 ROC 空间上看，效果还不错，但是 precision 低的可怜。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转载自知乎用户&lt;strong&gt;码农要术&lt;/strong&gt;的文章 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/141266017&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;衡量指标篇：ROC-AUC&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;1-历史起源&quot;&gt;&lt;a href=&quot;#1-历史起源&quot; class=&quot;headerlink&quot; title=&quot;1. 历史起源&quot;&gt;&lt;/a&gt;1. 历史起源&lt;/h1&gt;&lt;p&gt;1941年，日军偷袭珍珠港，太平洋战争由此爆发。美军的雷达操作员（Radar operator）开始忙碌了起来，他们要识别出雷达屏幕上的光点是不是日本的战机。&lt;/p&gt;
    
    </summary>
    
      <category term="博客转载" scheme="https://rogerspy.gitee.io/categories/%E5%8D%9A%E5%AE%A2%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="ROC-AUC" scheme="https://rogerspy.gitee.io/tags/roc-auc/"/>
    
  </entry>
  
  <entry>
    <title>Data Structures With Python</title>
    <link href="https://rogerspy.gitee.io/2021/07/27/data-structures-with-python/"/>
    <id>https://rogerspy.gitee.io/2021/07/27/data-structures-with-python/</id>
    <published>2021-07-27T15:41:30.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://mymasterdesigner.com/wp-content/uploads/2021/07/Data-Structures-With-Python-Big-Guide.png" alt></p><p>对于编程和计算机科学来说，数据结构是主要的主题，几乎涉及所有计算机领域。</p><p>本文介绍 <code>python</code> 中的一些数据结构。</p><a id="more"></a><h1 id="1-什么是数据结构"><a href="#1-什么是数据结构" class="headerlink" title="1. 什么是数据结构"></a>1. 什么是数据结构</h1><p>计算机科学中，数据结构是一种为了便于数据获取和修改的组织、管理和存储的形式。所有编程语言中，列表、字典和数组是最简单的数据结构。尽管语法不同，但是其内在的逻辑是相同的。因此，本文介绍的例子也适用于其它编程语言。</p><h1 id="2-字典、映射、哈希表"><a href="#2-字典、映射、哈希表" class="headerlink" title="2. 字典、映射、哈希表"></a>2. 字典、映射、哈希表</h1><p><code>Python</code> 中的字典（<code>dictionary</code>）可以用来存储任意数据，每条数据都有一个关键词。映射（<code>map</code>）也被称为哈希表（<code>hash table</code>）、查找表（<code>lookup table</code>）或者关联数组（<code>associative array</code>）。它可以更轻松地组织与特定关键字关联的数据，并以更有条理的形式呈现。</p><p>比如，用字典来存储每个人的年龄：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'Mark'</span>: <span class="number">12</span>,</span><br><span class="line">    <span class="string">'Alice'</span>: <span class="number">23</span>,</span><br><span class="line">    <span class="string">'David'</span>: <span class="number">8</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当我们想要查看特定的人的年龄时：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">'Mark'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output: 12</span></span><br></pre></td></tr></table></figure><blockquote><p>当然，你可以把数据写在同一行内，但是如果数据量比较大的时候，卸载一行看起来会比较乱。</p></blockquote><h2 id="2-1-OrderedDict-defaultdict-ChainMap"><a href="#2-1-OrderedDict-defaultdict-ChainMap" class="headerlink" title="2.1 OrderedDict, defaultdict, ChainMap"></a>2.1 <code>OrderedDict</code>, <code>defaultdict</code>, <code>ChainMap</code></h2><ul><li>字典是无序的，如果我们想按照顺序来存储数据，显然原生的字典就无能为力了，这个时候就可以用 <code>OrderedDict</code>：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections <span class="keyword">as</span> cs</span><br><span class="line"></span><br><span class="line">dict1 = cs.OrderedDict(</span><br><span class="line">    Mark=<span class="number">12</span>,</span><br><span class="line">    Alice=<span class="number">23</span>,</span><br><span class="line">    David=<span class="number">8</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>查看一下 <code>dcit1</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(dict1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ouput: ([('Mark', 12), ('Alice', 22), ('David', 8)])</span></span><br></pre></td></tr></table></figure><ul><li>当我们从字典里面取值的时候，遇到字典里并没有对应的 key 的时候，程序就会报错。这时 <code>defaultdict</code> 就派上用场了。<code>defaultdict</code> 的作用是在于，当字典里的key不存在但被查找时，返回的不是 <code>keyError</code> 而是一个默认值。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line">dict1 = defaultdict(int)</span><br><span class="line">dict2 = defaultdict(set)</span><br><span class="line">dict3 = defaultdict(str)</span><br><span class="line">dict4 = defaultdict(list)</span><br></pre></td></tr></table></figure><p><code>defaultdict</code> 接受 <code>int</code>, <code>set</code>, <code>str</code>, <code>list</code> 作为参数，也可以自定义函数作为参数。我们来看下，上面的例子中默认值分别是什么：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">print(dict1[<span class="number">1</span>]) </span><br><span class="line">print(dict2[<span class="number">1</span>])</span><br><span class="line">print(dict3[<span class="number">1</span>])</span><br><span class="line">print(dict4[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line">set()</span><br><span class="line"></span><br><span class="line">[]</span><br></pre></td></tr></table></figure><p>说明 <code>int</code> 默认值是 0，<code>set</code> 默认值是空集合，<code>str</code> 默认值是空字符串，<code>list</code> 默认值是空列表。</p><ul><li>当你有多个字典的时候，可以使用 <code>ChainMap</code> 将它们变成一个字典。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> ChainMap</span><br><span class="line"></span><br><span class="line">dict1 = &#123;<span class="string">"1"</span>: <span class="number">1</span>, <span class="string">"2"</span>: <span class="number">2</span>&#125;</span><br><span class="line">dict2 = &#123;<span class="string">"3"</span>: <span class="number">3</span>, <span class="string">"4"</span>: <span class="number">4</span>&#125;</span><br><span class="line">main = ChainMap(dict1, dict2)</span><br><span class="line"></span><br><span class="line">print(main[<span class="string">"3"</span>] , main[<span class="string">"1"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="number">3</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><h1 id="3-数组型数据结构"><a href="#3-数组型数据结构" class="headerlink" title="3. 数组型数据结构"></a>3. 数组型数据结构</h1><h2 id="3-1-列表"><a href="#3-1-列表" class="headerlink" title="3.1 列表"></a>3.1 列表</h2><p>列表可以存储任意类型的数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from 0 to 10 value</span></span><br><span class="line">arr = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># String Array</span></span><br><span class="line">arr1 = [<span class="string">"a"</span> , <span class="string">"b"</span> , <span class="string">"c"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get First Indexing</span></span><br><span class="line">arr1[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get from 0 to 4</span></span><br><span class="line">arr[<span class="number">0</span>:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Deleting Element</span></span><br><span class="line"><span class="keyword">del</span> arr[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Adding Element</span></span><br><span class="line">arr.append(<span class="number">11</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:  [1, 2, 3, 4]</span></span><br></pre></td></tr></table></figure><h2 id="3-2-元组"><a href="#3-2-元组" class="headerlink" title="3.2 元组"></a>3.2 元组</h2><p>元组是另一个可以存储任意类型数据的数据结构。与列表不同的是，元组是不可变的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tuple = (<span class="number">1</span> , <span class="number">2</span> , <span class="number">3</span>)</span><br><span class="line">tuple[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output: 1</span></span><br><span class="line"></span><br><span class="line">tuple1 = (<span class="string">"x"</span> , <span class="number">1</span> , <span class="number">1.25</span>)</span><br><span class="line">tuple1[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output: 1.25</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># you'll get error</span></span><br><span class="line"><span class="keyword">del</span> tuple[<span class="number">0</span>]</span><br><span class="line">tuple[<span class="number">1</span>] = <span class="string">"y"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 报错</span></span><br></pre></td></tr></table></figure><h2 id="3-3-array-数组"><a href="#3-3-array-数组" class="headerlink" title="3.3 array 数组"></a>3.3 <code>array</code> 数组</h2><p><code>python</code> 的 <code>array</code> 模块存储的数据包括整型、浮点型等等，它的空间占用率会更低。因为 <code>array</code> 只接受相同类型的数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Accessing array</span></span><br><span class="line"><span class="keyword">from</span> array <span class="keyword">import</span> array</span><br><span class="line"></span><br><span class="line"><span class="comment"># use type code</span></span><br><span class="line">arr = array(<span class="string">"f"</span> , [<span class="number">1.0</span> , <span class="number">1.2</span>])</span><br></pre></td></tr></table></figure><h2 id="3-4-字符串——字符编码的数组"><a href="#3-4-字符串——字符编码的数组" class="headerlink" title="3.4 字符串——字符编码的数组"></a>3.4 字符串——字符编码的数组</h2><p>字符串可以节省空间，因为它们被密集打包并专门处理特定的数据类型。 如果要保存 <code>Unicode</code> 文本，则应使用字符串。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">str = <span class="string">"55555"</span></span><br><span class="line">emoji = <span class="string">"😀"</span></span><br><span class="line"></span><br><span class="line">print(str , emoji)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Outtput: 55555 😀</span></span><br></pre></td></tr></table></figure><h2 id="3-5-字节-amp-字节数组"><a href="#3-5-字节-amp-字节数组" class="headerlink" title="3.5 字节 &amp; 字节数组"></a>3.5 字节 &amp; 字节数组</h2><p>字节（<em>Bytes</em>）存储的是 0 到 255 的数字，如果超过了这个范围程序会报错。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = bytes([<span class="number">1</span> , <span class="number">2</span> , <span class="number">3</span>])</span><br><span class="line">y = bytes([<span class="number">-1</span> , <span class="number">2</span> , <span class="number">3</span>])</span><br><span class="line">z = bytes([<span class="number">100</span> , <span class="number">200</span> , <span class="number">300</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Output: <span class="string">b'\x01\x02\x03'</span></span><br><span class="line">Output: error</span><br><span class="line">Output: error</span><br></pre></td></tr></table></figure><h1 id="4-集合-amp-多数组数据结构"><a href="#4-集合-amp-多数组数据结构" class="headerlink" title="4. 集合 &amp; 多数组数据结构"></a>4. 集合 &amp; 多数组数据结构</h1><h2 id="4-1-集合"><a href="#4-1-集合" class="headerlink" title="4.1 集合"></a>4.1 集合</h2><p>集合中不能包含相同的数据，且集合存储的是无序的数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">set = &#123;<span class="number">1</span> , <span class="number">2</span> , <span class="number">3</span>&#125;</span><br><span class="line"></span><br><span class="line">set.add(<span class="number">4</span>)</span><br><span class="line">set.remove(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h2 id="4-2-Frozen-Set"><a href="#4-2-Frozen-Set" class="headerlink" title="4.2 Frozen Set"></a>4.2 Frozen Set</h2><p>原始的集合元素可增可删，如果我们不想让集合发生改变，可以使用 <code>frozenset</code> 方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">frozen = frozenset(&#123;<span class="string">"x"</span> , <span class="string">"y"</span> , <span class="string">"z"</span>&#125;)</span><br><span class="line">frozen.add(<span class="string">"k"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 报错</span></span><br></pre></td></tr></table></figure><h2 id="4-3-Counter"><a href="#4-3-Counter" class="headerlink" title="4.3 Counter"></a>4.3 Counter</h2><p><code>counter</code> 可以对多个集合进行合并，并且可以对每个元素进行计数，得到每个元素的个数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line">merge = Counter()</span><br><span class="line"></span><br><span class="line">fruits = &#123;<span class="string">"apple"</span> , <span class="string">"banana"</span> , <span class="string">"orange"</span>&#125;</span><br><span class="line">merge.update(fruits)</span><br><span class="line">print(merge)</span><br><span class="line"></span><br><span class="line">fruits1 = &#123;<span class="string">"apple"</span> , <span class="string">"banana"</span> , <span class="string">"watermelon"</span>&#125;</span><br><span class="line">merge.update(fruits1)</span><br><span class="line">print(merge)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'orange'</span>: <span class="number">1</span>, <span class="string">'apple'</span>: <span class="number">1</span>, <span class="string">'banana'</span>: <span class="number">1</span>&#125;)</span><br><span class="line">&#123;<span class="string">'apple'</span>: <span class="number">2</span>, <span class="string">'banana'</span>: <span class="number">2</span>, <span class="string">'orange'</span>: <span class="number">1</span>, <span class="string">'watermelon'</span>: <span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure><h1 id="5-堆栈"><a href="#5-堆栈" class="headerlink" title="5. 堆栈"></a>5. 堆栈</h1><p>堆栈是支持用于插入和删除的快速输入/输出语义 (LIFO) 的项目集合。与数组和列表不同，你不能做随机访问，你需要使用函数进行插入和删除。</p><h2 id="5-1-list-实现堆栈"><a href="#5-1-list-实现堆栈" class="headerlink" title="5.1 list 实现堆栈"></a>5.1 <code>list</code> 实现堆栈</h2><p>你可以用 <code>append</code> 把数据加到最后，再用<code>pop</code>从 LIFO 队列中取出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">stack = []</span><br><span class="line"></span><br><span class="line">stack.append(<span class="number">1</span>)</span><br><span class="line">stack.append(<span class="number">2</span>)</span><br><span class="line">stack.append(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">print(stack)</span><br><span class="line"></span><br><span class="line">stack.pop()</span><br><span class="line">stack.pop()</span><br><span class="line"></span><br><span class="line">print(stack)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Output: [1,2,3]</span></span><br><span class="line"><span class="comment"># Output: [1]</span></span><br></pre></td></tr></table></figure><h2 id="5-2-deque-实现堆栈"><a href="#5-2-deque-实现堆栈" class="headerlink" title="5.2 deque 实现堆栈"></a>5.2 <code>deque</code> 实现堆栈</h2><p><code>deque</code> 与列表的区别还支持在固定时间添加和删除数组开头的元素。</p><p>因此，它比列表更有效、更快。 它还支持随机访问。</p><p>如果您尝试删除双端队列之间的数据，您可能会失去性能，主要原因是直到两端的所有元素都移动以腾出空间或填补空白。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line">stack = deque()</span><br><span class="line"></span><br><span class="line">stack.append(<span class="string">"a"</span>)</span><br><span class="line">stack.append(<span class="string">"b"</span>)</span><br><span class="line">stack.append(<span class="string">"c"</span>)</span><br><span class="line"></span><br><span class="line">print(stack)</span><br><span class="line"></span><br><span class="line">print(stack.pop())</span><br><span class="line">print(stack.pop())</span><br><span class="line"></span><br><span class="line">print(stack)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Output: deque(['a', 'b', 'c'])</span></span><br><span class="line"><span class="comment"># Output: deque(['a'])</span></span><br></pre></td></tr></table></figure><h1 id="6-Queues"><a href="#6-Queues" class="headerlink" title="6. Queues"></a>6. <code>Queues</code></h1><p>堆栈上的逻辑在这里略有不同，其中采用先进先出 (FIFO)，而在堆栈中采用先进后出。</p><p>我们这里可以使用栈中使用的 <code>list</code>和 <code>deque</code> 数据结构，也可以使用队列中的 <code>Queue</code> 类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">queue = []</span><br><span class="line"></span><br><span class="line">queue.append(<span class="string">"x"</span>)</span><br><span class="line">queue.append(<span class="string">"y"</span>)</span><br><span class="line">queue.append(<span class="string">"z"</span>)</span><br><span class="line"></span><br><span class="line">print(queue)</span><br><span class="line"></span><br><span class="line">queue.pop(<span class="number">0</span>)</span><br><span class="line">queue.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">print(queue)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Output: ['x', 'y', 'z']</span></span><br><span class="line"><span class="comment"># Output: ['z']</span></span><br></pre></td></tr></table></figure><h2 id="6-1-deque"><a href="#6-1-deque" class="headerlink" title="6.1 deque"></a>6.1 <code>deque</code></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line">queue = deque()</span><br><span class="line"></span><br><span class="line">queue.append(<span class="string">"x"</span>)</span><br><span class="line">queue.append(<span class="string">"y"</span>)</span><br><span class="line">queue.append(<span class="string">"z"</span>)</span><br><span class="line"></span><br><span class="line">print(queue)</span><br><span class="line"></span><br><span class="line">queue.popleft()</span><br><span class="line">queue.popleft()</span><br><span class="line"></span><br><span class="line">print(queue)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Output: deque(['x', 'y', 'z'])</span></span><br><span class="line"><span class="comment"># Output: deque(['z'])</span></span><br></pre></td></tr></table></figure><h2 id="6-2-queue"><a href="#6-2-queue" class="headerlink" title="6.2 queue"></a>6.2 <code>queue</code></h2><p>队列是一种结构，通过它我们可以确定队列可以容纳和存储多少数据。 它主要用于实现队列。</p><p>您可以通过将 <code>max size</code> 参数设置为 0 来创建无限队列，这符合 FIFO 规则。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"></span><br><span class="line">queue = Queue(maxsize = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Adding element</span></span><br><span class="line">queue.put(<span class="number">10</span>)</span><br><span class="line">queue.put(<span class="number">20</span>)</span><br><span class="line">queue.put(<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">print(queue.queue)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Removing element</span></span><br><span class="line">queue.get()</span><br><span class="line">queue.get()</span><br><span class="line"></span><br><span class="line">print(queue.queue)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Output: deque([10, 20, 30])</span></span><br><span class="line"><span class="comment"># Output: deque([30])</span></span><br></pre></td></tr></table></figure><h1 id="7-自定义数据类型"><a href="#7-自定义数据类型" class="headerlink" title="7. 自定义数据类型"></a>7. 自定义数据类型</h1><p>要更可控，您只需要您自己。 不要害怕创建和使用自己的类。 创建复杂的类有时会很累，但它会提高您的工作效率。</p><p>当您想通过方法向记录对象添加业务逻辑和活动时，创建自定义类是一个极好的解决方案。 然而，这意味着这些东西不再只是数据对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, note)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.note = note</span><br><span class="line"></span><br><span class="line">x = Student(<span class="string">"David"</span> , <span class="number">55</span>)</span><br><span class="line">y = Student(<span class="string">"Mark"</span> , <span class="number">35</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Access Data</span></span><br><span class="line">print(x.name , x.note)</span><br><span class="line"></span><br><span class="line">print(Student)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Output: David 55</span></span><br><span class="line"><span class="comment"># Output: &lt;main.Student object at 0x7f53925c2400&gt;</span></span><br></pre></td></tr></table></figure><h1 id="8-Reference"><a href="#8-Reference" class="headerlink" title="8. Reference"></a>8. Reference</h1><p><a href="https://mymasterdesigner.com/2021/07/06/data-structures-with-python-big-guide/" target="_blank" rel="noopener">Data Structures With Python – Big Guide</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://mymasterdesigner.com/wp-content/uploads/2021/07/Data-Structures-With-Python-Big-Guide.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;对于编程和计算机科学来说，数据结构是主要的主题，几乎涉及所有计算机领域。&lt;/p&gt;
&lt;p&gt;本文介绍 &lt;code&gt;python&lt;/code&gt; 中的一些数据结构。&lt;/p&gt;
    
    </summary>
    
      <category term="博客转载" scheme="https://rogerspy.gitee.io/categories/%E5%8D%9A%E5%AE%A2%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="Data Structure" scheme="https://rogerspy.gitee.io/tags/data-structure/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识建模（一）不那么简要的知识建模简介</title>
    <link href="https://rogerspy.gitee.io/2021/07/23/kg-data-modelling/"/>
    <id>https://rogerspy.gitee.io/2021/07/23/kg-data-modelling/</id>
    <published>2021-07-23T13:45:32.000Z</published>
    <updated>2021-09-15T15:36:17.312Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/kgicon.png" alt></p><h1 id="1-序言"><a href="#1-序言" class="headerlink" title="1. 序言"></a>1. 序言</h1><h2 id="1-1-什么是知识建模（语义建模）"><a href="#1-1-什么是知识建模（语义建模）" class="headerlink" title="1.1 什么是知识建模（语义建模）?"></a>1.1 什么是知识建模（语义建模）?</h2><blockquote><p>通过赋予数据指定的概念和数据之间的关系使数据包含语义。</p></blockquote><a id="more"></a><p>本质上讲，我们是通过明确数据代表的概念以及概念之间的关系来对数据进行建模。这样一个知识模型必须同时被人类和计算机所理解。对于人类来说相对比较容易，因为我们可以通过文字和数字对任意我们想要的东西进行建模，更重要的是赋予计算机更多的思考。</p><h2 id="1-2-我们为什么要知识建模？"><a href="#1-2-我们为什么要知识建模？" class="headerlink" title="1.2 我们为什么要知识建模？"></a>1.2 我们为什么要知识建模？</h2><p>对于数据来说，上下文信息非常重要。比如 “苹果”，我们是在讨论苹果电子产品还是水果？作为人类，当给定上下文的时候，我们可以很轻易的判断我们在讨论什么。当我说，“昨天买的苹果真好吃！”没有人会觉得我啃了一部手机。这就是问题的关键，没有上下文，数据所携带的信息总是不明确的。知识模型就是赋予数据以意义，避免这种歧义。</p><p>另外，还可以通过概念之间的关系帮助我们发散思维，找到数据之间的关联性。比如，“张三”是“张四”的父亲，而“张四”又是“张五”的父亲。人类可以很轻易的发现“张三”和“张五”是祖孙关系，但是如果没有知识模型构建的数据之间的关系，那么计算机是无法得知“张三”与“张五”的关系的。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210823222116.png" alt></p><h2 id="1-3-Led-Zeppelin-乐队知识模型"><a href="#1-3-Led-Zeppelin-乐队知识模型" class="headerlink" title="1.3 Led Zeppelin 乐队知识模型"></a>1.3 Led Zeppelin 乐队知识模型</h2><p>解释知识模型最好的方式就是举例子。下图展示了一个 Led Zeppelin 乐队简单的知识模型，包括一些与 Led Zeppelin 相关的概念和概念之间的关系。从图中我们可以看到， Led Zeppelin 是一个乐队，它有一张专辑叫做 “ Led Zeppelin IV”，这张专辑发布于 “1971年11月8日”，专辑中有一首歌叫做 “Black Dog”。“Jimmy Page” 是一个人，也是乐队的成员之一。当然这只是一小部分数据，我们仅仅用这部分数据作为一个例子进行介绍。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210823225518.png" style="zoom:67%;"></p><p>知识模型也可以将信息排列成层次结构。比如“唱片”和“歌曲”都是“具有创造性的作品”，同时“具有创造性的作品”还包括“书籍”、“电影”、“雕塑”等等。</p><p>上图中大多数的关系都是用实线箭头连接的，除了 “is a” 关系是用虚线箭头连接的。这是因为 “is a” 代表了一类特殊的关系——“rdf:type”。现在先不用管这啥，在后面的章节会介绍。</p><h1 id="2-知识模型基础"><a href="#2-知识模型基础" class="headerlink" title="2. 知识模型基础"></a>2. 知识模型基础</h1><p>虽然我么现在有了一张看起来很漂亮的图，但是如果计算机不能理解这张图，再漂亮也白搭。如何让计算机从图中抽取语义信息？下面我们就来介绍一个非常有用的工具——<strong>RDF</strong>。</p><h2 id="2-1-理解-RDF"><a href="#2-1-理解-RDF" class="headerlink" title="2.1 理解 RDF"></a>2.1 理解 RDF</h2><p>RDF（<em><a href="https://www.w3.org/TR/rdf11-concepts/" target="_blank" rel="noopener">Resource Description Framework</a></em>），翻译成中文：“资源描述框架”。顾名思义，它是一个用来描述数据的框架。在 RDF 数据模型中，我们用三元组来描述数据。一个三元组包含：<strong>subject</strong>、<strong>object</strong> 和 <strong>predicate</strong>，我们可以简单理解为，一个三元组就是有最简单的“主谓宾”构成的事实描述。RDF 图就是将很多三元组组合起来，其中 subject 和 object 是节点，predicate 是边。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210824001055.png" style="zoom:60%;"></p><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • NOTE            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            predicate 的方向很重要！如有必要，我们可以在三元组中定义双向关系，如下图：        </div>        </div>    </div><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210824002230.png" style="zoom:60%;"></p><p>对于 RDF 来说，节点有三种类型：</p><ul><li><strong>Resources</strong>：你想要描述的概念，比如 Led Zeppelin 乐队知识模型图中的矩形框中的内容。所有的概念都必须有一个唯一的标识符。</li><li><strong>Literals</strong>：即字面量，所有的字面量必须是字符串、数字和日期，如 Led Zeppelin 乐队知识模型图中的圆形框中的内容。</li><li><strong>Blank nodes</strong>：空节点表示没有唯一标识符的数据。</li></ul><h2 id="2-2-URI"><a href="#2-2-URI" class="headerlink" title="2.2 URI"></a>2.2 URI</h2><blockquote><p> 所有的 resources 和 predicates  都必须有<strong>机器可读</strong>的唯一标识符。</p></blockquote><p>为什么标识符的唯一性这么重要？比如，我们要对一个大型组织结构的雇员进行建模，其中可能有很多同名同姓的人，不考虑每个人的昵称的话，你怎么区分到底是财务室的张三，还是技术部的张三，又或者是食堂大厨张三？解决的办法就是每个人都分配一个唯一的标识符——Uniform Resource Identififiers（URIs）。</p><blockquote><p>URI 是一个字符串，用来准确的辨认特定的资源。为了保证统一性，所有的 URI 都有预定义的语法规则。</p></blockquote><p>URI 与我们平时上网的时候，各个网站的 URL 很像。URI 可以是层级结构的（hierarchical URIs），也可以是不透明的（opaque URI）。Hierarchical URI 会包含不同级别的信息，它可以编码资源的位置信息，即资源存放在模型中的哪个位置，或者共享资源的上下文信息。而 opaque URI 不会编码任何信息，它的后缀通常是随机字符串。</p><blockquote><ul><li>Hierarchical：&lt;<a href="http://mycompany.com/people/JediDepartment/LukeSkywalker" target="_blank" rel="noopener">http://mycompany.com/people/JediDepartment/LukeSkywalker</a> &gt;</li><li>Opaque：&lt;<a href="http://mycompany.com/AE04801" target="_blank" rel="noopener">http://mycompany.com/AE04801</a> &gt;</li></ul></blockquote><p>上例中 hierarchical URI 是人类可读的。从中我们知道 <em>Luke Skywalker</em> 为 <em>My Company</em> 工作，他是 <em>Jedi Department</em> 部门的员工。Opaque URI 同样是代表的 <em>Luke Skywalker</em>，但我们很难从中读取到任何信息。这就意味着 Opaque URI 的隐私性非常强。Opaque URI 的另一个优点是，不需要经常更新。比如如果 <em>Luke Skywalker</em> 变更了工作，从 <em>Jedi Department</em> 部门调到财务部门。Opaque URI 不需要做任何变更，而 Hierarchical URI 就要跟着改变。</p><p>从上面的例子中，我们可以看到两种 URI 各有优劣势，那么什么样的 URI 是一个好的 URI 呢？对此 <a href="https://www.ebi.ac.uk/rdf/documentation/good_practice_uri/" target="_blank" rel="noopener">European Bioinformatics Institute</a> 给出了几个性质，总结起来就是：</p><ul><li><strong>全局唯一性</strong>：一个 URI 决不能被两个不同的概念同时引用，即使两个概念是等价的。</li><li><strong>持久性</strong>：在可预见的将来，URI 要保证可用性。</li><li><strong>稳定性</strong>：一个 URI 决不能在不同的数据上重复使用，即使原来的版本已经删除了。</li><li><strong>可解析性（不可引用性）</strong>：简单来说就是，当用户在自己的浏览器上点击 URI 的时候，我们希望浏览器能重定向到合适的文档。</li></ul><p>在介绍 <em>Skywalker</em> 的时候，我随便造了一个 URI，用浏览器访问的时候会返回给你“404 Page Not Found”，也就是说这个 URI 不是一个好的 URI，因为它不满足上面第四个性质：可解析性。</p><p>下面我们回到 Led Zeppelin 的例子。我们用 URI 来表示三元组：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210824102652704.png" alt></p><p>当我们点击上面的 URI 的时候，浏览器会给我们展示相关的资源页面，比如：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210824103813.png" alt></p><p>上面我们是将一个三元组用 URI 来表示，而我们要做的是将所有的三元组都用 URI 来表示。但是全部都用完整的 URI 的话显得多余，所以我们可以用<strong>前缀</strong>：</p><ol><li>用 <code>@prefix</code> 作为定义前缀的开始；</li><li>选择前缀名；</li><li>描述前缀的命名空间；</li><li>以句号 <code>.</code> 结尾.</li></ol><div style="text-align: center">    <span style="background-color:#FFE4B5">@prefix</span>&nbsp;&nbsp;    <span style="background-color:#EE82EE">prefix name</span>&nbsp;&nbsp;    <span style="background-color:#FFC1C1">:</span>&nbsp;&nbsp;    <span style="background-color:#98FB98"> &lt; resource namespace &gt;</span>&nbsp;&nbsp;    <span style="background-color:#00BFFF">.</span></div><p>比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@prefix wd: &lt;https://www.wikidata.org/wiki/&gt;.</span><br></pre></td></tr></table></figure><p>现在回到上面的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@prefix wd: &lt;https://www.wikidata.org/wiki/&gt;.</span><br><span class="line">@prefix wdp: &lt;https://www.wikidata.org/wiki/Property&gt;</span><br><span class="line"></span><br><span class="line">&lt;wd:Q2331&gt; &lt;wdp:P527&gt; &lt;wd:Q16546&gt;</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210824112850.png" alt></p><p>现在我们就可以将整个图用 URI 来表示了：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/23.png" style="zoom: 67%;"></p><p>从图中我们可以看到，大多数的 URI 都是源自 Wikidata，少部分看起来有点奇怪，比如 <code>schema</code>、 <code>rdf</code>、<code>rdfs</code>。在介绍这几个比较奇怪的 URI 之前，我们再多说点关于<strong>空节点</strong>，即 “blank node” 的事情。</p><h2 id="2-3-Blank-node"><a href="#2-3-Blank-node" class="headerlink" title="2.3 Blank node"></a>2.3 Blank node</h2><p>空节点表示没有 URI 或者没有 Literal 的资源。听起来好像空节点是非法节点，但是实际上 RDF 允许这种情况的存在。必须说明的是，空节点只能出现在节点上，边是不允许的。空节点的 URI 并非是未知的，而是匿名的。当你想要表示一个复杂的资源特征，但是又不知道特征的名字，比如具体地址的街道门牌号。又或者你希望保护一些信息的隐私。类似于 “&lt;张三&gt;，&lt;生日&gt;，&lt;<em>*</em>&gt;”，我告诉你张三有一个属性叫做生日，但是我不告诉你他的生日是多少。</p><h2 id="2-4-RDFS"><a href="#2-4-RDFS" class="headerlink" title="2.4 RDFS"></a>2.4 RDFS</h2><p>RDFS 即 “RDF Schema”，本质上是一个知识建模的词表，用来表示 RDF 知识模型。RDFS 包含了一系列的属性和其他机制用于描述知识以及知识之间的关系。</p><p>在介绍 RDFS 之前需要搞清楚，我们为什么需要这样一个词表？在我们最初引入 Led Zeppelin 例子的时候，把虚线箭头以下的部分去掉似乎并不影响整体性。实际上这种知识建模的技术就是诞生于 20 世纪 60 年代的语义网络。语义网络有一定的优点，比如容易理解、相关概念容易聚类等。如上面例子展示的，对我们人类来说，整张图的概念很清晰，关系也很明确。但是这样一个图有一个非常严重的问题：</p><p><strong>没有标准！</strong></p><ol><li>节点和边的值没有标准，完全由用户自己定义。</li><li>多源数据融合困难。比如三元组1（鱼，住在，水里），三元组2（鱼，生活在，水里），对于我们人类来说，两个三元组描述的是同一个事实，应该融合成一个三元组。但是对于计算机来说，它无法理解“住在”和“生活在”是同一概念，所以就没有办法自动融合在一起。</li><li>无法区分概念和实例。比如在语义网络中（鱼，是，动物）中，“鱼”和“动物”是同级的概念。而我们很清楚，他们是有上下位关系的。</li></ol><p>为了解决语义网络存在的各种缺点，所以 W3C 制定了统一的标准，而这些标准就是相当于是由权威机构发布一些词汇，用来标准化常见的概念。比如，语义网络中</p><blockquote><p>鱼，是，动物</p><p>羊，是一种，动物</p></blockquote><p>我们将 “是”、“是一种”统一成 <code>rdf:type</code>，其中 <code>rdf</code> 表示前缀，完整的 URI 为 <code>http://www.w3.org/1999/02/22-rdf-syntax-ns#type</code>。这样既完成了标准化，也实现了 URI。</p><h3 id="2-4-1-RDFS-常用词汇"><a href="#2-4-1-RDFS-常用词汇" class="headerlink" title="2.4.1 RDFS 常用词汇"></a>2.4.1 RDFS 常用词汇</h3><p>下面我们就来介绍，RDFS 是如何构建标准化词表的。首先先介绍 “类” 的概念：</p><ul><li><p>知识可以被分成很多组，这些组称之为“<strong>类（class）</strong>”，这些类的成员就是“<strong>实例（instance）</strong>”。类和实例可以通过 URI 加以区分，也可以通过 RDF 属性加以描述。比如 <code>rdf:type</code> 就是用来描述是个实例属于某个类别：</p><blockquote><p>鱼，<code>rdf:type</code>，动物</p></blockquote></li><li><p>类也可以有子类 “<strong>subclass</strong>”，所有子类的实例也是类的实例。</p></li><li><p><strong>属性（property）</strong> 表示连接 subject 和 object 的边，即 predicate。</p></li></ul><p>用 RDFS 中一些重要的 Schema：</p><ul><li><p><strong><code>rdf:Class</code></strong>：定义类节点。比如 “Led Zeppelin”，“Led Zeppelin IV”，“Black Dog”，“Jimmy Page” 都是类。</p></li><li><p><strong><code>rdfs:Literal</code></strong>：用于定义节点的字面量，即字符串或者数字等。比如 “1971/8/11”。</p><div class="container" style="margin-top:40px;margin-bottom:20px;">    <div style="background-color:#54c7ec;height:36px;line-height:36px;vertical-align:middle;">        <div style="margin-left:10px">            <font color="white" size="4">                • NOTE            </font>        </div>    </div>    <div style="background-color:#F3F4F7">        <div style="padding:15px 10px 15px 20px;line-height:1.5;">            <code>rdfs:Literal</code> 本身是一个类，同时也是 <code>rdf:Class</code> 的实例。        </div>        </div>    </div></li><li><p><strong><code>rdf:Property</code></strong>：属性，即连接节点的边，还可以通过 <code>rdfs:subPropertyOf</code> 定义子属性。有一个很特殊而又常用的属性 <code>rdf:type</code> 用来描述一个实体是一个类别的实例，特殊在于我们经常缩写成 <code>a</code>。</p></li><li><p><strong><code>rdfs:domain</code> </strong> 和 <strong><code>rdfs:range</code></strong>：用来指定 <code>rdf:Property</code> 的定义域和值域。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;hasMember&gt; a rdf:Property . </span><br><span class="line">&lt;hasMember&gt; rdfs:domain &lt;Band&gt; . </span><br><span class="line">&lt;hasMember&gt; rdfs:range &lt;Person&gt; .</span><br><span class="line"></span><br><span class="line"># 用自然语言描述就是:</span><br><span class="line"># &lt;hasMember&gt; 是一条边</span><br><span class="line"># 定义域（subject）是&lt;Band&gt;</span><br><span class="line"># 值域（object）是&lt;Person&gt;</span><br><span class="line"># 等效于： &lt;Band&gt; &lt;hasMember&gt; &lt;Person&gt;</span><br></pre></td></tr></table></figure></li><li><p><strong><code>rdfs:subClassOf</code></strong>：定义类的子类，可以用来构建层级关系。比如，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;musician&gt; &lt;rdfsLsubClassOf&gt; &lt;Person&gt;</span><br></pre></td></tr></table></figure></li><li><p><strong><code>rdfs:label</code></strong> 和 <strong><code>rdfs:comments</code></strong>：之前介绍的 RDFS 词汇使数据变成计算机可读，但是我们还是希望对人类也可读。<code>rdfs:label</code> 是给一个节点人类可读的名字，帮助我们理解该节点，对 opaque URI 尤其有用。<code>rdfs:comment</code> 给节点添加文本描述，有点类似于给代码加注释。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;hasMember&gt; rdfs:label “has member” . </span><br><span class="line">&lt;hasMember&gt; rdfs:comment “Property relating a band to one of its band members” .</span><br></pre></td></tr></table></figure></li></ul><h2 id="2-5-OWL"><a href="#2-5-OWL" class="headerlink" title="2.5 OWL"></a>2.5 OWL</h2><p>RDFS 是节点和关系的标准化词汇表。随着技术的发展，人们发现 RDFS 的表达能力相当有限，因此提出了OWL。我们可以把 OWL 当做是 RDFS 的一个扩展，其添加了额外的预定义词汇。</p><p>OWL 也定义了类、属性和实例。不同于 RDFS，OWL 有更丰富，更严格的词汇表。这里可能会有一个疑问：既然 OWL 覆盖了 RDFS 大部分词汇，而且比 RDFS 表达能力更强，那我们为什么还要用 RDFS？</p><p>这就有点像牛刀可以用来杀鸡，但是不提倡，道理是一样的。虽然 OWL 表达能力更强，但是同时要求也更严格。当我们构建的知识模型本身就比较简单的时候， RDFS 就足够了。</p><p>OWL 的好处是，它支持和集成了 RDFS 的元素。比如 在OWL 里你仍可以用 <code>rdf:type</code>、<code>rdfs:range</code>、<code>rdfs:subPropertyOf</code> 等。</p><p>另外， OWL 也定义了自己的词汇，这些词汇比 RDFS 更细致。可以对一些属性添加约束，比如 <code>owl:allValuesFrom</code> 可以定义类的取值范围。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;hasParent&gt; owl:allValuesFrom &lt;Human&gt; .</span><br></pre></td></tr></table></figure><p>OWL 也支持用一系列操作来描述知识。比如，<code>owl:unionOf</code> 可以用来表示类，比如水果，包含甜水果和不甜的水果。<code>owl:unionOf</code> 的 subject 也可以是空节点。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Fruit&gt; owl:unionOf ( &lt;SweetFruit&gt; &lt;NonSweetFruit ) .</span><br></pre></td></tr></table></figure><p>我们还可以用 OWL 定义反向关系。还记得上面 Darth Vader 和 Luke 的例子吗？我们可以通过 <code>owl:inverseOf</code> 来定义 “<hasson>” 和 “<hasfather>” 是一对互逆关系：</hasfather></hasson></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;hasSon&gt; owl:inverseOf &lt;hasFather&gt; .</span><br></pre></td></tr></table></figure><p>OWL 中另一个重要的词汇是 <code>owl:sameAs</code>，它用来表示两个实体是相同的。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;BillClinton&gt; owl:sameAs &lt;WilliamJeffersonClinton&gt; .</span><br></pre></td></tr></table></figure><p>另一个用来表示两个类是等价的词汇是 <code>owl:equivalentClass</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;USPresident&gt; owl:equivalentClass &lt;PrincipalResidentOfWhiteHouse&gt; .</span><br></pre></td></tr></table></figure><p>说两个事情是等价的看起来有点多余，但是这确实是 OWL 的一大优势。用“等价”描述可以很轻松的引用外部知识模型和本体。比如，你可以说 wikidata 中的 Al Pacino 和 IMDB 中的 Al Pacino 是等价的。这个在帮助你构建知识模型的时候省掉很多工作。</p><p>最后， WOL 还可以定义两种不同的 property：</p><ul><li><strong>Object property</strong>：实体与实体之间的关系（&lt;hasMember &gt;）</li><li><strong>Data propery</strong>：实体与属性的关系（&lt;birthDay &gt;）</li></ul><h1 id="3-知识建模的步骤"><a href="#3-知识建模的步骤" class="headerlink" title="3. 知识建模的步骤"></a>3. 知识建模的步骤</h1><p>前面我们介绍了关于知识模型的理论，接下来就是如何用上面的理论一步一步从头构建一个知识模型。在实际的项目当中，不建议自己从头构建知识模型。现在有很多领域已经有专家、工程师构建好的知识模型，我们可以以此为基础进行开发。本文是为了介绍相关知识，所以介绍从头构建知识模型的内容。</p><p>这里我们主要介绍两点：</p><ul><li>RDF 知识模型的语法，或者更正式一点的说法——RDF 数据的序列化。</li><li>帮助我们进行知识建模的工具——Protege。</li></ul><h2 id="3-1-RDF-序列化"><a href="#3-1-RDF-序列化" class="headerlink" title="3.1 RDF 序列化"></a>3.1 RDF 序列化</h2><p>RDF 是一种知识描述框架，本质上也是一种模型。而序列化就是要讲这种描述框架落到实处。就像算法本身只是一种数学模型，而要如何实现算法就具体依赖你使用什么编程语言。RDF 三元组的序列化就是使用“编程语言”把它实现出来。RDF 序列化方法有多种：</p><ul><li><p>RDF/XML：就是用XML的格式来表示 RDF 数据。之所以提出这个方法，是因为 XML 的技术比较成熟，有许多现成的工具来存储和解析 XML。然而，对于 RDF 来说，XML 的格式太冗长，也不便于阅读，通常我们不会使用这种方式来处理 RDF 数据。</p></li><li><p>N-Triples：即用多个三元组来表示 RDF 数据集，是最直观的表示方法。在文件中，每一行表示一个三元组，方便机器解析和处理。</p></li><li>Turtle：应该是使用得最多的一种 RDF 序列化方式了。它比 RDF/XML 紧凑，且可读性比 N-Triples 好。</li><li>RDFa：即“The Resource Description Framework in Attributes”，是 HTML5 的一个扩展，在不改变任何显示效果的情况下，让网站构建者能够在页面中标记实体，像人物、地点、时间、评论等等。也就是说，将 RDF 数据嵌入到网页中，搜索引擎能够更好的解析非结构化页面，获取一些有用的结构化信息。</li><li>Json-LD：即“JSON for Linking Data”，用键值对的方式来存储 RDF 数据。</li></ul><p>我们以 Turtle 为例进行介绍，因为如上所述，它是目前用的最多的一种序列方法。Turtle 简称 TTL，表示 Time To Live。</p><h3 id="Turtle"><a href="#Turtle" class="headerlink" title="Turtle"></a>Turtle</h3><p>为了解释 TTL，我们从 TTL 的<a href="https://www.w3.org/TR/turtle/" target="_blank" rel="noopener">官网</a> 借来一个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@base &lt;http://example.org/&gt; .</span><br><span class="line">@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .</span><br><span class="line">@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .</span><br><span class="line">@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .</span><br><span class="line">@prefix rel: &lt;http://www.perceive.net/schemas/relationship/&gt; .</span><br><span class="line"></span><br><span class="line">&lt;#green-goblin&gt; rel:enemyOf &lt;#spiderman&gt; ;</span><br><span class="line">&lt;#green-goblin&gt; a foaf:Person ;    # in the context of the Marvel universe</span><br><span class="line">&lt;#green-goblin&gt; foaf:name &quot;Green Goblin&quot; .</span><br><span class="line"></span><br><span class="line">&lt;#spiderman&gt; rel:enemyOf &lt;#green-goblin&gt; ;</span><br><span class="line">&lt;#spiderman&gt; a foaf:Person ;</span><br><span class="line">&lt;#spiderman&gt; foaf:name &quot;Spiderman&quot;, &quot;Человек-паук&quot;@ru .</span><br></pre></td></tr></table></figure><p>下面我们详细介绍这个例子。</p><ul><li><p>1-5 行：定义前缀。任何好的 TTL 文件都是先定义前缀。其中 2-3 行是我们之前介绍的 <code>rdf</code> 和 <code>rdfs</code>，4-5 行是两个新词 <code>foaf</code> 和 <code>rel</code>。第 1 行 <code>base</code> 是比较特殊的前缀，它表示一个基础的 URI，所有 “&lt;&gt;” 内的内容都是属于它的命名空间。需要注意的是，每一行都必须有 “.” 作为结束。</p></li><li><p>7-9 行：描述了一条关于“&lt;#green-goblin&gt;”的知识。</p><ol><li><code>&lt;#green-goblin&gt;</code> 就是以 <code>@base</code> 为前缀的节点，等价于 <code>&lt;http://example.org/#green-goblin&gt;</code>。</li><li><code>rel:enemyOf</code> 表示以 <code>rel</code> 为前缀的关系，等价于 <code>&lt;http://www.perceive.net/schemas/relationship/enemyOf&gt;</code>。后面的 <code>&lt;#spiderman&gt;</code> 和 <code>&lt;#green-goblin&gt;</code> 类似。</li><li><code>a</code> 表示 <code>rdf:type</code>，后面的表示法都与之前类似。</li><li>这三行描述的信息是：Green Goblin 有一个敌人叫做 Spiderman，Green Goblin 是一个人，Green Goblin 的名字叫做 Green Goblin。</li><li>字符串用双引号表示。</li><li>注释用 “#” 。</li><li>每一个三元组都以 “<strong>空格  .</strong>” 结尾。</li></ol></li><li><p>每一个三元组都写 &lt;#green-goblin&gt; 有点重复，显得笨重又耗时。我们可以用 <strong>predicate list</strong> 的方法，将有相同 subject 的描述组合在一起，每条 predicate-object 描述用 “;” 分割。然后最后一条 predicate list 用空格和句号结束。我们将 7-9 行和11-13 行改造如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;#green-goblin&gt;</span><br><span class="line">    rel:enemyOf &lt;#spiderman&gt; ;</span><br><span class="line">    a foaf:Person ;    # in the context of the Marvel universe</span><br><span class="line">    foaf:name &quot;Green Goblin&quot; .</span><br><span class="line">    </span><br><span class="line">&lt;#spiderman&gt;</span><br><span class="line">    rel:enemyOf &lt;#green-goblin&gt; ;</span><br><span class="line">    a foaf:Person ;</span><br><span class="line">    foaf:name &quot;Spiderman&quot;, &quot;Человек-паук&quot;@ru .</span><br></pre></td></tr></table></figure></li><li><p>我们来看改造后的第 9 行。Spiderman 有两个名字，一个是英文名，另一个是俄文名。两个英文名之间用 “,” 分割。在俄文名的引号后面有一个语言标签 <code>@ru</code>。语言标签有两部分组成 <code>@</code> 和 语言关键词。</p></li></ul><p>除了上面的例子展示的一些语法，Turtle 还有一些其他语法。比如可以使用 <code>xsd</code> 里指定数据类型，比如日期、字符串、数字等。更详细内容可查看<a href="https://www.w3.org/TR/turtle/" target="_blank" rel="noopener">官网</a>。</p><p>另外，如果你之前已经用一种序列化方法实现了一个知识模型，现在处于某种原因，你想换成另一种序列化方法。不要紧，可以试试这个<a href="https://www.easyrdf.org/converter" target="_blank" rel="noopener">小工具</a>。</p><h2 id="3-2-知识建模工具"><a href="#3-2-知识建模工具" class="headerlink" title="3.2 知识建模工具"></a>3.2 知识建模工具</h2><p>在我看来，有两种方法构建知识模型：</p><ol><li>在文本编辑器中写三元组（手动或者自动）。</li><li>用工具创建三元组。</li></ol><p>就个人而言，我更喜欢前者。因为这样我们可以完全掌控我们要构建的知识模型。更重要的是，不需要从头学习一个工具的使用。当然，这纯属是个人原因。如果你找到一款趁手的工具，完全没必要手写三元组。如果你要手写三元组的话，这里推荐一个 python 包 —— <a href="https://rdflflib.readthedocs.io/en/stable/" target="_blank" rel="noopener">rdflib</a>。</p><p>考虑使用工具的话，现在市面上的开源而又实用的工具只有 <a href="https://protege.stanford.edu" target="_blank" rel="noopener">Protégé</a>。</p><p>Protégé 是斯坦福大学开发的一款本体（本文提到的“本体”等效于“知识模型”）建模工具。包括网页版和桌面版。</p><p>基本上，Protégé 允许用户添加类、对象和数据属性和实例，不需要手写三元组。用过给类添加子类来构建层级结构。知识建模完成以后可以将文件保存成 OWL 文件。</p><h2 id="3-3-按步骤构建知识模型"><a href="#3-3-按步骤构建知识模型" class="headerlink" title="3.3 按步骤构建知识模型"></a>3.3 按步骤构建知识模型</h2><p>斯坦福大学不仅开发了知识建模工具，还发表了一篇文章叫我们怎样进行知识建模——<a href="https://protege.stanford.edu/publications/ontology_development/ontology101.pdf" target="_blank" rel="noopener">《Ontology Development 101 guide》</a>。更详细的内容可以看另一篇文章：<a href="https://rogerspy.gitee.io/2021/08/23/kg-build-ontology-method/">知识图谱：知识建模（二）构建本体的方法论</a>，或者去看原文。</p><p>总的来说，知识建模有三大原则：</p><blockquote><ol><li>对于一个领域来说，没有一个唯一正确的建模方法。我们可以用不同的方法进行建模。最好的方法依赖于实际应用和需求。</li><li>本体构建（知识建模）需要不断迭代。</li><li>本体中的概念和关系应该接近你感兴趣的领域（物理上或逻辑上）。</li></ol></blockquote><p>具体步骤如下：</p><ol><li>确定知识领域及范围，即应用场景。</li><li>确定知识模型的重要概念。</li><li>本体复用。</li><li>定义类，类的层级结构以及关系。</li><li>定义限制条件。</li></ol><h2 id="3-4-可视化知识模型"><a href="#3-4-可视化知识模型" class="headerlink" title="3.4 可视化知识模型"></a>3.4 可视化知识模型</h2><p>无论你是怎么建模的，最后你都希望看下你建模出来的知识模型长什么样子。可视化工具有两种：</p><ol><li><p>Protege 自带的插件 OntoGraf。</p><p>在菜单中选择 Windows -&gt; Tabs -&gt; OntoGraf</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210826102126.png" alt></p></li><li><p>网页工具 <a href="http://vowl.visualdataweb.org/webvo" target="_blank" rel="noopener">WebVOWL</a>。</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/第34页-35.PNG" alt></p></li></ol><h1 id="4-知识模型查询"><a href="#4-知识模型查询" class="headerlink" title="4. 知识模型查询"></a>4. 知识模型查询</h1><p>在知识建模的时候，我们提到知识建模的目的是希望它能回答我们一些什么问题。现在，我们就要介绍一下我们该怎么像知识模型问问题。</p><h2 id="4-1-SPARQL"><a href="#4-1-SPARQL" class="headerlink" title="4.1 SPARQL"></a>4.1 SPARQL</h2><p><a href="https://www.w3.org/TR/2008/REC-rdf-sparql-query-20080115/" target="_blank" rel="noopener">SPARQL</a> 是 “SPARQL Protocol and RDF Query Language” 的首字母缩写。SPARQL 对 RDF 来说，就像 SQL 对关系型数据库一样。如果你会一点 SQL，那 SPARQL 学起来也会比较快。</p><p>我们用下面的例子做一个简单的介绍：</p><ul><li><p>例 1：</p><p><strong>数据</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@prefix schemaL &lt;http://schema.org&gt; .</span><br><span class="line">@prefix wd: &lt;http://www.wikidata.org/wiki/&gt; .</span><br><span class="line"></span><br><span class="line">wd:Q2331 schema:album wd:Q201940 .</span><br><span class="line">wd:Q2331 schema:album wd:Q209539 .</span><br></pre></td></tr></table></figure><p>上面这两个三元组相当于：Led Zeppelin (wd:Q2331) 有两张专辑，分别是 wd:Q201940 和 Q209539。</p><p><strong>Query</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@prefix schemaL &lt;http://schema.org&gt; .</span><br><span class="line">@prefix wd: &lt;http://www.wikidata.org/wiki/&gt; .</span><br><span class="line"></span><br><span class="line">SELECT ?album_name</span><br><span class="line">WHRER &#123;</span><br><span class="line">    wd:Q2331 schema:album ?album_name .</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这一条查询语句包括两部分：</p><ul><li>SELECT：定义我们要查询的变量（album_name），以 “?” 开头。</li><li>WHERE：定义了基本的匹配模式。</li></ul><p>上面的查询语句返回结果是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wd:Q201940</span><br><span class="line">wd:Q209539</span><br></pre></td></tr></table></figure></li><li><p>例 2：</p><p><strong>数据</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@prefix schemaL &lt;http://schema.org&gt; .</span><br><span class="line">@prefix wd: &lt;http://www.wikidata.org/wiki/&gt; .</span><br><span class="line">@prefix wpd: &lt;http://www.wikidata.org/wiki/Property&gt; .</span><br><span class="line"></span><br><span class="line">wd:Q201940 a wd:208569;  # Led Zeppelin IV 是一张专辑</span><br><span class="line">    wd:P1449 &quot;Led Zeppelin IV&quot;  # 有一个名字叫做 “Led Zeppelin IV”</span><br></pre></td></tr></table></figure><p>上面两条三元组的意思是：Led Zeppelin IV 是一张专辑，Led Zeppelin IV 的名字是 “Led Zeppelin IV”。现在我想查询所有叫做 “Led Zeppelin IV” 的专辑，那我可以用下面的查询语句：</p><p><strong>Query</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@prefix schemaL &lt;http://schema.org&gt; .</span><br><span class="line">@prefix wd: &lt;http://www.wikidata.org/wiki/&gt; .</span><br><span class="line">@prefix wpd: &lt;http://www.wikidata.org/wiki/Property&gt; .</span><br><span class="line"></span><br><span class="line">SELECT ?album</span><br><span class="line">WHERE &#123;</span><br><span class="line">    ?alubm wd:P1449 &quot;Led Zeppelin IV&quot; .</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，在 SELECT 语句中以 “?” 开头定义我们需要查询的变量，在 WHERE 中定义查询模式。最后返回结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wd:Q201940</span><br></pre></td></tr></table></figure></li></ul><p>以上两个例子都是非常基础的查询语句。<a href="https://www.stardog.com/tutorials/sparql/" target="_blank" rel="noopener">Stardog tutorial</a> 是一份非常好的 SPARQL 教程，我们可以在这里找到更详细的介绍。</p><h2 id="4-2-SPARQL-endpoint"><a href="#4-2-SPARQL-endpoint" class="headerlink" title="4.2 SPARQL endpoint"></a>4.2 SPARQL endpoint</h2><p>前面我们已经将某一领域的知识建模完成了，存成了 <code>.ttl</code> 文件。实际上这个 <code>.ttl</code> 文件是一个文本文件。我们说知识查询需要用到 SPARQL 查询语言。但是对于一个文本文件来说，我们能做的似乎只有字符串匹配或者正则匹配。SPARQL 语句应该在哪里输入？又在哪里执行？在哪里输出结果？也就是说，现在我们的知识模型文件和知识查询之间形成了一个断层。填补这个断层的就是 endpoint。这里我们介绍三种 SPARQL endpoint：</p><ul><li>D2RQ SPARQL endpoint</li><li>Apache jena SPARQL endpoint</li><li>rdflib</li></ul><h3 id="4-2-1-D2RQ-SPARQL-endpoint"><a href="#4-2-1-D2RQ-SPARQL-endpoint" class="headerlink" title="4.2.1 D2RQ SPARQL endpoint"></a>4.2.1 D2RQ SPARQL endpoint</h3><p>SPARQL endpoint 用于处理客户端的请求，可以类比web server提供用户浏览网页的服务。通过endpoint，我们可以把数据发布在网上，供用户查询。</p><p>D2RQ 是以虚拟 RDF 的方式访问关系型数据库的一个工具。也就是说，假设我们原来的数据是存储在关系型数据库中的，我们不需要把这些数据手动转成 RDF 型数据，就可以通过 D2RQ 使用 SPARQL 语句而不是 SQL 语句进行查询。</p><p>它的工作原理也很简单，就是 D2RQ 会根据关系型数据库的表结构生成一个 mapping 文件，然后 D2RQ 会根据这个 mapping 文件将 SPARQL 语句翻译成 SQL 语句，然后进行查询。这里隐藏着一个 D2RQ 很重要的一个功能：将关系型数据库的数据转化成 RDF 数据。这也是我们常用来批量生成 RDF 数据的方式。关于这个功能不是我们要介绍的，想了解更多可以去 <a href="http://d2rq.org/getting-started" target="_blank" rel="noopener">D2RQ 的官网</a>进行了解。</p><p>我们通过 D2RQ 中的 D2RQ server 功能来进行 SPARQL 查询。D2RQ server 架构图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/d2rq_server.png" alt></p><p>进入 D2RQ 目录，使用下面的命令启动 D2R Server:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d2r-server.bat mapping.ttl  # windows</span><br><span class="line">d2r-server mapping.ttl  # linux</span><br></pre></td></tr></table></figure><p>其中 “mapping.ttl” 就是我们上面说的 mapping 文件。</p><blockquote><p>这里多说两句：</p><p>以 mysql 关系型数据库为例。生成 mapping.ttl 的方式如下：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">generate-mapping -u root -o mapping.ttl jdbc:mysql:///demo</span><br></pre></td></tr></table></figure><blockquote><ul><li><code>generate-mapping</code> 是转换命令</li><li><code>-u root</code> 表示关系型数据库的用户名</li><li><code>-o mapping.ttl</code> 表示输出 mapping 文件名，可自定义</li><li><code>jdbc:mysql:///demo</code> 关系型数据库</li></ul><p>生成 mapping 文件之后，根据我们用 protege 知识建模的时候生成的 <code>.owl</code> 文件对 mapping文件进行修改，得到我们最终要用的 mapping 文件。更多关于 mapping 的语法参看：<a href="http://d2rq.org/d2rq-language" target="_blank" rel="noopener">The D2RQ Mapping Language</a>。</p></blockquote><p>此时，D2RQ 服务就启动的。我们有两种方式进行 RDF 查询：</p><ol><li>浏览器中查询</li><li>命令行查询</li><li>Python 脚本查询</li></ol><h4 id="4-2-1-1-浏览器查询"><a href="#4-2-1-1-浏览器查询" class="headerlink" title="4.2.1.1 浏览器查询"></a>4.2.1.1 浏览器查询</h4><p>在浏览器中输入 “<a href="http://localhost:2020/" target="_blank" rel="noopener">http://localhost:2020/</a> ”，可以看到如下页面：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/d2rs-screenshot-start.png" alt></p><p>点击页面右下角红框地方的链接，进入 endpoint。然后就可以进行查询了，如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/sparql_browser.png" style="zoom:80%;"></p><h4 id="4-2-1-2-命令行查询"><a href="#4-2-1-2-命令行查询" class="headerlink" title="4.2.1.2 命令行查询"></a>4.2.1.2 命令行查询</h4><p>使用 <code>d2rq-query</code> 工具进行命令行查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d2r-query mapping.ttl &quot;SELECT * &#123; ?s ?p ?o &#125; LIMIT 10&quot;</span><br></pre></td></tr></table></figure><p>或者加载一个查询文件，比如 <code>query.sparql</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d2r-query mapping.ttl @query.sparql</span><br></pre></td></tr></table></figure><h4 id="4-2-1-3-Python-脚本查询"><a href="#4-2-1-3-Python-脚本查询" class="headerlink" title="4.2.1.3 Python 脚本查询"></a>4.2.1.3 Python 脚本查询</h4><p>通常情况下，我们对 RDF 的查询是集成在代码中的。为了能在代码中进行查询，人们就开发了一个 python 库—— <a href="https://github.com/RDFLib/sparqlwrapper" target="_blank" rel="noopener">SPARQLWrapper</a>。这是一个Python下的包装器，可以让我们十分方便地和endpoint进行交互。下面是通过SPARQLWrapper，向 D2RQ endpoint发送查询“巩俐参演的评分大于 7 的电影有哪些”，得到结果的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> SPARQLWrapper <span class="keyword">import</span> SPARQLWrapper, JSON</span><br><span class="line"></span><br><span class="line">sparql = SPARQLWrapper(<span class="string">"http://localhost:2020/sparql"</span>)</span><br><span class="line">sparql.setQuery(<span class="string">"""</span></span><br><span class="line"><span class="string">    PREFIX : &lt;http://www.kgdemo.com#&gt;</span></span><br><span class="line"><span class="string">    PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    SELECT ?n WHERE &#123;</span></span><br><span class="line"><span class="string">      ?s rdf:type :Person.</span></span><br><span class="line"><span class="string">      ?s :personName '巩俐'.</span></span><br><span class="line"><span class="string">      ?s :hasActedIn ?o.</span></span><br><span class="line"><span class="string">      ?o :movieTitle ?n.</span></span><br><span class="line"><span class="string">      ?o :movieRating ?r.</span></span><br><span class="line"><span class="string">    FILTER (?r &gt;= 7)</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">"""</span>)</span><br><span class="line">sparql.setReturnFormat(JSON)</span><br><span class="line">results = sparql.query().convert()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results[<span class="string">"results"</span>][<span class="string">"bindings"</span>]:</span><br><span class="line">    print(result[<span class="string">"n"</span>][<span class="string">"value"</span>])</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">2046</span><br><span class="line">Memoirs of a Geisha</span><br><span class="line">荆轲刺秦王</span><br><span class="line">大红灯笼高高挂</span><br><span class="line">霸王别姬</span><br><span class="line">活着</span><br><span class="line">唐伯虎点秋香</span><br><span class="line">秋菊打官司</span><br><span class="line">菊豆</span><br><span class="line">Hong gao liang</span><br><span class="line">画魂</span><br><span class="line">风月</span><br><span class="line">Piao Liang Ma Ma</span><br><span class="line">The Hand</span><br></pre></td></tr></table></figure><h3 id="4-2-2-Apache-jena-SPARQL-endpoint"><a href="#4-2-2-Apache-jena-SPARQL-endpoint" class="headerlink" title="4.2.2 Apache jena SPARQL endpoint"></a>4.2.2 Apache jena SPARQL endpoint</h3><p> <a href="https://jena.apache.org/getting_started/index.html" target="_blank" rel="noopener">Apache jena</a> 严格来说是语义网框架，包括存储、查询和推理组件，架构图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/jena-architecture.png" style="zoom:70%;"></p><p>我们可以将 <code>.ttl</code> 数据存储到 jena 数据库中，然后通过 Fuseki 查询组件进行查询。操作流程同样是可以在浏览器端和命令行和通过调用 api 在代码里进行操作。这里我们不再详细介绍，在接下来的知识存储相关文章中进行详细介绍。</p><h3 id="4-2-3-RDFLib"><a href="#4-2-3-RDFLib" class="headerlink" title="4.2.3 RDFLib"></a>4.2.3 RDFLib</h3><p><a href="https://rdflib.readthedocs.io/en/stable/intro_to_sparql.html" target="_blank" rel="noopener">RDFLib</a> 是一个 python 包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> rdflib</span><br><span class="line">g = rdflib.Graph()</span><br><span class="line">g.parse(<span class="string">"demo.ttl"</span>)  <span class="comment"># 导入 ttl 文件</span></span><br><span class="line"></span><br><span class="line">knows_query = <span class="string">"""</span></span><br><span class="line"><span class="string">SELECT DISTINCT ?aname ?bname</span></span><br><span class="line"><span class="string">WHERE &#123;</span></span><br><span class="line"><span class="string">    ?a foaf:knows ?b .</span></span><br><span class="line"><span class="string">    ?a foaf:name ?aname .</span></span><br><span class="line"><span class="string">    ?b foaf:name ?bname .</span></span><br><span class="line"><span class="string">&#125;"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> qres:</span><br><span class="line">    print(<span class="string">f"<span class="subst">&#123;row.aname&#125;</span> knows <span class="subst">&#123;row.bname&#125;</span>"</span>)</span><br></pre></td></tr></table></figure><h3 id="4-2-4-Wikidata-Query-Service"><a href="#4-2-4-Wikidata-Query-Service" class="headerlink" title="4.2.4 Wikidata Query Service"></a>4.2.4 Wikidata Query Service</h3><p>如果你想快速体验 SPARQL 的话，wikidata 提供了一个服务——<a href="https://query.wikidata.org/" target="_blank" rel="noopener">Wikidata Query Service</a>：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20210826173014.png" style="zoom:80%;"></p><h2 id="4-3-更多-SPARQL-语法"><a href="#4-3-更多-SPARQL-语法" class="headerlink" title="4.3 更多 SPARQL 语法"></a>4.3 更多 SPARQL 语法</h2><p>接下来，我们再介绍一些比较常用的 SPARQL 语法。</p><h3 id="4-3-1-DISTINCT"><a href="#4-3-1-DISTINCT" class="headerlink" title="4.3.1 DISTINCT"></a>4.3.1 DISTINCT</h3><p>用于数据去重。</p><p><strong>数据</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@prefix  foaf:  &lt;http://xmlns.com/foaf/0.1/&gt; .</span><br><span class="line"></span><br><span class="line">_:x    foaf:name   &quot;Alice&quot; .</span><br><span class="line">_:x    foaf:mbox   &lt;mailto:alice@example.com&gt; .</span><br><span class="line"></span><br><span class="line">_:y    foaf:name   &quot;Alice&quot; .</span><br><span class="line">_:y    foaf:mbox   &lt;mailto:asmith@example.com&gt; .</span><br><span class="line"></span><br><span class="line">_:z    foaf:name   &quot;Alice&quot; .</span><br><span class="line">_:z    foaf:mbox   &lt;mailto:alice.smith@example.com&gt; .</span><br></pre></td></tr></table></figure><p><strong>Query</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PREFIX foaf:    &lt;http://xmlns.com/foaf/0.1/&gt;</span><br><span class="line">SELECT DISTINCT ?name WHERE &#123; ?x foaf:name ?name &#125;</span><br></pre></td></tr></table></figure><p><strong>返回结果</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;Alice&quot;</span><br></pre></td></tr></table></figure><h3 id="4-3-2-OPTIONAL"><a href="#4-3-2-OPTIONAL" class="headerlink" title="4.3.2 OPTIONAL"></a>4.3.2 OPTIONAL</h3><p>通常的 query 语句只会返回匹配到的数据，OPTIONAL 可以返回一些匹配到的数据包含的额外信息：</p><p><strong>数据</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@prefix foaf:       &lt;http://xmlns.com/foaf/0.1/&gt; .</span><br><span class="line">@prefix rdf:        &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .</span><br><span class="line"></span><br><span class="line">_:a  rdf:type        foaf:Person .</span><br><span class="line">_:a  foaf:name       &quot;Alice&quot; .</span><br><span class="line">_:a  foaf:mbox       &lt;mailto:alice@example.com&gt; .</span><br><span class="line">_:a  foaf:mbox       &lt;mailto:alice@work.example&gt; .</span><br><span class="line"></span><br><span class="line">_:b  rdf:type        foaf:Person .</span><br><span class="line">_:b  foaf:name       &quot;Bob&quot; .</span><br></pre></td></tr></table></figure><p><strong>Query</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;</span><br><span class="line">SELECT ?name ?mbox</span><br><span class="line">WHERE  &#123; ?x foaf:name  ?name .</span><br><span class="line">         OPTIONAL &#123; ?x  foaf:mbox  ?mbox &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><p><strong>返回结果</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;Alice&quot;&lt;mailto:alice@example.com&gt;</span><br><span class="line">&quot;Alice&quot;&lt;mailto:alice@work.example&gt;</span><br><span class="line">&quot;Bob&quot;</span><br></pre></td></tr></table></figure><h3 id="4-3-3-UNION"><a href="#4-3-3-UNION" class="headerlink" title="4.3.3 UNION"></a>4.3.3 UNION</h3><p>求并集。</p><p><strong>数据</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@prefix dc10:  &lt;http://purl.org/dc/elements/1.0/&gt; .</span><br><span class="line">@prefix dc11:  &lt;http://purl.org/dc/elements/1.1/&gt; .</span><br><span class="line"></span><br><span class="line">_:a  dc10:title     &quot;SPARQL Query Language Tutorial&quot; .</span><br><span class="line">_:a  dc10:creator   &quot;Alice&quot; .</span><br><span class="line"></span><br><span class="line">_:b  dc11:title     &quot;SPARQL Protocol Tutorial&quot; .</span><br><span class="line">_:b  dc11:creator   &quot;Bob&quot; .</span><br><span class="line"></span><br><span class="line">_:c  dc10:title     &quot;SPARQL&quot; .</span><br><span class="line">_:c  dc11:title     &quot;SPARQL (updated)&quot; .</span><br></pre></td></tr></table></figure><p><strong>Query</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PREFIX dc10:  &lt;http://purl.org/dc/elements/1.0/&gt;</span><br><span class="line">PREFIX dc11:  &lt;http://purl.org/dc/elements/1.1/&gt;</span><br><span class="line"></span><br><span class="line">SELECT ?title</span><br><span class="line">WHERE  &#123; &#123; ?book dc10:title  ?title &#125; UNION &#123; ?book dc11:title  ?title &#125; &#125;</span><br></pre></td></tr></table></figure><p><strong>返回结果</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&quot;SPARQL Protocol Tutorial&quot;</span><br><span class="line">&quot;SPARQL&quot;</span><br><span class="line">&quot;SPARQL (updated)&quot;</span><br><span class="line">&quot;SPARQL Query Language Tutorial&quot;</span><br></pre></td></tr></table></figure><h3 id="4-3-4-FILTER"><a href="#4-3-4-FILTER" class="headerlink" title="4.3.4 FILTER"></a>4.3.4 FILTER</h3><p>过滤器。</p><p><strong>数据</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@prefix dc:   &lt;http://purl.org/dc/elements/1.1/&gt; .</span><br><span class="line">@prefix :     &lt;http://example.org/book/&gt; .</span><br><span class="line">@prefix ns:   &lt;http://example.org/ns#&gt; .</span><br><span class="line"></span><br><span class="line">:book1  dc:title  &quot;SPARQL Tutorial&quot; .</span><br><span class="line">:book1  ns:price  42 .</span><br><span class="line">:book2  dc:title  &quot;The Semantic Web&quot; .</span><br><span class="line">:book2  ns:price  23 .</span><br></pre></td></tr></table></figure><p><strong>Query</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PREFIX  dc:  &lt;http://purl.org/dc/elements/1.1/&gt;</span><br><span class="line">SELECT  ?title</span><br><span class="line">WHERE   &#123; ?x dc:title ?title</span><br><span class="line">          FILTER regex(?title, &quot;^SPARQL&quot;) </span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p><strong>返回结果</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;SPARQL Tutorial&quot;</span><br></pre></td></tr></table></figure><h3 id="4-3-5-ORDER-BY"><a href="#4-3-5-ORDER-BY" class="headerlink" title="4.3.5 ORDER BY"></a>4.3.5 ORDER BY</h3><p>排序。</p><p><strong>数据</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@prefix dc:   &lt;http://purl.org/dc/elements/1.1/&gt; .</span><br><span class="line">@prefix :     &lt;http://example.org/book/&gt; .</span><br><span class="line">@prefix ns:   &lt;http://example.org/ns#&gt; .</span><br><span class="line">@prefix schema: &lt;https://schema.org&gt; .</span><br><span class="line"></span><br><span class="line">:book1  dc:title  &quot;SPARQL Tutorial&quot; .</span><br><span class="line">:book1  ns:price  42 .</span><br><span class="line">:book2  dc:title  &quot;The Semantic Web&quot; .</span><br><span class="line">:book2  ns:price  23 .</span><br><span class="line">:book3 schema:name &quot;A data engineer&apos;s guide to semantic models&quot; .</span><br><span class="line">:book3 ns:price 0 .</span><br></pre></td></tr></table></figure><p><strong>Query</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PREFIX  dc:  &lt;http://purl.org/dc/elements/1.1/&gt;</span><br><span class="line">PREFIX  schema: &lt;https://schema.org&gt; .</span><br><span class="line">SELECT  ?title</span><br><span class="line">WHERE   &#123; </span><br><span class="line">    &#123; ?x dc:title ?title&#125; UNION &#123;?x schema:name ?title&#125;</span><br><span class="line">        &#125;</span><br><span class="line">ORDER BY DESC(?title)</span><br></pre></td></tr></table></figure><p><strong>返回结果</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;A data engineer&apos;s guide to semantic models&quot;</span><br><span class="line">&quot;SPARQL Tutorial&quot;</span><br><span class="line">&quot;The Semantic Web&quot;</span><br></pre></td></tr></table></figure><h3 id="4-3-6-LIMIT"><a href="#4-3-6-LIMIT" class="headerlink" title="4.3.6 LIMIT"></a>4.3.6 LIMIT</h3><p><strong>数据</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@prefix dc:   &lt;http://purl.org/dc/elements/1.1/&gt; .</span><br><span class="line">@prefix :     &lt;http://example.org/book/&gt; .</span><br><span class="line">@prefix ns:   &lt;http://example.org/ns#&gt; .</span><br><span class="line">@prefix schema: &lt;https://schema.org&gt; .</span><br><span class="line"></span><br><span class="line">:book1  dc:title  &quot;SPARQL Tutorial&quot; .</span><br><span class="line">:book1  ns:price  42 .</span><br><span class="line">:book2  dc:title  &quot;The Semantic Web&quot; .</span><br><span class="line">:book2  ns:price  23 .</span><br><span class="line">:book3 schema:name &quot;A data engineer&apos;s guide to semantic models&quot; .</span><br><span class="line">:book3 ns:price 0 .</span><br></pre></td></tr></table></figure><p><strong>Query</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PREFIX  dc:  &lt;http://purl.org/dc/elements/1.1/&gt;</span><br><span class="line">PREFIX  schema: &lt;https://schema.org&gt; .</span><br><span class="line">SELECT  ?title</span><br><span class="line">WHERE   &#123; </span><br><span class="line">    &#123; ?x dc:title ?title&#125; UNION &#123;?x schema:name ?title&#125;</span><br><span class="line">        &#125;</span><br><span class="line">ORDER BY DESC(?title)</span><br><span class="line">LIMIT 2</span><br></pre></td></tr></table></figure><p><strong>返回结果</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;A data engineer&apos;s guide to semantic models&quot;</span><br><span class="line">&quot;SPARQL Tutorial&quot;</span><br></pre></td></tr></table></figure><p>更详细的 SPARQL 语法可参考之前提到的资源。</p><h1 id="5-结语"><a href="#5-结语" class="headerlink" title="5. 结语"></a>5. 结语</h1><p>到这里，我们的知识建模简介就结束了。但是对于我们来说，它才刚刚开始。学习这个理论是一个很好的开始，但最好的学习方法是将理论付诸实践。注意建议：当您决定构建一个模型时，尝试与一个团队一起构建模型。由于建模是如此的主观，所以把一群不同的思想家聚集在一起总是一个好主意。语义建模并不一定需要以语义模型开始和结束。</p><p>不管怎样，无论你可能读了多少。我希望我能让你对知识建模领域更了解一点，最重要的是，我希望你能对链接数据感到最小兴奋。毕竟，我们不需要更多的数据，我们需要更多有意义的数据。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><p><a href="https://www.semanticarts.com/a-data-engineers-guide-to-semantic-modelling/" target="_blank" rel="noopener">A DATA ENGINEER’S GUIDE TO SEMANTIC MODELLING</a>, <em>Ilaria Maresi, 2020</em> </p></li><li><p><a href="https://zhuanlan.zhihu.com/p/32122644" target="_blank" rel="noopener">知识图谱基础之RDF，RDFS与OWL</a>, <em>SimmerChan</em></p></li><li><a href="https://zhuanlan.zhihu.com/p/32880610" target="_blank" rel="noopener">实践篇（三）：D2RQ SPARQL endpoint与两种交互方式</a>, <em>SimmerChan</em></li><li><a href="https://zhuanlan.zhihu.com/p/33224431" target="_blank" rel="noopener">实践篇（四）：Apache jena SPARQL endpoint及推理</a>, <em>SimmerChan</em> </li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/kgicon.png&quot; alt&gt;&lt;/p&gt;
&lt;h1 id=&quot;1-序言&quot;&gt;&lt;a href=&quot;#1-序言&quot; class=&quot;headerlink&quot; title=&quot;1. 序言&quot;&gt;&lt;/a&gt;1. 序言&lt;/h1&gt;&lt;h2 id=&quot;1-1-什么是知识建模（语义建模）&quot;&gt;&lt;a href=&quot;#1-1-什么是知识建模（语义建模）&quot; class=&quot;headerlink&quot; title=&quot;1.1 什么是知识建模（语义建模）?&quot;&gt;&lt;/a&gt;1.1 什么是知识建模（语义建模）?&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;通过赋予数据指定的概念和数据之间的关系使数据包含语义。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="知识图谱" scheme="https://rogerspy.gitee.io/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="KG" scheme="https://rogerspy.gitee.io/tags/kg/"/>
    
      <category term="knowledge-modelling" scheme="https://rogerspy.gitee.io/tags/knowledge-modelling/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：综述（一）Data graphs</title>
    <link href="https://rogerspy.gitee.io/2021/05/25/kg-survey-1/"/>
    <id>https://rogerspy.gitee.io/2021/05/25/kg-survey-1/</id>
    <published>2021-05-25T02:37:24.000Z</published>
    <updated>2021-09-15T15:55:00.402Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/kgicon.png" alt></p><p>目前，知识图谱在学术界和工业界都引起了重视。本人目前也开始负责知识图谱项目，因此从本文开始对知识图谱进行系统性的介绍。首先从综述入手可以使我们对知识图谱有一个整体的概念，然后对其中的每个细节进行深入介绍。本文来自论文<a href="https://arxiv.org/abs/2003.02320v3" target="_blank" rel="noopener">《Knowledge Graphs》</a>，是一篇长达 132 页（558篇引用）的综述，可谓干货满满，所以以这篇综述作为切入点。因为内容过长，所以我们将论文的每一章作为一篇博文，一共大概会有十几篇博文。</p><a id="more"></a><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>尽管“知识图谱”这个名词在 1972 年的文献中就已经出现了，但是现代意义上的知识图谱是在 2012 年谷歌知识图谱发布以后逐渐形成的。由于谷歌将知识图谱应用于搜索业务上的巨大成功，AirBnb、亚马逊、eBay、IBM、LinkedIn、微软、Uber、百度等巨头公司相继开展相关业务。随着知识图谱在工业界的发展，知识图谱技术的研究也在学术界遍地开花。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/kgicon.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;目前，知识图谱在学术界和工业界都引起了重视。本人目前也开始负责知识图谱项目，因此从本文开始对知识图谱进行系统性的介绍。首先从综述入手可以使我们对知识图谱有一个整体的概念，然后对其中的每个细节进行深入介绍。本文来自论文&lt;a href=&quot;https://arxiv.org/abs/2003.02320v3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;《Knowledge Graphs》&lt;/a&gt;，是一篇长达 132 页（558篇引用）的综述，可谓干货满满，所以以这篇综述作为切入点。因为内容过长，所以我们将论文的每一章作为一篇博文，一共大概会有十几篇博文。&lt;/p&gt;
    
    </summary>
    
      <category term="知识图谱" scheme="https://rogerspy.gitee.io/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="KG" scheme="https://rogerspy.gitee.io/tags/kg/"/>
    
      <category term="survey" scheme="https://rogerspy.gitee.io/tags/survey/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法：分治算法</title>
    <link href="https://rogerspy.gitee.io/2021/05/22/ds-divide-and-conquer/"/>
    <id>https://rogerspy.gitee.io/2021/05/22/ds-divide-and-conquer/</id>
    <published>2021-05-22T08:21:41.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png" alt></p><p>分治算法（<em>divide and conquer</em>）是一种解决大问题的策略，通过：</p><ol><li>将一个大问题分解成小问题</li><li>解决小问题</li><li>蒋小问题的解合并在一起得到想要的答案</li></ol><a id="more"></a><p>分治思想通常应用在递归函数上。下面我们以一个数组的排序问题进行介绍。</p><ol><li><p>给定一个数组</p><p><img width="300" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/divide-and-conquer-0.png"></p></li><li><p>将数组分解</p><p><img width="400" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/divide-and-conquer-1.png"></p><p>将子问题继续分解，直到每个分支只有一个元素</p><p><img width="500" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/divide-and-conquer-2.png"></p></li><li><p>对分解后的元素进行排序，然后合并排序结果。这里我们边排序边合并。</p><p><img width="500" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/divide-and-conquer-3.png"></p></li></ol><ul><li><p><strong>时间复杂度</strong></p><p>以合并排序算法为例，根据<a href="https://rogerspy.gitee.io/2021/04/22/ds-time-complexity/">主定理</a>：</p><blockquote><p>$T(n)=aT(n/b)+f(n)=2T(n/2)+O(n)$</p><ul><li>$a=2$：每次将问题分解成两个子问题；</li><li>$b=2$：每个子问题的规模是输入数据的一半；</li><li>$f(n)=n$：分解和合并子问题的复杂度是线性增加的；</li><li>$\log_ba=1 \Rightarrow f(n)=n^1=n$;</li><li>由主定理可得：$T(n)=O(n\log n)$</li></ul></blockquote></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.programiz.com/dsa/divide-and-conquer" target="_blank" rel="noopener">Divide and Conquer Algorithm</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210820161802.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;分治算法（&lt;em&gt;divide and conquer&lt;/em&gt;）是一种解决大问题的策略，通过：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将一个大问题分解成小问题&lt;/li&gt;
&lt;li&gt;解决小问题&lt;/li&gt;
&lt;li&gt;蒋小问题的解合并在一起得到想要的答案&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://rogerspy.gitee.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="https://rogerspy.gitee.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="divide-conquer" scheme="https://rogerspy.gitee.io/tags/divide-conquer/"/>
    
  </entry>
  
  <entry>
    <title>24种二分类模型的评估方法</title>
    <link href="https://rogerspy.gitee.io/2021/04/28/24-binary-class-evaluateion-metrics/"/>
    <id>https://rogerspy.gitee.io/2021/04/28/24-binary-class-evaluateion-metrics/</id>
    <published>2021-04-28T09:06:47.000Z</published>
    <updated>2021-09-15T15:36:16.765Z</updated>
    
    <content type="html"><![CDATA[<p><img width="75%" src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/4f4d15426607b3fd4051791fa9224979.jpg"></p><p>评估一个模型的好坏有很多指标，每个指标都有其优缺点。如何针对不同场合选取合适的评估指标是一个非常重要的工作。本文将会介绍一些用于分类模型的评估指标，然后介绍我们该如何选取。</p><a id="more"></a><h1 id="1-混淆矩阵（Confusion-Matrix）"><a href="#1-混淆矩阵（Confusion-Matrix）" class="headerlink" title="1. 混淆矩阵（Confusion Matrix）"></a>1. 混淆矩阵（Confusion Matrix）</h1><p>混淆矩阵（混淆表）是一个用来评估分类模型的 $N\times N$ 矩阵，其中 $N$ 表示类别数量。混淆矩阵通过对比真实的类别标签和模型预测的类别标签从整体上对模型进行评估。</p><h2 id="1-1-二分类混淆矩阵"><a href="#1-1-二分类混淆矩阵" class="headerlink" title="1.1 二分类混淆矩阵"></a>1.1 二分类混淆矩阵</h2><p>对于二分类问题，混淆矩阵是一个 $2 \times 2$ 的矩阵，如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210508163046.png" alt></p><ul><li>目标标签有两个类别：<strong>Positive</strong> 和 <strong>Negative</strong></li><li>每一列表示真实的标签类别（actual values）</li><li>每一行表示模型预测的标签类别（predicted values）</li></ul><p>矩阵中的 <strong>TP</strong>、<strong>TN</strong>、<strong>FP</strong>、<strong>FN</strong> 分别表示什么呢？</p><p><strong>True Positive（TP）</strong></p><ul><li>模型预测的标签和真实的标签相同</li><li>真实的标签是 <strong>Positive</strong>，模型预测的标签也是 <strong>Positive</strong></li></ul><p><strong>True Negative（TN）</strong></p><ul><li>模型预测的标签与真实的标签相同</li><li>真实的标签是 <strong>Negative</strong>，模型预测的标签也是 <strong>Negative</strong></li></ul><p><strong>False Positive（FP）</strong></p><ul><li>模型预测的结果与真实的标签不一致</li><li>真实的标签是 <strong>Negative</strong>，但模型预测的是 <strong>Positive</strong></li><li>这种错误称之为 “第一类错误”（<em>Type-I error</em>）</li></ul><p><strong>False Negative（FN）</strong></p><ul><li>模型预测的结果与真实的标签不一致</li><li>真实的标签是 <strong>Positive</strong>，但模型预测的是 <strong>Negative</strong></li><li>这种错误称之为 “第二类错误”（<em>Type-II error</em>）</li></ul><p>举例说明：假设有 1000 个样本，分类模型在这些样本上得到了下面这个混淆矩阵：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210508163200.png" alt></p><p>矩阵中不同的值表示：</p><ul><li>True Positive (TP) = 560，有 560个 正样本被模型正确预测了；</li><li>True Negative (TN) = 330，有 330 个负样本被正确预测了；</li><li>False Positive (FP) = 60，有 60 负样本被模型预测成了正样本；</li><li>False Negative (FN) = 50，有 50 个正样本被模型预测成了负样本。</li></ul><p>从混淆矩阵中可以看出，绝大多数的正样本和负样本可以被模型准确识别出来，说明这是一个还不错的分类模型。</p><h2 id="1-2-多分类混淆矩阵"><a href="#1-2-多分类混淆矩阵" class="headerlink" title="1.2 多分类混淆矩阵"></a>1.2 多分类混淆矩阵</h2><p>有了二分类的混淆矩阵，我们可以把它扩展到多分类问题上。假设有三个类别：A,B,C。那么混淆矩阵应该是一个 $3 \times 3$ 的矩阵：</p><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/20210508164822.png" alt></p><p>对于每个类别的 TP、TN、FP、FN 的计算方式如下：</p><script type="math/tex; mode=display">\begin{equation} \nonumber\begin{split}A:\\\\& TP=Cell_1 \\\\& TN=Cell_5+Cell_6+Cell_8+Cell_9 \\\\& FP=Cell_2+Cell_3 \\\\& FN=Cell_4+Cell_7 \\\\B:\\\\& TP=Cell_5 \\\\& TN=Cell_1+Cell_3+Cell_7+Cell_9 \\\\& FP=Cell_4+Cell_6 \\\\& FN=Cell_2+Cell_8 \\\\C:\\\\& TP=Cell_9 \\\\& TN=Cell_1+Cell_2+Cell_4+Cell_5 \\\\& FP=Cell_7+Cell_8 \\\\& FN=Cell_3+Cell_6 \\\\\end{split}\end{equation}</script><h2 id="1-3-用-scikit-learn-计算混淆矩阵"><a href="#1-3-用-scikit-learn-计算混淆矩阵" class="headerlink" title="1.3 用 scikit-learn 计算混淆矩阵"></a>1.3 用 scikit-learn 计算混淆矩阵</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">predict_class = y_pred_pos &gt; threshold</span><br><span class="line">confusion = metrics.confusion_matrix(true_class, predict_class)</span><br><span class="line">print(confusion)</span><br></pre></td></tr></table></figure><p>输出的结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">330</span>, <span class="number">60</span>]  </span><br><span class="line">[<span class="number">50</span>, <span class="number">560</span>]]</span><br></pre></td></tr></table></figure><p>需要注意的是，<code>scikit-learn</code> 的混淆矩阵<code>(0, 0)</code> 位置是 TN，<code>(1,1)</code> 位置是 TP。</p><h2 id="1-4-什么时候用？"><a href="#1-4-什么时候用？" class="headerlink" title="1.4 什么时候用？"></a>1.4 什么时候用？</h2><p>几乎在所有的分类问题上都可以使用，尤其是在了解具体数量而非归一化的比例的时候（通常是类别不平衡）。</p><h1 id="2-准确率（Accuracy）"><a href="#2-准确率（Accuracy）" class="headerlink" title="2. 准确率（Accuracy）"></a>2. 准确率（Accuracy）</h1><h2 id="2-1-准确率定义"><a href="#2-1-准确率定义" class="headerlink" title="2.1 准确率定义"></a>2.1 准确率定义</h2><p>准确率评估的是模型对样本正确分类的比例，计算方法如下：</p><script type="math/tex; mode=display">\mathrm{accuracy}=\frac{TP+TN}{TP+TN+FP+FN}</script><h2 id="2-2-用-scikit-learn-计算准确率"><a href="#2-2-用-scikit-learn-计算准确率" class="headerlink" title="2.2 用 scikit-learn 计算准确率"></a>2.2 用 scikit-learn 计算准确率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, accuracy_score </span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold </span><br><span class="line">tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel() </span><br><span class="line">accuracy = (tp + tn) / (tp + fp + fn + tn) </span><br><span class="line"></span><br><span class="line"><span class="comment"># or simply </span></span><br><span class="line">accuracy_score(y_true, y_pred_class)</span><br></pre></td></tr></table></figure><h2 id="2-3-准确率与阈值的关系"><a href="#2-3-准确率与阈值的关系" class="headerlink" title="2.3 准确率与阈值的关系"></a>2.3 准确率与阈值的关系</h2><p><img src="https://i2.wp.com/neptune.ai/wp-content/uploads/acc_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><p>分类任务中，模型输出的是每个类别对应的概率。比如二分类，当正类别概率大于 50% 的时候，我们认为该样本是正样本，其中 50% 就是分类的阈值。阈值是可以人为设定的，比如可以规定当概率大于 70% 的时候才认为是正样本。</p><p>对于二分类模型，通常选择 0.5 作为阈值。阈值过大会造成 FN 过大，从而降低准确率。阈值太小会造成 FP 多大，同样会造成准确率过低。</p><h2 id="2-4-什么时候用？"><a href="#2-4-什么时候用？" class="headerlink" title="2.4 什么时候用？"></a>2.4 什么时候用？</h2><ul><li>各类别比较平衡</li><li>每个类别对我们来说同等重要</li></ul><h2 id="2-5-什么时候不能用？"><a href="#2-5-什么时候不能用？" class="headerlink" title="2.5 什么时候不能用？"></a>2.5 什么时候不能用？</h2><p>考虑一个场景：假设每 100 个人中就有 1 个人生病了，我们用一个分类模型对生病的人和没有生病的人进行分类。即使模型所有的输出都是没有生病那准确率也有 99%，但是这个模型却是很糟糕的一个模型。</p><p>仔细观察一下上面的数据分布，很容易发现问题：数据类别不平衡。也就是说，在类别不平衡的数据上评估分类模型的好坏是不可以使用准确率的。</p><h1 id="3-精准度（Precision）"><a href="#3-精准度（Precision）" class="headerlink" title="3. 精准度（Precision）"></a>3. 精准度（Precision）</h1><h2 id="3-1-精准度定义"><a href="#3-1-精准度定义" class="headerlink" title="3.1 精准度定义"></a>3.1 精准度定义</h2><p>精准度表示在模型预测为正样本的数据中，有多少是真正的正样本。比如用渔网捞鱼，这一网捞上来的有鱼有虾，其中是鱼的比例就是精准度。计算公式如下：</p><script type="math/tex; mode=display">\mathrm{Precision} = \frac{TP}{TP+FP}</script><h2 id="3-2-用-scikit-learn-计算精准度"><a href="#3-2-用-scikit-learn-计算精准度" class="headerlink" title="3.2 用 scikit-learn 计算精准度"></a>3.2 用 scikit-learn 计算精准度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, precision_score</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()</span><br><span class="line">positive_predictive_value = tp/ (tp + fp)</span><br><span class="line"></span><br><span class="line"><span class="comment"># or simply</span></span><br><span class="line">precision_score(y_true, y_pred_class)</span><br></pre></td></tr></table></figure><h2 id="3-3-精准度与阈值的关系"><a href="#3-3-精准度与阈值的关系" class="headerlink" title="3.3 精准度与阈值的关系"></a>3.3 精准度与阈值的关系</h2><p><img src="https://i0.wp.com/neptune.ai/wp-content/uploads/ppv_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><p>从这个解释中我们可以看出，阈值越高说明概率越大。从直觉上可以判断，概率越大说明可信度越高。那么样本被正确分类的可能性就越高。回到精准度的角度，精准度表示真正的正样本比例。如果阈值设定较高的话，正样本分类的正确率也会越高，精准度也会越高。极端情况下，把阈值设定成 100%，精准度也会达到最大。</p><h2 id="3-4-什么时候用？"><a href="#3-4-什么时候用？" class="headerlink" title="3.4 什么时候用？"></a>3.4 什么时候用？</h2><ul><li>单独使用精准度没有什么意义，通常会配合其他指标一起使用</li><li>当错误警报成本过高，或者当你认为每个预测为正样本的样例都值得一看的时候，可以针对精准度进行调整</li></ul><h1 id="4-召回率（Recall）"><a href="#4-召回率（Recall）" class="headerlink" title="4. 召回率（Recall）"></a>4. 召回率（Recall）</h1><h2 id="4-1-召回率定义"><a href="#4-1-召回率定义" class="headerlink" title="4.1 召回率定义"></a>4.1 召回率定义</h2><p>召回率又叫真阳性率，表示有多少是真正的正样本被模型正确识别出来了。我们经常会听到某某产品出现了质量问题，厂家紧急召回的新闻。召回率就是说，市面上所有的问题产品，厂家召回了多少。另外一个例子，目前新冠肆虐，新冠的检测是通过咽拭子。召回率表示，通过咽拭子找到了多少新冠患者。</p><p>通过这两个例子我们可以对准确率，精确度和召回率加以区分。准确率关注的是所有类别的分类正确率，精确度是正样本的准确率，而召回率表示找到的正样本占总正样本的比例。</p><p>用公式表示如下：</p><script type="math/tex; mode=display">\mathrm{recall} = \frac{TP}{TP+FN}</script><h2 id="4-2-用-scikit-learn-计算召回率"><a href="#4-2-用-scikit-learn-计算召回率" class="headerlink" title="4.2 用 scikit-learn 计算召回率"></a>4.2 用 scikit-learn 计算召回率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, recall_score</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()</span><br><span class="line">true_positive_rate = tp / (tp + fn)</span><br><span class="line"></span><br><span class="line"><span class="comment"># or simply</span></span><br><span class="line"></span><br><span class="line">recall_score(y_true, y_pred_class)</span><br></pre></td></tr></table></figure><h2 id="4-3-召回率与阈值的关系"><a href="#4-3-召回率与阈值的关系" class="headerlink" title="4.3 召回率与阈值的关系"></a>4.3 召回率与阈值的关系</h2><p><img src="https://i1.wp.com/neptune.ai/wp-content/uploads/tpr_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><p>阈值设定越低，模型预测为正样本的门槛就越低，就越容易把所有的正样本找出来。所以召回率与阈值是一个负相关的关系。</p><h2 id="4-4-什么时候用？"><a href="#4-4-什么时候用？" class="headerlink" title="4.4 什么时候用？"></a>4.4 什么时候用？</h2><ul><li>单独使用召回率没有什么意义，通常会配合其他指标一起使用</li><li>但是有些情况，比如灾难预警、欺诈性交易等，即使收到一些错误预警，我们也必须谨慎对待。即在宁可信其有不可信其无的场景下，适当调整召回率是有必要的</li></ul><h1 id="5-F1-得分（F1-score）"><a href="#5-F1-得分（F1-score）" class="headerlink" title="5. F1 得分（F1-score）"></a>5. F1 得分（F1-score）</h1><h2 id="5-1-F1-得分定义"><a href="#5-1-F1-得分定义" class="headerlink" title="5.1 F1 得分定义"></a>5.1 F1 得分定义</h2><p>通常情况下，我们想提高精准度就需要牺牲召回率，要想提高召回率就要牺牲精准度。从之前介绍的精准度、召回率和阈值的关系中我们就可以看出一些端倪。当然，一个理想的分类模型是精准度和召回率都可以达到很高，但是实际上却是比较困难。</p><p>为了综合评估精准度和召回率，我们可以使用 F1 得分：</p><script type="math/tex; mode=display">F1 = \frac{1}{\frac{1}{\mathrm{Recall}}+\frac{1}{\mathrm{Precision}}} = \frac{2\times \mathrm{Precision} \times \mathrm{Recall}}{\mathrm{Precision}+\mathrm{Recall}}</script><p>从定义上看，我们可以认为 F1 得分是精准度和召回率的一个平均。</p><h2 id="5-2-用-scikit-learn-计算-F1得分"><a href="#5-2-用-scikit-learn-计算-F1得分" class="headerlink" title="5.2 用 scikit-learn 计算 F1得分"></a>5.2 用 scikit-learn 计算 F1得分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">f1_score(y_true, y_pred_class)</span><br></pre></td></tr></table></figure><p>在实际情况中，精准度、召回率和 F1 得分都不会单独使用，而是综合一起来评估模型的好坏：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">classification_report(y_true, y_pred_class)</span><br></pre></td></tr></table></figure><p>我们会得到一个类似如下的结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           <span class="number">1</span>       <span class="number">1.00</span>      <span class="number">0.67</span>      <span class="number">0.80</span>         <span class="number">3</span></span><br><span class="line">           <span class="number">2</span>       <span class="number">0.00</span>      <span class="number">0.00</span>      <span class="number">0.00</span>         <span class="number">0</span></span><br><span class="line"></span><br><span class="line">   micro avg       <span class="number">1.00</span>      <span class="number">0.67</span>      <span class="number">0.80</span>         <span class="number">3</span></span><br><span class="line">   macro avg       <span class="number">0.33</span>      <span class="number">0.22</span>      <span class="number">0.27</span>         <span class="number">3</span></span><br><span class="line">weighted avg       <span class="number">1.00</span>      <span class="number">0.67</span>      <span class="number">0.80</span>         <span class="number">3</span></span><br></pre></td></tr></table></figure><p>其中 <code>support</code> 是参与评估的总样本数，<code>1,2,3</code> 分别是类别标签。<code>mirco avg</code>，<code>marco avg</code> 和 <code>weighted avg</code> 的计算方式分别如下：</p><p><code>micro avg</code>:</p><script type="math/tex; mode=display">\begin{equation}\nonumber\begin{split}\mathrm{micro\ avg\ Precision} &= \frac{TP1+TP2}{TP1+TP2+FP1+FP2} = \frac{\sum TP_i}{\sum(TP_i+FP_i)} \\\\\mathrm{micro\ avg\ Recall} &= \frac{TP1+TP2}{TP1+TP2+FN1+FN2} = \frac{\sum TP_i}{\sum(TP_i+FN_i)} \\\\\mathrm{micro\ avg\ F1} &= \frac{2\times \mathrm{micro\ avg\ Precision} \times \mathrm{micro\ avg\ Recall}}{\mathrm{micro\ avg\ Precision} + \mathrm{micro\ avg\ Recall}}\end{split}\end{equation}</script><p><code>macro avg</code>:</p><script type="math/tex; mode=display">\begin{equation}\nonumber\begin{split}\mathrm{macro\ avg\ Precision} &= \frac{1}{n} \sum \mathrm{Precision}_i \\\\\mathrm{macro\ avg\ Recall} &= \frac{1}{n} \sum \mathrm{Recall}_i \\\\\mathrm{macro\ avg\ F1} &= \frac{1}{n} \sum \mathrm{F1}_i\end{split}\end{equation}</script><p><code>weighted avg</code>:</p><p>假设类别 1 有 4 个，类别 2 有 10 个。</p><script type="math/tex; mode=display">\begin{equation}\nonumber\begin{split}\mathrm{weighted\ avg\ Precision} &= \frac{4 \times \mathrm{Precision}_{1}+10 \times \mathrm{Precision}_{2}}{14} &= \frac{\sum(n_i\times \mathrm{Precision}_{i})}{\sum n_i} \\\\\mathrm{weighted\ avg\ Recall} &= \frac{4 \times \mathrm{Recall}_{1}+10 \times \mathrm{Recall}_{2}}{14} &= \frac{\sum(n_i\times \mathrm{Recall}_{i})}{\sum n_i} \\\\\mathrm{weighted\ avg\ F1} &= \frac{4 \times F1_{1}+10 \times F1_{2}}{14} &= \frac{\sum(n_i\times F1_{i})}{\sum n_i}\end{split}\end{equation}</script><h2 id="5-3-F1-得分与阈值的关系"><a href="#5-3-F1-得分与阈值的关系" class="headerlink" title="5.3 F1 得分与阈值的关系"></a>5.3 F1 得分与阈值的关系</h2><p><img src="https://i2.wp.com/neptune.ai/wp-content/uploads/f1_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><p>精准度与阈值的关系是正相关，召回率与阈值的关系是负相关，F1 是精准度和召回率的综合平均值，所以当阈值过大或过小的时候都会对 F1 造成损失，所以要保证较高的 F1 得分，阈值必须在一个合理的范围内。</p><h2 id="5-4-什么时候用？"><a href="#5-4-什么时候用？" class="headerlink" title="5.4 什么时候用？"></a>5.4 什么时候用？</h2><ul><li>F1 得分是常规分类问题的首选评估指标，但是通常也会配合准确率，精准度和召回率</li></ul><h1 id="6-F2-得分（F2-score）"><a href="#6-F2-得分（F2-score）" class="headerlink" title="6. F2 得分（F2-score）"></a>6. F2 得分（F2-score）</h1><h2 id="6-1-F2-得分定义"><a href="#6-1-F2-得分定义" class="headerlink" title="6.1 F2 得分定义"></a>6.1 F2 得分定义</h2><p>F2 得分表示精准度和召回率的综合评价，与 F1 不同的是，F2 着重强调召回率：</p><script type="math/tex; mode=display">F2 = \frac{5 \times \mathrm{Precision}\times \mathrm{Recall}}{4\times  \mathrm{Precision+Recall}}</script><h2 id="6-2-用-scikit-learn-计算-F2-得分"><a href="#6-2-用-scikit-learn-计算-F2-得分" class="headerlink" title="6.2 用 scikit-learn 计算 F2 得分"></a>6.2 用 scikit-learn 计算 F2 得分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> fbeta_score</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">fbeta_score(y_true, y_pred_class, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><h2 id="6-3-F2-得分与阈值的关系"><a href="#6-3-F2-得分与阈值的关系" class="headerlink" title="6.3 F2 得分与阈值的关系"></a>6.3 F2 得分与阈值的关系</h2><p><img src="https://i0.wp.com/neptune.ai/wp-content/uploads/f2_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><p>由于 F2 得分更强调召回率的作用，所以 F2 的性质也与召回率的性质相似，随着阈值的提高 F2 得分会有一个库快速的上升，然后短暂达到平衡，然后随着阈值的升高 F2 得分逐渐下降。</p><h2 id="6-4-什么时候用？"><a href="#6-4-什么时候用？" class="headerlink" title="6.4 什么时候用？"></a>6.4 什么时候用？</h2><ul><li>在注重召回率的场景下都可以使用</li></ul><h1 id="7-F-beta-得分（F-beta-score）"><a href="#7-F-beta-得分（F-beta-score）" class="headerlink" title="7. F-beta 得分（F-beta score）"></a>7. F-beta 得分（F-beta score）</h1><h2 id="7-1-F-beta-定义"><a href="#7-1-F-beta-定义" class="headerlink" title="7.1 F-beta 定义"></a>7.1 F-beta 定义</h2><p>既然有 F1 得分，有 F2 得分，那么我顶定义一个 $\beta$ ，当 $\beta=1$ 时，即为 F1 得分，当 $\beta=2$ 时，即为 F2 得分。计算方法如下：</p><script type="math/tex; mode=display">F_{beta} = (1+\beta^2)\frac{\mathrm{Precision}\times \mathrm{Recall}}{\beta^2 \times \mathrm{Precision}+\mathrm{Recall}}</script><p>我肯可以通过调整 $\beta$ 值来确定召回率在我们的评估指标中占有的比重。</p><h2 id="7-2-用-scikit-learn-计算-F-beta-得分"><a href="#7-2-用-scikit-learn-计算-F-beta-得分" class="headerlink" title="7.2 用 scikit-learn 计算 F-beta 得分"></a>7.2 用 scikit-learn 计算 F-beta 得分</h2><p>在上面计算 F2 得分的时候，我们就可以发现，用到了 <code>fbeta_score</code> 函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> fbeta_score</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">fbeta_score(y_true, y_pred_class, beta)</span><br></pre></td></tr></table></figure><h2 id="7-3-F-beta-得分与阈值的关系"><a href="#7-3-F-beta-得分与阈值的关系" class="headerlink" title="7.3 F-beta 得分与阈值的关系"></a>7.3 F-beta 得分与阈值的关系</h2><p><img src="https://i0.wp.com/neptune.ai/wp-content/uploads/f_by_beta.png?fit=933%2C518&amp;ssl=1" alt></p><p>上图展示了不同 $\beta$ 值时， F-beta 与阈值的关系。</p><h1 id="8-假阳性率（Type-I-error）"><a href="#8-假阳性率（Type-I-error）" class="headerlink" title="8. 假阳性率（Type-I error）"></a>8. 假阳性率（Type-I error）</h1><h2 id="8-1-假阳性率定义"><a href="#8-1-假阳性率定义" class="headerlink" title="8.1 假阳性率定义"></a>8.1 假阳性率定义</h2><p>假阳性率表示，我们预测的某事但没有发生。因此，假阳性率又可以叫做误报率。比如，本来没有大雨，但是天气预报却预报说有雨，说明天气预报误报了。我们可以将其视为模型发出的错误报警。</p><script type="math/tex; mode=display">FPR = \frac{\mathrm{FP}}{FP+TN}</script><h2 id="8-2-用-scikit-learn-计算假阳性率"><a href="#8-2-用-scikit-learn-计算假阳性率" class="headerlink" title="8.2 用 scikit-learn 计算假阳性率"></a>8.2 用 scikit-learn 计算假阳性率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()</span><br><span class="line">false_positive_rate = fp / (fp + tn)</span><br></pre></td></tr></table></figure><h2 id="8-3-假阳性率与阈值的关系"><a href="#8-3-假阳性率与阈值的关系" class="headerlink" title="8.3 假阳性率与阈值的关系"></a>8.3 假阳性率与阈值的关系</h2><p>通常一个好的模型假阳性率都比较低，但是我们还可以通过调节阈值来进一步降低假阳性率。因为在分母中包含真负样本（$TN$），当我们的数据不平衡时，假阳性率通常会很低。</p><p><img src="https://i2.wp.com/neptune.ai/wp-content/uploads/fpr_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><p>显然，随着阈值的增大，假阳性率在降低。</p><h2 id="8-4-什么时候用？"><a href="#8-4-什么时候用？" class="headerlink" title="8.4 什么时候用？"></a>8.4 什么时候用？</h2><ul><li>很少单独使用假阳性率，通常是和其他指标一起使用；</li><li>如果误报会导致较严重的后果，可以通过调节阈值来降低。</li></ul><h1 id="9-假阴性率（Type-II-error）"><a href="#9-假阴性率（Type-II-error）" class="headerlink" title="9. 假阴性率（Type-II error）"></a>9. 假阴性率（Type-II error）</h1><h2 id="9-1-假阴性率定义"><a href="#9-1-假阴性率定义" class="headerlink" title="9.1 假阴性率定义"></a>9.1 假阴性率定义</h2><p>假阴性率表示，当我们没有预测的事情却发生了。因此，假阴性率又可以叫做漏报率。比如，本来有一场大雨，但是天气预报没有预报，说明天气预报对这次大雨漏报了。</p><script type="math/tex; mode=display">FNR = \frac{FN}{TP+FN}</script><h2 id="9-2-用-scikit-learn-计算假阴性率"><a href="#9-2-用-scikit-learn-计算假阴性率" class="headerlink" title="9.2 用 scikit-learn 计算假阴性率"></a>9.2 用 scikit-learn 计算假阴性率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()</span><br><span class="line">false_negative_rate = fn / (tp + fn)</span><br></pre></td></tr></table></figure><h2 id="9-3-假阴性率与阈值的关系"><a href="#9-3-假阴性率与阈值的关系" class="headerlink" title="9.3 假阴性率与阈值的关系"></a>9.3 假阴性率与阈值的关系</h2><p><img src="https://i2.wp.com/neptune.ai/wp-content/uploads/fnr_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><p>当我们提高阈值的时候，假阴性率也会随之升高。</p><h2 id="9-4-什么时候用？"><a href="#9-4-什么时候用？" class="headerlink" title="9.4 什么时候用？"></a>9.4 什么时候用？</h2><ul><li>通常与其他指标一起使用；</li><li>如果漏报的代价比较大的时候，就需要关注这个指标了。</li></ul><h1 id="10-真阴性率（True-negative-rate）"><a href="#10-真阴性率（True-negative-rate）" class="headerlink" title="10. 真阴性率（True negative rate）"></a>10. 真阴性率（True negative rate）</h1><h2 id="10-1-真阴性率定义"><a href="#10-1-真阴性率定义" class="headerlink" title="10.1 真阴性率定义"></a>10.1 真阴性率定义</h2><p>真阴性率表示，在所有的负样本中有多少负样本被检测出来。</p><script type="math/tex; mode=display">TNR = \frac{TN}{TN+FP}</script><h2 id="10-2-用-scikit-learn-计算真阴性率"><a href="#10-2-用-scikit-learn-计算真阴性率" class="headerlink" title="10.2 用 scikit-learn 计算真阴性率"></a>10.2 用 scikit-learn 计算真阴性率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()</span><br><span class="line">true_negative_rate = tn / (tn + fp)</span><br></pre></td></tr></table></figure><h2 id="10-3-真阴性率与阈值的关系"><a href="#10-3-真阴性率与阈值的关系" class="headerlink" title="10.3 真阴性率与阈值的关系"></a>10.3 真阴性率与阈值的关系</h2><p><img src="https://i0.wp.com/neptune.ai/wp-content/uploads/tnr_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><p>阈值越高，真阴性率越高。</p><h2 id="10-4-什么时候用？"><a href="#10-4-什么时候用？" class="headerlink" title="10.4 什么时候用？"></a>10.4 什么时候用？</h2><ul><li>通常与其他指标一起用；</li><li>当你确实希望确保你所说的每一句都是正确的时候，可以考虑该指标。比如，当一个医生对病人说 “你很健康”  的时候。</li></ul><h1 id="11-负样本预测值（Negative-Predictive-Value）"><a href="#11-负样本预测值（Negative-Predictive-Value）" class="headerlink" title="11. 负样本预测值（Negative Predictive Value）"></a>11. 负样本预测值（Negative Predictive Value）</h1><h2 id="11-1-负样本预测值定义"><a href="#11-1-负样本预测值定义" class="headerlink" title="11.1 负样本预测值定义"></a>11.1 负样本预测值定义</h2><p>负样本预测值表示，模型预测的负样本有多少是真正的负样本，我们可以认为它是负类别的准确率。</p><script type="math/tex; mode=display">NPV = \frac{TN}{TN+FN}</script><h2 id="11-2-用-scikit-learn-计算负样本预测值"><a href="#11-2-用-scikit-learn-计算负样本预测值" class="headerlink" title="11.2 用 scikit-learn 计算负样本预测值"></a>11.2 用 scikit-learn 计算负样本预测值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()</span><br><span class="line">negative_predictive_value = tn/ (tn + fn)</span><br></pre></td></tr></table></figure><h2 id="11-3-负样本预测值与阈值的关系"><a href="#11-3-负样本预测值与阈值的关系" class="headerlink" title="11.3 负样本预测值与阈值的关系"></a>11.3 负样本预测值与阈值的关系</h2><p><img src="https://i2.wp.com/neptune.ai/wp-content/uploads/npv_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><p>阈值越高就会有越多的样本被预测为负样本，被误分类成负样本的几率就越高。但是对于非平衡数据集来说，一个较高的阈值通常负样本预测值表现也还不错。</p><h2 id="11-4-什么时候用？"><a href="#11-4-什么时候用？" class="headerlink" title="11.4 什么时候用？"></a>11.4 什么时候用？</h2><ul><li>当我们更加关注负样本的预测准确率时，可以考虑使用这一评估指标。</li></ul><h1 id="12-假发现率（False-Discovery-Rate）"><a href="#12-假发现率（False-Discovery-Rate）" class="headerlink" title="12. 假发现率（False Discovery Rate）"></a>12. 假发现率（False Discovery Rate）</h1><h2 id="12-1-假发现率定义"><a href="#12-1-假发现率定义" class="headerlink" title="12.1 假发现率定义"></a>12.1 假发现率定义</h2><p>假发现率表示，所有预测为正样本的数据中有多少是真正的正样本。</p><script type="math/tex; mode=display">FDR = \frac{TP}{TP+FP}</script><h2 id="12-2-用-scikit-learn-计算假发现率"><a href="#12-2-用-scikit-learn-计算假发现率" class="headerlink" title="12.2 用 scikit-learn 计算假发现率"></a>12.2 用 scikit-learn 计算假发现率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()</span><br><span class="line">false_discovery_rate = fp/ (tp + fp)</span><br></pre></td></tr></table></figure><h2 id="12-3-假发现率与阈值的关系"><a href="#12-3-假发现率与阈值的关系" class="headerlink" title="12.3 假发现率与阈值的关系"></a>12.3 假发现率与阈值的关系</h2><p><img src="https://i2.wp.com/neptune.ai/wp-content/uploads/fdr_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><p>阈值越高，假发现率越低。</p><h2 id="12-4-什么时候用？"><a href="#12-4-什么时候用？" class="headerlink" title="12.4 什么时候用？"></a>12.4 什么时候用？</h2><ul><li>通常和其他指标一起使用；</li><li>如果误报的代价过高，或者当你希望所有预测为正样本的数据都值得一看的时候，可以考虑该指标。</li></ul><h1 id="13-Cohen-Kappa-Metric"><a href="#13-Cohen-Kappa-Metric" class="headerlink" title="13. Cohen Kappa Metric"></a>13. Cohen Kappa Metric</h1><h2 id="13-1-Cohen-Kappa-定义"><a href="#13-1-Cohen-Kappa-定义" class="headerlink" title="13.1 Cohen Kappa 定义"></a>13.1 Cohen Kappa 定义</h2><p>简单来说，<em>Cohen Kappa</em> 指的是你的模型比一个随机分类器好多少。</p><script type="math/tex; mode=display">\kappa = \frac{p_0-p_e}{1-p_e}</script><ul><li>$p_0$ 表示模型预测结果，通常为准确率；</li><li>$p_e$ 表示随机预测结果，通常为随机模型的准确率。</li></ul><h2 id="13-2-用-scikit-learn-计算-Cohen-Kappa"><a href="#13-2-用-scikit-learn-计算-Cohen-Kappa" class="headerlink" title="13.2 用 scikit-learn 计算 Cohen Kappa"></a>13.2 用 scikit-learn 计算 Cohen Kappa</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> cohen_kappa_score</span><br><span class="line"></span><br><span class="line">cohen_kappa_score(y_true, y_pred_class)</span><br></pre></td></tr></table></figure><h2 id="13-3-Cohen-Kappa-与阈值的关系"><a href="#13-3-Cohen-Kappa-与阈值的关系" class="headerlink" title="13.3 Cohen Kappa 与阈值的关系"></a>13.3 Cohen Kappa 与阈值的关系</h2><p><img src="https://i0.wp.com/neptune.ai/wp-content/uploads/kappa_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><h2 id="13-4-什么时候用？"><a href="#13-4-什么时候用？" class="headerlink" title="13.4 什么时候用？"></a>13.4 什么时候用？</h2><ul><li>Cohen Kappa 通常不会用在一般的文本分类上，而是在非平衡数据的分类模型上。</li></ul><h1 id="14-Matthews-Correlation-Coefficient-（MCC）"><a href="#14-Matthews-Correlation-Coefficient-（MCC）" class="headerlink" title="14. Matthews Correlation Coefficient （MCC）"></a>14. Matthews Correlation Coefficient （MCC）</h1><p>$MCC$ 表示真实标签和预测标签的相关性。</p><h2 id="14-1-MCC-定义"><a href="#14-1-MCC-定义" class="headerlink" title="14.1 MCC 定义"></a>14.1 MCC 定义</h2><script type="math/tex; mode=display">MCC = \frac{TP\times TN-FP\times FN}{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}</script><h2 id="14-2-scikit-learn-计算-MCC"><a href="#14-2-scikit-learn-计算-MCC" class="headerlink" title="14.2 scikit-learn 计算 MCC"></a>14.2 scikit-learn 计算 MCC</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> matthews_corrcoef</span><br><span class="line"></span><br><span class="line">y_pred_class = y_pred_pos &gt; threshold</span><br><span class="line">matthews_corrcoef(y_true, y_pred_class)</span><br></pre></td></tr></table></figure><h2 id="14-3-MCC-与阈值的关系"><a href="#14-3-MCC-与阈值的关系" class="headerlink" title="14.3 MCC 与阈值的关系"></a>14.3 MCC 与阈值的关系</h2><p><img src="https://i0.wp.com/neptune.ai/wp-content/uploads/mcc_by_thres.png?fit=1024%2C768&amp;ssl=1" alt></p><h2 id="14-4-什么时候用？"><a href="#14-4-什么时候用？" class="headerlink" title="14.4 什么时候用？"></a>14.4 什么时候用？</h2><ul><li>不平衡数据集</li><li>希望预测结果有更强的可解释性的</li></ul><h1 id="15-ROC-曲线"><a href="#15-ROC-曲线" class="headerlink" title="15. ROC 曲线"></a>15. ROC 曲线</h1><p>ROC 曲线是一个图表，用于展示真阳性率（$TPR$）和假阳性率（$FPR$）之间的权衡。基本上，对于每个阈值，我们计算 $TPR$ 和 $FPR$ 并将其绘制在一张图表上。它代表的是分类器以多大的置信度将样本分类为正样本。</p><p>可以在 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.10.9777&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Tom Fawcett</a> 的这篇文章中找到对 ROC 曲线和 ROC AUC 分数的广泛详细的讨论。</p><h2 id="15-1-用-scikit-learn-计算-ROC"><a href="#15-1-用-scikit-learn-计算-ROC" class="headerlink" title="15.1 用 scikit-learn 计算 ROC"></a>15.1 用 scikit-learn 计算 ROC</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scikitplot.metrics <span class="keyword">import</span> plot_roc</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">plot_roc(y_true, y_pred, ax=ax)</span><br></pre></td></tr></table></figure><h2 id="15-2-曲线图是什么样的？"><a href="#15-2-曲线图是什么样的？" class="headerlink" title="15.2 曲线图是什么样的？"></a>15.2 曲线图是什么样的？</h2><p><img src="https://i1.wp.com/neptune.ai/wp-content/uploads/roc_auc_curve.png?fit=1024%2C768&amp;ssl=1" alt></p><p>每个不同的阈值对应曲线上不同的点（即不同的混淆矩阵）。对于每个阈值，较高的 $TPR$ 和较低的 $FPR$ 越好，因此具有更多左上角曲线的分类器更好。从上图可以看出，在大约（0.15， 0.85）左右的位置（左上角黑色实线和黑色虚线焦点）二者取得平衡。因此该位置对应的阈值应该是最佳的分类阈值。</p><h1 id="16-ROC-AUC-得分"><a href="#16-ROC-AUC-得分" class="headerlink" title="16. ROC-AUC 得分"></a>16. ROC-AUC 得分</h1><p>为了从 ROC 曲线上得到一个量化的指标，我们可以计算 ROC-AUC（<em>Area Under the ROC Curve</em>） 得分。</p><h2 id="16-1-用-scikit-learn-计算-ROC-AUC"><a href="#16-1-用-scikit-learn-计算-ROC-AUC" class="headerlink" title="16.1 用 scikit-learn 计算 ROC-AUC"></a>16.1 用 scikit-learn 计算 ROC-AUC</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"></span><br><span class="line">roc_auc = roc_auc_score(y_true, y_pred_pos)</span><br></pre></td></tr></table></figure><h2 id="16-2-什么时候用？"><a href="#16-2-什么时候用？" class="headerlink" title="16.2 什么时候用？"></a>16.2 什么时候用？</h2><ul><li>当你非常关心排序预测的时候，应该使用 ROC-AUC 得分而没有必要关注<a href="https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/" target="_blank" rel="noopener">概率修正</a>。</li><li>当你的数据严重不平衡的时候，不应该使用 ROC-AUC 作为评估指标。直观上来讲，当数据严重类别不平衡的时候， $FPR$ 会被严重拉低，因为大量的数据是 <em>True Negative</em> 的。</li><li>当正负样本的类别平衡的时候，可以使用 ROC-AUC 作为评估指标。</li></ul><h1 id="17-Precision-Recall-Curve"><a href="#17-Precision-Recall-Curve" class="headerlink" title="17. Precision-Recall Curve"></a>17. Precision-Recall Curve</h1><p>PRC 是一条融合了精准度和召回率的可视化曲线。对于每个阈值，计算相应的精准度和召回率，然后画在图上即可。Y 轴对应的值越高，则模型表现越好。</p><h2 id="17-1-用-scikit-learn-计算-PRC"><a href="#17-1-用-scikit-learn-计算-PRC" class="headerlink" title="17.1 用 scikit-learn 计算 PRC"></a>17.1 用 scikit-learn 计算 PRC</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scikitplot.metrics <span class="keyword">import</span> plot_precision_recall</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">plot_precision_recall(y_true, y_pred, ax=ax)</span><br></pre></td></tr></table></figure><h2 id="17-2-曲线长什么样？"><a href="#17-2-曲线长什么样？" class="headerlink" title="17.2 曲线长什么样？"></a>17.2 曲线长什么样？</h2><p><img src="https://i1.wp.com/neptune.ai/wp-content/uploads/prec_rec_curve.png?fit=1024%2C768&amp;ssl=1" alt></p><h1 id="18-PR-AUC-得分-平均精准度"><a href="#18-PR-AUC-得分-平均精准度" class="headerlink" title="18. PR AUC 得分 | 平均精准度"></a>18. PR AUC 得分 | 平均精准度</h1><p>与 ROC-AUC 类似，我们也可以计算 <strong>A</strong>rea <strong>U</strong>nder the Precision-Recall <strong>C</strong>urve 以获得评估模型的量化指标。</p><h2 id="18-1-用-sickit-learn计算-PR-AUC"><a href="#18-1-用-sickit-learn计算-PR-AUC" class="headerlink" title="18.1 用 sickit-learn计算 PR AUC"></a>18.1 用 sickit-learn计算 PR AUC</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> average_precision_score</span><br><span class="line"></span><br><span class="line">average_precision_score(y_true, y_pred_pos)</span><br></pre></td></tr></table></figure><h2 id="18-2-什么时候用？"><a href="#18-2-什么时候用？" class="headerlink" title="18.2 什么时候用？"></a>18.2 什么时候用？</h2><ul><li>当你要在精准度和召回率之间做取舍的时候</li><li>当你要选择一个合适的阈值符合实际情况的时候</li><li>当你的数据严重不平衡的时候。就像之前讨论的那样，由于 PR AUC 主要关注点是正样本的类别，很少关注到负样本。所以在类别严重不平衡的时候可以使用 PR AUC 作为模型的评估指标。</li><li>当你更关注正样本而非负样本的时候，可以使用 PR AUC 作为模型的评估指标。</li></ul><h1 id="19-Log-loss"><a href="#19-Log-loss" class="headerlink" title="19. Log loss"></a>19. Log loss</h1><p>对数损失函数经常用来优化机器学习模型的参数。然后实际上它也可以作为模型的评估指标。</p><h2 id="19-1-定义对数损失"><a href="#19-1-定义对数损失" class="headerlink" title="19.1 定义对数损失"></a>19.1 定义对数损失</h2><p>对数损失用来计算真实标签与预测标签之间的差别：</p><script type="math/tex; mode=display">\mathrm{Logloss} = -(y_{\mathrm{true}}\times\log(y_{\mathrm{pred}})) + (1-y_{\mathrm{true}})\times\log(1-y_{\mathrm{pred}})</script><p>观测到的正样本置信度越高，那么它与真实的正样本之间的差距就越小。但是这并不是一个线性关系，真实的关系如下图：</p><p><img src="https://i1.wp.com/neptune.ai/wp-content/uploads/log_los_chart.png?fit=724%2C496&amp;ssl=1" alt></p><h2 id="19-2-用-scikit-learn-计算对数损失"><a href="#19-2-用-scikit-learn-计算对数损失" class="headerlink" title="19.2 用 scikit-learn 计算对数损失"></a>19.2 用 scikit-learn 计算对数损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> log_loss</span><br><span class="line"></span><br><span class="line">log_loss(y_true, y_pred)</span><br></pre></td></tr></table></figure><h2 id="19-3-什么时候用？"><a href="#19-3-什么时候用？" class="headerlink" title="19.3 什么时候用？"></a>19.3 什么时候用？</h2><ul><li>几乎总是有一个性能指标可以更好地匹配我们的业务问题。 因此，我们可以使用对数损失作为模型的目标，并使用其他一些指标来评估性能。</li></ul><h1 id="20-Brier-得分"><a href="#20-Brier-得分" class="headerlink" title="20. Brier 得分"></a>20. Brier 得分</h1><h2 id="20-1-Brier-得分定义"><a href="#20-1-Brier-得分定义" class="headerlink" title="20.1 Brier 得分定义"></a>20.1 Brier 得分定义</h2><script type="math/tex; mode=display">\mathrm{Brierloss} = (y_{\mathrm{pred}}-y_{\mathrm{true}})^2</script><h2 id="20-2-用-scikit-learn-计算-Brier-得分"><a href="#20-2-用-scikit-learn-计算-Brier-得分" class="headerlink" title="20.2 用 scikit-learn 计算 Brier 得分"></a>20.2 用 scikit-learn 计算 Brier 得分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> brier_score_loss</span><br><span class="line"></span><br><span class="line">brier_score_loss(y_true, y_pred_pos)</span><br></pre></td></tr></table></figure><h2 id="20-3-什么时候用？"><a href="#20-3-什么时候用？" class="headerlink" title="20.3 什么时候用？"></a>20.3 什么时候用？</h2><ul><li>当你关心修正概率的时候</li></ul><h1 id="21-累积收益表"><a href="#21-累积收益表" class="headerlink" title="21. 累积收益表"></a>21. 累积收益表</h1><h2 id="21-1-定义累积收益表"><a href="#21-1-定义累积收益表" class="headerlink" title="21.1 定义累积收益表"></a>21.1 定义累积收益表</h2><p>简单来说，累积收益表（Cumulative gains chart）可以帮助我们判断使用当前模型的收益超过一个随机模型多少。</p><ul><li>先对预测结果从高到低进行排序</li><li>对于每个百分数，我们计算大于这个百分数的真阳性样本比例。</li></ul><h2 id="21-2-用-scikit-learn-计算-CGC"><a href="#21-2-用-scikit-learn-计算-CGC" class="headerlink" title="21.2 用 scikit-learn 计算 CGC"></a>21.2 用 scikit-learn 计算 CGC</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scikitplot.metrics <span class="keyword">import</span> plot_cumulative_gain</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">plot_cumulative_gain(y_true, y_pred, ax=ax)</span><br></pre></td></tr></table></figure><h2 id="21-3-CGC-看起来是什么样的？"><a href="#21-3-CGC-看起来是什么样的？" class="headerlink" title="21.3 CGC 看起来是什么样的？"></a>21.3 CGC 看起来是什么样的？</h2><p><img src="https://i0.wp.com/neptune.ai/wp-content/uploads/cum_gain_chart.png?fit=1024%2C768&amp;ssl=1" alt></p><h2 id="21-4-什么时候用？"><a href="#21-4-什么时候用？" class="headerlink" title="21.4 什么时候用？"></a>21.4 什么时候用？</h2><ul><li>当你想选择最有希望与你进行交易的客户的时候，可以使用 CGC 作为评估指标。</li><li>它可以作为 ROC-AUC 指标的一个很好的额外补充。</li></ul><h1 id="22-Lift-curve-lift-chart"><a href="#22-Lift-curve-lift-chart" class="headerlink" title="22. Lift curve | lift chart"></a>22. Lift curve | lift chart</h1><h2 id="22-1-定义-lift-curve"><a href="#22-1-定义-lift-curve" class="headerlink" title="22.1 定义 lift curve"></a>22.1 定义 lift curve</h2><p>Lift curve 基本上只是 CGC 的另一种表示形式：</p><ul><li>首先对预测结果由高到低进行排序；</li><li>对于每个预测值，计算训练好的模型和随机模型达到该百分比概率的真阳性比例</li><li>计算上述比例，然后画图</li></ul><p>它能告诉我们对于给定最大预测值，它比一个随机模型好多少。</p><h2 id="22-2-用-scikit-learn-计算-lift-curve"><a href="#22-2-用-scikit-learn-计算-lift-curve" class="headerlink" title="22.2 用 scikit-learn 计算 lift curve"></a>22.2 用 scikit-learn 计算 lift curve</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scikitplot.metrics <span class="keyword">import</span> plot_lift_curve </span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots() plot_lift_curve(y_true, y_pred, ax=ax)</span><br></pre></td></tr></table></figure><p><img src="https://i2.wp.com/neptune.ai/wp-content/uploads/lift_curve_chart.png?fit=1024%2C768&amp;ssl=1" alt></p><h2 id="22-3-什么时候用？"><a href="#22-3-什么时候用？" class="headerlink" title="22.3 什么时候用？"></a>22.3 什么时候用？</h2><ul><li>当你想选择最有希望与你进行交易的客户的时候，可以使用 CGC 作为评估指标。</li><li>它可以作为 ROC-AUC 指标的一个很好的额外补充。</li></ul><h1 id="23-Kolmogorov-Smirnov-plot"><a href="#23-Kolmogorov-Smirnov-plot" class="headerlink" title="23. Kolmogorov-Smirnov plot"></a>23. Kolmogorov-Smirnov plot</h1><h2 id="23-1-定义-KS-plot"><a href="#23-1-定义-KS-plot" class="headerlink" title="23.1 定义 KS plot"></a>23.1 定义 KS plot</h2><p>KS plot 帮助我们从预测结果中获得独立的正样本分布和负样本分布。</p><ul><li>根据预测得分进行排序</li><li>对 [0.0, 1.0] 之间的每个截点计算相邻截点（depth）之间的数据中的真阳性和真阴性比例</li><li>画出计算出来的比例，y 轴表示 $positive(depth)/positive(all)$，$negative(depth)/negative(all)$，x 轴表示 depth</li></ul><p>KS plot有点类似于 CGC，但是CGC 只关注正样本，而 KS plot同时关注正负样本。</p><h2 id="23-2-用-scikit-learn-计算-KS-plot"><a href="#23-2-用-scikit-learn-计算-KS-plot" class="headerlink" title="23.2 用 scikit-learn 计算 KS plot"></a>23.2 用 scikit-learn 计算 KS plot</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scikitplot.metrics <span class="keyword">import</span> plot_ks_statistic</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">plot_ks_statistic(y_true, y_pred, ax=ax)</span><br></pre></td></tr></table></figure><p><img src="https://i0.wp.com/neptune.ai/wp-content/uploads/ks_plot.png?fit=1024%2C768&amp;ssl=1" alt></p><h1 id="24-Kolmogorov-Smirnov-statistic"><a href="#24-Kolmogorov-Smirnov-statistic" class="headerlink" title="24. Kolmogorov-Smirnov statistic"></a>24. Kolmogorov-Smirnov statistic</h1><h2 id="24-1-定义-KS-statistic"><a href="#24-1-定义-KS-statistic" class="headerlink" title="24.1 定义 KS statistic"></a>24.1 定义 KS statistic</h2><p>如果我们想从 KS plot 中选择一个值作为指标，那么我们可以查看所有 KS plot 中所有阈值，然后找到正负样本分布距离最远的点。</p><p>如果有一个阈值，所有观测到的上方样本都是真阳性，而所有下方的样本都是真阴性，那么我们就找到了一个完美的 KS statistic 值：1.0</p><h2 id="24-2-用-scikit-learn-计算-KS-statistic"><a href="#24-2-用-scikit-learn-计算-KS-statistic" class="headerlink" title="24.2 用 scikit-learn 计算 KS statistic"></a>24.2 用 scikit-learn 计算 KS statistic</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scikitplot.helpers <span class="keyword">import</span> binary_ks_curve</span><br><span class="line"></span><br><span class="line">res = binary_ks_curve(y_true, y_pred_pos)</span><br><span class="line">ks_stat = res[<span class="number">3</span>]</span><br></pre></td></tr></table></figure><h2 id="24-3-什么时候用？"><a href="#24-3-什么时候用？" class="headerlink" title="24.3 什么时候用？"></a>24.3 什么时候用？</h2><ul><li>当你面对的是排序问题且你对正负样本都很关心的时候</li><li>可以作为 ROC-AUC  的补充指标</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://neptune.ai/blog/evaluation-metrics-binary-classification" target="_blank" rel="noopener">24 Evaluation Metrics for Binary Classification (And When to Use Them)</a></li><li><a href="https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/" target="_blank" rel="noopener">Everything you Should Know about Confusion Matrix for Machine Learning</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img width=&quot;75%&quot; src=&quot;https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/4f4d15426607b3fd4051791fa9224979.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;评估一个模型的好坏有很多指标，每个指标都有其优缺点。如何针对不同场合选取合适的评估指标是一个非常重要的工作。本文将会介绍一些用于分类模型的评估指标，然后介绍我们该如何选取。&lt;/p&gt;
    
    </summary>
    
      <category term="博客转载" scheme="https://rogerspy.gitee.io/categories/%E5%8D%9A%E5%AE%A2%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="评估方法" scheme="https://rogerspy.gitee.io/tags/%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
</feed>

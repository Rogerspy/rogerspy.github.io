<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <title>模型压缩——知识蒸馏 | Rogerspy&#39;s Home</title>
  
  <meta name="keywords" content="Machine Learning, Deep Learning, NLP">
  
  

  
  <link rel="alternate" href="/atom.xml" title="Rogerspy's Home">
  

  <meta name="HandheldFriendly" content="True">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  
  
  <meta name="theme-color" content="#FFFFFF">
  <meta name="msapplication-TileColor" content="#1BC3FB">
  <meta name="msapplication-config" content="https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/browserconfig.xml">
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.10.1/css/all.min.css">
  
  
  <link rel="shortcut icon" type="image/x-icon" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicon.ico">
  <link rel="icon" type="image/x-icon" sizes="32x32" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/favicon-32x32.png">
  <link rel="apple-touch-icon" type="image/png" sizes="180x180" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/apple-touch-icon.png">
  <link rel="mask-icon" color="#1BC3FB" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/safari-pinned-tab.svg">
  <link rel="manifest" href="https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/site.webmanifest">
  

  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.5/css/style.css">
  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>
  

  
  
  <!-- 时间线 -->
  <link rel="stylesheet" href="/css/timeline.css">
  <!-- 血小板-->
  <link rel="stylesheet" href="/live2d/css/live2d.css">
  <style>
	.article p .mjx-math {
	    font-family: Menlo,Monaco,courier,monospace,"Lucida Console",'Source Code Pro',"Microsoft YaHei",Helvetica,Arial,sans-serif,Ubuntu;
        background: none;
        padding: 2px;
        border-radius: 4px;
	}
  </style>
</head>

<body>
  
  
  <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href='/' >
        
          Rogerspy's Home
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/blog/"
                  
                  
                  id="blog">
									<i class='fas fa-edit fa-fw'></i>&nbsp;博客
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/video/"
                  
                  
                  id="video">
									<i class='fas fa-film fa-fw'></i>&nbsp;视频小站
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/material/"
                  
                  
                  id="material">
									<i class='fas fa-briefcase fa-fw'></i>&nbsp;学习资料
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/categories/"
                  
                    rel="nofollow"
                  
                  
                  id="categories">
									<i class='fas fa-folder-open fa-fw'></i>&nbsp;分类
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/archives/"
                  
                    rel="nofollow"
                  
                  
                  id="archives">
									<i class='fas fa-archive fa-fw'></i>&nbsp;归档
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="搜索" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/"
                
                
                id="home">
								<i class='fas fa-clock fa-fw'></i>&nbsp;近期文章
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/blog/archives/"
                
                  rel="nofollow"
                
                
                id="blogarchives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;文章归档
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/blog/"
                
                
                id="blog">
								<i class='fas fa-edit fa-fw'></i>&nbsp;我的博客
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/video/"
                
                  rel="nofollow"
                
                
                id="video">
								<i class='fas fa-film fa-fw'></i>&nbsp;我的视频
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/material/"
                
                  rel="nofollow"
                
                
                id="material">
								<i class='fas fa-briefcase fa-fw'></i>&nbsp;学习资料
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/about/"
                
                  rel="nofollow"
                
                
                id="about">
								<i class='fas fa-info-circle fa-fw'></i>&nbsp;关于小站
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>



  <div class="l_body nocover">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  
    <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
      


  <section class='meta'>
    
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2021/02/15/knowledge-distilling/">
        模型压缩——知识蒸馏
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            
  <div class='new-meta-item author'>
    <a href="https://rogerspy.gitee.io" rel="nofollow">
      
        <i class="fas fa-user" aria-hidden="true"></i>
      
      <p>Rogerspy</p>
    </a>
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2021-02-15</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/笔记/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>笔记</p>
    </a>
  </div>


          
        
          
            
  
    <div class="new-meta-item browse busuanzi">
      <a class='notlink'>
        <i class="fas fa-eye" aria-hidden="true"></i>
        <p>
          <span id="busuanzi_value_page_pv">
            <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
          </span>
        </p>
      </a>
    </div>
  


          
        
          
            

          
        
          
            
  
    <div style="margin-right: 10px;">
      <span class="post-time">
        <span class="post-meta-item-icon">
          <i class="fa fa-keyboard"></i>
          <span class="post-meta-item-text">  字数统计: </span>
          <span class="post-count">4.2k字</span>
        </span>
      </span>
      &nbsp; | &nbsp;
      <span class="post-time">
        <span class="post-meta-item-icon">
          <i class="fa fa-hourglass-half"></i>
          <span class="post-meta-item-text">  阅读时长≈</span>
          <span class="post-count">18分</span>
        </span>
      </span>
    </div>
  

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


      <section class="article typo">
        <div class="article-entry" itemprop="articleBody">
          <p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20220315151511.png" alt></p>
<blockquote>
<p>文章转载自：<a href="https://mp.weixin.qq.com/s/9S0hNMdinQMbAPlZyHclFg" target="_blank" rel="noopener">模型压缩 | 知识蒸馏经典解读</a>。</p>
</blockquote>
<p>知识蒸馏是一种模型压缩方法，是一种基于“教师-学生网络思想”的训练方法，由于其简单，有效，在工业界被广泛应用。这一技术的理论来自于2015年Hinton发表的一篇神作：<a href="https://arxiv.org/pdf/1503.02531.pdf" target="_blank" rel="noopener">Distilling the Knowledge in a Neural Network</a></p>
<a id="more"></a>
<p>Knowledge Distillation，简称KD，顾名思义，就是将已经训练好的模型包含的知识(”Knowledge”)，蒸馏(“Distill”)提取到另一个模型里面去。今天，我们就来简单读一下这篇论文，力求用简单的语言描述论文作者的主要思想。在本文中，我们将从背景和动机讲起，然后着重介绍“知识蒸馏”的方法，最后我会讨论“温度“这个名词:</p>
<blockquote>
<p><strong>「温度」</strong>: 我们都知道“蒸馏”需要在高温下进行，那么这个“蒸馏”的温度代表了什么，又是如何选取合适的温度？</p>
</blockquote>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>虽然在一般情况下，我们不会去区分训练和部署使用的模型，但是训练和部署之间存在着一定的不一致性:</p>
<ul>
<li>在训练过程中，我们需要使用复杂的模型，大量的计算资源，以便从非常大、高度冗余的数据集中提取出信息。在实验中，效果最好的模型往往规模很大，甚至由多个模型集成得到。而大模型不方便部署到服务中去，常见的瓶颈如下:<ul>
<li>推断速度慢</li>
<li>对部署资源要求高(内存，显存等)</li>
</ul>
</li>
<li>在部署时，我们对延迟以及计算资源都有着严格的限制。</li>
</ul>
<p>因此，模型压缩（在保证性能的前提下减少模型的参数量）成为了一个重要的问题。而<strong>「模型蒸馏」</strong>属于模型压缩的一种方法。</p>
<h2 id="“思想歧路”"><a href="#“思想歧路”" class="headerlink" title="“思想歧路”"></a>“思想歧路”</h2><p>人们在直觉上会觉得，要保留相近的知识量，必须保留相近规模的模型。也就是说，一个模型的参数量基本决定了其所能捕获到的数据内蕴含的“知识”的量。</p>
<p>这样的想法是基本正确的，但是需要注意的是:</p>
<ol>
<li>模型的参数量和其所能捕获的“知识“量之间并非稳定的线性关系(下图中的1)，而是接近边际收益逐渐减少的一种增长曲线(下图中的2和3)。</li>
<li>完全相同的模型架构和模型参数量，使用完全相同的训练数据，能捕获的“知识”量并不一定完全相同，另一个关键因素是训练的方法。合适的训练方法可以使得在模型参数总量比较小时，尽可能地获取到更多的“知识”(下图中的3与2曲线的对比)。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/640kd.png" style="zoom:50%;"></p>
<h1 id="知识蒸馏的理论依据"><a href="#知识蒸馏的理论依据" class="headerlink" title="知识蒸馏的理论依据"></a>知识蒸馏的理论依据</h1><h2 id="Teacher-Model-和-Student-Model"><a href="#Teacher-Model-和-Student-Model" class="headerlink" title="Teacher Model 和 Student Model"></a>Teacher Model 和 Student Model</h2><p>知识蒸馏使用的是Teacher—Student模型，其中teacher是“知识”的输出者，student是“知识”的接受者。知识蒸馏的过程分为2个阶段:</p>
<ol>
<li>原始模型训练: 训练”Teacher模型”, 简称为Net-T，它的特点是模型相对复杂，也可以由多个分别训练的模型集成而成。我们对”Teacher模型”不作任何关于模型架构、参数量、是否集成方面的限制，唯一的要求就是，对于输入X, 其都能输出Y，其中Y经过softmax的映射，输出值对应相应类别的概率值。</li>
<li>精简模型训练: 训练”Student模型”, 简称为Net-S，它是参数量较小、模型结构相对简单的单模型。同样的，对于输入X，其都能输出Y，Y经过softmax映射后同样能输出对应相应类别的概率值。</li>
</ol>
<p>在本论文中，作者将问题限定在<strong>「分类问题」</strong>下，或者其他本质上属于分类问题的问题，该类问题的共同点是模型最后会有一个softmax层，其输出值对应了相应类别的概率值。</p>
<h2 id="知识蒸馏的关键点"><a href="#知识蒸馏的关键点" class="headerlink" title="知识蒸馏的关键点"></a>知识蒸馏的关键点</h2><p>如果回归机器学习最最基础的理论，我们可以很清楚地意识到一点(而这一点往往在我们深入研究机器学习之后被忽略): 机器学习<strong>「最根本的目的」</strong>在于训练出在某个问题上泛化能力强的模型。</p>
<ul>
<li>泛化能力强: 在某问题的所有数据上都能很好地反应输入和输出之间的关系，无论是训练数据，还是测试数据，还是任何属于该问题的未知数据。</li>
</ul>
<p>而现实中，由于我们不可能收集到某问题的所有数据来作为训练数据，并且新数据总是在源源不断的产生，因此我们只能退而求其次，训练目标变成在已有的训练数据集上建模输入和输出之间的关系。由于训练数据集是对真实数据分布情况的采样，训练数据集上的最优解往往会多少偏离真正的最优解(这里的讨论不考虑模型容量)。</p>
<p>而在知识蒸馏时，由于我们已经有了一个泛化能力较强的Net-T，我们在利用Net-T来蒸馏训练Net-S时，可以直接让Net-S去学习Net-T的泛化能力。</p>
<p>一个很直白且高效的迁移泛化能力的方法就是使用 softmax 层输出的类别的概率来作为 “soft target”。</p>
<ol>
<li>传统 training 过程 (hard targets): 对 ground truth 求极大似然。</li>
<li>KD 的 training 过程(soft targets): 用 large model 的 class probabilities 作为 soft targets。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/640kd1.png" alt></p>
<h3 id="为什么？"><a href="#为什么？" class="headerlink" title="为什么？"></a>为什么？</h3><p>softmax 层的输出，除了正例之外，负标签也带有大量的信息，比如某些负标签对应的概率远远大于其他负标签。而在传统的训练过程 (hard target) 中，所有负标签都被统一对待。也就是说，KD的训练方式使得每个样本给Net-S带来的信息量大于传统的训练方式。</p>
<p>举个例子来说明一下: 在手写体数字识别任务 MNIST 中，输出类别有10个。</p>
<p>假设某个输入的“2”更加形似”3”，softmax 的输出值中”3”对应的概率为0.1，而其他负标签对应的值都很小，而另一个”2”更加形似”7”，”7”对应的概率为0.1。这两个”2”对应的hard target的值是相同的，但是它们的soft target却是不同的，由此我们可见soft target蕴含着比hard target多的信息。并且soft target分布的熵相对高时，其soft target蕴含的知识就更丰富。</p>
<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/640kd2.png" style="zoom:50%;"></p>
<p>这就解释了为什么通过蒸馏的方法训练出的 Net-S 相比使用完全相同的模型结构和训练数据只使用 hard target 的训练方法得到的模型，拥有更好的泛化能力。</p>
<h3 id="softmax-函数"><a href="#softmax-函数" class="headerlink" title="softmax 函数"></a>softmax 函数</h3><p>先回顾一下原始的 softmax 函数：</p>
<script type="math/tex; mode=display">
\text{softmax}(z_i) = \frac{\exp(z_i)}{\sum_j \exp(z_j)}</script><p>但要是直接使用 softmax 层的输出值作为 soft target，这又会带来一个问题: 当 softmax 输出的概率分布熵相对较小时，负标签的值都很接近 0，对损失函数的贡献非常小，小到可以忽略不计。因此”温度”这个变量就派上了用场。</p>
<p>下面的公式时加了温度这个变量之后的 softmax 函数:</p>
<script type="math/tex; mode=display">
\text{softmax}(z_i) = \frac{\exp(z_i/T)}{\sum_j\exp(z_j/T)}</script><ul>
<li>这里的 $T$ 就是<strong>「温度」</strong>。</li>
<li>原来的 softmax 函数是 $T = 1$ 的特例。$T$ 越高，softmax 的概率分布越趋于平滑，其分布的熵越大，负标签携带的信息会被相对地放大，模型训练将更加关注负标签。</li>
</ul>
<h1 id="知识蒸馏的具体方法"><a href="#知识蒸馏的具体方法" class="headerlink" title="知识蒸馏的具体方法"></a>知识蒸馏的具体方法</h1><h2 id="通用的知识蒸馏方法"><a href="#通用的知识蒸馏方法" class="headerlink" title="通用的知识蒸馏方法"></a>通用的知识蒸馏方法</h2><p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/640kd3.png" style="zoom:80%;"></p>
<ul>
<li><p>第一步是训练 Net-T；第二步是在高温 $T$ 下，蒸馏 Net-T 的知识到 Net-S。训练 Net-T 的过程很简单，下面详细讲讲第二步:高温蒸馏的过程。高温蒸馏过程的目标函数由 distill loss (对应soft target) 和 student loss (对应 hard target)加权得到，示意图如上。</p>
<script type="math/tex; mode=display">
L = \alpha L_{\text{soft}} +\beta L_{\text{hard}}</script></li>
<li><p>Net-T 和 Net-S 同时输如训练集, 用 Net-T 输出概率来作为 soft target，Net-S 在相同温度 $T$ 下的 softmax 输出和 soft target 的 cross entropy 就是<strong>「Loss函数的第一部分」</strong>$L_{\text{soft}}$：</p>
<script type="math/tex; mode=display">
L_{soft} = -\sum_j^N p_j^T \log(q_j^T)</script><p>其中 $p_i^T=\frac{\exp(v_i/T)}{\sum_k^N \exp(v_k/T)}$，$q_i^T=\frac{\exp(z_i/T)}{\sum_k^N \log(z_k/T)}$。</p>
</li>
<li><p>Net-S 在 $T=1$下的 softmax 输出和 ground truth 的 cross entropy 就是<strong>「Loss函数的第二部分」</strong> $L_{\text{hard}}$：</p>
<script type="math/tex; mode=display">
L_{\text{hard}} = -\sum_j^N c_j \log(q_j^1)</script><p>其中，$c_j$ 表示在第 $j$ 类上的 ground truth 值，$c_j \in \{0,1\}$， 正标签取 1，负标签取 0。$q_j^1=\frac{\exp(z_i)}{\sum_j^N \exp(z_j)}$。</p>
</li>
<li><p>第二部分 $L_{\text{hard}}$ 的必要性其实很好理解: Net-T 也有一定的错误率，使用 ground truth 可以有效降低错误被传播给 Net-S 的可能。打个比方，老师虽然学识远远超过学生，但是他仍然有出错的可能，而这时候如果学生在老师的教授之外，可以同时参考到标准答案，就可以有效地降低被老师偶尔的错误“带偏”的可能性。</p>
</li>
</ul>
<h2 id="一种特殊情形-直接match-logits-不经过softmax"><a href="#一种特殊情形-直接match-logits-不经过softmax" class="headerlink" title="一种特殊情形: 直接match logits(不经过softmax)"></a>一种特殊情形: 直接match logits(不经过softmax)</h2><p>直接 match logits 指的是，直接使用 softmax 层的输入 logits（而不是输出）作为 soft targets，需要最小化的目标函数是 Net-T 和 Net-S 的 logits 之间的平方差。</p>
<p>由单个 case 贡献的 loss，推算出对应在 Net-S 每个 logit $z_i$上的梯度:</p>
<script type="math/tex; mode=display">
\frac{\partial L_{\text{soft}}}{\partial z_i} = \frac{1}{T}(q_i-p_i) = \frac{1}{T}(\frac{e^{z_i/T}}{\sum_j e^{z_j/T}}-\frac{e^{v_i/T}}{\sum_j e^{v_j/T}})</script><p>当 $T \rightarrow \infty$ 时，$e^{x/T} \rightarrow 1 + x/T$ ，于是：</p>
<script type="math/tex; mode=display">
\frac{\partial L_{\text{soft}}}{\partial z_i} = \frac{1}{T}(\frac{1+z_i/T}{N+z_j/T}-\frac{1+v_i/T}{N+ v_j/T})</script><p>假设 logits 是零均值的，即 $\sum_j z_j = \sum_j v_j=0$，则</p>
<script type="math/tex; mode=display">
\frac{\partial L_{\text{soft}}}{\partial z_i} \approx \frac{1}{NT^2}(z_i-v_i)</script><p>也就是相当于最小化：</p>
<script type="math/tex; mode=display">
L'_{\text{soft}} = \frac{1}{2}(z_i-v_i)^2</script><h1 id="关于”温度”的讨论"><a href="#关于”温度”的讨论" class="headerlink" title="关于”温度”的讨论"></a>关于”温度”的讨论</h1><p>【问题】 我们都知道“蒸馏”需要在高温下进行，那么这个“蒸馏”的温度代表了什么，又是如何选取合适的温度？</p>
<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/640kd4.png" alt></p>
<h4 id="温度的特点"><a href="#温度的特点" class="headerlink" title="温度的特点"></a>温度的特点</h4><p>在回答这个问题之前，先讨论一下<strong>「温度T的特点」</strong></p>
<ol>
<li>原始的softmax函数是 时的特例， 时，概率分布比原始更“陡峭”， 时，概率分布比原始更“平缓”。</li>
<li>温度越高，softmax上各个值的分布就越平均（思考极端情况: (i), 此时softmax的值是平均分布的；(ii) ，此时softmax的值就相当于,即最大的概率处的值趋近于1，而其他值趋近于0）</li>
<li>不管温度T怎么取值，Soft target都有忽略小的 携带的信息的倾向</li>
</ol>
<h4 id="温度代表了什么，如何选取合适的温度？"><a href="#温度代表了什么，如何选取合适的温度？" class="headerlink" title="温度代表了什么，如何选取合适的温度？"></a>温度代表了什么，如何选取合适的温度？</h4><p>温度的高低改变的是Net-S训练过程中对负标签的关注程度: 温度较低时，对负标签的关注，尤其是那些显著低于平均值的负标签的关注较少；而温度较高时，负标签相关的值会相对增大，Net-S会相对多地关注到负标签。</p>
<p>实际上，负标签中包含一定的信息，尤其是那些值显著<strong>「高于」</strong>平均值的负标签。但由于Net-T的训练过程决定了负标签部分比较noisy，并且负标签的值越低，其信息就越不可靠。因此温度的选取比较empirical，本质上就是在下面两件事之中取舍:</p>
<ol>
<li>从有部分信息量的负标签中学习 –&gt; 温度要高一些</li>
<li>防止受负标签中噪声的影响 –&gt; 温度要低一些</li>
</ol>
<p>总的来说，$T$ 的选择和 Net-S 的大小有关，Net-S 参数量比较小的时候，相对比较低的温度就可以了（因为参数量小的模型不能 capture all knowledge，所以可以适当忽略掉一些负标签的信息）</p>
<h1 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h1><p>下面我们用一个图像分类器举个例子。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入tensorflow包</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.random.set_seed(<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.applications <span class="keyword">import</span> MobileNetV2</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line">tfds.disable_progress_bar()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获得数据</span></span><br><span class="line">train_ds, validation_ds = tfds.load(</span><br><span class="line">    <span class="string">"tf_flowers"</span>,</span><br><span class="line">    split=[<span class="string">"train[:85%]"</span>, <span class="string">"train[85%:]"</span>],</span><br><span class="line">    as_supervised=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line"><span class="comment"># Visualization</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i, (image, label) <span class="keyword">in</span> enumerate(train_ds.take(<span class="number">9</span>)):</span><br><span class="line">    ax = plt.subplot(<span class="number">3</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.title(int(label))</span><br><span class="line">    plt.axis(<span class="string">"off"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/blog-imgs/20220316104840.png" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 图片处理</span></span><br><span class="line"></span><br><span class="line">SIZE = (<span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_image</span><span class="params">(image, label)</span>:</span></span><br><span class="line">    image = tf.image.convert_image_dtype(image, tf.float32)</span><br><span class="line">    image = tf.image.resize(image, SIZE)</span><br><span class="line">    <span class="keyword">return</span> (image, label)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造 batch 训练数据</span></span><br><span class="line">BATCH_SIZE = <span class="number">64</span></span><br><span class="line">AUTO = tf.data.experimental.AUTOTUNE</span><br><span class="line"></span><br><span class="line">train_ds = (</span><br><span class="line">    train_ds</span><br><span class="line">    .map(preprocess_image, num_parallel_calls=AUTO)</span><br><span class="line">    .cache()</span><br><span class="line">    .shuffle(<span class="number">1024</span>)</span><br><span class="line">    .batch(BATCH_SIZE)</span><br><span class="line">    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">validation_ds = (</span><br><span class="line">    validation_ds</span><br><span class="line">    .map(preprocess_image, num_parallel_calls=AUTO)</span><br><span class="line">    .cache()</span><br><span class="line">    .batch(BATCH_SIZE)</span><br><span class="line">    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Teacher model</span></span><br><span class="line">base_model = MobileNetV2(weights=<span class="string">"imagenet"</span>, include_top=<span class="literal">False</span>,</span><br><span class="line">        input_shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line">base_model.trainable = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_teacher_model</span><span class="params">()</span>:</span></span><br><span class="line">    inputs = layers.Input(shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line">    x = base_model(inputs, training=<span class="literal">False</span>)</span><br><span class="line">    x = layers.GlobalAveragePooling2D()(x)</span><br><span class="line">    x = layers.Dense(<span class="number">5</span>)(x)</span><br><span class="line">    classifier = models.Model(inputs=inputs, outputs=x)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> classifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印 teacher model 结构</span></span><br><span class="line">get_teacher_model().summary()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;functional_1&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">input_2 (InputLayer)         [(None, 224, 224, 3)]     0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">global_average_pooling2d (Gl (None, 1280)              0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense (Dense)                (None, 5)                 6405      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 2,264,389</span><br><span class="line">Trainable params: 2,230,277</span><br><span class="line">Non-trainable params: 34,112</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>)</span><br><span class="line">optimizer = tf.keras.optimizers.Adam(learning_rate=<span class="number">1e-5</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练 teacher model</span></span><br><span class="line">teacher_model = get_teacher_model()</span><br><span class="line">teacher_model.compile(loss=loss_func, optimizer=optimizer, metrics=[<span class="string">"accuracy"</span>])</span><br><span class="line">teacher_model.fit(train_ds,</span><br><span class="line">                  validation_data=validation_ds,</span><br><span class="line">                  epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/5</span><br><span class="line">      2/Unknown - 0s 245ms/step - loss: 1.6895 - accuracy: 0.2969WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1600s vs `on_train_batch_end` time: 0.3296s). Check your callbacks.</span><br><span class="line">WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1600s vs `on_train_batch_end` time: 0.3296s). Check your callbacks.</span><br><span class="line">49/49 [==============================] - 24s 490ms/step - loss: 0.9725 - accuracy: 0.6224 - val_loss: 0.5764 - val_accuracy: 0.8000</span><br><span class="line">Epoch 2/5</span><br><span class="line">49/49 [==============================] - 22s 456ms/step - loss: 0.4474 - accuracy: 0.8449 - val_loss: 0.3946 - val_accuracy: 0.8655</span><br><span class="line">Epoch 3/5</span><br><span class="line">49/49 [==============================] - 23s 463ms/step - loss: 0.3020 - accuracy: 0.9006 - val_loss: 0.3256 - val_accuracy: 0.8782</span><br><span class="line">Epoch 4/5</span><br><span class="line">49/49 [==============================] - 23s 466ms/step - loss: 0.2312 - accuracy: 0.9282 - val_loss: 0.2882 - val_accuracy: 0.8982</span><br><span class="line">Epoch 5/5</span><br><span class="line">49/49 [==============================] - 22s 456ms/step - loss: 0.1779 - accuracy: 0.9446 - val_loss: 0.2606 - val_accuracy: 0.9145</span><br><span class="line">&lt;tensorflow.python.keras.callbacks.History at 0x7ff81abec8d0&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 评估并保存模型</span></span><br><span class="line">print(<span class="string">"Test accuracy: &#123;:.2f&#125;"</span>.format(teacher_model.evaluate(validation_ds)[<span class="number">1</span>]*<span class="number">100</span>))</span><br><span class="line">teacher_model.save_weights(<span class="string">"teacher_model.h5"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">9/9 [==============================] - 1s 67ms/step - loss: 0.2606 - accuracy: 0.9145</span><br><span class="line">Test accuracy: 91.45</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Student model</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_student_model</span><span class="params">(deeper=False)</span>:</span></span><br><span class="line">    student_model = models.Sequential()</span><br><span class="line">    student_model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), </span><br><span class="line">        input_shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>), </span><br><span class="line">        activation=<span class="string">"relu"</span>,</span><br><span class="line">        kernel_initializer=<span class="string">"he_normal"</span>))</span><br><span class="line">    student_model.add(layers.MaxPooling2D((<span class="number">4</span>, <span class="number">4</span>)))</span><br><span class="line">    </span><br><span class="line">    student_model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), </span><br><span class="line">        activation=<span class="string">"relu"</span>,</span><br><span class="line">        kernel_initializer=<span class="string">"he_normal"</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> deeper:</span><br><span class="line">        student_model.add(tf.keras.layers.MaxPooling2D((<span class="number">4</span>, <span class="number">4</span>)))</span><br><span class="line">        student_model.add(tf.keras.layers.Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), </span><br><span class="line">            activation=<span class="string">"relu"</span>,</span><br><span class="line">            kernel_initializer=<span class="string">"he_normal"</span>))</span><br><span class="line">    </span><br><span class="line">    student_model.add(layers.GlobalAveragePooling2D())</span><br><span class="line">    student_model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    student_model.add(layers.Dense(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> student_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印模型结构</span></span><br><span class="line">get_student_model().summary()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;sequential&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">conv2d (Conv2D)              (None, 222, 222, 64)      1792      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d (MaxPooling2D) (None, 55, 55, 64)        0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv2d_1 (Conv2D)            (None, 53, 53, 128)       73856     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">global_average_pooling2d_2 ( (None, 128)               0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense)              (None, 512)               66048     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_3 (Dense)              (None, 5)                 2565      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 144,261</span><br><span class="line">Trainable params: 144,261</span><br><span class="line">Non-trainable params: 0</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Average the loss across the batch size within an epoch</span></span><br><span class="line">train_loss = tf.keras.metrics.Mean(name=<span class="string">"train_loss"</span>)</span><br><span class="line">valid_loss = tf.keras.metrics.Mean(name=<span class="string">"test_loss"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify the performance metric</span></span><br><span class="line">train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">"train_acc"</span>)</span><br><span class="line">valid_acc = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">"valid_acc"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define the training loop</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_kd_loss</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    student_logits, </span></span></span><br><span class="line"><span class="function"><span class="params">    teacher_logits,        </span></span></span><br><span class="line"><span class="function"><span class="params">    true_labels, </span></span></span><br><span class="line"><span class="function"><span class="params">    temperature,</span></span></span><br><span class="line"><span class="function"><span class="params">    alpha, </span></span></span><br><span class="line"><span class="function"><span class="params">    beta</span></span></span><br><span class="line"><span class="function"><span class="params">)</span>:</span></span><br><span class="line">    teacher_probs = tf.nn.softmax(teacher_logits / temperature)</span><br><span class="line">    kd_loss = tf.keras.losses.categorical_crossentropy(</span><br><span class="line">        teacher_probs, </span><br><span class="line">        student_logits / temperature, </span><br><span class="line">        from_logits=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    ce_loss = tf.keras.losses.sparse_categorical_crossentropy(</span><br><span class="line">        true_labels, </span><br><span class="line">        student_logits, </span><br><span class="line">        from_logits=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    total_loss = (alpha * kd_loss) + (beta * ce_loss)</span><br><span class="line">    <span class="keyword">return</span> total_loss / (alpha + beta)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        self, </span></span></span><br><span class="line"><span class="function"><span class="params">        trained_teacher, </span></span></span><br><span class="line"><span class="function"><span class="params">        student, </span></span></span><br><span class="line"><span class="function"><span class="params">        temperature=<span class="number">5.</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">        alpha=<span class="number">0.9</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">        beta=<span class="number">0.1</span></span></span></span><br><span class="line"><span class="function"><span class="params">    )</span>:</span></span><br><span class="line">        super(Student, self).__init__()</span><br><span class="line">        self.trained_teacher = trained_teacher</span><br><span class="line">        self.student = student</span><br><span class="line">        self.temperature = temperature</span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        self.beta = beta</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        images, labels = data</span><br><span class="line">        teacher_logits = self.trained_teacher(images)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            student_logits = self.student(images)</span><br><span class="line">            loss = get_kd_loss(student_logits, teacher_logits,  </span><br><span class="line">                               labels, self.temperature,</span><br><span class="line">                               self.alpha, self.beta)</span><br><span class="line">        gradients = tape.gradient(loss, self.student.trainable_variables)</span><br><span class="line">        <span class="comment"># As mentioned in https://arxiv.org/abs/1503.02531</span></span><br><span class="line">        gradients = [gradient * (self.temperature ** <span class="number">2</span>) <span class="keyword">for</span> gradient <span class="keyword">in</span> gradients]</span><br><span class="line">        self.optimizer.apply_gradients(zip(gradients, self.student.trainable_variables))</span><br><span class="line"></span><br><span class="line">        train_loss.update_state(loss)</span><br><span class="line">        train_acc.update_state(labels, tf.nn.softmax(student_logits))</span><br><span class="line">        t_loss, t_acc = train_loss.result(), train_acc.result()</span><br><span class="line">        train_loss.reset_states(), train_acc.reset_states()</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">"train_loss"</span>: t_loss, <span class="string">"train_accuracy"</span>: t_acc&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_step</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        images, labels = data</span><br><span class="line">        teacher_logits = self.trained_teacher(images)</span><br><span class="line">        </span><br><span class="line">        student_logits = self.student(images, training=<span class="literal">False</span>)</span><br><span class="line">        loss = get_kd_loss(student_logits, teacher_logits,  </span><br><span class="line">                               labels, self.temperature,</span><br><span class="line">                               self.alpha, self.beta)</span><br><span class="line">        </span><br><span class="line">        valid_loss.update_state(loss)</span><br><span class="line">        valid_acc.update_state(labels, tf.nn.softmax(student_logits))</span><br><span class="line">        v_loss, v_acc = valid_loss.result(), valid_acc.result()</span><br><span class="line">        valid_loss.reset_states(), valid_acc.reset_states()</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">"loss"</span>: v_loss, <span class="string">"accuracy"</span>: v_acc&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">student = Student(teacher_model, get_student_model())</span><br><span class="line">optimizer = tf.keras.optimizers.Adam(learning_rate=<span class="number">0.01</span>)</span><br><span class="line">student.compile(optimizer)</span><br><span class="line"></span><br><span class="line">student.fit(train_ds, </span><br><span class="line">            validation_data=validation_ds,</span><br><span class="line">            epochs=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/10</span><br><span class="line">49/49 [==============================] - 9s 183ms/step - train_loss: 1.5737 - train_accuracy: 0.3676 - val_loss: 1.5175 - val_accuracy: 0.5526</span><br><span class="line">Epoch 2/10</span><br><span class="line">49/49 [==============================] - 8s 162ms/step - train_loss: 1.4912 - train_accuracy: 0.4995 - val_loss: 1.5057 - val_accuracy: 0.5000</span><br><span class="line">Epoch 3/10</span><br><span class="line">49/49 [==============================] - 8s 163ms/step - train_loss: 1.4781 - train_accuracy: 0.5353 - val_loss: 1.4710 - val_accuracy: 0.5789</span><br><span class="line">Epoch 4/10</span><br><span class="line">49/49 [==============================] - 8s 162ms/step - train_loss: 1.4695 - train_accuracy: 0.5513 - val_loss: 1.5139 - val_accuracy: 0.5263</span><br><span class="line">Epoch 5/10</span><br><span class="line">49/49 [==============================] - 8s 161ms/step - train_loss: 1.4600 - train_accuracy: 0.5866 - val_loss: 1.4609 - val_accuracy: 0.6316</span><br><span class="line">Epoch 6/10</span><br><span class="line">49/49 [==============================] - 8s 161ms/step - train_loss: 1.4436 - train_accuracy: 0.6128 - val_loss: 1.4620 - val_accuracy: 0.5789</span><br><span class="line">Epoch 7/10</span><br><span class="line">49/49 [==============================] - 8s 161ms/step - train_loss: 1.4367 - train_accuracy: 0.6258 - val_loss: 1.4253 - val_accuracy: 0.7105</span><br><span class="line">Epoch 8/10</span><br><span class="line">49/49 [==============================] - 8s 161ms/step - train_loss: 1.4337 - train_accuracy: 0.6344 - val_loss: 1.4406 - val_accuracy: 0.6579</span><br><span class="line">Epoch 9/10</span><br><span class="line">49/49 [==============================] - 8s 160ms/step - train_loss: 1.4210 - train_accuracy: 0.6578 - val_loss: 1.4136 - val_accuracy: 0.7105</span><br><span class="line">Epoch 10/10</span><br><span class="line">49/49 [==============================] - 8s 160ms/step - train_loss: 1.4085 - train_accuracy: 0.6797 - val_loss: 1.4602 - val_accuracy: 0.5789</span><br><span class="line">&lt;tensorflow.python.keras.callbacks.History at 0x7ff823b11b00&gt;</span><br></pre></td></tr></table></figure>

        </div>
        
          


  <section class='meta' id="footer-meta">
    <hr>
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2022-03-16T11:04:14+08:00">
  <a class='notlink'>
    <i class="fas fa-clock" aria-hidden="true"></i>
    <p>最后更新于 2022年3月16日</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/knowledge-distillation/" rel="nofollow"><i class="fas fa-hashtag" aria-hidden="true"></i>&nbsp;<p>knowledge distillation</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="QQ好友" rel="external nofollow noopener noreferrer"
          
          href="http://connect.qq.com/widget/shareqq/index.html?url=https://rogerspy.gitee.io/2021/02/15/knowledge-distilling/&title=模型压缩——知识蒸馏 | Rogerspy's Home&summary=

文章转载自：模型压缩 | 知识蒸馏经典解读。

知识蒸馏是一种模型压缩方法，是一种基于“教师-学生网络思想”的训练方法，由于其简单，有效，在工业界被广泛应用。这一技术的理论来自于2015年Hinton发表的一篇神作：Distilling the Knowledge in a Neural Network"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="QQ空间" rel="external nofollow noopener noreferrer"
          
          href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://rogerspy.gitee.io/2021/02/15/knowledge-distilling/&title=模型压缩——知识蒸馏 | Rogerspy's Home&summary=

文章转载自：模型压缩 | 知识蒸馏经典解读。

知识蒸馏是一种模型压缩方法，是一种基于“教师-学生网络思想”的训练方法，由于其简单，有效，在工业界被广泛应用。这一技术的理论来自于2015年Hinton发表的一篇神作：Distilling the Knowledge in a Neural Network"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class='qrcode' rel="external nofollow noopener noreferrer" href='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACr0lEQVR42u3aUW4qQQwEQO5/6bwD5AHd9gwiUu0XUjbs1H7YxvbjEV8/L6/fdz77/Pobnt3/+6+HLzw8PLwLR2+P0h539uKS/8LDw8O7x3sWUZOvfv1t+dGTV5CfGQ8PD+97eJsCNwrlcSLBw8PD+7u8JG1s7sHDw8P7Tt6swZq3WduSOqEe7rXg4eHhxby8FP6ez1fme3h4eHjrqXqbAPIA3a4I/IwuPDw8vBu8POC2xWu+FtA+vb4TDw8P7yO82YBqNsRq17DqtggeHh7eBd5sNWqzZLBJD235joeHh3eWlyeATVuhTSH7MRgeHh7ePV5eKM/G9ptlgotzPDw8PLxrCwEbQB7QN/8Vzffw8PDwjvLqZmg5jsqbCPsxWN2SwMPDw1vwkvozKYJnaWaWkOrSHA8PD+8oLwnTSZLYD7r2reR6fwEPDw9vxMvbAe1CQDKmygdaq6UrPDw8vEO8dgS1L4s3iwXta8XDw8O7zTsL2If7BPMmjeHh4eF9hLcZ9reFeJsS2uYIHh4e3g3epoDOB2CztuwmweDh4eHd4+3XAtqU0DZ526fX2154eHh4o/l78fO+DOuP+GobHMUT8fDw8C7wNqOmPJQn6wKbEny4dIWHh4c34uUPbg86Syrt06MxGB4eHt4F3qmBfT76apNN/mMgWr3Cw8PDW/PyUL5Zt5otE+SvI+pV4+Hh4V3gzULzLBkc66O0dToeHh7eAtYOn2brUO0awWy54T9LV3h4eHhHeZsYO1u0ao/efj6WQvDw8PCC2Xoe3GdH3CShNjHg4eHhfYa3H1nlieRs0+FN6xkPDw/vC3gbQLuY1Y7EDiQGPDw8vGu85DGzY7Xl+JvUgoeHh3eN165P5UX2ZpyWt4YP9Frw8PDwYt6BH/xxwyJnzAr3A3tneHh4eK+uf4pLQQXne2mWAAAAAElFTkSuQmCC'>
        
          <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/wechat.png">
        
        </a>
      
    
      
        <a class="-mob-share-weibo" title="微博" rel="external nofollow noopener noreferrer"
          
          href="http://service.weibo.com/share/share.php?url=https://rogerspy.gitee.io/2021/02/15/knowledge-distilling/&title=模型压缩——知识蒸馏 | Rogerspy's Home&summary=

文章转载自：模型压缩 | 知识蒸馏经典解读。

知识蒸馏是一种模型压缩方法，是一种基于“教师-学生网络思想”的训练方法，由于其简单，有效，在工业界被广泛应用。这一技术的理论来自于2015年Hinton发表的一篇神作：Distilling the Knowledge in a Neural Network"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/assets@19.1.9/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


        
        
            <div class="prev-next">
                
                    <section class="prev">
                        <span class="art-item-left">
                            <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;上一页</h6>
                            <h4>
                                <a href="/2021/02/25/quantization/" rel="prev" title="模型压缩——网络量化">
                                  
                                      模型压缩——网络量化
                                  
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/quantization/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>quantization</a>
                                </h6>
                            
                        </span>
                    </section>
                
                
                    <section class="next">
                        <span class="art-item-right" aria-hidden="true">
                            <h6>下一页&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                            <h4>
                                <a href="/2020/10/13/ptm-introduction/" rel="prev" title="预训练语言模型-前言">
                                    
                                        预训练语言模型-前言
                                    
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/nlp/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>NLP</a> <a class="tag" href="/tags/language-model/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>Language Model</a>
                                </h6>
                            
                        </span>
                    </section>
                
            </div>
        
      </section>
    </article>
  

  
    <!-- 显示推荐文章和评论 -->



  <article class="post white-box comments">
    <section class="article typo">
      <h4><i class="fas fa-comments fa-fw" aria-hidden="true"></i>&nbsp;评论</h4>
      
      
      
        <section id="comments">
          <div id="gitalk-container"></div>
        </section>
      
      
    </section>
  </article>


  




<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->

  <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX","TeX"],
      linebreaks: { automatic:true },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: { autoNumber: "AMS" },
      noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
      Macros: { href: "{}" }
    },
    messageStyle: "none"
  });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += (all[i].SourceElement().parentNode.className ? ' ' : '') + 'has-jax';
    }
  });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>




  <script>
    window.subData = {
      title: '模型压缩——知识蒸馏',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
    
    
      
        
          
          
            <section class='widget shake author'>
  <div class='content pure'>
    
      <div class='avatar'>
        <img class='avatar' src='https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/65-1Z31313530JC.jpeg'/>
      </div>
    
    
    
      <div class="social-wrapper">
        
          
            <a href="/atom.xml"
              class="social fas fa-rss flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="mailto:rogerspy@163.com"
              class="social fas fa-envelope flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://github.com/rogerspy"
              class="social fab fa-github flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
          
            <a href="https://music.163.com/#/user/home?id=1960721923"
              class="social fas fa-headphones-alt flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
            </a>
          
        
      </div>
    
  </div>
</section>

          
        
      
        
          
          
            
  <section class='widget toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;本文目录</div>
  
    <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div>
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#背景"><span class="toc-text">背景</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#“思想歧路”"><span class="toc-text">“思想歧路”</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#知识蒸馏的理论依据"><span class="toc-text">知识蒸馏的理论依据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Teacher-Model-和-Student-Model"><span class="toc-text">Teacher Model 和 Student Model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#知识蒸馏的关键点"><span class="toc-text">知识蒸馏的关键点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么？"><span class="toc-text">为什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#softmax-函数"><span class="toc-text">softmax 函数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#知识蒸馏的具体方法"><span class="toc-text">知识蒸馏的具体方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#通用的知识蒸馏方法"><span class="toc-text">通用的知识蒸馏方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#一种特殊情形-直接match-logits-不经过softmax"><span class="toc-text">一种特殊情形: 直接match logits(不经过softmax)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#关于”温度”的讨论"><span class="toc-text">关于”温度”的讨论</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#温度的特点"><span class="toc-text">温度的特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#温度代表了什么，如何选取合适的温度？"><span class="toc-text">温度代表了什么，如何选取合适的温度？</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实例"><span class="toc-text">实例</span></a></li></ol>
    </div>
  </section>


          
        
      
        
          
          
            <section class='widget grid'>
  
<header class='pure'>
  <div><i class="fas fa-map-signs fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;站内导航</div>
  
</header>

  <div class='content pure'>
    <ul class="grid navgation">
      
        <li><a class="flat-box" " href="/"
          
          
          id="home">
          
            <i class="fas fa-clock fa-fw" aria-hidden="true"></i>
          
          近期文章
        </a></li>
      
        <li><a class="flat-box" " href="/blog/"
          
          
          id="blog">
          
            <i class="fas fa-edit fa-fw" aria-hidden="true"></i>
          
          我的博客
        </a></li>
      
        <li><a class="flat-box" " href="/paper_note/"
          
          
          id="paper_note">
          
            <i class="fas fa-book fa-fw" aria-hidden="true"></i>
          
          论文笔记
        </a></li>
      
        <li><a class="flat-box" " href="/algorithm/"
          
          
          id="algorithm">
          
            <i class="fas fa-cube fa-fw" aria-hidden="true"></i>
          
          算法基础
        </a></li>
      
        <li><a class="flat-box" " href="/leetcode/"
          
          
          id="leetcode">
          
            <i class="fas fa-code fa-fw" aria-hidden="true"></i>
          
          Leetcode
        </a></li>
      
        <li><a class="flat-box" " href="/leetcode/"
          
          
          id="leetcode">
          
            <i class="fab fa-kaggle fa-fw" aria-hidden="true"></i>
          
          Kaggle
        </a></li>
      
        <li><a class="flat-box" " href="/paper_note/"
          
          
          id="paper_note">
          
            <i class="fas fa-brain fa-fw" aria-hidden="true"></i>
          
          思维逻辑
        </a></li>
      
        <li><a class="flat-box" " href="/algorithm/"
          
          
          id="algorithm">
          
            <i class="fas fa-keyboard fa-fw" aria-hidden="true"></i>
          
          学习小测
        </a></li>
      
        <li><a class="flat-box" " href="/video/"
          
          
          id="video">
          
            <i class="fas fa-film fa-fw" aria-hidden="true"></i>
          
          视频小站
        </a></li>
      
        <li><a class="flat-box" " href="/material/"
          
          
          id="material">
          
            <i class="fas fa-briefcase fa-fw" aria-hidden="true"></i>
          
          学习资料
        </a></li>
      
        <li><a class="flat-box" " href="/dataset/"
          
          
          id="dataset">
          
            <i class="fas fa-database fa-fw" aria-hidden="true"></i>
          
          数据集
        </a></li>
      
        <li><a class="flat-box" " href="/articles/"
          
          
          id="articles">
          
            <i class="fas fa-sticky-note fa-fw" aria-hidden="true"></i>
          
          杂文天地
        </a></li>
      
        <li><a class="flat-box" " href="/archives/"
          
            rel="nofollow"
          
          
          id="archives">
          
            <i class="fas fa-archive fa-fw" aria-hidden="true"></i>
          
          文章归档
        </a></li>
      
        <li><a class="flat-box" " href="/personal_center/"
          
          
          id="personal_center">
          
            <i class="fas fa-university fa-fw" aria-hidden="true"></i>
          
          个人中心
        </a></li>
      
        <li><a class="flat-box" " href="/about/"
          
            rel="nofollow"
          
          
          id="about">
          
            <i class="fas fa-info-circle fa-fw" aria-hidden="true"></i>
          
          关于小站
        </a></li>
      
    </ul>
  </div>
</section>

          
        
      
        
          
          
            <section class='widget list'>
  
<header class='pure'>
  <div><i class="fas fa-terminal fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;机器学习框架</div>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" href="https://rogerspy.gitee.io/pytorch-zh/"
          
          
          >
          <div class='name'>
            
              <i class="fas fa-star fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;PyTorch 中文文档
          </div>
          
        </a></li>
      
        <li><a class="flat-box" href="https://keras-zh.readthedocs.io/"
          
          
          >
          <div class='name'>
            
              <i class="fas fa-star fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Keras 中文文档
          </div>
          
        </a></li>
      
        <li><a class="flat-box" href="https://tensorflow.google.cn/"
          
          
          >
          <div class='name'>
            
              <i class="fas fa-star fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Tensorflow 中文文档
          </div>
          
        </a></li>
      
        <li><a class="flat-box" href="http://scikitlearn.com.cn/"
          
          
          >
          <div class='name'>
            
              <i class="fas fa-star fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Scikit Learn 中文文档
          </div>
          
        </a></li>
      
    </ul>
  </div>
</section>

          
        
      
        
          
          
            <section class='widget list'>
  
<header class='pure'>
  <div><i class="fas fa-wrench fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;百宝箱</div>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" href="https://rogerspy.github.io/excalidraw-claymate/"
          
          
            target="_blank"
          
          >
          <div class='name'>
            
              <i class="fas fa-magic fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Excalidraw-Claymate
          </div>
          
        </a></li>
      
        <li><a class="flat-box" href="https://rogerspy.github.io/jupyterlite/"
          
          
            target="_blank"
          
          >
          <div class='name'>
            
              <i class="fas fa-terminal fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;JupyterLite
          </div>
          
        </a></li>
      
        <li><a class="flat-box" href="https://rogerspy.github.io/kanban/"
          
          
            target="_blank"
          
          >
          <div class='name'>
            
              <i class="fas fa-table fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Kanban
          </div>
          
        </a></li>
      
    </ul>
  </div>
</section>

          
        
      
        
          
          
            <section class='widget list'>
  
<header class='pure'>
  <div><i class="fas fa-eye fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;睁眼看世界</div>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" href="https://deeplearn.org/"
          
          
          >
          <div class='name'>
            
              <i class="fas fa-link fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Deep Learning Monitor
          </div>
          
        </a></li>
      
        <li><a class="flat-box" href="https://paperswithcode.com/sota"
          
          
          >
          <div class='name'>
            
              <i class="fas fa-link fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Browse State-of-the-Art
          </div>
          
        </a></li>
      
        <li><a class="flat-box" href="https://huggingface.co/transformers/"
          
          
          >
          <div class='name'>
            
              <i class="fas fa-link fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Transformers
          </div>
          
        </a></li>
      
        <li><a class="flat-box" href="https://huggingface.co/models"
          
          
          >
          <div class='name'>
            
              <i class="fas fa-link fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;Transformers-models
          </div>
          
        </a></li>
      
    </ul>
  </div>
</section>

          
        
      
        
          
          
            
  <section class='widget category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;文章分类</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/categories/"
    title="categories/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" " href="/categories/nl2sql/"><div class='name'>NL2SQL</div><div class='badge'>(1)</div></a></li>
        
          <li><a class="flat-box" " href="/categories/nlp/"><div class='name'>NLP</div><div class='badge'>(23)</div></a></li>
        
          <li><a class="flat-box" " href="/categories/博客转载/"><div class='name'>博客转载</div><div class='badge'>(7)</div></a></li>
        
          <li><a class="flat-box" " href="/categories/数据结构与算法/"><div class='name'>数据结构与算法</div><div class='badge'>(11)</div></a></li>
        
          <li><a class="flat-box" " href="/categories/知识图谱/"><div class='name'>知识图谱</div><div class='badge'>(6)</div></a></li>
        
          <li><a class="flat-box" " href="/categories/笔记/"><div class='name'>笔记</div><div class='badge'>(4)</div></a></li>
        
          <li><a class="flat-box" " href="/categories/论文解读/"><div class='name'>论文解读</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" " href="/categories/语言模型/"><div class='name'>语言模型</div><div class='badge'>(15)</div></a></li>
        
      </ul>
    </div>
  </section>


          
        
      
        
          
          
            
  <section class='widget tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-fire fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;热门标签</div>
  
    <a class="rightBtn"
    
      rel="nofollow"
    
    
    href="/tags/"
    title="tags/">
    <i class="fas fa-expand-arrows-alt fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      <a href="/tags/attention/" style="font-size: 16.5px; color: #888">Attention</a> <a href="/tags/cnnlm/" style="font-size: 14px; color: #999">CNNLM</a> <a href="/tags/cvt/" style="font-size: 14px; color: #999">CVT</a> <a href="/tags/data-structure/" style="font-size: 14px; color: #999">Data Structure</a> <a href="/tags/deep/" style="font-size: 14px; color: #999">Deep</a> <a href="/tags/dijkstra-s-algorithm/" style="font-size: 14px; color: #999">Dijkstra's Algorithm</a> <a href="/tags/ffnnlm/" style="font-size: 14px; color: #999">FFNNLM</a> <a href="/tags/gaussian/" style="font-size: 14px; color: #999">Gaussian</a> <a href="/tags/graph-algorithm/" style="font-size: 14px; color: #999">Graph Algorithm</a> <a href="/tags/initialization/" style="font-size: 14px; color: #999">Initialization</a> <a href="/tags/kg/" style="font-size: 19px; color: #777">KG</a> <a href="/tags/l1/" style="font-size: 14px; color: #999">L1</a> <a href="/tags/l2/" style="font-size: 14px; color: #999">L2</a> <a href="/tags/lstm/" style="font-size: 14px; color: #999">LSTM</a> <a href="/tags/lstmlm/" style="font-size: 14px; color: #999">LSTMLM</a> <a href="/tags/language-model/" style="font-size: 20.25px; color: #6f6f6f">Language Model</a> <a href="/tags/log-linear-language-model/" style="font-size: 14px; color: #999">Log-Linear Language Model</a> <a href="/tags/mhsa/" style="font-size: 14px; color: #999">MHSA</a> <a href="/tags/nlp/" style="font-size: 20.25px; color: #6f6f6f">NLP</a> <a href="/tags/nmt/" style="font-size: 22.75px; color: #5e5e5e">NMT</a> <a href="/tags/norm/" style="font-size: 14px; color: #999">Norm</a> <a href="/tags/probabilistic-language-model/" style="font-size: 14px; color: #999">Probabilistic Language Model</a> <a href="/tags/rnnlm/" style="font-size: 14px; color: #999">RNNLM</a> <a href="/tags/roc-auc/" style="font-size: 14px; color: #999">ROC-AUC</a> <a href="/tags/smoothing/" style="font-size: 14px; color: #999">Smoothing</a> <a href="/tags/transformer/" style="font-size: 24px; color: #555">Transformer</a> <a href="/tags/context2vec/" style="font-size: 14px; color: #999">context2vec</a> <a href="/tags/cross-entropy/" style="font-size: 14px; color: #999">cross-entropy</a> <a href="/tags/data-noising/" style="font-size: 14px; color: #999">data noising</a> <a href="/tags/divide-conquer/" style="font-size: 14px; color: #999">divide-conquer</a> <a href="/tags/einsum/" style="font-size: 14px; color: #999">einsum</a> <a href="/tags/insertion/" style="font-size: 16.5px; color: #888">insertion</a> <a href="/tags/insertion-deletion/" style="font-size: 15.25px; color: #919191">insertion-deletion</a> <a href="/tags/knowledge-distillation/" style="font-size: 14px; color: #999">knowledge distillation</a> <a href="/tags/knowledge-modelling/" style="font-size: 15.25px; color: #919191">knowledge-modelling</a> <a href="/tags/nl2infographic/" style="font-size: 14px; color: #999">nl2infographic</a> <a href="/tags/nl2sql/" style="font-size: 14px; color: #999">nl2sql</a> <a href="/tags/ontology/" style="font-size: 14px; color: #999">ontology</a> <a href="/tags/parallel-recurrent/" style="font-size: 14px; color: #999">parallel-recurrent</a> <a href="/tags/pre-trained-seq2seq/" style="font-size: 14px; color: #999">pre-trained seq2seq</a> <a href="/tags/pytorch/" style="font-size: 14px; color: #999">pytorch</a> <a href="/tags/quantization/" style="font-size: 14px; color: #999">quantization</a> <a href="/tags/queue/" style="font-size: 17.75px; color: #808080">queue</a> <a href="/tags/sparse/" style="font-size: 14px; color: #999">sparse</a> <a href="/tags/stack/" style="font-size: 14px; color: #999">stack</a> <a href="/tags/survey/" style="font-size: 16.5px; color: #888">survey</a> <a href="/tags/tensorflow/" style="font-size: 14px; color: #999">tensorflow</a> <a href="/tags/text2viz/" style="font-size: 14px; color: #999">text2viz</a> <a href="/tags/weighted-head/" style="font-size: 14px; color: #999">weighted-head</a> <a href="/tags/半监督语言模型/" style="font-size: 14px; color: #999">半监督语言模型</a> <a href="/tags/双数组前缀树/" style="font-size: 14px; color: #999">双数组前缀树</a> <a href="/tags/推荐系统/" style="font-size: 14px; color: #999">推荐系统</a> <a href="/tags/数据结构/" style="font-size: 21.5px; color: #666">数据结构</a> <a href="/tags/数组/" style="font-size: 14px; color: #999">数组</a> <a href="/tags/时间复杂度/" style="font-size: 14px; color: #999">时间复杂度</a> <a href="/tags/算法/" style="font-size: 14px; color: #999">算法</a> <a href="/tags/评估方法/" style="font-size: 14px; color: #999">评估方法</a> <a href="/tags/词向量/" style="font-size: 15.25px; color: #919191">词向量</a> <a href="/tags/隐式正则化/" style="font-size: 14px; color: #999">隐式正则化</a>
    </div>
  </section>


          
        
      
        
          
          
            


  <section class='widget music'>
    
<header class='pure'>
  <div><i class="fas fa-compact-disc fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;最近在听</div>
  
    <a class="rightBtn"
    
      rel="external nofollow noopener noreferrer"
    
    
      target="_blank"
    
    href="https://music.163.com/#/user/home?id=1960721923"
    title="https://music.163.com/#/user/home?id=1960721923">
    <i class="far fa-heart fa-fw"></i></a>
  
</header>

    <div class='content pure'>
      
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css">
  <div class="aplayer"
    data-theme="#1BCDFC"
    
    
    data-mode="circulation"
    data-server="tencent"
    data-type="playlist"
    data-id="3351822215"
    data-volume="0.7">
  </div>
  <script src="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js"></script>


    </div>
  </section>


          
        
      
    

  
</aside>

<footer id="footer" class="clearfix">
  <div id="sitetime"></div>
  
  
    <div class="social-wrapper">
      
        
          <a href="/atom.xml"
            class="social fas fa-rss flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="mailto:rogerspy@163.com"
            class="social fas fa-envelope flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://github.com/rogerspy"
            class="social fab fa-github flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
        
          <a href="https://music.163.com/#/user/home?id=1960721923"
            class="social fas fa-headphones-alt flat-btn"
            target="_blank"
            rel="external nofollow noopener noreferrer">
          </a>
        
      
    </div>
  
  <br>
  <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
  <div>
    本站使用
    <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a>
    作为主题
    
      ，
      总访问量为
      <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span>
      次
    
    。
  </div>
	</footer>

<script>setLoadingBarProgress(80);</script>
<!-- 点击特效，输入特效 运行时间 -->
<script type="text/javascript" src="/cool/cooltext.js"></script>
<script type="text/javascript" src="/cool/clicklove.js"></script>
<script type="text/javascript" src="/cool/sitetime.js"></script>



      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>

  <script>
    var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
    var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
    var ALGOLIA_API_KEY = "";
    var ALGOLIA_APP_ID = "";
    var ALGOLIA_INDEX_NAME = "";
    var AZURE_SERVICE_NAME = "";
    var AZURE_INDEX_NAME = "";
    var AZURE_QUERY_KEY = "";
    var BAIDU_API_ID = "";
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/"||"/";
    if(!ROOT.endsWith('/'))ROOT += '/';
  </script>

<script src="//instant.page/1.2.2" type="module" integrity="sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU"></script>


  <script async src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>




  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
    <script type="text/javascript">
      $(function(){
        if ('.cover') {
          $('.cover').backstretch(
          ["https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/a0c9e6f9efad8b731cb7376504bd10d79d2053.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        } else {
          $.backstretch(
          ["https://cdn.jsdelivr.net/gh/rogerspy/blog-imgs/a0c9e6f9efad8b731cb7376504bd10d79d2053.jpg"],
          {
            duration: "6000",
            fade: "2500"
          });
        }
      });
    </script>
  







  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script type="text/javascript">
    var gitalk = new Gitalk({
      clientID: "35a5e4dc744cc7d162af",
      clientSecret: "7b5a409e17ce0c1971f284eac9f8902eb4b8feba",
      repo: "rogerspy.github.io",
      owner: "Rogerspy",
      admin: "Rogerspy",
      
        id: "/wiki/material-x/",
      
      distractionFreeMode: false  // Facebook-like distraction free mode
    });
    gitalk.render('gitalk-container');
  </script>





  <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.5/js/app.js"></script>


  <script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-material-x@19.5/js/search.js"></script>




<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "复制成功";
  let COPY_FAILURE = "复制失败";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>复制</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("fancybox").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





  <script>setLoadingBarProgress(100);</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!--<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>

{"meta":{"title":"Rogerspy's Home","subtitle":null,"description":null,"author":"Rogerspy","url":"https://rogerspy.gitee.io","root":"/"},"pages":[{"title":"404 Not Found","date":"2021-09-15T15:36:16.765Z","updated":"2021-09-15T15:36:16.765Z","comments":true,"path":"404.html","permalink":"https://rogerspy.gitee.io/404.html","excerpt":"","text":"# **404 Not Found** 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"算法基础","date":"2022-01-12T10:01:07.069Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"algorithm/index.html","permalink":"https://rogerspy.gitee.io/algorithm/index.html","excerpt":"","text":""},{"title":"关于小站","date":"2022-01-12T09:06:14.330Z","updated":"2022-01-12T09:06:14.330Z","comments":true,"path":"about/index.html","permalink":"https://rogerspy.gitee.io/about/index.html","excerpt":"","text":"本站搭建过程参考了很多大佬的博客，在此向大佬们表示感谢！这里介绍一下本站搭建的一些配置与主题的优化。 1. 安装Node.js首先下载稳定版Node.js，我这里给的是64位的。 安装选项全部默认，一路点击Next。 最后安装好之后，按Win+R打开命令提示符，输入node -v和npm -v，如果出现版本号，那么就安装成功了。 如果没有梯子的话，可以使用阿里的国内镜像进行加速。 1npm config set registry https://registry.npm.taobao.org 2. 安装Git为了把本地的网页文件上传到github上面去，我们需要用到分布式版本控制工具————Git[下载地址]。 安装选项还是全部默认，只不过最后一步添加路径时选择Use Git from the Windows Command Prompt，这样我们就可以直接在命令提示符里打开git了。 安装完成后在命令提示符中输入git --version验证是否安装成功。 3. 配置Github Pages首先是要注册一个github账号，链接：https://github.com/，按照步骤填写一些信息完成注册即可。 接下来新建一个项目： 然后输入项目名字，注意：后面一定要加上.github.io后缀，否可能引起不可知的bug。 点击create repository这样项目就建好了。 项目建好以后，点击Settings，向下拉到最后有个GitHub Pages，点击Choose a theme选择一个主题。 然后等一会儿，再回到GitHub Pages，会变成下面这样： 4. 安装Hexo在合适的地方新建一个文件夹，用来存放自己的博客文件，比如我的博客文件都存放在D:\\blog目录下。 在该目录下右键点击Git Bash Here，打开git的控制台窗口 定位到该目录下，输入npm i hexo-cli -g安装Hexo 安装完后输入hexo -v验证是否安装成功。 然后就要初始化我们的网站，输入hexo init初始化文件夹，接着输入npm install安装必备的组件。 这样本地的网站配置也弄好啦，输入hexo g生成静态网页，然后输入hexo s打开本地服务器，然后浏览器打开http://localhost:4000/，就可以看到我们的博客啦，效果如下： 5. 连接Github与本地首先右键打开git bash，然后输入下面命令： 12git config --global user.name \"yourname\"git config --global user.email \"your-email\" 然后生成密钥SSH key： 1ssh-keygen -t rsa -C \"your-email\" 打开github，在头像下面点击settings，再点击SSH and GPG keys，新建一个SSH，名字随便。 git bash中输入 1cat ~/.ssh/id_rsa.pub 如果是 windows用户，id_rsa.pub一般会在c:/user下面。 将输出的内容复制到框中，点击确定保存。 打开博客根目录下的_config.yml文件，这是博客的配置文件，在这里你可以修改与博客相关的各种信息。 修改最后一行的配置： 1234deploy: type: git repository: https://github.com/yourname/abc.github.io branch: master repository修改为你自己的github项目地址。 6. 写/发布文章 安装hexo-deployer-git 1npm i hexo-deployer-git 新建文章 1hexo new post &quot;article title&quot; 打开博客根目录下的source/_post目录，可以发现多了一个.md文件，这个文件就是你刚刚新建的文章，然后就可以往里面写入你的文章 写完.md文件以后 12hexo g # 生成静态网页hexo s # 启动本地服务 打开localhost:4000就可以预览刚刚写的文章 如果没有问题 1hexo d # 上传到github 这样就可以在刚刚生成abc.github.io上看到 你的文章，到这里文章就发布完毕了。 因为我没有购买私有化域名，所以就不介绍了。 7. 个性化配置本博客用的主题是Material-X， 作者主页：https://xaoxuu.com/wiki/material-x/ Github地址: https://github.com/xaoxuu/hexo-theme-material-x 7.1 更换主题作者提供了两种方式： A. 使用脚本全自动安装（目前仅支持macOS） 打开终端输入下面命令安装脚本，脚本文档见#hexo.sh。 1curl -s https://xaoxuu.com/install | sh -s hexo.sh 安装成功后，在你的博客路径打开终端，输入下面命令即可安装主题和依赖包。 1hexo.sh i x B. 手动安装 下载主题到 themes/ 文件夹 1git clone https://github.com/xaoxuu/hexo-theme-material-x themes/material-x 然后安装必要的依赖包 1npm i -S hexo-generator-search hexo-generator-json-content hexo-renderer-less 7.2 文章头设置为了新建文章方便，建议把博客根目录下/scaffolds/post.md修改为： 123456789101112131415---type: blogtitle: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;top: falsecover: falsetoc: truemathjax: truesummary:tags:categories:body: [article, comments]gitalk: id: /wiki/material-x/c--- 这样新建文章后不用你自己补充了，修改信息就行。至于其中每一个字段的意义可以参考主题作者的说明文档。 7.3 添加404页面原来的主题没有404页面，加一个也不是什么难事。首先在/source/目录下新建一个404.md，内容如下： 12345678910111213141516171819202122---layout: pagetitle: 404 Not Foundbody: [article, comments]meta: header: false footer: falsesidebar: falsegitalk: path: /404.html placeholder: 请留言告诉我您要访问哪个页面找不到了---# &lt;center&gt;404 Not Found&lt;/center&gt;&lt;br&gt;&lt;center&gt;很抱歉，您访问的页面不存在&lt;/center&gt;&lt;center&gt;可能是输入地址有误或该地址已被删除&lt;/center&gt;&lt;br&gt;&lt;br&gt; 7.4 Mathjax数学公式渲染优化这部分的优化主要参考了hexo中的mathjax数学公式渲染优化这篇文章。 mathjax渲染修改1. 修改渲染引擎更改hexo的默认渲染引擎，使其支持mathjax 打开cmd，cd到hexo博客文件夹下，输入 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 2. 更改配置找到/node_modules/hexo-renderer-kramed/lib/renderer.js，将 1234function formatText(text) &#123; // Fit kramed&apos;s rule: $$ + \\1 + $$ return text.replace(/`\\ $(.*?)\\$ `/g, &apos; $$$$$ 1 $$$$ &apos;);&#125; 改为 123function formatText(text) &#123; return text;&#125; 3. 修改数学包在cmd中输入 12npm uninstall hexo-math --savenpm install hexo-renderer-mathjax --save 4. 更新mathjax配置文件找到/node_modules/hexo-renderer-mathjax/mathjax.html，将最下面那一行&lt;script&gt;注释掉，改成 1&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt; 5. 修改转义规则因为markdown和mathjax语法有冲突，我们修改转义规则以避免冲突 找到\\node_modules\\kramed\\lib\\rules\\inline.js，将escape和em这两行注释掉，改成 12escape: /^\\\\([`*\\[\\]()# +\\-.!_&gt;])/,em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, 6. 开始使用找到\\_config.yml，加上一行mathjax: true就可以了 mathjax渲染优化其实这应该就结束了 但不知什么原因，部分情况直接渲染出来会有一个灰色的框，十分难看 所以我们还要进行优化 打开/node_modules/hexo-renderer-mathjax/mathjax.html，在MathJax.Hub.Config中加上 12extensions: [&quot;tex2jax.js&quot;],jax: [&quot;input/TeX&quot;, &quot;output/HTML-CSS&quot;], 将刚刚第4步修改的链接修改为 1&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLCSS&quot;&gt;&lt;/script&gt; 就可以了 但是仍然有一些不尽人意的地方，比如： 部分公式渲染出错比如这个公式： 1$\\dfrac&#123;1&#125;&#123;2&#125;$ 显示Undefined control sequence \\dfrac 不仅是这个，还有很多会出错，比如\\geqslant 这是由于更改链接后，缺少了amsmath包 在MathJax.Hub.Config中加上 1234TeX: &#123; equationNumbers: &#123; autoNumber: &quot;AMS&quot; &#125;, extensions: [&quot;AMSmath.js&quot;, &quot;AMSsymbols.js&quot;]&#125;, 即可解决 修改字体在MathJax.Hub.Config中加上 1234&quot;HTML-CSS&quot;: &#123; preferredFont: &quot;TeX&quot;, availableFonts: [&quot;STIX&quot;,&quot;TeX&quot;]&#125; 关闭右下角加载信息在MathJax.Hub.Config中加上 12showProcessingMessages: false,messageStyle: &quot;none&quot;, 关闭右键菜单在&quot;HTML-CSS&quot;中加上 1showMathMenu: false 代码整合可以根据需要自行修改 123456789101112131415161718192021222324252627&lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config(&#123; TeX: &#123; equationNumbers: &#123; autoNumber: &quot;AMS&quot; &#125;, extensions: [&quot;AMSmath.js&quot;, &quot;AMSsymbols.js&quot;] &#125;, &quot;HTML-CSS&quot;: &#123; preferredFont: &quot;TeX&quot;, availableFonts: [&quot;STIX&quot;, &quot;TeX&quot;], showMathMenu: false &#125;, showProcessingMessages: false, messageStyle: &quot;none&quot;, extensions: [&quot;tex2jax.js&quot;], jax: [&quot;input/TeX&quot;, &quot;output/HTML-CSS&quot;], tex2jax: &#123; inlineMath: [ [&quot;$&quot;,&quot;$&quot;] ], skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;, &apos;code&apos;, &apos;a&apos;] &#125; &#125;); MathJax.Hub.Queue(function() &#123; var all = MathJax.Hub.getAllJax(); for (var i = 0; i &lt; all.length; ++i) all[i].SourceElement().parentNode.className += &apos; has-jax&apos;; &#125;);&lt;/script&gt;&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLCSS&quot;&gt;&lt;/script&gt; 7.5 其他美化其他的美化包括，添加血小板，鼠标单击效果，输入特效等都是参考的Hexo博客Material-X主题个性化这篇文章。 添加血小板添加方式 live2d资源目录添加至主目录/source下 在主题目录/layout/_partial/head.ejs文件中引入live2.css文件 12&lt;!-- 血小板--&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;/live2d/css/live2d.css&quot; /&gt; 在主题目录/layout/_partial/footer.ejs文件中添加以下代码 123456789101112131415&lt;!-- 血小板 --&gt;&lt;div id=&quot;landlord&quot;&gt; &lt;div class=&quot;message&quot; style=&quot;opacity:0&quot;&gt;&lt;/div&gt; &lt;canvas id=&quot;live2d&quot; width=&quot;560&quot; height=&quot;500&quot; class=&quot;live2d&quot;&gt;&lt;/canvas&gt; &lt;div class=&quot;hide-button&quot;&gt;隐藏&lt;/div&gt;&lt;/div&gt;&lt;!-- 血小板--&gt;&lt;script type=&quot;text/javascript&quot;&gt; var message_Path = &apos;/live2d/&apos;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/live2d/js/live2d.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/live2d/js/message.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; loadlive2d(&quot;live2d&quot;, &quot;/live2d/model/xiaoban/model.json&quot;);&lt;/script&gt; 为了移动端更好的阅读效果，请将以下代码添加至主题目录/source/less/_footer.less文件下 123456789101112131415161718192021@media (max-width: @on_phone) &#123; #footer&#123; background-color:transparent; padding-bottom: 180px ; &#125; #landlord&#123; width: 200px; height: 170px; .message&#123; width: 200px; left: 43px; top: 15px; &#125; &#125; #live2d&#123; width: 200px; height: 170px; bottom: -80px; left: 43px; &#125;&#125; 添加页面点击小心心特效,文本输入特效、运行时间添加方式注意：由于博客使用了防盗链，请将脚本另存为1.将 https://blog.treelo.xin/cool/clicklove.js 另存在主题目录/source/下2.将 https://blog.treelo.xin/cool/cooltext.js 另存在主题目录/source/下3.将 https://blog.treelo.xin/cool/sitetime.js 另存在主题目录/source/下4.修改sitetime.js参数5.在主题目录/layout/_partial/footer.ejs文件中引入 1234&lt;!-- 点击特效，输入特效 运行时间 --&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/cool/cooltext.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/cool/clicklove.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/cool/sitetime.js&quot;&gt;&lt;/script&gt; 6.在主题目录/layout/_partial/footer.ejs文件中上方添加 1&lt;div id=&quot;sitetime&quot;&gt;&lt;/div&gt; 8. 2021.8 附加一：图床搭建8.1 下载 picgo这里是最新版本的项目发布地址： 1https://github.com/Molunerfinn/PicGo/releases 如果是macos系统，请选择dmg版本下载，windows系统请选择exe版本下载。 8.2 配置 picgo 首先，我们要在 github 中新建一个仓库，这个仓库可以随意命名，建议名字短一点，这样最后生成的链接也更短。（注：一定要创建公共仓库，私有仓库是无法通过外链显示的) 创建好后，我们需要在 github 上生成一个 token，这样 PicGo 才能直接对 github 仓库内容进行操作。 点击头像–&gt; setting –&gt; Developer settings 在侧边栏选择 Personal access tokens 点击 Generate new token，输入密码，进入创建 token 的界面 Note 可以随便填，建议填 PicGo 将repo这一栏的权限全部勾选，其他的不用动。 拖到最底下，点击 Generate token 创建好 token 后，我们需要记录下这个 token，因为它只会出现一次。 接下来，我们进入 PicGo 的主程序中，找到 Github 图床。 按照以下内容填入： 仓库名：github用户名/仓库名 分支：填 master Token:填你之前创建的那个Token 指定存储路径：这个可以随便填，也可以不填 设定自定义域名：https://cdn.jsdelivr.net/gh/github用户名/仓库名@master 8.3 jsdelivr 加速因为github的服务器在国外，所以用来当图床的时候，国内的速度非常感人，但是我们可以使用jsdelivr提供的CDN 服务，速度非常的快，基本不大的图片可以秒开。 所以上述自定义域名实际上是使用的jsdelivr的CDN服务。 8.4 得到图片的直链这样，我们就可以直接在PicGo的上传区将要传入的图片拖入即可。 然后，在相册区，我们可以复制对应图片的外链。 还可以选择相册顶部的小倒三角，选择链接的各种，有markdown,html，URL等方式供选择。 9. 2021.8 附加二：Excalidraw-Claymate 下载 1git clone https://github.com/dai-shi/excalidraw-claymate 新建一个仓库 在新仓库里启动 github actions 将刚刚拉下来的代码 push 到新仓库里 在新仓库 settings 中找到 pages，选择部署的文件。 10. 2021.8 附加三：字数统计先在博客目录下执行以下命令安装 hexo-wordcount 插件： 1$ npm i --save hexo-wordcount 注意：在 Material X 主题中，字数统计和阅读时长的功能我已提交 PR，在最新版本中，只需要安装插件后，在主题 config.yml 配置文件里，将 word_count 关键字设置为 true 即可，对于旧版本，可以通过以下方法实现： 以 Material X 主题（版本 1.2.1）为例，在 \\themes\\material-x\\layout_meta 目录下创建 word.ejs 文件，在 word.ejs 文件中写入以下代码: 123456789101112131415161718192021&lt;% if(isPostList || !isPostList)&#123; %&gt; &lt;% if (theme.word_count &amp;&amp; !post.no_word_count) &#123; %&gt; &lt;div style=&quot;margin-right: 10px;&quot;&gt; &lt;span class=&quot;post-time&quot;&gt; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;fa fa-keyboard&quot;&gt;&lt;/i&gt; &lt;span class=&quot;post-meta-item-text&quot;&gt; 字数统计: &lt;/span&gt; &lt;span class=&quot;post-count&quot;&gt;&lt;%= wordcount(post.content) %&gt;字&lt;/span&gt; &lt;/span&gt; &lt;/span&gt; &amp;nbsp; | &amp;nbsp; &lt;span class=&quot;post-time&quot;&gt; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;fa fa-hourglass-half&quot;&gt;&lt;/i&gt; &lt;span class=&quot;post-meta-item-text&quot;&gt; 阅读时长≈&lt;/span&gt; &lt;span class=&quot;post-count&quot;&gt;&lt;%= min2read(post.content) %&gt;分&lt;/span&gt; &lt;/span&gt; &lt;/span&gt; &lt;/div&gt; &lt;% &#125; %&gt;&lt;% &#125; %&gt; 然后在主题的配置文件 _config.yml 找到 meta 关键字，将 word 填入 header 中： 123meta: header: [title, author, date, categories, tags, counter, word, top] footer: [updated, share] 最后在主题目录下的 _config.yml 添加以下配置即可 1word_count: true 11. hexo中的mathjax数学公式渲染优化 转载自 hexo中的mathjax数学公式渲染优化 在使用hexo博客和material-x等博客主题时，难免会遇到mathjax数学公式渲染失败或者与markdown渲染冲突的问题。 xaoxuu给出了解决方案，只需在_config.yml里加入mathjax: true即可解决，可以解决大量的mathjax公式渲染，但仍有部分复杂的公式渲染出现问题。 我在这里给出一种解决方案。 注：部分资料来自互联网 11.1 mathjax渲染修改11.1.1 修改渲染引擎更改hexo的默认渲染引擎，使其支持mathjax 打开cmd，cd到hexo博客文件夹下，输入： 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 11.1.2 更改配置找到/node_modules/hexo-renderer-kramed/lib/renderer.js，将 1234function formatText(text) &#123; // Fit kramed's rule: $$ + \\1 + $$ return text.replace(/`\\ $(.*?)\\$ `/g, ' $$$$$ 1 $$$$ ');&#125; 改为 123function formatText(text) &#123; return text;&#125; 11.1.3 修改数学包在cmd中输入 12npm uninstall hexo-math --savenpm install hexo-renderer-mathjax --save 11.1.4 更新mathjax配置文件找到/node_modules/hexo-renderer-mathjax/mathjax.html，将最下面那一行&lt;script&gt;注释掉，改成 1&lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML\"&gt;&lt;/script&gt; 11.1.5 修改转义规则因为 markdown 和 mathjax 语法有冲突，我们修改转义规则以避免冲突 找到\\node_modules\\kramed\\lib\\rules\\inline.js，将escape和em这两行注释掉，改成 123escape: /^\\\\([`*\\[\\]()# +\\-.!_&gt;])/,em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, 6. 开始使用找到\\_config.yml，加上一行mathjax: true就可以了。 11.2 mathjax渲染优化其实这应该就结束了 但不知什么原因，部分情况直接渲染出来会有一个灰色的框，十分难看 所以我们还要进行优化 打开/node_modules/hexo-renderer-mathjax/mathjax.html，在MathJax.Hub.Config中加上 12extensions: [\"tex2jax.js\"],jax: [\"input/TeX\", \"output/HTML-CSS\"], 将刚刚第4步修改的链接修改为 1&lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLCSS\"&gt;&lt;/script&gt; 就可以了 但是仍然有一些不尽人意的地方，比如： 11.2.1 部分公式渲染出错比如这个公式： 1$\\dfrac&#123;1&#125;&#123;2&#125;$ 显示Undefined control sequence \\dfrac 不仅是这个，还有很多会出错，比如\\geqslant 这是由于更改链接后，缺少了amsmath包 在MathJax.Hub.Config中加上 1234TeX: &#123; equationNumbers: &#123; autoNumber: \"AMS\" &#125;, extensions: [\"AMSmath.js\", \"AMSsymbols.js\"]&#125;, 即可解决。 11.2.2 修改字体在MathJax.Hub.Config中加上 1234\"HTML-CSS\": &#123; preferredFont: \"TeX\", availableFonts: [\"STIX\",\"TeX\"]&#125; 其实这没什么用。 11.2.3 关闭右下角加载信息在MathJax.Hub.Config中加上 12showProcessingMessages: false,messageStyle: \"none\", 11.2.4 关闭右键菜单在&quot;HTML-CSS&quot;中加上 1showMathMenu: false 11.2.5 代码整合可以根据需要自行修改 123456789101112131415161718192021222324252627&lt;script type=\"text/x-mathjax-config\"&gt; MathJax.Hub.Config(&#123; TeX: &#123; equationNumbers: &#123; autoNumber: \"AMS\" &#125;, extensions: [\"AMSmath.js\", \"AMSsymbols.js\"] &#125;, \"HTML-CSS\": &#123; preferredFont: \"TeX\", availableFonts: [\"STIX\", \"TeX\"], showMathMenu: false &#125;, showProcessingMessages: false, messageStyle: \"none\", extensions: [\"tex2jax.js\"], jax: [\"input/TeX\", \"output/HTML-CSS\"], tex2jax: &#123; inlineMath: [ [\"$\",\"$\"] ], skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code', 'a'] &#125; &#125;); MathJax.Hub.Queue(function() &#123; var all = MathJax.Hub.getAllJax(); for (var i = 0; i &lt; all.length; ++i) all[i].SourceElement().parentNode.className += ' has-jax'; &#125;);&lt;/script&gt;&lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLCSS\"&gt;&lt;/script&gt;"},{"title":"杂文天下","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"articles/index.html","permalink":"https://rogerspy.gitee.io/articles/index.html","excerpt":"","text":""},{"title":"bb","date":"2021-09-16T03:35:33.000Z","updated":"2021-09-16T03:37:38.909Z","comments":true,"path":"bb/index.html","permalink":"https://rogerspy.gitee.io/bb/index.html","excerpt":"","text":""},{"title":"我的博客","date":"2022-01-12T10:04:27.882Z","updated":"2022-01-12T10:04:27.882Z","comments":true,"path":"blog/index.html","permalink":"https://rogerspy.gitee.io/blog/index.html","excerpt":"","text":""},{"title":"links","date":"2021-09-16T03:35:35.000Z","updated":"2021-09-16T03:37:01.266Z","comments":true,"path":"links/index.html","permalink":"https://rogerspy.gitee.io/links/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-09-16T03:35:27.000Z","updated":"2021-09-16T03:36:41.027Z","comments":true,"path":"categories/index.html","permalink":"https://rogerspy.gitee.io/categories/index.html","excerpt":"","text":""},{"title":"人工智能基础","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"material/index.html","permalink":"https://rogerspy.gitee.io/material/index.html","excerpt":"","text":""},{"title":"随机梯度下降中隐式正则化的起源","date":"2021-04-05T16:01:32.000Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"paper_note/Implicit_Regularization.html","permalink":"https://rogerspy.gitee.io/paper_note/Implicit_Regularization.html","excerpt":"首先推荐两篇论文： Samuel L Smith, Benoit Dherin, David Barrett, Soham De (2021) On the Origin of Implicit Regularization in Stochastic Gradient Descent David G.T. Barrett, Benoit Dherin (2021) Implicit Gradient Regularization","text":"首先推荐两篇论文： Samuel L Smith, Benoit Dherin, David Barrett, Soham De (2021) On the Origin of Implicit Regularization in Stochastic Gradient Descent David G.T. Barrett, Benoit Dherin (2021) Implicit Gradient Regularization 1. 深度学习为什么起作用？为了理解为什么深度学习会如此有效，仅对损失函数或模型进行分析是不够的，这是经典泛化理论所关注的。 相反，我们用来寻找极小值的算法（即，随机梯度下降）似乎起着重要作用。 在许多任务中，强大的神经网络能够内插（interpolate）训练数据，即达到接近0的训练损失。 实际上，存在一些训练损失的最小值，它们在训练数据上几乎没有区别。 在这些最小值中，有一些也可以很好地泛化（即导致较低的测试误差），而另一些则可以任意严重地过度拟合。 那么似乎重要的不是优化算法是否迅速收敛到局部最小值，而是它希望达到那个可用的“虚拟全局”最小值。 似乎是我们用于训练深度神经网络的优化算法比其他算法更喜欢一些最小值，并且这种偏好会导致更好的泛化性能。 优化算法优先收敛到特定的最小值而避免其他最小值的情况称为隐式正则化。 2. 有限步长的影响分析帮助我们想象深度学习模型训练过程中发生的事情的新理论之一是神经正切核（neural tangent kernels）。在这个框架下，我们研究了在无限宽层（infinitely wide layers）、全批次（full batch）和无限小学习率（ infinitesimally small learning rate）的限制下的神经网络训练。尽管这个理论有用且具有吸引力。但是使用全批、无限小学习率进行模型训练是不切实际的。实际上太小的学习率并不是总是有用的，minibatch-SGD 中梯度更新的随机性似乎也很重要。 Smith et al. (2021) 等人在的做法不同的是，他们尝试针对小型（但不是无限小的）学习率来研究minibatch-SGD，这更接近实际。 允许他们研究这种情况的工具是从微分方程的研究中借来的，称为后向误差分析（backward error analysis），无下图所示： 假设有一个微分方程 $\\dot{\\omega} = f(\\omega)$，上图中黑色的曲线表示该微分方程 $\\omega_t$ 的运动轨迹，初始条件为 $\\omega_0$。我们通常没有办法直接进行求解，而是使用欧拉法对该微分方程进行近似： \\omega_{k+1} = \\omega_k + \\epsilon f(\\omega_k)这个近似是离散的，如上图绿色线所示。由于离散化带来的误差，对于有限的步长 $\\epsilon$ ，离散路径可能不完全位于连续的黑色路径所在的位置。误差随着时间积累，如图所示。后向误差分析的目标是找到一个不同的微分方程 $\\dot{\\omega}=\\widetilde f(\\omega)$，使得我们找到的近似离散路径位于新的微分方程路径附近。我们的目标是对 $\\widetilde{f}$ 进行反向工程使得离散化迭代能很好的用微分方程进行建模。 这个方法为什么有效？因为 $\\widetilde{f}$ 采用的形式可以揭示离散化算法行为的偏好，尤其是如果它对进入不同空间有隐含偏好的话。 损失函数 $C$ 的梯度下降中，原始的微分方程是 $f(\\omega)=-\\nabla C(\\omega)$。修正后的微分方程： \\dot{\\omega} = - \\nabla \\widetilde{C}_{GD}(\\omega) \\\\\\\\ \\widetilde{C}_{GD}(\\omega) = C(\\omega)+\\frac{\\epsilon}{4}\\lVert \\nabla C(\\omega)\\rVert^2因此，具有有限步长 $\\epsilon$ 的梯度下降就像运行梯度流一样，但是增加了用来惩罚损失函数梯度的惩罚项。第二项就是所谓的隐式梯度正则化。 3. 随机梯度在这个框架下分析 SGD 有点困难，因为随机梯度下降的轨迹是随机的。 因此，没有一个单一的要优化的离散轨迹，而是有一个不同轨迹的分布，如果要随机重排数据，则要遍历这些轨迹。如下图所示： 从起始点 $\\omega_0$ 开始，我们有多条路径。这些路径对应于不同的数据重排的方式（论文中假设 mini-batch 中的数据是固定的，而随机性来源于 mini-batch 的处理顺序）。路径最终在一个随机位置处结束，绿色点显示了轨迹可能最终在其处的其他随机端点。 绿色星号代表了随机轨迹终点分布的平均值。 Smith et al. (2021) 的目标是对微分方程反向工程使得图中橙色的轨迹靠近绿色线的平均轨迹： \\dot{\\omega} = - \\nabla \\widetilde{C}_{SGD}(\\omega) \\\\\\\\ \\widetilde{C}_{SGD}(\\omega) = C(\\omega) + \\frac{\\epsilon}{4m} \\sum_{k=1}^{m} \\lVert \\nabla\\hat{C}_k(\\omega) \\rVert^2其中 $\\hat{C}_k$ 表示第 $k$ 个 mini-batch 的损失函数，总共有 $m$ 个mini-batch。注意，这里与我们平时见到的梯度下降很类似，但是这里使用的是 mini-batch 梯度的平均数。另一个有趣的视角是看看 GD 和 SGD 的不同之处： \\widetilde{C}_{SGD} = \\widetilde{C}_{GD} + \\frac{\\epsilon}{4m} \\sum_{k=1}^m \\rVert \\nabla\\hat{C}_k(\\omega)-C(\\omega) \\rVert^2其中额外的正则项 $\\frac{\\epsilon}{4m} \\sum_{k=1}^m \\rVert \\nabla\\hat{C}_k(\\omega)-C(\\omega) \\rVert^2$，有点像 mini-batch 的总方差。直观来说，此正则化项将避免参数空间中在不同 mini-batch 上计算出的梯度变化太大。 重要的是 $C_{GD}$ 与 $C$ 有相同的最小值，但 $C_{SGD}$ 就不一定了。这就意味着，SGD 不仅与 full-batch GD 有不同的轨迹，而且可能会收敛到完全不同的解。 4. 与泛化的关系为什么隐式正则化效果可以避免 mini-batch 梯度方差过大？ 考虑下面两个局部极小值的插图： 就平均损失 $C$ 来说，左右两边是相同的：最小值相同，宽度相同。但是，在左侧情况下，最小值是几个 mini-batch 损失的平均值，这些损失看起来都一样，而它们本身也相对较宽。 在右边的最小值中，宽泛的平均损失最小值是许多尖峰小批量损失的平均值，所有这些都无法确定最小值的确切位置。 可以合理地预期左边最小值可以更好地泛化，因为损失函数似乎对我们正在评估的任何特定 mini-batch 不那么敏感。这样，损失函数也可能对数据点是在训练集中还是在测试集中不太敏感。 5. 总结总而言之，本文是对随机梯度下降的非常有趣的分析。 尽管有其局限性（作者并没有试图在本文中进行透明地隐藏和讨论），但它还是为分析有限步长优化算法提供了一种非常有趣的新技术。 论文写得很好，清楚地阐明了分析中一些乏味的细节。"},{"title":"论文笔记","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"paper_note/index.html","permalink":"https://rogerspy.gitee.io/paper_note/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-09-16T03:35:30.000Z","updated":"2021-09-16T03:37:20.965Z","comments":true,"path":"tags/index.html","permalink":"https://rogerspy.gitee.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2022-01-12T08:56:23.907Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"personal_center/index.html","permalink":"https://rogerspy.gitee.io/personal_center/index.html","excerpt":"","text":"我的照片 aaa aaa aaa"},{"title":"视频小站","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/index.html","permalink":"https://rogerspy.gitee.io/video/index.html","excerpt":"","text":""},{"title":"","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"material/math_foundation/caculus.html","permalink":"https://rogerspy.gitee.io/material/math_foundation/caculus.html","excerpt":"","text":""},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/backpropagation.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/backpropagation.html","excerpt":"","text":""},{"title":"","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"material/css/footer.css","permalink":"https://rogerspy.gitee.io/material/css/footer.css","excerpt":"","text":"#footer{position:relative;padding:40px 10px 120px 10px;width:100%;color:rgba(85,85,85,.5);margin:0 auto;font-size:14px;overflow:hidden;text-align:center;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif} #footer .licenses{color:rgba(85,85,85,.5);text-decoration:underline} #footer .codename{text-decoration:underline} #footer .social-wrapper{display:flex;justify-content:center;flex-wrap:wrap;margin:4px 8px} #footer a{color:rgba(85,85,85,.7);padding:0;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} #footer a:hover{color:#1bc3fb} #footer a.social{position:relative;display:inline-block;text-align:center;display:flex;justify-content:center;align-items:center;width:32px;height:32px;margin:4px;border-radius:100px} #footer a.social:hover{background:rgba(27,195,251,.1);color:#1bc3fb} @media (max-width:768px){ #footer{justify-content:center} } .clearfix{zoom:1} .clearfix:after,.clearfix:before{content:\" \";display:table} .clearfix:after{clear:both}"},{"title":"","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"material/css/header.css","permalink":"https://rogerspy.gitee.io/material/css/header.css","excerpt":"","text":"@charset \"utf-8\"; @font-face{font-family:'Varela Round';src:url(https://cdn.jsdelivr.net/gh/xaoxuu/cdn-fonts@19.1.7/VarelaRound/VarelaRound-Regular.ttf);font-weight:400;font-style:normal} @font-face{font-family:'Source Sans Pro';src:url(https://cdn.jsdelivr.net/gh/xaoxuu/cdn-fonts@master/SourceSansPro/SourceSansPro-Regular.ttf);font-weight:400;font-style:normal} /*! normalize.css v3.0.2 | MIT License | git.io/normalize */ html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%} body{margin:0} article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block;} audio,canvas,progress,video{display:inline-block;vertical-align:baseline} audio:not([controls]){display:none;height:0} [hidden],template{display:none} a{color: #444; cursor: pointer; text-decoration: none; transition: all .25s ease; -moz-transition: all .25s ease; -webkit-transition: all .25s ease; -o-transition: all .25s ease;} a:active,a:hover{outline:0} abbr[title]{border-bottom:1px dotted} b,strong{font-weight:700} dfn{font-style:italic} h1{font-size:2em;margin:.67em 0} mark{background:#ff0;color:#000} small{font-size:80%} sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline} sup{top:-.5em} sub{bottom:-.25em} img{border:0} li{list-style:none} svg:not(:root){overflow:hidden} figure{margin:1em 40px} hr{box-sizing:content-box;height:0;border:0;border-radius:1px;border-bottom:1px solid rgba(0,0,0,.1)} pre{overflow:auto} code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em} button,input,optgroup,select,textarea{color:inherit;font:inherit;margin:0} button{overflow:visible} button,select{text-transform:none} button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer} button[disabled],html input[disabled]{cursor:default} button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0} input{line-height:normal} input[type=checkbox],input[type=radio]{box-sizing:border-box;padding:0} input[type=number]::-webkit-inner-spin-button,input[type=number]::-webkit-outer-spin-button{height:auto} input[type=search]{-webkit-appearance:textfield;box-sizing:content-box} input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration{-webkit-appearance:none} fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em} legend{border:0;padding:0} textarea{overflow:auto} optgroup{font-weight:700} table{border-collapse:collapse;width:100%} table th{background-color:#f7f7f7} table td,table th{text-align:justify;padding:4px 8px;border:1px solid #f4f4f4} td,th{padding:0} html{color:#555;width:100%;height:100%;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif;font-size:16px;line-height:1.5rem;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%;text-rendering:optimizelegibility;-webkit-tap-highlight-color:transparent} body{background-color:#f4f4f4} body.modal-active{overflow:hidden} @media (max-width:680px){body.modal-active{position:fixed;top:0;right:0;bottom:0;left:0} } body.z_menu-open .menu-phone{transform:translate3d(-16px,0,0)} fancybox{display:flex;justify-content:center} .l_header{position:fixed;z-index:9999;top:0;width:100%;font-size:16px;line-height:64px;height:64px;overflow:hidden;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif;padding:0 16px;margin-bottom:16px;background:#1bc3fb;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} .l_header .wrapper{padding:auto 16px;max-width:1080px;margin:auto;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} .l_header,.l_header a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;height:64px;line-height:64px;color:#fff} .l_header .logo{padding:0 16px;line-height:64px;font-size:19.2px;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif;letter-spacing:0} .l_header .menu{position:relative;flex:1 0 auto;height:64px;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;margin:0 16px} .l_header .menu ul>li>a{transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;display:block;font-size:16px;color:rgba(255,255,255,.7);padding:0 8px} .l_header .menu ul>li>a:hover{color:#fff;border-bottom:2px solid #fff;background:rgba(255,255,255,.1)} .l_header .menu ul>li>a.active,.l_header .menu ul>li>a:active{color:#fff;border-bottom:2px solid #fff} @media (max-width:580px){.l_header .menu{display:none} } .l_header .m_search{position:relative;display:flex;width:285px;height:64px} @media (max-width:1350px){.l_header .m_search{width:240px} } .l_header .m_search .form{position:relative;display:block;width:100%;margin:auto} .l_header .m_search .icon,.l_header .m_search .input{transition:all .3s ease;-moz-transition:all .3s ease;-webkit-transition:all .3s ease;-o-transition:all .3s ease} .l_header .m_search .icon{position:absolute;display:block;line-height:40px;height:40px;width:32px;top:0;left:5px;font-size:16px;color:rgba(255,255,255,.6)} .l_header .m_search .input{display:block;font-size:16px;line-height:16px;height:40px;width:100%;color:rgba(255,255,255,.6);box-shadow:none;box-sizing:border-box;-webkit-appearance:none;padding-left:36px;border-radius:8px;background:rgba(255,255,255,.15);border:1px dashed transparent} @media (max-width:580px){.l_header .m_search .input{padding-left:36px} } .l_header .m_search .input::-webkit-input-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input:-moz-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input::-moz-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input:-ms-input-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input:hover{color:#fff;border:1px solid rgba(255,255,255,.6)} .l_header .m_search .input:focus{color:#fff;border:1px solid #fff} /* .l_header .m_search .input:focus~.icon{color:#fff} */ .l_header.pure{background:#fff;box-shadow:0 1px 2px 0 rgba(0,0,0,.1),0 2px 4px 0 rgba(0,0,0,.1)} .l_header.pure,.l_header.pure a{color:#1bc3fb} .l_header.pure .menu ul>li>a{transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;color:rgba(85,85,85,.7)} .l_header.pure .menu ul>li>a.current{border-bottom:2px solid rgba(27,195,251,.8)} .l_header.pure .menu ul>li>a:hover{color:#1bc3fb;border-bottom:2px solid #1bc3fb;background:rgba(27,195,251,.1)} .l_header.pure .menu ul>li>a.active,.l_header.pure .menu ul>li>a:active{color:#1bc3fb;border-bottom:2px solid #1bc3fb} .l_header.pure .switcher>li a:hover{background:rgba(27,195,251,.15)} .l_header.pure .m_search .icon{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input{color:#555;background:#f4f4f4} .l_header.pure .m_search .input::-webkit-input-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input:-moz-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input::-moz-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input:-ms-input-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input:hover{border:1px solid rgba(27,195,251,.6)} .l_header.pure .m_search .input:hover~.icon{color:rgba(27,195,251,.8)} .l_header.pure .m_search .input:focus{color:#555;background:rgba(27,195,251,.15);border:1px solid #1bc3fb} .l_header.pure .m_search .input:focus~.icon{color:#1bc3fb} @media (max-width:580px){.l_header{padding:0} .l_header .m_search{width:0;overflow:hidden;position:absolute;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;margin:0 8px} .l_header.z_search-open .logo{opacity:0} .l_header.z_search-open .m_search{width:calc(100vw - 2*16px - 2*32px)} } .menu-phone{position:fixed;top:80px;right:0;z-index:10000;line-height:32px;background:#fff;border-right:0;box-shadow:0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1),0 8px 16px 0 rgba(0,0,0,.1),0 16px 32px 0 rgba(0,0,0,.1);border-radius:12px;transform:translate3d(-40px,-40px,0) scale(0,0);transform-origin:right top;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} .menu-phone .header{border-top-left-radius:12px;border-top-right-radius:12px;background-color:rgba(27,195,251,.9);color:#fff;font-size:16px;line-height:1.8em;padding:8px 22px} .menu-phone:hover{box-shadow:0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1),0 8px 16px 0 rgba(0,0,0,.1),0 16px 32px 0 rgba(0,0,0,.1)} .menu-phone:active{box-shadow:0 1px 2px 0 rgba(0,0,0,.1),0 2px 4px 0 rgba(0,0,0,.1)} .menu-phone nav{padding:8px 0} .menu-phone nav .nav{height:36px;line-height:36px;position:relative;display:block;color:#444;padding:2px 20px;border-left:4px solid transparent;border-right:4px solid transparent} .menu-phone nav .nav.active,.menu-phone nav .nav:hover{border-left:4px solid #1bc3fb;background:rgba(27,195,251,.1)} .cover-wrapper .l_header{transition:all .5s ease;-moz-transition:all .5s ease;-webkit-transition:all .5s ease;-o-transition:all .5s ease;transform:translateY(-96px)} .cover-wrapper .l_header.show{transform:translateY(0)} .cover-wrapper{padding-bottom:2px} .cover-wrapper .cover{top:0;left:0;max-width:100%;height:calc(100vh);display:flex;flex-wrap:nowrap;flex-direction:column;align-items:center;align-self:center;align-content:center;padding:16px} .cover-wrapper .cover .logo,.cover-wrapper .cover .title{font-size:72px;line-height:79.2px;margin-top:calc(28vh - 2*16px);text-align:center;font-weight:700} .cover-wrapper .cover .logo{max-height:150px;max-width:calc(100% - 4*16px)} @media (max-width:580px){.cover-wrapper .cover .logo,.cover-wrapper .cover .title{font-size:48px;line-height:52.8px} } .cover-wrapper .cover .m_search{margin-top:calc(2vh + 2*16px);position:relative;max-width:calc(100% - 1*16px);width:313.5px;line-height:48px;vertical-align:middle} @media (max-width:1024px){.cover-wrapper .cover .m_search{width:288px} } .cover-wrapper .cover .m_search .form{position:relative;display:block;width:100%} .cover-wrapper .cover .m_search .icon,.cover-wrapper .cover .m_search .input{transition:all .3s ease;-moz-transition:all .3s ease;-webkit-transition:all .3s ease;-o-transition:all .3s ease} .cover-wrapper .cover .m_search .icon{position:absolute;display:block;line-height:44px;height:44px;width:32px;top:0;left:5px;font-size:16px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input{display:block;font-size:16px;line-height:16px;height:44px;width:100%;color:#555;box-shadow:none;box-sizing:border-box;-webkit-appearance:none;padding-left:36px;border-radius:64px;background:#fff;border:1px dashed transparent} @media (max-width:580px){.cover-wrapper .cover .m_search .input{padding-left:36px} } .cover-wrapper .cover .m_search .input::-webkit-input-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input:-moz-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input::-moz-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input:-ms-input-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input:hover~.icon{color:#1bc3fb} .cover-wrapper .cover .m_search .input:focus{border:1px solid #1bc3fb} .cover-wrapper .cover .m_search .input:focus~.icon{color:#1bc3fb} .cover-wrapper .cover.half{height:calc(60vh - 16px - 64px)} .cover-wrapper .cover.half .logo,.cover-wrapper .cover.half .title{margin-top:calc(20vh - 4*16px)} @media (max-width:580px){.cover-wrapper .cover.half .logo,.cover-wrapper .cover.half .title{margin-top:calc(32vh - 6*16px)} } .cover-wrapper .cover.half .m_search{margin-top:1vh} .cover-wrapper .cover,.cover-wrapper .cover a{color:#1bc3fb} .cover-wrapper .cover .menu{margin-top:4vh} .cover-wrapper .cover .menu ul{display:flex;flex-wrap:wrap;align-items:baseline;justify-content:center} .cover-wrapper .cover .menu ul li{display:flex;flex-wrap:wrap;align-items:center;padding:0;height:auto} .cover-wrapper .cover .menu ul>li>a{font-size:14px;padding:2px;margin:0 4px;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;color:rgba(85,85,85,.7);border-bottom:1px solid transparent} .cover-wrapper .cover .menu ul>li>a.active,.cover-wrapper .cover .menu ul>li>a:hover{color:#1bc3fb;border-bottom:1px solid #1bc3fb} .cover-wrapper .cover .switcher>li a:hover{background:rgba(27,195,251,.15)} ul.h-list{display:flex;align-items:center;height:100%} ul.h-list>li{height:100%;justify-content:center} #loading-bar-wrapper{position:fixed;top:62px;left:0;width:100%;z-index:99999} #loading-bar{position:fixed;width:0;height:2px;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;background-color:rgba(255,255,255,.5)} #loading-bar.pure{background-color:rgba(27,195,251,.5)} .container--flex{display:flex;flex-wrap:nowrap;justify-content:space-between;align-items:center} .backstretch{opacity:.75}"},{"title":"","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"material/css/list.css","permalink":"https://rogerspy.gitee.io/material/css/list.css","excerpt":"","text":"a:hover, a:focus{ text-decoration: none; outline: none; } #accordion .panel{ border: none; box-shadow: none; border-radius: 0; margin: 40px 0 40px 0; } #accordion .panel-heading{ padding: 0; border-radius: 30px; } #accordion .panel-title a{ display: block; padding: 12px 20px 12px 50px; background: #85D18B; font-size: 18px; font-weight: 600; color: #fff; border: 1px solid transparent; box-shadow: 0 3px 10px rgba(0, 0, 0, 0.58); border-radius: 30px; position: relative; transition: all 0.3s ease 0s; } #accordion .panel-title a.collapsed{ background: #fff; color: #0d345d; border: 1px solid #ddd; box-shadow: 0 1px 2px 0 rgba(0,0,0,.1), 0 2px 4px 0 rgba(0,0,0,.1); } #accordion .panel-title a.collapsed:hover{ box-shadow: 0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1), 0 8px 16px 0 rgba(0,0,0,.1), 0 16px 32px 0 rgba(0,0,0,.1); } #accordion .panel-title a:after, #accordion .panel-title a.collapsed:after{ content: \"\\f107\"; font-family: fontawesome; width: 55px; height: 55px; line-height: 55px; border-radius: 50%; background: #85D18B; font-size: 25px; color: #fff; text-align: center; border: 1px solid transparent; box-shadow: 0 3px 10px rgba(0, 0, 0, 0.58); position: absolute; top: -5px; left: -20px; transition: all 0.3s ease 0s; } #accordion .panel-title a.collapsed:after{ content: \"\\f105\"; background: #fff; color: #0d345d; border: 1px solid #ddd; box-shadow: 0 3px 10px rgba(0, 0, 0, 0.58); } #accordion .panel-body{ padding: 20px 25px 10px 9px; background: transparent; font-size: 14px; color: #8c8c8c; line-height: 25px; border-top: none; position: relative; } #accordion .panel-body a:target{ color: #444; cursor: pointer; text-decoration: none; } #accordion .panel-body a:hover{ color: #1bc3fb; } #accordion .panel-body p{ padding-left: 25px; border-left: 1px dashed #8c8c8c; }"},{"title":"","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"material/css/sidebar.css","permalink":"https://rogerspy.gitee.io/material/css/sidebar.css","excerpt":"","text":"* { margin:0; padding:0; outline:0; } html {height: 100%;} .navbox { position: relative; float: left; } ul.nav { list-style: none; display: block; width: 250px; position: relative; top: 40px; left: 0px; padding: 0px 0 60px 0; background: url(images/shad2.png) no-repeat; -webkit-background-size: 50% 100%; } li { margin: 5px 0 0 0; } ul.nav li a { -webkit-transition: all 0.3s ease-out; font-size: 18px; font-family: KaiTi,Permanent Marker,cursive; font-weight: 200; color: #174867; padding: 7px 15px 7px 15px; -webkit-border-top-right-radius: 10px; -webkit-border-bottom-right-radius: 10px; -webkit-border-top-left-radius: 10px; -webkit-border-bottom-left-radius: 10px; width: 250px; display: block; text-decoration: none; -webkit-box-shadow: 2px 2px 4px #888; } ul.nav li a:hover { color: #F46E7C; padding: 7px 15px 7px 30px; } .scrollbar { margin-left: 15px; float: left; height: 610px; width: 300px; overflow-y: scroll; margin-bottom: 40px; margin-top: 40px; } .force-overflow { min-height: 450px; } #style-1::-webkit-scrollbar-track { -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,0.3); border-radius: 10px; background-color: #F5F5F5; } #style-1::-webkit-scrollbar { width: 0px; background-color: #F5F5F5; } #style-1::-webkit-scrollbar-thumb { border-radius: 0px; -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,.3); background-color: #555; }"},{"title":"","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"material/css/style.css","permalink":"https://rogerspy.gitee.io/material/css/style.css","excerpt":"","text":"body{ background: #F4F4F4; overflow-x: hidden;} #box{ display: flex; align-items: center; } .container-x{ max-width: 1080px; margin: 40px auto 40px auto; background: #FFFFFF; border-radius: 12px; box-shadow: 0 1px 2px 0 rgba(0,0,0,.1), 0 2px 4px 0 rgba(0,0,0,.1); } .container-x:hover{ box-shadow: 0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1), 0 8px 16px 0 rgba(0,0,0,.1), 0 16px 32px 0 rgba(0,0,0,.1); } .title-list{text-align:left; color:#555555; font-size:30px; padding:40px 0 20px 0; margin-bottom:10px; margin-top:40px} .heading-list{font-family:\"Microsoft YaHei\",Permanent Marker,cursive; font-weight:400; margin:0;}"},{"title":"","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"material/math_foundation/index.html","permalink":"https://rogerspy.gitee.io/material/math_foundation/index.html","excerpt":"","text":"机器学习数学基础 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Mathematics for Machine Learning Part I Mathematical Foundations 1. Linear Algebra 1.1 System of Linear Equations 1.2 Matrices 1.3 Solving Systems of Linear Equations 1.4 Vector Spaces 1.5 Linear Independence 1.6 Basis and Rank 1.7 Linear Mappings 1.8 Affine Spaces 1.9 Further Reading 2. Analytic Geometry 2.1 Norms 2.2 Inner Products 2.3 Lengths and Distances 2.4 Angles and Orthogonality 2.5 Orthogonal Basis 2.6 Orthogonal Complement 2.7 Inner Product of Functions 2.8 Rotations 2.9 Further Reading 3. Matrix Decompositions 3.1 Determinant and Trace 3.2 Eigenvalues and Eigenvectors 3.3 Cholesky Decomposition 3.4 Eigendecomposition and Diagonalization 3.5 Singular Value Decomposition 3.6 Matrix Approximation 3.7 Matrix Phylogeny 3.8 Further Reading 4. Vector Calculus 4.1 Differentiation of Univariate Functions 4.2 Partial Differentiation and Gradients 4.3 Gradients of Vector-Valued Functions 4.4 Gradients of Matrices 4.5 Useful Identities for Computing Gradients 4.6 Backpropagation and Automatic Differentiation 4.7 Higher-Order Derivatives 4.8 Linearization and Multivariate Taylor Series 4.9 Further Reading 5. Probability and Distributions 5.1 Construction of a Probability Space 5.2 Discrete and Continuous Probabilities 5.3 Sum Rule, Product Rule, and Bayes’ Theorem 5.4 Summary Statistics and Independence 5.5 Gaussian Distribution 5.6 Conjugacy and the Exponential Family 5.7 Change of Variables/Inverse Transform 5.8 Further Reading 6. Continuous Optimization 6.1 Optimization Using Gradient Descent 6.2 Constrained Optimization and Lagrange Multipliers 6.3 Convex Optimization 6.4 Further Reading Part II Central Machine Learning Problems 7. When Models Meet Data 7.1 Data, Models, and Learning 7.2 Empirical Risk Minimization 7.3 Parameter Estimation 7.4 Probabilistic Modeling and Inference 7.5 Directed Graphical Models 7.6 Model Selection 8. Linear Regression 8.1 Problem Formulation 8.2 Parameter Estimation 8.3 Bayesian Linear Regression 8.4 Maximum Likelihood as Orthogonal Projection 8.5 Further Reading 9. Dimensionality Reduction with Principal Component Analysis 9.1 Problem Setting 9.2 Maximum Variance Perspective 9.3 Projection Perspective 9.4 Eigenvector Computation and Low-Rank Approximations 9.5 PCA in High Dimensions 9.6 Key Steps of PCA in Practice 9.7 Latent Variable Perspective 9.8 Further Reading 10. Density Estimation with Gaussian Mixture Models 10.1 Gaussian Mixture Model 10.2 Parameter Learning via Maximum Likelihood 10.3 EM Algorithm 10.4 Latent-Variable Perspective 10.5 Further Reading 11. Classification with Support Vector Machines 11.1 Separating Hyperplanes 11.2 Primal Support Vector Machine 11.3 Dual Support Vector Machine 11.4 Kernels 11.5 Numerical Solution 11.6 Further Reading Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"material/foundation_ml/index.html","permalink":"https://rogerspy.gitee.io/material/foundation_ml/index.html","excerpt":"","text":"机器学习基础 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Foundations for Machine Learning 1. Introduction 1.1 What is machine learning? 1.2 What kind of problems can be tackled using machine learning? 1.3 Some standard learning tasks 1.4 Learning stages 1.5 Learning scenarios 1.6 Generalization 2. The PAC Learning Framework 2.1 The PCA learning model 2.2 Guarantees for finite hyperthesissets — consistent case 2.3 Guarantees for finite hypothesis sets — inconsistent case 2.4 Generalities 3. Rademacher Complexity and VC-Dimension 3.1 Rademacher complexity 3.2 Growth function 3.3 VC-dimension 3.4 Lower bounds 4. Model Selection 4.1 Estimation and approximation errors 4.2 Empirical risk minimization (ERM) 4.3 Structural risk minimization (SRM) 4.4 Cross-validation 4.5 n-Fold cross-validation 4.6 Regularization-based algorithms 4.7 Convex surrogate losses 5. Support Vector Machines 5.1 Linear classification 5.2 Separable case 5.3 Non-separable case 5.4 Margin theory 6. Kernel Methods 6.1 Introduction 6.2 Positive definite symmetric kernels 6.3 Kernel-based algorithms 6.4 Negative definite symmetric kernels 6.5 Sequence kernels 6.6 Approximate kernel feature maps 7. Boosting 7.1 Introduction 7.2 AdaBoost 7.3 Theoretical results 7.4 L1-regularization 7.5 Discussion 8. On-Line Learning 8.1 Introduction 8.2 Prediction with expert advice 8.3 Linear classification 8.4 On-line to batch conversion 8.5 Game-theoretic connection 9. Multi-Class Classification 9.1 Multi-class classification problem 9.2 Generalization bounds 9.3 Uncombined multi-class algorithms 9.4 Aggregated multi-class algorithms 9.5 Structured prediction algorithms 10. Ranking 10.1 The problem of ranking 10.2 Generalization bound 10.3 Ranking with SVMs 10.4 RankBoost 10.5 Bipartite ranking 10.6 Preference-based setting 10.7 Other ranking criteria 11. Regression 11.1 The problem of regression 11.2 Generalization bounds 11.3 Regression algorithms 12. Maximum Entropy Models 12.1 Density estimation problem 12.2 Density estimation problem augmented with features 12.3 Maxent principle 12.4 Maxent models 12.5 Dual problem 12.6 Generalization bound 12.7 Coordinate descent algorithm 12.8 Extensions 12.9 L2-regularization 13. Conditional Maximum Entropy Models 13.1 Learning problem 13.2 Conditional Maxent principle 13.3 Conditional Maxent models 13.4 Dual problem 13.5 Properties 13.6 Generalization bound 13.7 Logistic regression 13.8 L2-regularization 13.9 Proof of the duality theorem 14. Algorithmic Stability 14.1 Definitions 14.2 Stability-based generalization guarantee 14.3 Stability of kernel-based regularization algorithms 15. Dimensionality Reduction 15.1 Principal component analysis 15.2 Kernel principal component analysis (KPCA) 15.3 KPCA and manifold learning 15.4 Johnson-Lindenstrauss lemma 16. Learning Automata and Languages 16.1 Introduction 16.2 Finite automata 16.3 Efficient exact learning 16.4 Identification in the limit 17. Reinforcement Learning 17.1 Learning scenario 17.2 Markov decision process model 17.3 Policy 17.4 Planning algorithms 17.5 Learning algorithms Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"personal_center/css/header.css","permalink":"https://rogerspy.gitee.io/personal_center/css/header.css","excerpt":"","text":"@charset \"utf-8\"; @font-face{font-family:'Varela Round';src:url(https://cdn.jsdelivr.net/gh/xaoxuu/cdn-fonts@19.1.7/VarelaRound/VarelaRound-Regular.ttf);font-weight:400;font-style:normal} @font-face{font-family:'Source Sans Pro';src:url(https://cdn.jsdelivr.net/gh/xaoxuu/cdn-fonts@master/SourceSansPro/SourceSansPro-Regular.ttf);font-weight:400;font-style:normal} /*! normalize.css v3.0.2 | MIT License | git.io/normalize */ html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%} body{margin:0} article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block;} audio,canvas,progress,video{display:inline-block;vertical-align:baseline} audio:not([controls]){display:none;height:0} [hidden],template{display:none} a{color: #444; cursor: pointer; text-decoration: none; transition: all .25s ease; -moz-transition: all .25s ease; -webkit-transition: all .25s ease; -o-transition: all .25s ease;} a:active,a:hover{outline:0} abbr[title]{border-bottom:1px dotted} b,strong{font-weight:700} dfn{font-style:italic} h1{font-size:2em;margin:.67em 0} mark{background:#ff0;color:#000} small{font-size:80%} sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline} sup{top:-.5em} sub{bottom:-.25em} img{border:0} li{list-style:none} svg:not(:root){overflow:hidden} figure{margin:1em 40px} hr{box-sizing:content-box;height:0;border:0;border-radius:1px;border-bottom:1px solid rgba(0,0,0,.1)} pre{overflow:auto} code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em} button,input,optgroup,select,textarea{color:inherit;font:inherit;margin:0} button{overflow:visible} button,select{text-transform:none} button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer} button[disabled],html input[disabled]{cursor:default} button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0} input{line-height:normal} input[type=checkbox],input[type=radio]{box-sizing:border-box;padding:0} input[type=number]::-webkit-inner-spin-button,input[type=number]::-webkit-outer-spin-button{height:auto} input[type=search]{-webkit-appearance:textfield;box-sizing:content-box} input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration{-webkit-appearance:none} fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em} legend{border:0;padding:0} textarea{overflow:auto} optgroup{font-weight:700} table{border-collapse:collapse;width:100%} table th{background-color:#f7f7f7} table td,table th{text-align:justify;padding:4px 8px;border:1px solid #f4f4f4} td,th{padding:0} /* *{box-sizing:border-box;outline:0;margin:0;padding:0} */ html{color:#555;width:100%;height:100%;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif;font-size:16px;line-height:1.5rem;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%;text-rendering:optimizelegibility;-webkit-tap-highlight-color:transparent} body{background-color:#f4f4f4} body.modal-active{overflow:hidden} @media (max-width:680px){body.modal-active{position:fixed;top:0;right:0;bottom:0;left:0} } body.z_menu-open .menu-phone{transform:translate3d(-16px,0,0)} fancybox{display:flex;justify-content:center} .l_header{position:fixed;z-index:9999;top:0;width:100%;font-size:16px;line-height:64px;height:64px;overflow:hidden;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif;padding:0 16px;margin-bottom:16px;background:#1bc3fb;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} .l_header .wrapper{padding:auto 16px;max-width:1080px;margin:auto;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} .l_header,.l_header a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;height:64px;line-height:64px;color:#fff} .l_header .logo{padding:0 16px;line-height:64px;font-size:19.2px;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif;letter-spacing:0} .l_header .menu{position:relative;flex:1 0 auto;height:64px;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;margin:0 16px} .l_header .menu ul>li>a{transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;display:block;font-size:16px;color:rgba(255,255,255,.7);padding:0 8px} .l_header .menu ul>li>a:hover{color:#fff;border-bottom:2px solid #fff;background:rgba(255,255,255,.1)} .l_header .menu ul>li>a.active,.l_header .menu ul>li>a:active{color:#fff;border-bottom:2px solid #fff} @media (max-width:580px){.l_header .menu{display:none} } .l_header .m_search{position:relative;display:flex;width:285px;height:64px} @media (max-width:1350px){.l_header .m_search{width:240px} } .l_header .m_search .form{position:relative;display:block;width:100%;margin:auto} .l_header .m_search .icon,.l_header .m_search .input{transition:all .3s ease;-moz-transition:all .3s ease;-webkit-transition:all .3s ease;-o-transition:all .3s ease} .l_header .m_search .icon{position:absolute;display:block;line-height:40px;height:40px;width:32px;top:0;left:5px;font-size:16px;color:rgba(255,255,255,.6)} .l_header .m_search .input{display:block;font-size:16px;line-height:16px;height:40px;width:100%;color:rgba(255,255,255,.6);box-shadow:none;box-sizing:border-box;-webkit-appearance:none;padding-left:36px;border-radius:8px;background:rgba(255,255,255,.15);border:1px dashed transparent} @media (max-width:580px){.l_header .m_search .input{padding-left:36px} } .l_header .m_search .input::-webkit-input-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input:-moz-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input::-moz-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input:-ms-input-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input:hover{color:#fff;border:1px solid rgba(255,255,255,.6)} .l_header .m_search .input:focus{color:#fff;border:1px solid #fff} /* .l_header .m_search .input:focus~.icon{color:#fff} */ .l_header.pure{background:#fff;box-shadow:0 1px 2px 0 rgba(0,0,0,.1),0 2px 4px 0 rgba(0,0,0,.1)} .l_header.pure,.l_header.pure a{color:#1bc3fb} .l_header.pure .menu ul>li>a{transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;color:rgba(85,85,85,.7)} .l_header.pure .menu ul>li>a.current{border-bottom:2px solid rgba(27,195,251,.8)} .l_header.pure .menu ul>li>a:hover{color:#1bc3fb;border-bottom:2px solid #1bc3fb;background:rgba(27,195,251,.1)} .l_header.pure .menu ul>li>a.active,.l_header.pure .menu ul>li>a:active{color:#1bc3fb;border-bottom:2px solid #1bc3fb} .l_header.pure .switcher>li a:hover{background:rgba(27,195,251,.15)} .l_header.pure .m_search .icon{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input{color:#555;background:#f4f4f4} .l_header.pure .m_search .input::-webkit-input-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input:-moz-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input::-moz-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input:-ms-input-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input:hover{border:1px solid rgba(27,195,251,.6)} .l_header.pure .m_search .input:hover~.icon{color:rgba(27,195,251,.8)} .l_header.pure .m_search .input:focus{color:#555;background:rgba(27,195,251,.15);border:1px solid #1bc3fb} .l_header.pure .m_search .input:focus~.icon{color:#1bc3fb} @media (max-width:580px){.l_header{padding:0} .l_header .m_search{width:0;overflow:hidden;position:absolute;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;margin:0 8px} .l_header.z_search-open .logo{opacity:0} .l_header.z_search-open .m_search{width:calc(100vw - 2*16px - 2*32px)} } .menu-phone{position:fixed;top:80px;right:0;z-index:10000;line-height:32px;background:#fff;border-right:0;box-shadow:0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1),0 8px 16px 0 rgba(0,0,0,.1),0 16px 32px 0 rgba(0,0,0,.1);border-radius:12px;transform:translate3d(-40px,-40px,0) scale(0,0);transform-origin:right top;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} .menu-phone .header{border-top-left-radius:12px;border-top-right-radius:12px;background-color:rgba(27,195,251,.9);color:#fff;font-size:16px;line-height:1.8em;padding:8px 22px} .menu-phone:hover{box-shadow:0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1),0 8px 16px 0 rgba(0,0,0,.1),0 16px 32px 0 rgba(0,0,0,.1)} .menu-phone:active{box-shadow:0 1px 2px 0 rgba(0,0,0,.1),0 2px 4px 0 rgba(0,0,0,.1)} .menu-phone nav{padding:8px 0} .menu-phone nav .nav{height:36px;line-height:36px;position:relative;display:block;color:#444;padding:2px 20px;border-left:4px solid transparent;border-right:4px solid transparent} .menu-phone nav .nav.active,.menu-phone nav .nav:hover{border-left:4px solid #1bc3fb;background:rgba(27,195,251,.1)} .cover-wrapper .l_header{transition:all .5s ease;-moz-transition:all .5s ease;-webkit-transition:all .5s ease;-o-transition:all .5s ease;transform:translateY(-96px)} .cover-wrapper .l_header.show{transform:translateY(0)} .cover-wrapper{padding-bottom:2px} .cover-wrapper .cover{top:0;left:0;max-width:100%;height:calc(100vh);display:flex;flex-wrap:nowrap;flex-direction:column;align-items:center;align-self:center;align-content:center;padding:16px} .cover-wrapper .cover .logo,.cover-wrapper .cover .title{font-size:72px;line-height:79.2px;margin-top:calc(28vh - 2*16px);text-align:center;font-weight:700} .cover-wrapper .cover .logo{max-height:150px;max-width:calc(100% - 4*16px)} @media (max-width:580px){.cover-wrapper .cover .logo,.cover-wrapper .cover .title{font-size:48px;line-height:52.8px} } .cover-wrapper .cover .m_search{margin-top:calc(2vh + 2*16px);position:relative;max-width:calc(100% - 1*16px);width:313.5px;line-height:48px;vertical-align:middle} @media (max-width:1024px){.cover-wrapper .cover .m_search{width:288px} } .cover-wrapper .cover .m_search .form{position:relative;display:block;width:100%} .cover-wrapper .cover .m_search .icon,.cover-wrapper .cover .m_search .input{transition:all .3s ease;-moz-transition:all .3s ease;-webkit-transition:all .3s ease;-o-transition:all .3s ease} .cover-wrapper .cover .m_search .icon{position:absolute;display:block;line-height:44px;height:44px;width:32px;top:0;left:5px;font-size:16px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input{display:block;font-size:16px;line-height:16px;height:44px;width:100%;color:#555;box-shadow:none;box-sizing:border-box;-webkit-appearance:none;padding-left:36px;border-radius:64px;background:#fff;border:1px dashed transparent} @media (max-width:580px){.cover-wrapper .cover .m_search .input{padding-left:36px} } .cover-wrapper .cover .m_search .input::-webkit-input-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input:-moz-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input::-moz-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input:-ms-input-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input:hover~.icon{color:#1bc3fb} .cover-wrapper .cover .m_search .input:focus{border:1px solid #1bc3fb} .cover-wrapper .cover .m_search .input:focus~.icon{color:#1bc3fb} .cover-wrapper .cover.half{height:calc(60vh - 16px - 64px)} .cover-wrapper .cover.half .logo,.cover-wrapper .cover.half .title{margin-top:calc(20vh - 4*16px)} @media (max-width:580px){.cover-wrapper .cover.half .logo,.cover-wrapper .cover.half .title{margin-top:calc(32vh - 6*16px)} } .cover-wrapper .cover.half .m_search{margin-top:1vh} .cover-wrapper .cover,.cover-wrapper .cover a{color:#1bc3fb} .cover-wrapper .cover .menu{margin-top:4vh} .cover-wrapper .cover .menu ul{display:flex;flex-wrap:wrap;align-items:baseline;justify-content:center} .cover-wrapper .cover .menu ul li{display:flex;flex-wrap:wrap;align-items:center;padding:0;height:auto} .cover-wrapper .cover .menu ul>li>a{font-size:14px;padding:2px;margin:0 4px;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;color:rgba(85,85,85,.7);border-bottom:1px solid transparent} .cover-wrapper .cover .menu ul>li>a.active,.cover-wrapper .cover .menu ul>li>a:hover{color:#1bc3fb;border-bottom:1px solid #1bc3fb} .cover-wrapper .cover .switcher>li a:hover{background:rgba(27,195,251,.15)} ul.h-list{display:flex;align-items:center;height:100%} ul.h-list>li{height:100%;justify-content:center} #loading-bar-wrapper{position:fixed;top:62px;left:0;width:100%;z-index:99999} #loading-bar{position:fixed;width:0;height:2px;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;background-color:rgba(255,255,255,.5)} #loading-bar.pure{background-color:rgba(27,195,251,.5)} .container--flex{display:flex;flex-wrap:nowrap;justify-content:space-between;align-items:center} .backstretch{opacity:.75}"},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"personal_center/css/style.css","permalink":"https://rogerspy.gitee.io/personal_center/css/style.css","excerpt":"","text":"body{ background: #F4F4F4; overflow-x: hidden;} iframe, object, embed { width:735px; height:536px; border-radius:12px; border: none; margin-bottom: -8px; margin-left: 0px; } #box{ display: flex; align-items: center; } .container-x{ max-width: 1080px; margin: 40px auto 40px auto; background: #FFFFFF; border-radius: 12px; box-shadow: 0 1px 2px 0 rgba(0,0,0,.1), 0 2px 4px 0 rgba(0,0,0,.1); } .container-x:hover{ box-shadow: 0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1), 0 8px 16px 0 rgba(0,0,0,.1), 0 16px 32px 0 rgba(0,0,0,.1); } .video-section{padding:40px 0px} .video-section--light{background:#fffff; width:735px; height: 735px} .container-video{max-width:735px; min-height: 556px; margin:0 0 0 0px; box-shadow: 0 1px 2px 0 rgba(0,0,0,.1), 0 2px 4px 0 rgba(0,0,0,.1); border-radius: 12px; } .container-video:hover{ box-shadow: 0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1), 0 8px 16px 0 rgba(0,0,0,.1), 0 16px 32px 0 rgba(0,0,0,.1); } .title-video{text-align:left; color:#555555; font-size:30px; padding:0 0 20px 0; margin-bottom:10px; margin-top:40px} .heading-video{font-family:\"Microsoft YaHei\",Permanent Marker,cursive; font-weight:400; margin:0;}"},{"title":"","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"personal_center/css/footer.css","permalink":"https://rogerspy.gitee.io/personal_center/css/footer.css","excerpt":"","text":"#footer{position:relative;padding:40px 10px 120px 10px;width:100%;color:rgba(85,85,85,.5);margin:0 auto;font-size:14px;overflow:hidden;text-align:center;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif} #footer .licenses{color:rgba(85,85,85,.5);text-decoration:underline} #footer .codename{text-decoration:underline} #footer .social-wrapper{display:flex;justify-content:center;flex-wrap:wrap;margin:4px 8px} #footer a{color:rgba(85,85,85,.7);padding:0;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} #footer a:hover{color:#1bc3fb} #footer a.social{position:relative;display:inline-block;text-align:center;display:flex;justify-content:center;align-items:center;width:32px;height:32px;margin:4px;border-radius:100px} #footer a.social:hover{background:rgba(27,195,251,.1);color:#1bc3fb} @media (max-width:768px){ #footer{justify-content:center} } .clearfix{zoom:1} .clearfix:after,.clearfix:before{content:\" \";display:table} .clearfix:after{clear:both}"},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"personal_center/css/sidebar.css","permalink":"https://rogerspy.gitee.io/personal_center/css/sidebar.css","excerpt":"","text":"* { margin:0; padding:0; outline:0; } html {height: 100%;} .navbox { position: relative; float: left; } ul.nav { list-style: none; display: block; width: 250px; position: relative; top: 40px; left: 0px; padding: 0px 0 60px 0; background: url(images/shad2.png) no-repeat; -webkit-background-size: 50% 100%; } li { margin: 5px 0 0 0; } ul.nav li a { -webkit-transition: all 0.3s ease-out; font-size: 18px; font-family: KaiTi,Permanent Marker,cursive; font-weight: 200; color: #174867; padding: 7px 15px 7px 15px; -webkit-border-top-right-radius: 10px; -webkit-border-bottom-right-radius: 10px; -webkit-border-top-left-radius: 10px; -webkit-border-bottom-left-radius: 10px; width: 250px; display: block; text-decoration: none; -webkit-box-shadow: 2px 2px 4px #888; } ul.nav li a:hover { color: #F46E7C; padding: 7px 15px 7px 30px; } .scrollbar { margin-left: 15px; float: left; height: 610px; width: 300px; overflow-y: scroll; margin-bottom: 40px; margin-top: 40px; } .force-overflow { min-height: 450px; } #style-1::-webkit-scrollbar-track { -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,0.3); border-radius: 10px; background-color: #F5F5F5; } #style-1::-webkit-scrollbar { width: 0px; background-color: #F5F5F5; } #style-1::-webkit-scrollbar-thumb { border-radius: 0px; -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,.3); background-color: #555; }"},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/bp.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/bp.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 反向传播和项目建议 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/cnn.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/cnn.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 卷积神经网络 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/end_end_lm.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/end_end_lm.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 自然语言处理的端对端模型 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/gru.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/gru.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 GRU及NMT其他议题 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/dependency_parsing.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/dependency_parsing.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 依存分析 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/entity_disambugation.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/entity_disambugation.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 共指消解 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/mt.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/mt.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 机器翻译和高级循环神经网络 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/index.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/index.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 NLP和深度学习入门 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/nlp_constrain.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/nlp_constrain.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 应对深度NLP的局限性 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/nlp_problem.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/nlp_problem.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 NLP的问题和可能性架构 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/qa.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/qa.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 用于问答的动态神经网络 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/nmt.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/nmt.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 神经机器翻译和注意力模型 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/tree_rnn.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/tree_rnn.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 树RNN和短语句法分析 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/tensorflow.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/tensorflow.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 TensorFlow入门 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/rnn_lm.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/rnn_lm.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 RNN和语言模型 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/word_vec.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/word_vec.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 词向量表示 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/word2vec.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/word2vec.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 高级词向量表示 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2017/word_window.html","permalink":"https://rogerspy.gitee.io/video/cs224n2017/word_window.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2017） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 NLP和深度学习入门 词向量表示 高级词向量表示 word window分类与神经网络 反向传播和项目建议 依存分析 TensorFlow入门 RNN和语言模型 机器翻译和高级循环神经网络 神经机器翻译和注意力模型 GRU及NMT其他议题 自然语言处理的端对端模型 卷积神经网络 树RNN和短语句法分析 共指消解 用于问答的动态神经网络 NLP的问题和可能性架构 应对深度NLP的局限性 word window分类与神经网络 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/bp2.html","permalink":"https://rogerspy.gitee.io/video/cs231n/bp2.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 反向传播与神经网络初步（下） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/bp1.html","permalink":"https://rogerspy.gitee.io/video/cs231n/bp1.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 反向传播与神经网络初步（上） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/cnn1.html","permalink":"https://rogerspy.gitee.io/video/cs231n/cnn1.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 卷积神经网络详解（上） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/detail1.html","permalink":"https://rogerspy.gitee.io/video/cs231n/detail1.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 神经网络训练细节（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/cnn2.html","permalink":"https://rogerspy.gitee.io/video/cs231n/cnn2.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 卷积神经网络详解（下） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/detail2.html","permalink":"https://rogerspy.gitee.io/video/cs231n/detail2.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 神经网络训练细节（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/detail3.html","permalink":"https://rogerspy.gitee.io/video/cs231n/detail3.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 神经网络训练细节（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/detail4.html","permalink":"https://rogerspy.gitee.io/video/cs231n/detail4.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 神经网络训练细节（4） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/history2.html","permalink":"https://rogerspy.gitee.io/video/cs231n/history2.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 计算机视觉历史回顾与介绍（中） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/history3.html","permalink":"https://rogerspy.gitee.io/video/cs231n/history3.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 计算机视觉历史回顾与介绍（下） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/k_near2.html","permalink":"https://rogerspy.gitee.io/video/cs231n/k_near2.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） K邻近与线性分类器（下） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/k_near1.html","permalink":"https://rogerspy.gitee.io/video/cs231n/k_near1.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） K邻近与线性分类器（上） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/index.html","permalink":"https://rogerspy.gitee.io/video/cs231n/index.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 计算机视觉历史回顾与介绍（上） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/loss_function1.html","permalink":"https://rogerspy.gitee.io/video/cs231n/loss_function1.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 线性分类器损失函数与最优化（上） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/loss_function2.html","permalink":"https://rogerspy.gitee.io/video/cs231n/loss_function2.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 线性分类器损失函数与最优化（下） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/object_detection1.html","permalink":"https://rogerspy.gitee.io/video/cs231n/object_detection1.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 物体定位与检测（上） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/object_detection2.html","permalink":"https://rogerspy.gitee.io/video/cs231n/object_detection2.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 物体定位与检测（下） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/visualiztion1.html","permalink":"https://rogerspy.gitee.io/video/cs231n/visualiztion1.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 卷积神经网络可视化（上） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs231n/visualiztion2.html","permalink":"https://rogerspy.gitee.io/video/cs231n/visualiztion2.html","excerpt":"","text":"CS231N-斯坦福深度深度学习与计算机视觉 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 计算机视觉历史回顾与介绍（上） 计算机视觉历史回顾与介绍（中） 计算机视觉历史回顾与介绍（下） K邻近与线性分类器（上） K邻近与线性分类器（下） 线性分类器损失函数与最优化（上） 线性分类器损失函数与最优化（下） 反向传播与神经网络初步（上） 反向传播与神经网络初步（下） 神经网络训练细节（1） 神经网络训练细节（2） 神经网络训练细节（3） 神经网络训练细节（4） 卷积神经网络详解（上） 卷积神经网络详解（下） 物体定位与检测（上） 物体定位与检测（下） 卷积神经网络可视化（上） 卷积神经网络可视化（下） 卷积神经网络可视化（下） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/bias_in_ai.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/bias_in_ai.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 AI偏见 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/bp.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/bp.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 反向传播 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/conference_resolution.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/conference_resolution.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 共指消解 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/cnn_for_nlp.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/cnn_for_nlp.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 NLP中的CNN Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/context.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/context.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 上下文词向量 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/future.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/future.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 NLP和深度学习的未来 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/dependency_parsing.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/dependency_parsing.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 依存句法分析 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/index.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/index.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 Word2vec Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/gradient.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/gradient.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 Vanishing Gradient Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/nlg.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/nlg.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 自然语言生成 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/mt.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/mt.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 机器翻译 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/multi_task.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/multi_task.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 多任务学习 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/qa.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/qa.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 问答 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/rnn_lm.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/rnn_lm.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 语言模型和RNN Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.343Z","updated":"2021-09-15T15:36:17.343Z","comments":true,"path":"video/cs224n2019/nn.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/nn.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 神经网络 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs224n2019/subword.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/subword.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 subword模型 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs224n2019/tips.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/tips.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 项目建议 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs224n2019/tree_rnn.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/tree_rnn.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 树RNN Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs224n2019/word_sense.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/word_sense.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 word senses Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/cs224n2019/transformer.html","permalink":"https://rogerspy.gitee.io/video/cs224n2019/transformer.html","excerpt":"","text":"CS224N-斯坦福深度自然语言处理（2019） Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 Word2vec word senses 神经网络 反向传播 依存句法分析 语言模型和RNN Vanishing Gradient 机器翻译 项目建议 问答 NLP中的CNN subword模型 上下文词向量 Transformer 自然语言生成 共指消解 多任务学习 树RNN AI偏见 NLP和深度学习的未来 Transformer Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/css/footer.css","permalink":"https://rogerspy.gitee.io/video/css/footer.css","excerpt":"","text":"#footer{position:relative;padding:40px 10px 120px 10px;width:100%;color:rgba(85,85,85,.5);margin:0 auto;font-size:14px;overflow:hidden;text-align:center;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif} #footer .licenses{color:rgba(85,85,85,.5);text-decoration:underline} #footer .codename{text-decoration:underline} #footer .social-wrapper{display:flex;justify-content:center;flex-wrap:wrap;margin:4px 8px} #footer a{color:rgba(85,85,85,.7);padding:0;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} #footer a:hover{color:#1bc3fb} #footer a.social{position:relative;display:inline-block;text-align:center;display:flex;justify-content:center;align-items:center;width:32px;height:32px;margin:4px;border-radius:100px} #footer a.social:hover{background:rgba(27,195,251,.1);color:#1bc3fb} @media (max-width:768px){ #footer{justify-content:center} } .clearfix{zoom:1} .clearfix:after,.clearfix:before{content:\" \";display:table} .clearfix:after{clear:both}"},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/css/header.css","permalink":"https://rogerspy.gitee.io/video/css/header.css","excerpt":"","text":"@charset \"utf-8\"; @font-face{font-family:'Varela Round';src:url(https://cdn.jsdelivr.net/gh/xaoxuu/cdn-fonts@19.1.7/VarelaRound/VarelaRound-Regular.ttf);font-weight:400;font-style:normal} @font-face{font-family:'Source Sans Pro';src:url(https://cdn.jsdelivr.net/gh/xaoxuu/cdn-fonts@master/SourceSansPro/SourceSansPro-Regular.ttf);font-weight:400;font-style:normal} /*! normalize.css v3.0.2 | MIT License | git.io/normalize */ html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%} body{margin:0} article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block;} audio,canvas,progress,video{display:inline-block;vertical-align:baseline} audio:not([controls]){display:none;height:0} [hidden],template{display:none} a{color: #444; cursor: pointer; text-decoration: none; transition: all .25s ease; -moz-transition: all .25s ease; -webkit-transition: all .25s ease; -o-transition: all .25s ease;} a:active,a:hover{outline:0} abbr[title]{border-bottom:1px dotted} b,strong{font-weight:700} dfn{font-style:italic} h1{font-size:2em;margin:.67em 0} mark{background:#ff0;color:#000} small{font-size:80%} sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline} sup{top:-.5em} sub{bottom:-.25em} img{border:0} li{list-style:none} svg:not(:root){overflow:hidden} figure{margin:1em 40px} hr{box-sizing:content-box;height:0;border:0;border-radius:1px;border-bottom:1px solid rgba(0,0,0,.1)} pre{overflow:auto} code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em} button,input,optgroup,select,textarea{color:inherit;font:inherit;margin:0} button{overflow:visible} button,select{text-transform:none} button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer} button[disabled],html input[disabled]{cursor:default} button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0} input{line-height:normal} input[type=checkbox],input[type=radio]{box-sizing:border-box;padding:0} input[type=number]::-webkit-inner-spin-button,input[type=number]::-webkit-outer-spin-button{height:auto} input[type=search]{-webkit-appearance:textfield;box-sizing:content-box} input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration{-webkit-appearance:none} fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em} legend{border:0;padding:0} textarea{overflow:auto} optgroup{font-weight:700} table{border-collapse:collapse;width:100%} table th{background-color:#f7f7f7} table td,table th{text-align:justify;padding:4px 8px;border:1px solid #f4f4f4} td,th{padding:0} /* *{box-sizing:border-box;outline:0;margin:0;padding:0} */ html{color:#555;width:100%;height:100%;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif;font-size:16px;line-height:1.5rem;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%;text-rendering:optimizelegibility;-webkit-tap-highlight-color:transparent} body{background-color:#f4f4f4} body.modal-active{overflow:hidden} @media (max-width:680px){body.modal-active{position:fixed;top:0;right:0;bottom:0;left:0} } body.z_menu-open .menu-phone{transform:translate3d(-16px,0,0)} fancybox{display:flex;justify-content:center} .l_header{position:fixed;z-index:9999;top:0;width:100%;font-size:16px;line-height:64px;height:64px;overflow:hidden;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif;padding:0 16px;margin-bottom:16px;background:#1bc3fb;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} .l_header .wrapper{padding:auto 16px;max-width:1080px;margin:auto;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} .l_header,.l_header a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;height:64px;line-height:64px;color:#fff} .l_header .logo{padding:0 16px;line-height:64px;font-size:19.2px;font-family:'Varela Round',\"Microsoft YaHei\",\"Source Sans Pro\",\"Helvetica Neue\",Menlo,Monaco,monospace,\"Lucida Console\",sans-serif,Helvetica,\"Hiragino Sans GB\",\"Hiragino Sans GB W3\",Source Han Sans CN Regular,WenQuanYi Micro Hei,Arial,sans-serif;letter-spacing:0} .l_header .menu{position:relative;flex:1 0 auto;height:64px;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;margin:0 16px} .l_header .menu ul>li>a{transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;display:block;font-size:16px;color:rgba(255,255,255,.7);padding:0 8px} .l_header .menu ul>li>a:hover{color:#fff;border-bottom:2px solid #fff;background:rgba(255,255,255,.1)} .l_header .menu ul>li>a.active,.l_header .menu ul>li>a:active{color:#fff;border-bottom:2px solid #fff} @media (max-width:580px){.l_header .menu{display:none} } .l_header .m_search{position:relative;display:flex;width:285px;height:64px} @media (max-width:1350px){.l_header .m_search{width:240px} } .l_header .m_search .form{position:relative;display:block;width:100%;margin:auto} .l_header .m_search .icon,.l_header .m_search .input{transition:all .3s ease;-moz-transition:all .3s ease;-webkit-transition:all .3s ease;-o-transition:all .3s ease} .l_header .m_search .icon{position:absolute;display:block;line-height:40px;height:40px;width:32px;top:0;left:5px;font-size:16px;color:rgba(255,255,255,.6)} .l_header .m_search .input{display:block;font-size:16px;line-height:16px;height:40px;width:100%;color:rgba(255,255,255,.6);box-shadow:none;box-sizing:border-box;-webkit-appearance:none;padding-left:36px;border-radius:8px;background:rgba(255,255,255,.15);border:1px dashed transparent} @media (max-width:580px){.l_header .m_search .input{padding-left:36px} } .l_header .m_search .input::-webkit-input-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input:-moz-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input::-moz-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input:-ms-input-placeholder{padding-top:2px;color:rgba(255,255,255,.6)} .l_header .m_search .input:hover{color:#fff;border:1px solid rgba(255,255,255,.6)} .l_header .m_search .input:focus{color:#fff;border:1px solid #fff} /* .l_header .m_search .input:focus~.icon{color:#fff} */ .l_header.pure{background:#fff;box-shadow:0 1px 2px 0 rgba(0,0,0,.1),0 2px 4px 0 rgba(0,0,0,.1)} .l_header.pure,.l_header.pure a{color:#1bc3fb} .l_header.pure .menu ul>li>a{transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;color:rgba(85,85,85,.7)} .l_header.pure .menu ul>li>a.current{border-bottom:2px solid rgba(27,195,251,.8)} .l_header.pure .menu ul>li>a:hover{color:#1bc3fb;border-bottom:2px solid #1bc3fb;background:rgba(27,195,251,.1)} .l_header.pure .menu ul>li>a.active,.l_header.pure .menu ul>li>a:active{color:#1bc3fb;border-bottom:2px solid #1bc3fb} .l_header.pure .switcher>li a:hover{background:rgba(27,195,251,.15)} .l_header.pure .m_search .icon{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input{color:#555;background:#f4f4f4} .l_header.pure .m_search .input::-webkit-input-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input:-moz-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input::-moz-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input:-ms-input-placeholder{color:rgba(85,85,85,.6)} .l_header.pure .m_search .input:hover{border:1px solid rgba(27,195,251,.6)} .l_header.pure .m_search .input:hover~.icon{color:rgba(27,195,251,.8)} .l_header.pure .m_search .input:focus{color:#555;background:rgba(27,195,251,.15);border:1px solid #1bc3fb} .l_header.pure .m_search .input:focus~.icon{color:#1bc3fb} @media (max-width:580px){.l_header{padding:0} .l_header .m_search{width:0;overflow:hidden;position:absolute;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;margin:0 8px} .l_header.z_search-open .logo{opacity:0} .l_header.z_search-open .m_search{width:calc(100vw - 2*16px - 2*32px)} } .menu-phone{position:fixed;top:80px;right:0;z-index:10000;line-height:32px;background:#fff;border-right:0;box-shadow:0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1),0 8px 16px 0 rgba(0,0,0,.1),0 16px 32px 0 rgba(0,0,0,.1);border-radius:12px;transform:translate3d(-40px,-40px,0) scale(0,0);transform-origin:right top;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease} .menu-phone .header{border-top-left-radius:12px;border-top-right-radius:12px;background-color:rgba(27,195,251,.9);color:#fff;font-size:16px;line-height:1.8em;padding:8px 22px} .menu-phone:hover{box-shadow:0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1),0 8px 16px 0 rgba(0,0,0,.1),0 16px 32px 0 rgba(0,0,0,.1)} .menu-phone:active{box-shadow:0 1px 2px 0 rgba(0,0,0,.1),0 2px 4px 0 rgba(0,0,0,.1)} .menu-phone nav{padding:8px 0} .menu-phone nav .nav{height:36px;line-height:36px;position:relative;display:block;color:#444;padding:2px 20px;border-left:4px solid transparent;border-right:4px solid transparent} .menu-phone nav .nav.active,.menu-phone nav .nav:hover{border-left:4px solid #1bc3fb;background:rgba(27,195,251,.1)} .cover-wrapper .l_header{transition:all .5s ease;-moz-transition:all .5s ease;-webkit-transition:all .5s ease;-o-transition:all .5s ease;transform:translateY(-96px)} .cover-wrapper .l_header.show{transform:translateY(0)} .cover-wrapper{padding-bottom:2px} .cover-wrapper .cover{top:0;left:0;max-width:100%;height:calc(100vh);display:flex;flex-wrap:nowrap;flex-direction:column;align-items:center;align-self:center;align-content:center;padding:16px} .cover-wrapper .cover .logo,.cover-wrapper .cover .title{font-size:72px;line-height:79.2px;margin-top:calc(28vh - 2*16px);text-align:center;font-weight:700} .cover-wrapper .cover .logo{max-height:150px;max-width:calc(100% - 4*16px)} @media (max-width:580px){.cover-wrapper .cover .logo,.cover-wrapper .cover .title{font-size:48px;line-height:52.8px} } .cover-wrapper .cover .m_search{margin-top:calc(2vh + 2*16px);position:relative;max-width:calc(100% - 1*16px);width:313.5px;line-height:48px;vertical-align:middle} @media (max-width:1024px){.cover-wrapper .cover .m_search{width:288px} } .cover-wrapper .cover .m_search .form{position:relative;display:block;width:100%} .cover-wrapper .cover .m_search .icon,.cover-wrapper .cover .m_search .input{transition:all .3s ease;-moz-transition:all .3s ease;-webkit-transition:all .3s ease;-o-transition:all .3s ease} .cover-wrapper .cover .m_search .icon{position:absolute;display:block;line-height:44px;height:44px;width:32px;top:0;left:5px;font-size:16px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input{display:block;font-size:16px;line-height:16px;height:44px;width:100%;color:#555;box-shadow:none;box-sizing:border-box;-webkit-appearance:none;padding-left:36px;border-radius:64px;background:#fff;border:1px dashed transparent} @media (max-width:580px){.cover-wrapper .cover .m_search .input{padding-left:36px} } .cover-wrapper .cover .m_search .input::-webkit-input-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input:-moz-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input::-moz-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input:-ms-input-placeholder{padding-top:2px;color:rgba(85,85,85,.6)} .cover-wrapper .cover .m_search .input:hover~.icon{color:#1bc3fb} .cover-wrapper .cover .m_search .input:focus{border:1px solid #1bc3fb} .cover-wrapper .cover .m_search .input:focus~.icon{color:#1bc3fb} .cover-wrapper .cover.half{height:calc(60vh - 16px - 64px)} .cover-wrapper .cover.half .logo,.cover-wrapper .cover.half .title{margin-top:calc(20vh - 4*16px)} @media (max-width:580px){.cover-wrapper .cover.half .logo,.cover-wrapper .cover.half .title{margin-top:calc(32vh - 6*16px)} } .cover-wrapper .cover.half .m_search{margin-top:1vh} .cover-wrapper .cover,.cover-wrapper .cover a{color:#1bc3fb} .cover-wrapper .cover .menu{margin-top:4vh} .cover-wrapper .cover .menu ul{display:flex;flex-wrap:wrap;align-items:baseline;justify-content:center} .cover-wrapper .cover .menu ul li{display:flex;flex-wrap:wrap;align-items:center;padding:0;height:auto} .cover-wrapper .cover .menu ul>li>a{font-size:14px;padding:2px;margin:0 4px;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;color:rgba(85,85,85,.7);border-bottom:1px solid transparent} .cover-wrapper .cover .menu ul>li>a.active,.cover-wrapper .cover .menu ul>li>a:hover{color:#1bc3fb;border-bottom:1px solid #1bc3fb} .cover-wrapper .cover .switcher>li a:hover{background:rgba(27,195,251,.15)} ul.h-list{display:flex;align-items:center;height:100%} ul.h-list>li{height:100%;justify-content:center} #loading-bar-wrapper{position:fixed;top:62px;left:0;width:100%;z-index:99999} #loading-bar{position:fixed;width:0;height:2px;transition:all .25s ease;-moz-transition:all .25s ease;-webkit-transition:all .25s ease;-o-transition:all .25s ease;background-color:rgba(255,255,255,.5)} #loading-bar.pure{background-color:rgba(27,195,251,.5)} .container--flex{display:flex;flex-wrap:nowrap;justify-content:space-between;align-items:center} .backstretch{opacity:.75}"},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/css/sidebar.css","permalink":"https://rogerspy.gitee.io/video/css/sidebar.css","excerpt":"","text":"* { margin:0; padding:0; outline:0; } html {height: 100%;} .navbox { position: relative; float: left; } ul.nav { list-style: none; display: block; width: 250px; position: relative; top: 40px; left: 0px; padding: 0px 0 60px 0; background: url(images/shad2.png) no-repeat; -webkit-background-size: 50% 100%; } li { margin: 5px 0 0 0; } ul.nav li a { -webkit-transition: all 0.3s ease-out; font-size: 18px; font-family: KaiTi,Permanent Marker,cursive; font-weight: 200; color: #174867; padding: 7px 15px 7px 15px; -webkit-border-top-right-radius: 10px; -webkit-border-bottom-right-radius: 10px; -webkit-border-top-left-radius: 10px; -webkit-border-bottom-left-radius: 10px; width: 250px; display: block; text-decoration: none; -webkit-box-shadow: 2px 2px 4px #888; } ul.nav li a:hover { color: #F46E7C; padding: 7px 15px 7px 30px; } .scrollbar { margin-left: 15px; float: left; height: 610px; width: 300px; overflow-y: scroll; margin-bottom: 40px; margin-top: 40px; } .force-overflow { min-height: 450px; } #style-1::-webkit-scrollbar-track { -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,0.3); border-radius: 10px; background-color: #F5F5F5; } #style-1::-webkit-scrollbar { width: 0px; background-color: #F5F5F5; } #style-1::-webkit-scrollbar-thumb { border-radius: 0px; -webkit-box-shadow: inset 0 0 6px rgba(0,0,0,.3); background-color: #555; }"},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/css/style.css","permalink":"https://rogerspy.gitee.io/video/css/style.css","excerpt":"","text":"body{ background: #F4F4F4; overflow-x: hidden;} iframe, object, embed { width:735px; height:536px; border-radius:12px; border: none; margin-bottom: -8px; margin-left: 0px; } #box{ display: flex; align-items: center; } .container-x{ max-width: 1080px; margin: 40px auto 40px auto; background: #FFFFFF; border-radius: 12px; box-shadow: 0 1px 2px 0 rgba(0,0,0,.1), 0 2px 4px 0 rgba(0,0,0,.1); } .container-x:hover{ box-shadow: 0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1), 0 8px 16px 0 rgba(0,0,0,.1), 0 16px 32px 0 rgba(0,0,0,.1); } .video-section{padding:40px 0px} .video-section--light{background:#fffff; width:735px;} .container-video{max-width:735px; min-height: 556px; margin:0 0 0 0px; box-shadow: 0 1px 2px 0 rgba(0,0,0,.1), 0 2px 4px 0 rgba(0,0,0,.1); border-radius: 12px; } .container-video:hover{ box-shadow: 0 2px 4px 0 rgba(0,0,0,.1),0 4px 8px 0 rgba(0,0,0,.1), 0 8px 16px 0 rgba(0,0,0,.1), 0 16px 32px 0 rgba(0,0,0,.1); } .title-video{text-align:left; color:#555555; font-size:30px; padding:0 0 20px 0; margin-bottom:10px; margin-top:40px} .heading-video{font-family:\"Microsoft YaHei\",Permanent Marker,cursive; font-weight:400; margin:0;}"},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/fast.ai2019/bp.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/bp.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift 后向传播 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/fast.ai2019/data_clean.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/data_clean.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift 数据清洗与生成 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/fast.ai2019/data_api.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/data_api.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift 后向传播 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/fast.ai2019/foundation.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/foundation.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift 数据清洗与生成 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/fast.ai2019/index.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/index.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift 图像分类 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/fast.ai2019/look_into_model.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/look_into_model.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift NLP Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/fast.ai2019/multi_label.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/multi_label.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift 多标签分类 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/fast.ai2019/nlp.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/nlp.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift NLP Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/fast.ai2019/resnet.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/resnet.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift Resnet Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/fast.ai2019/swift.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/swift.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift 从基础开始深度学习 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.359Z","updated":"2021-09-15T15:36:17.359Z","comments":true,"path":"video/fast.ai2019/regularization.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/regularization.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift 正则化 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/fast.ai2019/swift_basic.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/swift_basic.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift Resnet Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/fast.ai2019/train_technique.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/train_technique.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift 正则化 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/fast.ai2019/train_model.html","permalink":"https://rogerspy.gitee.io/video/fast.ai2019/train_model.html","excerpt":"","text":"fast.ai-深度学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 图像分类 数据清洗与生成 多标签分类 NLP 后向传播 正则化 Resnet 从基础开始深度学习 如何训练你的模型 深入了解模型 数据块API 高级训练技巧 深度学习swift基础 swift 多标签分类 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/a3c.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/a3c.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 A3C Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/bm.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/bm.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 Batch Normalization Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/computional_graph_bp.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/computional_graph_bp.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 计算图和后向传播 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/capsule.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/capsule.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 Capsule Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/dl_structure2.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/dl_structure2.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 深度学习模型基本结构（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/dllm.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/dllm.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 深度学习语言模型 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/energy_gan.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/energy_gan.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 基于能量的GAN Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/ensembel_gan.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/ensembel_gan.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 GAN集成 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/evaluation.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/evaluation.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 生成模型评估 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/gan.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/gan.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 GAN Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/highway.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/highway.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 High-way Network & Grid LSTM Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/imitation_learning.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/imitation_learning.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 模仿学习 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/gated_rnn.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/gated_rnn.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 门RNN和序列生成 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/index.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/index.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 深度学习模型基本结构（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/imporved_gan.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/imporved_gan.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 Improved GAN Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/hyperparameter.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/hyperparameter.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 超参数微调 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/interesting.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/interesting.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 深度学习中一些有趣的事 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/ml_beauty.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/ml_beauty.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 机器学习美少女 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/pointer_network.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/pointer_network.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 指针网络 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/rl_gan_generateion.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/rl_gan_generateion.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 RL和GAN用于句子生成和对话系统 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/rnn.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/rnn.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 Recursive Network Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/rnn_generation.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/rnn_generation.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 RNN和Attention条件生成 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leela2018/bias.html","permalink":"https://rogerspy.gitee.io/video/leela2018/bias.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 偏置 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/transformer.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/transformer.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 Transformer Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/selu.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/selu.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 SELU Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leela2018/how_many_solutions.html","permalink":"https://rogerspy.gitee.io/video/leela2018/how_many_solutions.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 有多少解？ Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leedl2017/video_gan.html","permalink":"https://rogerspy.gitee.io/video/leedl2017/video_gan.html","excerpt":"","text":"李宏毅-深度学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 深度学习模型基本结构（1） 深度学习模型基本结构（2） 计算图和后向传播 深度学习语言模型 Transformer High-way Network & Grid LSTM Recursive Network RNN和Attention条件生成 指针网络 Batch Normalization SELU Capsule 超参数微调 深度学习中一些有趣的事 GAN Improved GAN RL和GAN用于句子生成和对话系统 机器学习美少女 模仿学习 生成模型评估 GAN集成 基于能量的GAN GAN生成视频 A3C 门RNN和序列生成 GAN生成视频 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leela2018/column.html","permalink":"https://rogerspy.gitee.io/video/leela2018/column.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 列空间 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leela2018/index.html","permalink":"https://rogerspy.gitee.io/video/leela2018/index.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 课程介绍 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leela2018/inverse_matrix.html","permalink":"https://rogerspy.gitee.io/video/leela2018/inverse_matrix.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 逆矩阵 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.374Z","updated":"2021-09-15T15:36:17.374Z","comments":true,"path":"video/leela2018/invert_matrix.html","permalink":"https://rogerspy.gitee.io/video/leela2018/invert_matrix.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 如何找到逆矩阵 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/invertible.html","permalink":"https://rogerspy.gitee.io/video/leela2018/invertible.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 可逆性 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/matrix.html","permalink":"https://rogerspy.gitee.io/video/leela2018/matrix.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 矩阵 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/rref1.html","permalink":"https://rogerspy.gitee.io/video/leela2018/rref1.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 我们能从RREF中知道什么？（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/matrix_product.html","permalink":"https://rogerspy.gitee.io/video/leela2018/matrix_product.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 矩阵乘法 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/product.html","permalink":"https://rogerspy.gitee.io/video/leela2018/product.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 矩阵-向量乘法 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/rref2.html","permalink":"https://rogerspy.gitee.io/video/leela2018/rref2.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 我们能从RREF中知道什么？（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/rref3.html","permalink":"https://rogerspy.gitee.io/video/leela2018/rref3.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 我们能从RREF中知道什么？（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/rref4.html","permalink":"https://rogerspy.gitee.io/video/leela2018/rref4.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 我们能从RREF中知道什么？（4） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/solution.html","permalink":"https://rogerspy.gitee.io/video/leela2018/solution.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 有解吗？ Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/solving_la2.html","permalink":"https://rogerspy.gitee.io/video/leela2018/solving_la2.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 线性方程求解系统（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/subspace.html","permalink":"https://rogerspy.gitee.io/video/leela2018/subspace.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 子空间 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/solving_la1.html","permalink":"https://rogerspy.gitee.io/video/leela2018/solving_la1.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 线性方程求解系统（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/vector.html","permalink":"https://rogerspy.gitee.io/video/leela2018/vector.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 向量 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leela2018/system_la.html","permalink":"https://rogerspy.gitee.io/video/leela2018/system_la.html","excerpt":"","text":"李宏毅-线性代数2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 线性方程系统 向量 矩阵 矩阵-向量乘法 有解吗？ 有多少解？ 线性方程求解系统（1） 线性方程求解系统（2） 我们能从RREF中知道什么？（1） 我们能从RREF中知道什么？（2） 我们能从RREF中知道什么？（3） 我们能从RREF中知道什么？（4） 矩阵乘法 逆矩阵 可逆性 如何找到逆矩阵 子空间 偏置 列空间 线性方程系统 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/RNN_II.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/RNN_II.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 循环神经网络（II） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/RNN_I.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/RNN_I.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 循环神经网络（I） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/classification.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/classification.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 分类 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/deep_learning_brief_introduction.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/deep_learning_brief_introduction.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 深度学习简介 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/cnn.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/cnn.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 卷积神经网络 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/drl.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/drl.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 深度强化学习 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/ensemble.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/ensemble.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 集成学习 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/index.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/index.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 课程介绍 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/next_step.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/next_step.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 机器学习的下一步 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/gradient_descent.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/gradient_descent.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 梯度下降 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/regression_case_study.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/regression_case_study.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 回归—案例研究 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/logistic_regression.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/logistic_regression.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 逻辑回归 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/regression_demo.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/regression_demo.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 回归—Demo Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/semisupervise_learning.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/semisupervise_learning.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 半监督学习 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/structure_learning_introduction.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/structure_learning_introduction.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 结构学习—简介 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/structure_learning_lm.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/structure_learning_lm.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 结构学习—线性模型 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/structure_learning_sl.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/structure_learning_sl.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 结构学习—序列标注 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/svm.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/svm.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 支持向量机 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/transfer_learning.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/transfer_learning.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 迁移学习 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/structure_learning_svm.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/structure_learning_svm.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 结构学习—结构化支持向量机 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/tips_of_training_dnn.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/tips_of_training_dnn.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 训练DNN的小技巧 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/unsupervise_learning_ae.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/unsupervise_learning_ae.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 无监督学习—自编码器 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.390Z","updated":"2021-09-15T15:36:17.390Z","comments":true,"path":"video/leeml2017/unsupervise_learning_dgi.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/unsupervise_learning_dgi.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 无监督学习—深度生成模型（I） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2017/unsupervise_learning_dgii.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/unsupervise_learning_dgii.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 无监督学习—深度生成模型（II） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2017/unsupervise_learning_linear_method.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/unsupervise_learning_linear_method.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 无监督学习—线性方法 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2017/unsupervise_learning_neighbored_method.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/unsupervise_learning_neighbored_method.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 无监督学习—Neighbor Embedding Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2017/unsupervise_learning_we.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/unsupervise_learning_we.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 无监督学习—Word Embedding Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2017/where_is_error_from.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/where_is_error_from.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 误差从哪里来？ Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2017/why_deep.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/why_deep.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 为什么需要深度？ Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2017/why_we_need_ml.html","permalink":"https://rogerspy.gitee.io/video/leeml2017/why_we_need_ml.html","excerpt":"","text":"李宏毅-机器学习2017 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 课程介绍 我们为什么需要机器学习？ 回归—案例研究 回归—Demo 误差从哪里来？ 梯度下降 分类 逻辑回归 深度学习简介 后向传播 训练DNN的小技巧 卷积神经网络 为什么需要深度？ 半监督学习 无监督学习—线性方法 无监督学习—Word Embedding 无监督学习—Neighbor Embedding 无监督学习—自编码器 无监督学习—深度生成模型（I） 无监督学习—深度生成模型（II） 迁移学习 支持向量机 结构学习—简介 结构学习—线性模型 结构学习—结构化支持向量机 结构学习—序列标注 循环神经网络（I） 循环神经网络（II） 集成学习 深度强化学习 机器学习的下一步 我们为什么需要机器学习？ Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leemlds2018/actor_critic.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/actor_critic.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning DRL-Actor-critic Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leemlds2018/bn.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/bn.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning Batch Normalization Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leemlds2018/attention_based.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/attention_based.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 基于注意力的模型 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leemlds2018/computional_graph.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/computional_graph.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 计算图 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/deep_linear.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/deep_linear.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 深度线性网络 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leemlds2018/cond_gen.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/cond_gen.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning GAN—条件生成 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/evaluation.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/evaluation.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning GAN-评估 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/gd_is_zero.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/gd_is_zero.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 当梯度为零时 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/general_framework.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/general_framework.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning GAN-通用框架 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/generalization.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/generalization.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 深度学习泛化能力 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/geometry_lossii.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/geometry_lossii.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 损失表面几何（经验） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/geometry_lossi.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/geometry_lossi.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 损失表面几何（猜想） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/imitation_learn.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/imitation_learn.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning DRL-Imitation Learning Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/indicator.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/indicator.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 泛化能力指示器 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/index.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/index.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 为什么需要深层结构？ Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/intro.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/intro.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning GAN-简介 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/infogan.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/infogan.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning GAN-InfoGAN, VAE-GAN, BiGAN Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/is_deep_better.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/is_deep_better.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 深层结构比浅层的好吗？ Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/l2l.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/l2l.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning learing2learn Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/local_min.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/local_min.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 深层网络有局部最小化吗？ Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/photo_editiing.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/photo_editiing.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning GAN-照片编辑 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/pointer_network.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/pointer_network.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 指针网络 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/potential_deep.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/potential_deep.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 深层结构的潜力 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/qlearning.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/qlearning.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning DRL-Q-Learning Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/ppo.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/ppo.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning DRL-Proximal Policy Optimization (PPO) Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/resursive_network.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/resursive_network.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 递归网络 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/seq2seq.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/seq2seq.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning 序列到序列学习 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/seq_gen.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/seq_gen.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning GAN-序列生成 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/sparse_reward.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/sparse_reward.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning DRL-Sparse Reward Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/unsupervise_cond_gen.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/unsupervise_cond_gen.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning GAN-无监督条件生成 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/theory.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/theory.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning GAN-基础理论 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/ae1.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/ae1.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 自编码器（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/ae2.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/ae2.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 自编码器（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.437Z","updated":"2021-09-15T15:36:17.437Z","comments":true,"path":"video/leemlds2018/wgan.html","permalink":"https://rogerspy.gitee.io/video/leemlds2018/wgan.html","excerpt":"","text":"李宏毅-机器学习及其深层与结构化2018 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 为什么需要深层网络？ 深层结构的潜力 深层结构比浅层的好吗？ 当梯度为零时 深度线性网络 深层网络有局部最小化吗？ 损失表面几何（猜想） 损失表面几何（经验） 深度学习泛化能力 泛化能力指示器 计算图 序列到序列学习 指针网络 递归网络 基于注意力的模型 Batch Normalization learing2learn GAN-简介 GAN—条件生成 GAN-无监督条件生成 GAN-基础理论 GAN-通用框架 GAN-WGAN, EBGAN GAN-InfoGAN, VAE-GAN, BiGAN GAN-照片编辑 GAN-序列生成 GAN-评估 DRL-Proximal Policy Optimization (PPO) DRL-Q-Learning DRL-Actor-critic DRL-Sparse Reward DRL-Imitation Learning GAN-WGAN, EBGAN Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/ae3.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/ae3.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 自编码器（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/ae4.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/ae4.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 自编码器（4） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/anomaly2.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/anomaly2.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 异常检测（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/anomaly1.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/anomaly1.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 异常检测（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/anomaly3.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/anomaly3.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 异常检测（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/anomaly4.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/anomaly4.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 异常检测（4） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/anomaly5.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/anomaly5.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 异常检测（5） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/anomaly6.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/anomaly6.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 异常检测（6） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/anomaly7.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/anomaly7.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 异常检测（7） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/attack1.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/attack1.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 机器学习攻击与防御（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/attack4.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/attack4.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 机器学习攻击与防御（4） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/attack2.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/attack2.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 机器学习攻击与防御（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/attack5.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/attack5.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 机器学习攻击与防御（5） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/attack3.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/attack3.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 机器学习攻击与防御（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/attack8.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/attack8.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 机器学习攻击与防御（8） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/attack6.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/attack6.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 机器学习攻击与防御（6） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/bert.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/bert.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT Elomo, Bert, GPT Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/explainable1.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/explainable1.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 可解释机器学习（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/explainable3.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/explainable3.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 可解释机器学习（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/attack7.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/attack7.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 机器学习攻击与防御（7） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/explainable2.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/explainable2.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 可解释机器学习（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/explainable4.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/explainable4.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 可解释机器学习（4） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/explainable5.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/explainable5.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 可解释机器学习（5） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/explainable6.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/explainable6.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 可解释机器学习（6） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/explainable7.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/explainable7.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 可解释机器学习（7） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/explainable8.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/explainable8.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 可解释机器学习（8） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/life_long2.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/life_long2.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 终生学习（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/fbgm.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/fbgm.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT Flow-based GM Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/index.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/index.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 机器学习的下一步 Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/life_long3.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/life_long3.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 终生学习（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/life_long1.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/life_long1.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 终生学习（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.405Z","updated":"2021-09-15T15:36:17.405Z","comments":true,"path":"video/leeml2019/gan.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/gan.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT GAN Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/life_long4.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/life_long4.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 终生学习（4） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/life_long5.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/life_long5.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 终生学习（5） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/life_long6.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/life_long6.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 终生学习（6） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/life_long7.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/life_long7.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 终生学习（7） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning11.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning11.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习-LSTM（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning1.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning1.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning10.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning10.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习-LSTM（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning13.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning13.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习-Metric-based（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning12.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning12.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习-LSTM（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning14.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning14.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习-Metric-based（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning15.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning15.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习-Metric-based（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning3.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning3.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning16.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning16.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习-RNN Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning2.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning2.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning5.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning5.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习（5） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning6.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning6.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习（6） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning7.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning7.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习（7） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning4.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning4.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习（4） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning9.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning9.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习（9） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/meta_learning8.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/meta_learning8.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 元学习（8） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/network_compress2.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/network_compress2.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 模型压缩（2） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/network_compress1.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/network_compress1.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 模型压缩（1） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/network_compress4.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/network_compress4.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 模型压缩（4） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/network_compress3.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/network_compress3.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 模型压缩（3） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/network_compress5.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/network_compress5.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 模型压缩（5） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/network_compress6.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/network_compress6.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT 模型压缩（6） Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.421Z","updated":"2021-09-15T15:36:17.421Z","comments":true,"path":"video/leeml2019/transformer.html","permalink":"https://rogerspy.gitee.io/video/leeml2019/transformer.html","excerpt":"","text":"李宏毅-机器学习2019 Rogerspy's Home &nbsp;博文 &nbsp;视频 &nbsp;资料 &nbsp;关于 Rogerspy's Home &nbsp;博客 &nbsp;视频小站 &nbsp;学习资料 &nbsp;随心记 &nbsp;分类 &nbsp;标签 &nbsp;归档 机器学习的下一步 异常检测（1） 异常检测（2） 异常检测（3） 异常检测（4） 异常检测（5） 异常检测（6） 异常检测（7） 机器学习攻击与防御（1） 机器学习攻击与防御（2） 机器学习攻击与防御（3） 机器学习攻击与防御（4） 机器学习攻击与防御（5） 机器学习攻击与防御（6） 机器学习攻击与防御（7） 机器学习攻击与防御（8） 可解释机器学习（1） 可解释机器学习（2） 可解释机器学习（3） 可解释机器学习（4） 可解释机器学习（5） 可解释机器学习（6） 可解释机器学习（7） 可解释机器学习（8） 终生学习（1） 终生学习（2） 终生学习（3） 终生学习（4） 终生学习（5） 终生学习（6） 终生学习（7） 元学习（1） 元学习（2） 元学习（3） 元学习（4） 元学习（5） 元学习（6） 元学习（7） 元学习（8） 元学习（9） 元学习-LSTM（1） 元学习-LSTM（2） 元学习-LSTM（3） 元学习-Metric-based（1） 元学习-Metric-based（2） 元学习-Metric-based（3） 元学习-RNN 自编码器（1） 自编码器（2） 自编码器（3） 自编码器（4） 模型压缩（1） 模型压缩（2） 模型压缩（3） 模型压缩（4） 模型压缩（5） 模型压缩（6） GAN Flow-based GM Transformer Elomo, Bert, GPT Transformer Blog content follows the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License Use Material X as theme, total visits times."},{"title":"","date":"2021-09-15T15:36:17.327Z","updated":"2021-09-15T15:36:17.327Z","comments":true,"path":"material/css/bootstrap.css","permalink":"https://rogerspy.gitee.io/material/css/bootstrap.css","excerpt":"","text":".container { margin-right: auto; margin-left: auto; padding-left: 15px; padding-right: 15px; } @media (min-width: 768px) { .container { width: 750px; } } @media (min-width: 992px) { .container { width: 970px; } } @media (min-width: 1200px) { .container { width: 1170px; } } .container-fluid { margin-right: auto; margin-left: auto; padding-left: 15px; padding-right: 15px; } .row { margin-left: -15px; margin-right: -15px; } .col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 { position: relative; min-height: 1px; padding-left: 15px; padding-right: 15px; } .col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 { float: left; } .col-xs-12 { width: 100%; } .col-xs-11 { width: 91.66666667%; } .col-xs-10 { width: 83.33333333%; } .col-xs-9 { width: 75%; } .col-xs-8 { width: 66.66666667%; } .col-xs-7 { width: 58.33333333%; } .col-xs-6 { width: 50%; } .col-xs-5 { width: 41.66666667%; } .col-xs-4 { width: 33.33333333%; } .col-xs-3 { width: 25%; } .col-xs-2 { width: 16.66666667%; } .col-xs-1 { width: 8.33333333%; } .col-xs-pull-12 { right: 100%; } .col-xs-pull-11 { right: 91.66666667%; } .col-xs-pull-10 { right: 83.33333333%; } .col-xs-pull-9 { right: 75%; } .col-xs-pull-8 { right: 66.66666667%; } .col-xs-pull-7 { right: 58.33333333%; } .col-xs-pull-6 { right: 50%; } .col-xs-pull-5 { right: 41.66666667%; } .col-xs-pull-4 { right: 33.33333333%; } .col-xs-pull-3 { right: 25%; } .col-xs-pull-2 { right: 16.66666667%; } .col-xs-pull-1 { right: 8.33333333%; } .col-xs-pull-0 { right: auto; } .col-xs-push-12 { left: 100%; } .col-xs-push-11 { left: 91.66666667%; } .col-xs-push-10 { left: 83.33333333%; } .col-xs-push-9 { left: 75%; } .col-xs-push-8 { left: 66.66666667%; } .col-xs-push-7 { left: 58.33333333%; } .col-xs-push-6 { left: 50%; } .col-xs-push-5 { left: 41.66666667%; } .col-xs-push-4 { left: 33.33333333%; } .col-xs-push-3 { left: 25%; } .col-xs-push-2 { left: 16.66666667%; } .col-xs-push-1 { left: 8.33333333%; } .col-xs-push-0 { left: auto; } .col-xs-offset-12 { margin-left: 100%; } .col-xs-offset-11 { margin-left: 91.66666667%; } .col-xs-offset-10 { margin-left: 83.33333333%; } .col-xs-offset-9 { margin-left: 75%; } .col-xs-offset-8 { margin-left: 66.66666667%; } .col-xs-offset-7 { margin-left: 58.33333333%; } .col-xs-offset-6 { margin-left: 50%; } .col-xs-offset-5 { margin-left: 41.66666667%; } .col-xs-offset-4 { margin-left: 33.33333333%; } .col-xs-offset-3 { margin-left: 25%; } .col-xs-offset-2 { margin-left: 16.66666667%; } .col-xs-offset-1 { margin-left: 8.33333333%; } .col-xs-offset-0 { margin-left: 0%; } @media (min-width: 768px) { .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 { float: left; } .col-sm-12 { width: 100%; } .col-sm-11 { width: 91.66666667%; } .col-sm-10 { width: 83.33333333%; } .col-sm-9 { width: 75%; } .col-sm-8 { width: 66.66666667%; } .col-sm-7 { width: 58.33333333%; } .col-sm-6 { width: 50%; } .col-sm-5 { width: 41.66666667%; } .col-sm-4 { width: 33.33333333%; } .col-sm-3 { width: 25%; } .col-sm-2 { width: 16.66666667%; } .col-sm-1 { width: 8.33333333%; } .col-sm-pull-12 { right: 100%; } .col-sm-pull-11 { right: 91.66666667%; } .col-sm-pull-10 { right: 83.33333333%; } .col-sm-pull-9 { right: 75%; } .col-sm-pull-8 { right: 66.66666667%; } .col-sm-pull-7 { right: 58.33333333%; } .col-sm-pull-6 { right: 50%; } .col-sm-pull-5 { right: 41.66666667%; } .col-sm-pull-4 { right: 33.33333333%; } .col-sm-pull-3 { right: 25%; } .col-sm-pull-2 { right: 16.66666667%; } .col-sm-pull-1 { right: 8.33333333%; } .col-sm-pull-0 { right: auto; } .col-sm-push-12 { left: 100%; } .col-sm-push-11 { left: 91.66666667%; } .col-sm-push-10 { left: 83.33333333%; } .col-sm-push-9 { left: 75%; } .col-sm-push-8 { left: 66.66666667%; } .col-sm-push-7 { left: 58.33333333%; } .col-sm-push-6 { left: 50%; } .col-sm-push-5 { left: 41.66666667%; } .col-sm-push-4 { left: 33.33333333%; } .col-sm-push-3 { left: 25%; } .col-sm-push-2 { left: 16.66666667%; } .col-sm-push-1 { left: 8.33333333%; } .col-sm-push-0 { left: auto; } .col-sm-offset-12 { margin-left: 100%; } .col-sm-offset-11 { margin-left: 91.66666667%; } .col-sm-offset-10 { margin-left: 83.33333333%; } .col-sm-offset-9 { margin-left: 75%; } .col-sm-offset-8 { margin-left: 66.66666667%; } .col-sm-offset-7 { margin-left: 58.33333333%; } .col-sm-offset-6 { margin-left: 50%; } .col-sm-offset-5 { margin-left: 41.66666667%; } .col-sm-offset-4 { margin-left: 33.33333333%; } .col-sm-offset-3 { margin-left: 25%; } .col-sm-offset-2 { margin-left: 16.66666667%; } .col-sm-offset-1 { margin-left: 8.33333333%; } .col-sm-offset-0 { margin-left: 0%; } } @media (min-width: 992px) { .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 { float: left; } .col-md-12 { width: 100%; } .col-md-11 { width: 91.66666667%; } .col-md-10 { width: 83.33333333%; } .col-md-9 { width: 75%; } .col-md-8 { width: 66.66666667%; } .col-md-7 { width: 58.33333333%; } .col-md-6 { width: 60%; } .col-md-5 { width: 41.66666667%; } .col-md-4 { width: 33.33333333%; } .col-md-3 { width: 25%; } .col-md-2 { width: 16.66666667%; } .col-md-1 { width: 8.33333333%; } .col-md-pull-12 { right: 100%; } .col-md-pull-11 { right: 91.66666667%; } .col-md-pull-10 { right: 83.33333333%; } .col-md-pull-9 { right: 75%; } .col-md-pull-8 { right: 66.66666667%; } .col-md-pull-7 { right: 58.33333333%; } .col-md-pull-6 { right: 50%; } .col-md-pull-5 { right: 41.66666667%; } .col-md-pull-4 { right: 33.33333333%; } .col-md-pull-3 { right: 25%; } .col-md-pull-2 { right: 16.66666667%; } .col-md-pull-1 { right: 8.33333333%; } .col-md-pull-0 { right: auto; } .col-md-push-12 { left: 100%; } .col-md-push-11 { left: 91.66666667%; } .col-md-push-10 { left: 83.33333333%; } .col-md-push-9 { left: 75%; } .col-md-push-8 { left: 66.66666667%; } .col-md-push-7 { left: 58.33333333%; } .col-md-push-6 { left: 50%; } .col-md-push-5 { left: 41.66666667%; } .col-md-push-4 { left: 33.33333333%; } .col-md-push-3 { left: 25%; } .col-md-push-2 { left: 16.66666667%; } .col-md-push-1 { left: 8.33333333%; } .col-md-push-0 { left: auto; } .col-md-offset-12 { margin-left: 100%; } .col-md-offset-11 { margin-left: 91.66666667%; } .col-md-offset-10 { margin-left: 83.33333333%; } .col-md-offset-9 { margin-left: 75%; } .col-md-offset-8 { margin-left: 66.66666667%; } .col-md-offset-7 { margin-left: 58.33333333%; } .col-md-offset-6 { margin-left: 50%; } .col-md-offset-5 { margin-left: 41.66666667%; } .col-md-offset-4 { margin-left: 33.33333333%; } .col-md-offset-3 { margin-left: 20%; } .col-md-offset-2 { margin-left: 16.66666667%; } .col-md-offset-1 { margin-left: 8.33333333%; } .col-md-offset-0 { margin-left: 0%; } } @media (min-width: 1200px) { .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 { float: left; } .col-lg-12 { width: 100%; } .col-lg-11 { width: 91.66666667%; } .col-lg-10 { width: 83.33333333%; } .col-lg-9 { width: 75%; } .col-lg-8 { width: 66.66666667%; } .col-lg-7 { width: 58.33333333%; } .col-lg-6 { width: 50%; } .col-lg-5 { width: 41.66666667%; } .col-lg-4 { width: 33.33333333%; } .col-lg-3 { width: 25%; } .col-lg-2 { width: 16.66666667%; } .col-lg-1 { width: 8.33333333%; } .col-lg-pull-12 { right: 100%; } .col-lg-pull-11 { right: 91.66666667%; } .col-lg-pull-10 { right: 83.33333333%; } .col-lg-pull-9 { right: 75%; } .col-lg-pull-8 { right: 66.66666667%; } .col-lg-pull-7 { right: 58.33333333%; } .col-lg-pull-6 { right: 50%; } .col-lg-pull-5 { right: 41.66666667%; } .col-lg-pull-4 { right: 33.33333333%; } .col-lg-pull-3 { right: 25%; } .col-lg-pull-2 { right: 16.66666667%; } .col-lg-pull-1 { right: 8.33333333%; } .col-lg-pull-0 { right: auto; } .col-lg-push-12 { left: 100%; } .col-lg-push-11 { left: 91.66666667%; } .col-lg-push-10 { left: 83.33333333%; } .col-lg-push-9 { left: 75%; } .col-lg-push-8 { left: 66.66666667%; } .col-lg-push-7 { left: 58.33333333%; } .col-lg-push-6 { left: 50%; } .col-lg-push-5 { left: 41.66666667%; } .col-lg-push-4 { left: 33.33333333%; } .col-lg-push-3 { left: 25%; } .col-lg-push-2 { left: 16.66666667%; } .col-lg-push-1 { left: 8.33333333%; } .col-lg-push-0 { left: auto; } .col-lg-offset-12 { margin-left: 100%; } .col-lg-offset-11 { margin-left: 91.66666667%; } .col-lg-offset-10 { margin-left: 83.33333333%; } .col-lg-offset-9 { margin-left: 75%; } .col-lg-offset-8 { margin-left: 66.66666667%; } .col-lg-offset-7 { margin-left: 58.33333333%; } .col-lg-offset-6 { margin-left: 50%; } .col-lg-offset-5 { margin-left: 41.66666667%; } .col-lg-offset-4 { margin-left: 33.33333333%; } .col-lg-offset-3 { margin-left: 25%; } .col-lg-offset-2 { margin-left: 16.66666667%; } .col-lg-offset-1 { margin-left: 8.33333333%; } .col-lg-offset-0 { margin-left: 0%; } } table { background-color: transparent; } caption { padding-top: 8px; padding-bottom: 8px; color: #777777; text-align: left; } th { text-align: left; } .table { width: 100%; max-width: 100%; margin-bottom: 20px; } .table > thead > tr > th, .table > tbody > tr > th, .table > tfoot > tr > th, .table > thead > tr > td, .table > tbody > tr > td, .table > tfoot > tr > td { padding: 8px; line-height: 1.42857143; vertical-align: top; border-top: 1px solid #ddd; } .table > thead > tr > th { vertical-align: bottom; border-bottom: 2px solid #ddd; } .table > caption + thead > tr:first-child > th, .table > colgroup + thead > tr:first-child > th, .table > thead:first-child > tr:first-child > th, .table > caption + thead > tr:first-child > td, .table > colgroup + thead > tr:first-child > td, .table > thead:first-child > tr:first-child > td { border-top: 0; } .table > tbody + tbody { border-top: 2px solid #ddd; } .table .table { background-color: #fff; } .table-condensed > thead > tr > th, .table-condensed > tbody > tr > th, .table-condensed > tfoot > tr > th, .table-condensed > thead > tr > td, .table-condensed > tbody > tr > td, .table-condensed > tfoot > tr > td { padding: 5px; } .table-bordered { border: 1px solid #ddd; } .table-bordered > thead > tr > th, .table-bordered > tbody > tr > th, .table-bordered > tfoot > tr > th, .table-bordered > thead > tr > td, .table-bordered > tbody > tr > td, .table-bordered > tfoot > tr > td { border: 1px solid #ddd; } .table-bordered > thead > tr > th, .table-bordered > thead > tr > td { border-bottom-width: 2px; } .table-striped > tbody > tr:nth-of-type(odd) { background-color: #f9f9f9; } .table-hover > tbody > tr:hover { background-color: #f5f5f5; } table col[class*=\"col-\"] { position: static; float: none; display: table-column; } table td[class*=\"col-\"], table th[class*=\"col-\"] { position: static; float: none; display: table-cell; } .table > thead > tr > td.active, .table > tbody > tr > td.active, .table > tfoot > tr > td.active, .table > thead > tr > th.active, .table > tbody > tr > th.active, .table > tfoot > tr > th.active, .table > thead > tr.active > td, .table > tbody > tr.active > td, .table > tfoot > tr.active > td, .table > thead > tr.active > th, .table > tbody > tr.active > th, .table > tfoot > tr.active > th { background-color: #f5f5f5; } .table-hover > tbody > tr > td.active:hover, .table-hover > tbody > tr > th.active:hover, .table-hover > tbody > tr.active:hover > td, .table-hover > tbody > tr:hover > .active, .table-hover > tbody > tr.active:hover > th { background-color: #e8e8e8; } .table > thead > tr > td.success, .table > tbody > tr > td.success, .table > tfoot > tr > td.success, .table > thead > tr > th.success, .table > tbody > tr > th.success, .table > tfoot > tr > th.success, .table > thead > tr.success > td, .table > tbody > tr.success > td, .table > tfoot > tr.success > td, .table > thead > tr.success > th, .table > tbody > tr.success > th, .table > tfoot > tr.success > th { background-color: #dff0d8; } .table-hover > tbody > tr > td.success:hover, .table-hover > tbody > tr > th.success:hover, .table-hover > tbody > tr.success:hover > td, .table-hover > tbody > tr:hover > .success, .table-hover > tbody > tr.success:hover > th { background-color: #d0e9c6; } .table > thead > tr > td.info, .table > tbody > tr > td.info, .table > tfoot > tr > td.info, .table > thead > tr > th.info, .table > tbody > tr > th.info, .table > tfoot > tr > th.info, .table > thead > tr.info > td, .table > tbody > tr.info > td, .table > tfoot > tr.info > td, .table > thead > tr.info > th, .table > tbody > tr.info > th, .table > tfoot > tr.info > th { background-color: #d9edf7; } .table-hover > tbody > tr > td.info:hover, .table-hover > tbody > tr > th.info:hover, .table-hover > tbody > tr.info:hover > td, .table-hover > tbody > tr:hover > .info, .table-hover > tbody > tr.info:hover > th { background-color: #c4e3f3; } .table > thead > tr > td.warning, .table > tbody > tr > td.warning, .table > tfoot > tr > td.warning, .table > thead > tr > th.warning, .table > tbody > tr > th.warning, .table > tfoot > tr > th.warning, .table > thead > tr.warning > td, .table > tbody > tr.warning > td, .table > tfoot > tr.warning > td, .table > thead > tr.warning > th, .table > tbody > tr.warning > th, .table > tfoot > tr.warning > th { background-color: #fcf8e3; } .table-hover > tbody > tr > td.warning:hover, .table-hover > tbody > tr > th.warning:hover, .table-hover > tbody > tr.warning:hover > td, .table-hover > tbody > tr:hover > .warning, .table-hover > tbody > tr.warning:hover > th { background-color: #faf2cc; } .table > thead > tr > td.danger, .table > tbody > tr > td.danger, .table > tfoot > tr > td.danger, .table > thead > tr > th.danger, .table > tbody > tr > th.danger, .table > tfoot > tr > th.danger, .table > thead > tr.danger > td, .table > tbody > tr.danger > td, .table > tfoot > tr.danger > td, .table > thead > tr.danger > th, .table > tbody > tr.danger > th, .table > tfoot > tr.danger > th { background-color: #f2dede; } .table-hover > tbody > tr > td.danger:hover, .table-hover > tbody > tr > th.danger:hover, .table-hover > tbody > tr.danger:hover > td, .table-hover > tbody > tr:hover > .danger, .table-hover > tbody > tr.danger:hover > th { background-color: #ebcccc; } .table-responsive { overflow-x: auto; min-height: 0.01%; } @media screen and (max-width: 767px) { .table-responsive { width: 100%; margin-bottom: 15px; overflow-y: hidden; -ms-overflow-style: -ms-autohiding-scrollbar; border: 1px solid #ddd; } .table-responsive > .table { margin-bottom: 0; } .table-responsive > .table > thead > tr > th, .table-responsive > .table > tbody > tr > th, .table-responsive > .table > tfoot > tr > th, .table-responsive > .table > thead > tr > td, .table-responsive > .table > tbody > tr > td, .table-responsive > .table > tfoot > tr > td { white-space: nowrap; } .table-responsive > .table-bordered { border: 0; } .table-responsive > .table-bordered > thead > tr > th:first-child, .table-responsive > .table-bordered > tbody > tr > th:first-child, .table-responsive > .table-bordered > tfoot > tr > th:first-child, .table-responsive > .table-bordered > thead > tr > td:first-child, .table-responsive > .table-bordered > tbody > tr > td:first-child, .table-responsive > .table-bordered > tfoot > tr > td:first-child { border-left: 0; } .table-responsive > .table-bordered > thead > tr > th:last-child, .table-responsive > .table-bordered > tbody > tr > th:last-child, .table-responsive > .table-bordered > tfoot > tr > th:last-child, .table-responsive > .table-bordered > thead > tr > td:last-child, .table-responsive > .table-bordered > tbody > tr > td:last-child, .table-responsive > .table-bordered > tfoot > tr > td:last-child { border-right: 0; } .table-responsive > .table-bordered > tbody > tr:last-child > th, .table-responsive > .table-bordered > tfoot > tr:last-child > th, .table-responsive > .table-bordered > tbody > tr:last-child > td, .table-responsive > .table-bordered > tfoot > tr:last-child > td { border-bottom: 0; } } fieldset { padding: 0; margin: 0; border: 0; min-width: 0; } legend { display: block; width: 100%; padding: 0; margin-bottom: 20px; font-size: 21px; line-height: inherit; color: #333333; border: 0; border-bottom: 1px solid #e5e5e5; } label { display: inline-block; max-width: 100%; margin-bottom: 5px; font-weight: bold; } input[type=\"search\"] { box-sizing: border-box; } input[type=\"radio\"], input[type=\"checkbox\"] { margin: 4px 0 0; margin-top: 1px \\9; line-height: normal; } input[type=\"file\"] { display: block; } input[type=\"range\"] { display: block; width: 100%; } select[multiple], select[size] { height: auto; } input[type=\"file\"]:focus, input[type=\"radio\"]:focus, input[type=\"checkbox\"]:focus { outline: 5px auto -webkit-focus-ring-color; outline-offset: -2px; } output { display: block; padding-top: 7px; font-size: 14px; line-height: 1.42857143; color: #555555; } .form-control { display: block; width: 100%; height: 34px; padding: 6px 12px; font-size: 14px; line-height: 1.42857143; color: #555555; background-color: #fff; background-image: none; border: 1px solid #ccc; border-radius: 4px; box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075); transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s; } .form-control:focus { border-color: #66afe9; outline: 0; box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6); } .form-control::-moz-placeholder { color: #999; opacity: 1; } .form-control:-ms-input-placeholder { color: #999; } .form-control::-webkit-input-placeholder { color: #999; } .form-control::-ms-expand { border: 0; background-color: transparent; } .form-control[disabled], .form-control[readonly], fieldset[disabled] .form-control { background-color: #eeeeee; opacity: 1; } .form-control[disabled], fieldset[disabled] .form-control { cursor: not-allowed; } textarea.form-control { height: auto; } input[type=\"search\"] { -webkit-appearance: none; } @media screen and (-webkit-min-device-pixel-ratio: 0) { input[type=\"date\"].form-control, input[type=\"time\"].form-control, input[type=\"datetime-local\"].form-control, input[type=\"month\"].form-control { line-height: 34px; } input[type=\"date\"].input-sm, input[type=\"time\"].input-sm, input[type=\"datetime-local\"].input-sm, input[type=\"month\"].input-sm, .input-group-sm input[type=\"date\"], .input-group-sm input[type=\"time\"], .input-group-sm input[type=\"datetime-local\"], .input-group-sm input[type=\"month\"] { line-height: 30px; } input[type=\"date\"].input-lg, input[type=\"time\"].input-lg, input[type=\"datetime-local\"].input-lg, input[type=\"month\"].input-lg, .input-group-lg input[type=\"date\"], .input-group-lg input[type=\"time\"], .input-group-lg input[type=\"datetime-local\"], .input-group-lg input[type=\"month\"] { line-height: 46px; } } .form-group { margin-bottom: 15px; } .radio, .checkbox { position: relative; display: block; margin-top: 10px; margin-bottom: 10px; } .radio label, .checkbox label { min-height: 20px; padding-left: 20px; margin-bottom: 0; font-weight: normal; cursor: pointer; } .radio input[type=\"radio\"], .radio-inline input[type=\"radio\"], .checkbox input[type=\"checkbox\"], .checkbox-inline input[type=\"checkbox\"] { position: absolute; margin-left: -20px; margin-top: 4px \\9; } .radio + .radio, .checkbox + .checkbox { margin-top: -5px; } .radio-inline, .checkbox-inline { position: relative; display: inline-block; padding-left: 20px; margin-bottom: 0; vertical-align: middle; font-weight: normal; cursor: pointer; } .radio-inline + .radio-inline, .checkbox-inline + .checkbox-inline { margin-top: 0; margin-left: 10px; } input[type=\"radio\"][disabled], input[type=\"checkbox\"][disabled], input[type=\"radio\"].disabled, input[type=\"checkbox\"].disabled, fieldset[disabled] input[type=\"radio\"], fieldset[disabled] input[type=\"checkbox\"] { cursor: not-allowed; } .radio-inline.disabled, .checkbox-inline.disabled, fieldset[disabled] .radio-inline, fieldset[disabled] .checkbox-inline { cursor: not-allowed; } .radio.disabled label, .checkbox.disabled label, fieldset[disabled] .radio label, fieldset[disabled] .checkbox label { cursor: not-allowed; } .form-control-static { padding-top: 7px; padding-bottom: 7px; margin-bottom: 0; min-height: 34px; } .form-control-static.input-lg, .form-control-static.input-sm { padding-left: 0; padding-right: 0; } .input-sm { height: 30px; padding: 5px 10px; font-size: 12px; line-height: 1.5; border-radius: 3px; } select.input-sm { height: 30px; line-height: 30px; } textarea.input-sm, select[multiple].input-sm { height: auto; } .form-group-sm .form-control { height: 30px; padding: 5px 10px; font-size: 12px; line-height: 1.5; border-radius: 3px; } .form-group-sm select.form-control { height: 30px; line-height: 30px; } .form-group-sm textarea.form-control, .form-group-sm select[multiple].form-control { height: auto; } .form-group-sm .form-control-static { height: 30px; min-height: 32px; padding: 6px 10px; font-size: 12px; line-height: 1.5; } .input-lg { height: 46px; padding: 10px 16px; font-size: 18px; line-height: 1.3333333; border-radius: 6px; } select.input-lg { height: 46px; line-height: 46px; } textarea.input-lg, select[multiple].input-lg { height: auto; } .form-group-lg .form-control { height: 46px; padding: 10px 16px; font-size: 18px; line-height: 1.3333333; border-radius: 6px; } .form-group-lg select.form-control { height: 46px; line-height: 46px; } .form-group-lg textarea.form-control, .form-group-lg select[multiple].form-control { height: auto; } .form-group-lg .form-control-static { height: 46px; min-height: 38px; padding: 11px 16px; font-size: 18px; line-height: 1.3333333; } .has-feedback { position: relative; } .has-feedback .form-control { padding-right: 42.5px; } .form-control-feedback { position: absolute; top: 0; right: 0; z-index: 2; display: block; width: 34px; height: 34px; line-height: 34px; text-align: center; pointer-events: none; } .input-lg + .form-control-feedback, .input-group-lg + .form-control-feedback, .form-group-lg .form-control + .form-control-feedback { width: 46px; height: 46px; line-height: 46px; } .input-sm + .form-control-feedback, .input-group-sm + .form-control-feedback, .form-group-sm .form-control + .form-control-feedback { width: 30px; height: 30px; line-height: 30px; } .has-success .help-block, .has-success .control-label, .has-success .radio, .has-success .checkbox, .has-success .radio-inline, .has-success .checkbox-inline, .has-success.radio label, .has-success.checkbox label, .has-success.radio-inline label, .has-success.checkbox-inline label { color: #3c763d; } .has-success .form-control { border-color: #3c763d; box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075); } .has-success .form-control:focus { border-color: #2b542c; box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168; } .has-success .input-group-addon { color: #3c763d; border-color: #3c763d; background-color: #dff0d8; } .has-success .form-control-feedback { color: #3c763d; } .has-warning .help-block, .has-warning .control-label, .has-warning .radio, .has-warning .checkbox, .has-warning .radio-inline, .has-warning .checkbox-inline, .has-warning.radio label, .has-warning.checkbox label, .has-warning.radio-inline label, .has-warning.checkbox-inline label { color: #8a6d3b; } .has-warning .form-control { border-color: #8a6d3b; box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075); } .has-warning .form-control:focus { border-color: #66512c; box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b; } .has-warning .input-group-addon { color: #8a6d3b; border-color: #8a6d3b; background-color: #fcf8e3; } .has-warning .form-control-feedback { color: #8a6d3b; } .has-error .help-block, .has-error .control-label, .has-error .radio, .has-error .checkbox, .has-error .radio-inline, .has-error .checkbox-inline, .has-error.radio label, .has-error.checkbox label, .has-error.radio-inline label, .has-error.checkbox-inline label { color: #a94442; } .has-error .form-control { border-color: #a94442; box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075); } .has-error .form-control:focus { border-color: #843534; box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483; } .has-error .input-group-addon { color: #a94442; border-color: #a94442; background-color: #f2dede; } .has-error .form-control-feedback { color: #a94442; } .has-feedback label ~ .form-control-feedback { top: 25px; } .has-feedback label.sr-only ~ .form-control-feedback { top: 0; } .help-block { display: block; margin-top: 5px; margin-bottom: 10px; color: #737373; } @media (min-width: 768px) { .form-inline .form-group { display: inline-block; margin-bottom: 0; vertical-align: middle; } .form-inline .form-control { display: inline-block; width: auto; vertical-align: middle; } .form-inline .form-control-static { display: inline-block; } .form-inline .input-group { display: inline-table; vertical-align: middle; } .form-inline .input-group .input-group-addon, .form-inline .input-group .input-group-btn, .form-inline .input-group .form-control { width: auto; } .form-inline .input-group > .form-control { width: 100%; } .form-inline .control-label { margin-bottom: 0; vertical-align: middle; } .form-inline .radio, .form-inline .checkbox { display: inline-block; margin-top: 0; margin-bottom: 0; vertical-align: middle; } .form-inline .radio label, .form-inline .checkbox label { padding-left: 0; } .form-inline .radio input[type=\"radio\"], .form-inline .checkbox input[type=\"checkbox\"] { position: relative; margin-left: 0; } .form-inline .has-feedback .form-control-feedback { top: 0; } } .form-horizontal .radio, .form-horizontal .checkbox, .form-horizontal .radio-inline, .form-horizontal .checkbox-inline { margin-top: 0; margin-bottom: 0; padding-top: 7px; } .form-horizontal .radio, .form-horizontal .checkbox { min-height: 27px; } .form-horizontal .form-group { margin-left: -15px; margin-right: -15px; } @media (min-width: 768px) { .form-horizontal .control-label { text-align: right; margin-bottom: 0; padding-top: 7px; } } .form-horizontal .has-feedback .form-control-feedback { right: 15px; } @media (min-width: 768px) { .form-horizontal .form-group-lg .control-label { padding-top: 11px; font-size: 18px; } } @media (min-width: 768px) { .form-horizontal .form-group-sm .control-label { padding-top: 6px; font-size: 12px; } } .btn { display: inline-block; margin-bottom: 0; font-weight: normal; text-align: center; vertical-align: middle; touch-action: manipulation; cursor: pointer; background-image: none; border: 1px solid transparent; white-space: nowrap; padding: 6px 12px; font-size: 14px; line-height: 1.42857143; border-radius: 4px; -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; } .btn:focus, .btn:active:focus, .btn.active:focus, .btn.focus, .btn:active.focus, .btn.active.focus { outline: 5px auto -webkit-focus-ring-color; outline-offset: -2px; } .btn:hover, .btn:focus, .btn.focus { color: #333; text-decoration: none; } .btn:active, .btn.active { outline: 0; background-image: none; box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125); } .btn.disabled, .btn[disabled], fieldset[disabled] .btn { cursor: not-allowed; opacity: 0.65; filter: alpha(opacity=65); box-shadow: none; } a.btn.disabled, fieldset[disabled] a.btn { pointer-events: none; } .btn-default { color: #333; background-color: #fff; border-color: #ccc; } .btn-default:focus, .btn-default.focus { color: #333; background-color: #e6e6e6; border-color: #8c8c8c; } .btn-default:hover { color: #333; background-color: #e6e6e6; border-color: #adadad; } .btn-default:active, .btn-default.active, .open > .dropdown-toggle.btn-default { color: #333; background-color: #e6e6e6; border-color: #adadad; } .btn-default:active:hover, .btn-default.active:hover, .open > .dropdown-toggle.btn-default:hover, .btn-default:active:focus, .btn-default.active:focus, .open > .dropdown-toggle.btn-default:focus, .btn-default:active.focus, .btn-default.active.focus, .open > .dropdown-toggle.btn-default.focus { color: #333; background-color: #d4d4d4; border-color: #8c8c8c; } .btn-default:active, .btn-default.active, .open > .dropdown-toggle.btn-default { background-image: none; } .btn-default.disabled:hover, .btn-default[disabled]:hover, fieldset[disabled] .btn-default:hover, .btn-default.disabled:focus, .btn-default[disabled]:focus, fieldset[disabled] .btn-default:focus, .btn-default.disabled.focus, .btn-default[disabled].focus, fieldset[disabled] .btn-default.focus { background-color: #fff; border-color: #ccc; } .btn-default .badge { color: #fff; background-color: #333; } .btn-primary { color: #fff; background-color: #337ab7; border-color: #2e6da4; } .btn-primary:focus, .btn-primary.focus { color: #fff; background-color: #286090; border-color: #122b40; } .btn-primary:hover { color: #fff; background-color: #286090; border-color: #204d74; } .btn-primary:active, .btn-primary.active, .open > .dropdown-toggle.btn-primary { color: #fff; background-color: #286090; border-color: #204d74; } .btn-primary:active:hover, .btn-primary.active:hover, .open > .dropdown-toggle.btn-primary:hover, .btn-primary:active:focus, .btn-primary.active:focus, .open > .dropdown-toggle.btn-primary:focus, .btn-primary:active.focus, .btn-primary.active.focus, .open > .dropdown-toggle.btn-primary.focus { color: #fff; background-color: #204d74; border-color: #122b40; } .btn-primary:active, .btn-primary.active, .open > .dropdown-toggle.btn-primary { background-image: none; } .btn-primary.disabled:hover, .btn-primary[disabled]:hover, fieldset[disabled] .btn-primary:hover, .btn-primary.disabled:focus, .btn-primary[disabled]:focus, fieldset[disabled] .btn-primary:focus, .btn-primary.disabled.focus, .btn-primary[disabled].focus, fieldset[disabled] .btn-primary.focus { background-color: #337ab7; border-color: #2e6da4; } .btn-primary .badge { color: #337ab7; background-color: #fff; } .btn-success { color: #fff; background-color: #5cb85c; border-color: #4cae4c; } .btn-success:focus, .btn-success.focus { color: #fff; background-color: #449d44; border-color: #255625; } .btn-success:hover { color: #fff; background-color: #449d44; border-color: #398439; } .btn-success:active, .btn-success.active, .open > .dropdown-toggle.btn-success { color: #fff; background-color: #449d44; border-color: #398439; } .btn-success:active:hover, .btn-success.active:hover, .open > .dropdown-toggle.btn-success:hover, .btn-success:active:focus, .btn-success.active:focus, .open > .dropdown-toggle.btn-success:focus, .btn-success:active.focus, .btn-success.active.focus, .open > .dropdown-toggle.btn-success.focus { color: #fff; background-color: #398439; border-color: #255625; } .btn-success:active, .btn-success.active, .open > .dropdown-toggle.btn-success { background-image: none; } .btn-success.disabled:hover, .btn-success[disabled]:hover, fieldset[disabled] .btn-success:hover, .btn-success.disabled:focus, .btn-success[disabled]:focus, fieldset[disabled] .btn-success:focus, .btn-success.disabled.focus, .btn-success[disabled].focus, fieldset[disabled] .btn-success.focus { background-color: #5cb85c; border-color: #4cae4c; } .btn-success .badge { color: #5cb85c; background-color: #fff; } .btn-info { color: #fff; background-color: #5bc0de; border-color: #46b8da; } .btn-info:focus, .btn-info.focus { color: #fff; background-color: #31b0d5; border-color: #1b6d85; } .btn-info:hover { color: #fff; background-color: #31b0d5; border-color: #269abc; } .btn-info:active, .btn-info.active, .open > .dropdown-toggle.btn-info { color: #fff; background-color: #31b0d5; border-color: #269abc; } .btn-info:active:hover, .btn-info.active:hover, .open > .dropdown-toggle.btn-info:hover, .btn-info:active:focus, .btn-info.active:focus, .open > .dropdown-toggle.btn-info:focus, .btn-info:active.focus, .btn-info.active.focus, .open > .dropdown-toggle.btn-info.focus { color: #fff; background-color: #269abc; border-color: #1b6d85; } .btn-info:active, .btn-info.active, .open > .dropdown-toggle.btn-info { background-image: none; } .btn-info.disabled:hover, .btn-info[disabled]:hover, fieldset[disabled] .btn-info:hover, .btn-info.disabled:focus, .btn-info[disabled]:focus, fieldset[disabled] .btn-info:focus, .btn-info.disabled.focus, .btn-info[disabled].focus, fieldset[disabled] .btn-info.focus { background-color: #5bc0de; border-color: #46b8da; } .btn-info .badge { color: #5bc0de; background-color: #fff; } .btn-warning { color: #fff; background-color: #f0ad4e; border-color: #eea236; } .btn-warning:focus, .btn-warning.focus { color: #fff; background-color: #ec971f; border-color: #985f0d; } .btn-warning:hover { color: #fff; background-color: #ec971f; border-color: #d58512; } .btn-warning:active, .btn-warning.active, .open > .dropdown-toggle.btn-warning { color: #fff; background-color: #ec971f; border-color: #d58512; } .btn-warning:active:hover, .btn-warning.active:hover, .open > .dropdown-toggle.btn-warning:hover, .btn-warning:active:focus, .btn-warning.active:focus, .open > .dropdown-toggle.btn-warning:focus, .btn-warning:active.focus, .btn-warning.active.focus, .open > .dropdown-toggle.btn-warning.focus { color: #fff; background-color: #d58512; border-color: #985f0d; } .btn-warning:active, .btn-warning.active, .open > .dropdown-toggle.btn-warning { background-image: none; } .btn-warning.disabled:hover, .btn-warning[disabled]:hover, fieldset[disabled] .btn-warning:hover, .btn-warning.disabled:focus, .btn-warning[disabled]:focus, fieldset[disabled] .btn-warning:focus, .btn-warning.disabled.focus, .btn-warning[disabled].focus, fieldset[disabled] .btn-warning.focus { background-color: #f0ad4e; border-color: #eea236; } .btn-warning .badge { color: #f0ad4e; background-color: #fff; } .btn-danger { color: #fff; background-color: #d9534f; border-color: #d43f3a; } .btn-danger:focus, .btn-danger.focus { color: #fff; background-color: #c9302c; border-color: #761c19; } .btn-danger:hover { color: #fff; background-color: #c9302c; border-color: #ac2925; } .btn-danger:active, .btn-danger.active, .open > .dropdown-toggle.btn-danger { color: #fff; background-color: #c9302c; border-color: #ac2925; } .btn-danger:active:hover, .btn-danger.active:hover, .open > .dropdown-toggle.btn-danger:hover, .btn-danger:active:focus, .btn-danger.active:focus, .open > .dropdown-toggle.btn-danger:focus, .btn-danger:active.focus, .btn-danger.active.focus, .open > .dropdown-toggle.btn-danger.focus { color: #fff; background-color: #ac2925; border-color: #761c19; } .btn-danger:active, .btn-danger.active, .open > .dropdown-toggle.btn-danger { background-image: none; } .btn-danger.disabled:hover, .btn-danger[disabled]:hover, fieldset[disabled] .btn-danger:hover, .btn-danger.disabled:focus, .btn-danger[disabled]:focus, fieldset[disabled] .btn-danger:focus, .btn-danger.disabled.focus, .btn-danger[disabled].focus, fieldset[disabled] .btn-danger.focus { background-color: #d9534f; border-color: #d43f3a; } .btn-danger .badge { color: #d9534f; background-color: #fff; } .btn-link { color: #337ab7; font-weight: normal; border-radius: 0; } .btn-link, .btn-link:active, .btn-link.active, .btn-link[disabled], fieldset[disabled] .btn-link { background-color: transparent; box-shadow: none; } .btn-link, .btn-link:hover, .btn-link:focus, .btn-link:active { border-color: transparent; } .btn-link:hover, .btn-link:focus { color: #23527c; text-decoration: underline; background-color: transparent; } .btn-link[disabled]:hover, fieldset[disabled] .btn-link:hover, .btn-link[disabled]:focus, fieldset[disabled] .btn-link:focus { color: #777777; text-decoration: none; } .btn-lg, .btn-group-lg > .btn { padding: 10px 16px; font-size: 18px; line-height: 1.3333333; border-radius: 6px; } .btn-sm, .btn-group-sm > .btn { padding: 5px 10px; font-size: 12px; line-height: 1.5; border-radius: 3px; } .btn-xs, .btn-group-xs > .btn { padding: 1px 5px; font-size: 12px; line-height: 1.5; border-radius: 3px; } .btn-block { display: block; width: 100%; } .btn-block + .btn-block { margin-top: 5px; } input[type=\"submit\"].btn-block, input[type=\"reset\"].btn-block, input[type=\"button\"].btn-block { width: 100%; } .fade { opacity: 0; transition: opacity 0.15s linear; } .fade.in { opacity: 1; } .collapse { display: none; } .collapse.in { display: block; margin-top: 20px; margin-left: 40px; } tr.collapse.in { display: table-row; } tbody.collapse.in { display: table-row-group; } .collapsing { position: relative; height: 0; overflow: hidden; transition-property: height, visibility; transition-duration: 0.35s; transition-timing-function: ease; } .caret { display: inline-block; width: 0; height: 0; margin-left: 2px; vertical-align: middle; border-top: 4px dashed; border-top: 4px solid \\9; border-right: 4px solid transparent; border-left: 4px solid transparent; } .dropup, .dropdown { position: relative; } .dropdown-toggle:focus { outline: 0; } .dropdown-menu { position: absolute; top: 100%; left: 0; z-index: 1000; display: none; float: left; min-width: 160px; padding: 5px 0; margin: 2px 0 0; list-style: none; font-size: 14px; text-align: left; background-color: #fff; border: 1px solid #ccc; border: 1px solid rgba(0, 0, 0, 0.15); border-radius: 4px; box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175); background-clip: padding-box; } .dropdown-menu.pull-right { right: 0; left: auto; } .dropdown-menu .divider { height: 1px; margin: 9px 0; overflow: hidden; background-color: #e5e5e5; } .dropdown-menu > li > a { display: block; padding: 3px 20px; clear: both; font-weight: normal; line-height: 1.42857143; color: #333333; white-space: nowrap; } .dropdown-menu > li > a:hover, .dropdown-menu > li > a:focus { text-decoration: none; color: #262626; background-color: #f5f5f5; } .dropdown-menu > .active > a, .dropdown-menu > .active > a:hover, .dropdown-menu > .active > a:focus { color: #fff; text-decoration: none; outline: 0; background-color: #337ab7; } .dropdown-menu > .disabled > a, .dropdown-menu > .disabled > a:hover, .dropdown-menu > .disabled > a:focus { color: #777777; } .dropdown-menu > .disabled > a:hover, .dropdown-menu > .disabled > a:focus { text-decoration: none; background-color: transparent; background-image: none; filter: progid:DXImageTransform.Microsoft.gradient(enabled = false); cursor: not-allowed; } .open > .dropdown-menu { display: block; } .open > a { outline: 0; } .dropdown-menu-right { left: auto; right: 0; } .dropdown-menu-left { left: 0; right: auto; } .dropdown-header { display: block; padding: 3px 20px; font-size: 12px; line-height: 1.42857143; color: #777777; white-space: nowrap; } .dropdown-backdrop { position: fixed; left: 0; right: 0; bottom: 0; top: 0; z-index: 990; } .pull-right > .dropdown-menu { right: 0; left: auto; } .dropup .caret, .navbar-fixed-bottom .dropdown .caret { border-top: 0; border-bottom: 4px dashed; border-bottom: 4px solid \\9; content: \"\"; } .dropup .dropdown-menu, .navbar-fixed-bottom .dropdown .dropdown-menu { top: auto; bottom: 100%; margin-bottom: 2px; } @media (min-width: 768px) { .navbar-right .dropdown-menu { left: auto; right: 0; } .navbar-right .dropdown-menu-left { left: 0; right: auto; } } .btn-group, .btn-group-vertical { position: relative; display: inline-block; vertical-align: middle; } .btn-group > .btn, .btn-group-vertical > .btn { position: relative; float: left; } .btn-group > .btn:hover, .btn-group-vertical > .btn:hover, .btn-group > .btn:focus, .btn-group-vertical > .btn:focus, .btn-group > .btn:active, .btn-group-vertical > .btn:active, .btn-group > .btn.active, .btn-group-vertical > .btn.active { z-index: 2; } .btn-group .btn + .btn, .btn-group .btn + .btn-group, .btn-group .btn-group + .btn, .btn-group .btn-group + .btn-group { margin-left: -1px; } .btn-toolbar { margin-left: -5px; } .btn-toolbar .btn, .btn-toolbar .btn-group, .btn-toolbar .input-group { float: left; } .btn-toolbar > .btn, .btn-toolbar > .btn-group, .btn-toolbar > .input-group { margin-left: 5px; } .btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) { border-radius: 0; } .btn-group > .btn:first-child { margin-left: 0; } .btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) { border-bottom-right-radius: 0; border-top-right-radius: 0; } .btn-group > .btn:last-child:not(:first-child), .btn-group > .dropdown-toggle:not(:first-child) { border-bottom-left-radius: 0; border-top-left-radius: 0; } .btn-group > .btn-group { float: left; } .btn-group > .btn-group:not(:first-child):not(:last-child) > .btn { border-radius: 0; } .btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child, .btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle { border-bottom-right-radius: 0; border-top-right-radius: 0; } .btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child { border-bottom-left-radius: 0; border-top-left-radius: 0; } .btn-group .dropdown-toggle:active, .btn-group.open .dropdown-toggle { outline: 0; } .btn-group > .btn + .dropdown-toggle { padding-left: 8px; padding-right: 8px; } .btn-group > .btn-lg + .dropdown-toggle { padding-left: 12px; padding-right: 12px; } .btn-group.open .dropdown-toggle { box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125); } .btn-group.open .dropdown-toggle.btn-link { box-shadow: none; } .btn .caret { margin-left: 0; } .btn-lg .caret { border-width: 5px 5px 0; border-bottom-width: 0; } .dropup .btn-lg .caret { border-width: 0 5px 5px; } .btn-group-vertical > .btn, .btn-group-vertical > .btn-group, .btn-group-vertical > .btn-group > .btn { display: block; float: none; width: 100%; max-width: 100%; } .btn-group-vertical > .btn-group > .btn { float: none; } .btn-group-vertical > .btn + .btn, .btn-group-vertical > .btn + .btn-group, .btn-group-vertical > .btn-group + .btn, .btn-group-vertical > .btn-group + .btn-group { margin-top: -1px; margin-left: 0; } .btn-group-vertical > .btn:not(:first-child):not(:last-child) { border-radius: 0; } .btn-group-vertical > .btn:first-child:not(:last-child) { border-top-right-radius: 4px; border-top-left-radius: 4px; border-bottom-right-radius: 0; border-bottom-left-radius: 0; } .btn-group-vertical > .btn:last-child:not(:first-child) { border-top-right-radius: 0; border-top-left-radius: 0; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; } .btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn { border-radius: 0; } .btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child, .btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle { border-bottom-right-radius: 0; border-bottom-left-radius: 0; } .btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child { border-top-right-radius: 0; border-top-left-radius: 0; } .btn-group-justified { display: table; width: 100%; table-layout: fixed; border-collapse: separate; } .btn-group-justified > .btn, .btn-group-justified > .btn-group { float: none; display: table-cell; width: 1%; } .btn-group-justified > .btn-group .btn { width: 100%; } .btn-group-justified > .btn-group .dropdown-menu { left: auto; } [data-toggle=\"buttons\"] > .btn input[type=\"radio\"], [data-toggle=\"buttons\"] > .btn-group > .btn input[type=\"radio\"], [data-toggle=\"buttons\"] > .btn input[type=\"checkbox\"], [data-toggle=\"buttons\"] > .btn-group > .btn input[type=\"checkbox\"] { position: absolute; clip: rect(0, 0, 0, 0); pointer-events: none; } .input-group { position: relative; display: table; border-collapse: separate; } .input-group[class*=\"col-\"] { float: none; padding-left: 0; padding-right: 0; } .input-group .form-control { position: relative; z-index: 2; float: left; width: 100%; margin-bottom: 0; } .input-group .form-control:focus { z-index: 3; } .input-group-lg > .form-control, .input-group-lg > .input-group-addon, .input-group-lg > .input-group-btn > .btn { height: 46px; padding: 10px 16px; font-size: 18px; line-height: 1.3333333; border-radius: 6px; } select.input-group-lg > .form-control, select.input-group-lg > .input-group-addon, select.input-group-lg > .input-group-btn > .btn { height: 46px; line-height: 46px; } textarea.input-group-lg > .form-control, textarea.input-group-lg > .input-group-addon, textarea.input-group-lg > .input-group-btn > .btn, select[multiple].input-group-lg > .form-control, select[multiple].input-group-lg > .input-group-addon, select[multiple].input-group-lg > .input-group-btn > .btn { height: auto; } .input-group-sm > .form-control, .input-group-sm > .input-group-addon, .input-group-sm > .input-group-btn > .btn { height: 30px; padding: 5px 10px; font-size: 12px; line-height: 1.5; border-radius: 3px; } select.input-group-sm > .form-control, select.input-group-sm > .input-group-addon, select.input-group-sm > .input-group-btn > .btn { height: 30px; line-height: 30px; } textarea.input-group-sm > .form-control, textarea.input-group-sm > .input-group-addon, textarea.input-group-sm > .input-group-btn > .btn, select[multiple].input-group-sm > .form-control, select[multiple].input-group-sm > .input-group-addon, select[multiple].input-group-sm > .input-group-btn > .btn { height: auto; } .input-group-addon, .input-group-btn, .input-group .form-control { display: table-cell; } .input-group-addon:not(:first-child):not(:last-child), .input-group-btn:not(:first-child):not(:last-child), .input-group .form-control:not(:first-child):not(:last-child) { border-radius: 0; } .input-group-addon, .input-group-btn { width: 1%; white-space: nowrap; vertical-align: middle; } .input-group-addon { padding: 6px 12px; font-size: 14px; font-weight: normal; line-height: 1; color: #555555; text-align: center; background-color: #eeeeee; border: 1px solid #ccc; border-radius: 4px; } .input-group-addon.input-sm { padding: 5px 10px; font-size: 12px; border-radius: 3px; } .input-group-addon.input-lg { padding: 10px 16px; font-size: 18px; border-radius: 6px; } .input-group-addon input[type=\"radio\"], .input-group-addon input[type=\"checkbox\"] { margin-top: 0; } .input-group .form-control:first-child, .input-group-addon:first-child, .input-group-btn:first-child > .btn, .input-group-btn:first-child > .btn-group > .btn, .input-group-btn:first-child > .dropdown-toggle, .input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle), .input-group-btn:last-child > .btn-group:not(:last-child) > .btn { border-bottom-right-radius: 0; border-top-right-radius: 0; } .input-group-addon:first-child { border-right: 0; } .input-group .form-control:last-child, .input-group-addon:last-child, .input-group-btn:last-child > .btn, .input-group-btn:last-child > .btn-group > .btn, .input-group-btn:last-child > .dropdown-toggle, .input-group-btn:first-child > .btn:not(:first-child), .input-group-btn:first-child > .btn-group:not(:first-child) > .btn { border-bottom-left-radius: 0; border-top-left-radius: 0; } .input-group-addon:last-child { border-left: 0; } .input-group-btn { position: relative; font-size: 0; white-space: nowrap; } .input-group-btn > .btn { position: relative; } .input-group-btn > .btn + .btn { margin-left: -1px; } .input-group-btn > .btn:hover, .input-group-btn > .btn:focus, .input-group-btn > .btn:active { z-index: 2; } .input-group-btn:first-child > .btn, .input-group-btn:first-child > .btn-group { margin-right: -1px; } .input-group-btn:last-child > .btn, .input-group-btn:last-child > .btn-group { z-index: 2; margin-left: -1px; } .nav { margin-bottom: 0; padding-left: 0; list-style: none; } .nav > li { position: relative; display: block; } .nav > li > a { position: relative; display: block; padding: 10px 15px; } .nav > li > a:hover, .nav > li > a:focus { text-decoration: none; background-color: #eeeeee; } .nav > li.disabled > a { color: #777777; } .nav > li.disabled > a:hover, .nav > li.disabled > a:focus { color: #777777; text-decoration: none; background-color: transparent; cursor: not-allowed; } .nav .open > a, .nav .open > a:hover, .nav .open > a:focus { background-color: #eeeeee; border-color: #337ab7; } .nav .nav-divider { height: 1px; margin: 9px 0; overflow: hidden; background-color: #e5e5e5; } .nav > li > a > img { max-width: none; } .nav-tabs { border-bottom: 1px solid #ddd; } .nav-tabs > li { float: left; margin-bottom: -1px; } .nav-tabs > li > a { margin-right: 2px; line-height: 1.42857143; border: 1px solid transparent; border-radius: 4px 4px 0 0; } .nav-tabs > li > a:hover { border-color: #eeeeee #eeeeee #ddd; } .nav-tabs > li.active > a, .nav-tabs > li.active > a:hover, .nav-tabs > li.active > a:focus { color: #555555; background-color: #fff; border: 1px solid #ddd; border-bottom-color: transparent; cursor: default; } .nav-tabs.nav-justified { width: 100%; border-bottom: 0; } .nav-tabs.nav-justified > li { float: none; } .nav-tabs.nav-justified > li > a { text-align: center; margin-bottom: 5px; } .nav-tabs.nav-justified > .dropdown .dropdown-menu { top: auto; left: auto; } @media (min-width: 768px) { .nav-tabs.nav-justified > li { display: table-cell; width: 1%; } .nav-tabs.nav-justified > li > a { margin-bottom: 0; } } .nav-tabs.nav-justified > li > a { margin-right: 0; border-radius: 4px; } .nav-tabs.nav-justified > .active > a, .nav-tabs.nav-justified > .active > a:hover, .nav-tabs.nav-justified > .active > a:focus { border: 1px solid #ddd; } @media (min-width: 768px) { .nav-tabs.nav-justified > li > a { border-bottom: 1px solid #ddd; border-radius: 4px 4px 0 0; } .nav-tabs.nav-justified > .active > a, .nav-tabs.nav-justified > .active > a:hover, .nav-tabs.nav-justified > .active > a:focus { border-bottom-color: #fff; } } .nav-pills > li { float: left; } .nav-pills > li > a { border-radius: 4px; } .nav-pills > li + li { margin-left: 2px; } .nav-pills > li.active > a, .nav-pills > li.active > a:hover, .nav-pills > li.active > a:focus { color: #fff; background-color: #337ab7; } .nav-stacked > li { float: none; } .nav-stacked > li + li { margin-top: 2px; margin-left: 0; } .nav-justified { width: 100%; } .nav-justified > li { float: none; } .nav-justified > li > a { text-align: center; margin-bottom: 5px; } .nav-justified > .dropdown .dropdown-menu { top: auto; left: auto; } @media (min-width: 768px) { .nav-justified > li { display: table-cell; width: 1%; } .nav-justified > li > a { margin-bottom: 0; } } .nav-tabs-justified { border-bottom: 0; } .nav-tabs-justified > li > a { margin-right: 0; border-radius: 4px; } .nav-tabs-justified > .active > a, .nav-tabs-justified > .active > a:hover, .nav-tabs-justified > .active > a:focus { border: 1px solid #ddd; } @media (min-width: 768px) { .nav-tabs-justified > li > a { border-bottom: 1px solid #ddd; border-radius: 4px 4px 0 0; } .nav-tabs-justified > .active > a, .nav-tabs-justified > .active > a:hover, .nav-tabs-justified > .active > a:focus { border-bottom-color: #fff; } } .tab-content > .tab-pane { display: none; } .tab-content > .active { display: block; } .nav-tabs .dropdown-menu { margin-top: -1px; border-top-right-radius: 0; border-top-left-radius: 0; } .navbar { position: relative; min-height: 50px; margin-bottom: 20px; border: 1px solid transparent; } @media (min-width: 768px) { .navbar { border-radius: 4px; } } @media (min-width: 768px) { .navbar-header { float: left; } } .navbar-collapse { overflow-x: visible; padding-right: 15px; padding-left: 15px; border-top: 1px solid transparent; box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1); -webkit-overflow-scrolling: touch; } .navbar-collapse.in { overflow-y: auto; } @media (min-width: 768px) { .navbar-collapse { width: auto; border-top: 0; box-shadow: none; } .navbar-collapse.collapse { display: block !important; height: auto !important; padding-bottom: 0; overflow: visible !important; } .navbar-collapse.in { overflow-y: visible; } .navbar-fixed-top .navbar-collapse, .navbar-static-top .navbar-collapse, .navbar-fixed-bottom .navbar-collapse { padding-left: 0; padding-right: 0; } } .navbar-fixed-top .navbar-collapse, .navbar-fixed-bottom .navbar-collapse { max-height: 340px; } @media (max-device-width: 480px) and (orientation: landscape) { .navbar-fixed-top .navbar-collapse, .navbar-fixed-bottom .navbar-collapse { max-height: 200px; } } .container > .navbar-header, .container-fluid > .navbar-header, .container > .navbar-collapse, .container-fluid > .navbar-collapse { margin-right: -15px; margin-left: -15px; } @media (min-width: 768px) { .container > .navbar-header, .container-fluid > .navbar-header, .container > .navbar-collapse, .container-fluid > .navbar-collapse { margin-right: 0; margin-left: 0; } } .navbar-static-top { z-index: 1000; border-width: 0 0 1px; } @media (min-width: 768px) { .navbar-static-top { border-radius: 0; } } .navbar-fixed-top, .navbar-fixed-bottom { position: fixed; right: 0; left: 0; z-index: 1030; } @media (min-width: 768px) { .navbar-fixed-top, .navbar-fixed-bottom { border-radius: 0; } } .navbar-fixed-top { top: 0; border-width: 0 0 1px; } .navbar-fixed-bottom { bottom: 0; margin-bottom: 0; border-width: 1px 0 0; } .navbar-brand { float: left; padding: 15px 15px; font-size: 18px; line-height: 20px; height: 50px; } .navbar-brand:hover, .navbar-brand:focus { text-decoration: none; } .navbar-brand > img { display: block; } @media (min-width: 768px) { .navbar > .container .navbar-brand, .navbar > .container-fluid .navbar-brand { margin-left: -15px; } } .navbar-toggle { position: relative; float: right; margin-right: 15px; padding: 9px 10px; margin-top: 8px; margin-bottom: 8px; background-color: transparent; background-image: none; border: 1px solid transparent; border-radius: 4px; } .navbar-toggle:focus { outline: 0; } .navbar-toggle .icon-bar { display: block; width: 22px; height: 2px; border-radius: 1px; } .navbar-toggle .icon-bar + .icon-bar { margin-top: 4px; } @media (min-width: 768px) { .navbar-toggle { display: none; } } .navbar-nav { margin: 7.5px -15px; } .navbar-nav > li > a { padding-top: 10px; padding-bottom: 10px; line-height: 20px; } @media (max-width: 767px) { .navbar-nav .open .dropdown-menu { position: static; float: none; width: auto; margin-top: 0; background-color: transparent; border: 0; box-shadow: none; } .navbar-nav .open .dropdown-menu > li > a, .navbar-nav .open .dropdown-menu .dropdown-header { padding: 5px 15px 5px 25px; } .navbar-nav .open .dropdown-menu > li > a { line-height: 20px; } .navbar-nav .open .dropdown-menu > li > a:hover, .navbar-nav .open .dropdown-menu > li > a:focus { background-image: none; } } @media (min-width: 768px) { .navbar-nav { float: left; margin: 0; } .navbar-nav > li { float: left; } .navbar-nav > li > a { padding-top: 15px; padding-bottom: 15px; } } .navbar-form { margin-left: -15px; margin-right: -15px; padding: 10px 15px; border-top: 1px solid transparent; border-bottom: 1px solid transparent; box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1); margin-top: 8px; margin-bottom: 8px; } @media (min-width: 768px) { .navbar-form .form-group { display: inline-block; margin-bottom: 0; vertical-align: middle; } .navbar-form .form-control { display: inline-block; width: auto; vertical-align: middle; } .navbar-form .form-control-static { display: inline-block; } .navbar-form .input-group { display: inline-table; vertical-align: middle; } .navbar-form .input-group .input-group-addon, .navbar-form .input-group .input-group-btn, .navbar-form .input-group .form-control { width: auto; } .navbar-form .input-group > .form-control { width: 100%; } .navbar-form .control-label { margin-bottom: 0; vertical-align: middle; } .navbar-form .radio, .navbar-form .checkbox { display: inline-block; margin-top: 0; margin-bottom: 0; vertical-align: middle; } .navbar-form .radio label, .navbar-form .checkbox label { padding-left: 0; } .navbar-form .radio input[type=\"radio\"], .navbar-form .checkbox input[type=\"checkbox\"] { position: relative; margin-left: 0; } .navbar-form .has-feedback .form-control-feedback { top: 0; } } @media (max-width: 767px) { .navbar-form .form-group { margin-bottom: 5px; } .navbar-form .form-group:last-child { margin-bottom: 0; } } @media (min-width: 768px) { .navbar-form { width: auto; border: 0; margin-left: 0; margin-right: 0; padding-top: 0; padding-bottom: 0; box-shadow: none; } } .navbar-nav > li > .dropdown-menu { margin-top: 0; border-top-right-radius: 0; border-top-left-radius: 0; } .navbar-fixed-bottom .navbar-nav > li > .dropdown-menu { margin-bottom: 0; border-top-right-radius: 4px; border-top-left-radius: 4px; border-bottom-right-radius: 0; border-bottom-left-radius: 0; } .navbar-btn { margin-top: 8px; margin-bottom: 8px; } .navbar-btn.btn-sm { margin-top: 10px; margin-bottom: 10px; } .navbar-btn.btn-xs { margin-top: 14px; margin-bottom: 14px; } .navbar-text { margin-top: 15px; margin-bottom: 15px; } @media (min-width: 768px) { .navbar-text { float: left; margin-left: 15px; margin-right: 15px; } } @media (min-width: 768px) { .navbar-left { float: left !important; } .navbar-right { float: right !important; margin-right: -15px; } .navbar-right ~ .navbar-right { margin-right: 0; } } .navbar-default { background-color: #f8f8f8; border-color: #e7e7e7; } .navbar-default .navbar-brand { color: #777; } .navbar-default .navbar-brand:hover, .navbar-default .navbar-brand:focus { color: #5e5e5e; background-color: transparent; } .navbar-default .navbar-text { color: #777; } .navbar-default .navbar-nav > li > a { color: #777; } .navbar-default .navbar-nav > li > a:hover, .navbar-default .navbar-nav > li > a:focus { color: #333; background-color: transparent; } .navbar-default .navbar-nav > .active > a, .navbar-default .navbar-nav > .active > a:hover, .navbar-default .navbar-nav > .active > a:focus { color: #555; background-color: #e7e7e7; } .navbar-default .navbar-nav > .disabled > a, .navbar-default .navbar-nav > .disabled > a:hover, .navbar-default .navbar-nav > .disabled > a:focus { color: #ccc; background-color: transparent; } .navbar-default .navbar-toggle { border-color: #ddd; } .navbar-default .navbar-toggle:hover, .navbar-default .navbar-toggle:focus { background-color: #ddd; } .navbar-default .navbar-toggle .icon-bar { background-color: #888; } .navbar-default .navbar-collapse, .navbar-default .navbar-form { border-color: #e7e7e7; } .navbar-default .navbar-nav > .open > a, .navbar-default .navbar-nav > .open > a:hover, .navbar-default .navbar-nav > .open > a:focus { background-color: #e7e7e7; color: #555; } @media (max-width: 767px) { .navbar-default .navbar-nav .open .dropdown-menu > li > a { color: #777; } .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover, .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus { color: #333; background-color: transparent; } .navbar-default .navbar-nav .open .dropdown-menu > .active > a, .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover, .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus { color: #555; background-color: #e7e7e7; } .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a, .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover, .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus { color: #ccc; background-color: transparent; } } .navbar-default .navbar-link { color: #777; } .navbar-default .navbar-link:hover { color: #333; } .navbar-default .btn-link { color: #777; } .navbar-default .btn-link:hover, .navbar-default .btn-link:focus { color: #333; } .navbar-default .btn-link[disabled]:hover, fieldset[disabled] .navbar-default .btn-link:hover, .navbar-default .btn-link[disabled]:focus, fieldset[disabled] .navbar-default .btn-link:focus { color: #ccc; } .navbar-inverse { background-color: #222; border-color: #080808; } .navbar-inverse .navbar-brand { color: #9d9d9d; } .navbar-inverse .navbar-brand:hover, .navbar-inverse .navbar-brand:focus { color: #fff; background-color: transparent; } .navbar-inverse .navbar-text { color: #9d9d9d; } .navbar-inverse .navbar-nav > li > a { color: #9d9d9d; } .navbar-inverse .navbar-nav > li > a:hover, .navbar-inverse .navbar-nav > li > a:focus { color: #fff; background-color: transparent; } .navbar-inverse .navbar-nav > .active > a, .navbar-inverse .navbar-nav > .active > a:hover, .navbar-inverse .navbar-nav > .active > a:focus { color: #fff; background-color: #080808; } .navbar-inverse .navbar-nav > .disabled > a, .navbar-inverse .navbar-nav > .disabled > a:hover, .navbar-inverse .navbar-nav > .disabled > a:focus { color: #444; background-color: transparent; } .navbar-inverse .navbar-toggle { border-color: #333; } .navbar-inverse .navbar-toggle:hover, .navbar-inverse .navbar-toggle:focus { background-color: #333; } .navbar-inverse .navbar-toggle .icon-bar { background-color: #fff; } .navbar-inverse .navbar-collapse, .navbar-inverse .navbar-form { border-color: #101010; } .navbar-inverse .navbar-nav > .open > a, .navbar-inverse .navbar-nav > .open > a:hover, .navbar-inverse .navbar-nav > .open > a:focus { background-color: #080808; color: #fff; } @media (max-width: 767px) { .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header { border-color: #080808; } .navbar-inverse .navbar-nav .open .dropdown-menu .divider { background-color: #080808; } .navbar-inverse .navbar-nav .open .dropdown-menu > li > a { color: #9d9d9d; } .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover, .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus { color: #fff; background-color: transparent; } .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a, .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover, .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus { color: #fff; background-color: #080808; } .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a, .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover, .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus { color: #444; background-color: transparent; } } .navbar-inverse .navbar-link { color: #9d9d9d; } .navbar-inverse .navbar-link:hover { color: #fff; } .navbar-inverse .btn-link { color: #9d9d9d; } .navbar-inverse .btn-link:hover, .navbar-inverse .btn-link:focus { color: #fff; } .navbar-inverse .btn-link[disabled]:hover, fieldset[disabled] .navbar-inverse .btn-link:hover, .navbar-inverse .btn-link[disabled]:focus, fieldset[disabled] .navbar-inverse .btn-link:focus { color: #444; } .breadcrumb { padding: 8px 15px; margin-bottom: 20px; list-style: none; background-color: #f5f5f5; border-radius: 4px; } .breadcrumb > li { display: inline-block; } .breadcrumb > li + li:before { content: \"/\\00a0\"; padding: 0 5px; color: #ccc; } .breadcrumb > .active { color: #777777; } .pagination { display: inline-block; padding-left: 0; margin: 20px 0; border-radius: 4px; } .pagination > li { display: inline; } .pagination > li > a, .pagination > li > span { position: relative; float: left; padding: 6px 12px; line-height: 1.42857143; text-decoration: none; color: #337ab7; background-color: #fff; border: 1px solid #ddd; margin-left: -1px; } .pagination > li:first-child > a, .pagination > li:first-child > span { margin-left: 0; border-bottom-left-radius: 4px; border-top-left-radius: 4px; } .pagination > li:last-child > a, .pagination > li:last-child > span { border-bottom-right-radius: 4px; border-top-right-radius: 4px; } .pagination > li > a:hover, .pagination > li > span:hover, .pagination > li > a:focus, .pagination > li > span:focus { z-index: 2; color: #23527c; background-color: #eeeeee; border-color: #ddd; } .pagination > .active > a, .pagination > .active > span, .pagination > .active > a:hover, .pagination > .active > span:hover, .pagination > .active > a:focus, .pagination > .active > span:focus { z-index: 3; color: #fff; background-color: #337ab7; border-color: #337ab7; cursor: default; } .pagination > .disabled > span, .pagination > .disabled > span:hover, .pagination > .disabled > span:focus, .pagination > .disabled > a, .pagination > .disabled > a:hover, .pagination > .disabled > a:focus { color: #777777; background-color: #fff; border-color: #ddd; cursor: not-allowed; } .pagination-lg > li > a, .pagination-lg > li > span { padding: 10px 16px; font-size: 18px; line-height: 1.3333333; } .pagination-lg > li:first-child > a, .pagination-lg > li:first-child > span { border-bottom-left-radius: 6px; border-top-left-radius: 6px; } .pagination-lg > li:last-child > a, .pagination-lg > li:last-child > span { border-bottom-right-radius: 6px; border-top-right-radius: 6px; } .pagination-sm > li > a, .pagination-sm > li > span { padding: 5px 10px; font-size: 12px; line-height: 1.5; } .pagination-sm > li:first-child > a, .pagination-sm > li:first-child > span { border-bottom-left-radius: 3px; border-top-left-radius: 3px; } .pagination-sm > li:last-child > a, .pagination-sm > li:last-child > span { border-bottom-right-radius: 3px; border-top-right-radius: 3px; } .pager { padding-left: 0; margin: 20px 0; list-style: none; text-align: center; } .pager li { display: inline; } .pager li > a, .pager li > span { display: inline-block; padding: 5px 14px; background-color: #fff; border: 1px solid #ddd; border-radius: 15px; } .pager li > a:hover, .pager li > a:focus { text-decoration: none; background-color: #eeeeee; } .pager .next > a, .pager .next > span { float: right; } .pager .previous > a, .pager .previous > span { float: left; } .pager .disabled > a, .pager .disabled > a:hover, .pager .disabled > a:focus, .pager .disabled > span { color: #777777; background-color: #fff; cursor: not-allowed; } .label { display: inline; padding: .2em .6em .3em; font-size: 75%; font-weight: bold; line-height: 1; color: #fff; text-align: center; white-space: nowrap; vertical-align: baseline; border-radius: .25em; } a.label:hover, a.label:focus { color: #fff; text-decoration: none; cursor: pointer; } .label:empty { display: none; } .btn .label { position: relative; top: -1px; } .label-default { background-color: #777777; } .label-default[href]:hover, .label-default[href]:focus { background-color: #5e5e5e; } .label-primary { background-color: #337ab7; } .label-primary[href]:hover, .label-primary[href]:focus { background-color: #286090; } .label-success { background-color: #5cb85c; } .label-success[href]:hover, .label-success[href]:focus { background-color: #449d44; } .label-info { background-color: #5bc0de; } .label-info[href]:hover, .label-info[href]:focus { background-color: #31b0d5; } .label-warning { background-color: #f0ad4e; } .label-warning[href]:hover, .label-warning[href]:focus { background-color: #ec971f; } .label-danger { background-color: #d9534f; } .label-danger[href]:hover, .label-danger[href]:focus { background-color: #c9302c; } .badge { display: inline-block; min-width: 10px; padding: 3px 7px; font-size: 12px; font-weight: bold; color: #fff; line-height: 1; vertical-align: middle; white-space: nowrap; text-align: center; background-color: #777777; border-radius: 10px; } .badge:empty { display: none; } .btn .badge { position: relative; top: -1px; } .btn-xs .badge, .btn-group-xs > .btn .badge { top: 0; padding: 1px 5px; } a.badge:hover, a.badge:focus { color: #fff; text-decoration: none; cursor: pointer; } .list-group-item.active > .badge, .nav-pills > .active > a > .badge { color: #337ab7; background-color: #fff; } .list-group-item > .badge { float: right; } .list-group-item > .badge + .badge { margin-right: 5px; } .nav-pills > li > a > .badge { margin-left: 3px; } .jumbotron { padding-top: 30px; padding-bottom: 30px; margin-bottom: 30px; color: inherit; background-color: #eeeeee; } .jumbotron h1, .jumbotron .h1 { color: inherit; } .jumbotron p { margin-bottom: 15px; font-size: 21px; font-weight: 200; } .jumbotron > hr { border-top-color: #d5d5d5; } .container .jumbotron, .container-fluid .jumbotron { border-radius: 6px; padding-left: 15px; padding-right: 15px; } .jumbotron .container { max-width: 100%; } @media screen and (min-width: 768px) { .jumbotron { padding-top: 48px; padding-bottom: 48px; } .container .jumbotron, .container-fluid .jumbotron { padding-left: 60px; padding-right: 60px; } .jumbotron h1, .jumbotron .h1 { font-size: 63px; } } .thumbnail { display: block; padding: 4px; margin-bottom: 20px; line-height: 1.42857143; background-color: #fff; border: 1px solid #ddd; border-radius: 4px; transition: border 0.2s ease-in-out; } .thumbnail > img, .thumbnail a > img { margin-left: auto; margin-right: auto; } a.thumbnail:hover, a.thumbnail:focus, a.thumbnail.active { border-color: #337ab7; } .thumbnail .caption { padding: 9px; color: #333333; } .alert { padding: 15px; margin-bottom: 20px; border: 1px solid transparent; border-radius: 4px; } .alert h4 { margin-top: 0; color: inherit; } .alert .alert-link { font-weight: bold; } .alert > p, .alert > ul { margin-bottom: 0; } .alert > p + p { margin-top: 5px; } .alert-dismissable, .alert-dismissible { padding-right: 35px; } .alert-dismissable .close, .alert-dismissible .close { position: relative; top: -2px; right: -21px; color: inherit; } .alert-success { background-color: #dff0d8; border-color: #d6e9c6; color: #3c763d; } .alert-success hr { border-top-color: #c9e2b3; } .alert-success .alert-link { color: #2b542c; } .alert-info { background-color: #d9edf7; border-color: #bce8f1; color: #31708f; } .alert-info hr { border-top-color: #a6e1ec; } .alert-info .alert-link { color: #245269; } .alert-warning { background-color: #fcf8e3; border-color: #faebcc; color: #8a6d3b; } .alert-warning hr { border-top-color: #f7e1b5; } .alert-warning .alert-link { color: #66512c; } .alert-danger { background-color: #f2dede; border-color: #ebccd1; color: #a94442; } .alert-danger hr { border-top-color: #e4b9c0; } .alert-danger .alert-link { color: #843534; } @-webkit-keyframes progress-bar-stripes { from { background-position: 40px 0; } to { background-position: 0 0; } } @keyframes progress-bar-stripes { from { background-position: 40px 0; } to { background-position: 0 0; } } .progress { overflow: hidden; height: 20px; margin-bottom: 20px; background-color: #f5f5f5; border-radius: 4px; box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1); } .progress-bar { float: left; width: 0%; height: 100%; font-size: 12px; line-height: 20px; color: #fff; text-align: center; background-color: #337ab7; box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15); transition: width 0.6s ease; } .progress-striped .progress-bar, .progress-bar-striped { background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent); background-size: 40px 40px; } .progress.active .progress-bar, .progress-bar.active { -webkit-animation: progress-bar-stripes 2s linear infinite; animation: progress-bar-stripes 2s linear infinite; } .progress-bar-success { background-color: #5cb85c; } .progress-striped .progress-bar-success { background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent); } .progress-bar-info { background-color: #5bc0de; } .progress-striped .progress-bar-info { background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent); } .progress-bar-warning { background-color: #f0ad4e; } .progress-striped .progress-bar-warning { background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent); } .progress-bar-danger { background-color: #d9534f; } .progress-striped .progress-bar-danger { background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent); } .media { margin-top: 15px; } .media:first-child { margin-top: 0; } .media, .media-body { zoom: 1; overflow: hidden; } .media-body { width: 10000px; } .media-object { display: block; } .media-object.img-thumbnail { max-width: none; } .media-right, .media > .pull-right { padding-left: 10px; } .media-left, .media > .pull-left { padding-right: 10px; } .media-left, .media-right, .media-body { display: table-cell; vertical-align: top; } .media-middle { vertical-align: middle; } .media-bottom { vertical-align: bottom; } .media-heading { margin-top: 0; margin-bottom: 5px; } .media-list { padding-left: 0; list-style: none; } .list-group { margin-bottom: 20px; padding-left: 0; } .list-group-item { position: relative; display: block; padding: 10px 15px; margin-bottom: -1px; background-color: #fff; border: 1px solid #ddd; } .list-group-item:first-child { border-top-right-radius: 4px; border-top-left-radius: 4px; } .list-group-item:last-child { margin-bottom: 0; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; } a.list-group-item, button.list-group-item { color: #555; } a.list-group-item .list-group-item-heading, button.list-group-item .list-group-item-heading { color: #333; } a.list-group-item:hover, button.list-group-item:hover, a.list-group-item:focus, button.list-group-item:focus { text-decoration: none; color: #555; background-color: #f5f5f5; } button.list-group-item { width: 100%; text-align: left; } .list-group-item.disabled, .list-group-item.disabled:hover, .list-group-item.disabled:focus { background-color: #eeeeee; color: #777777; cursor: not-allowed; } .list-group-item.disabled .list-group-item-heading, .list-group-item.disabled:hover .list-group-item-heading, .list-group-item.disabled:focus .list-group-item-heading { color: inherit; } .list-group-item.disabled .list-group-item-text, .list-group-item.disabled:hover .list-group-item-text, .list-group-item.disabled:focus .list-group-item-text { color: #777777; } .list-group-item.active, .list-group-item.active:hover, .list-group-item.active:focus { z-index: 2; color: #fff; background-color: #337ab7; border-color: #337ab7; } .list-group-item.active .list-group-item-heading, .list-group-item.active:hover .list-group-item-heading, .list-group-item.active:focus .list-group-item-heading, .list-group-item.active .list-group-item-heading > small, .list-group-item.active:hover .list-group-item-heading > small, .list-group-item.active:focus .list-group-item-heading > small, .list-group-item.active .list-group-item-heading > .small, .list-group-item.active:hover .list-group-item-heading > .small, .list-group-item.active:focus .list-group-item-heading > .small { color: inherit; } .list-group-item.active .list-group-item-text, .list-group-item.active:hover .list-group-item-text, .list-group-item.active:focus .list-group-item-text { color: #c7ddef; } .list-group-item-success { color: #3c763d; background-color: #dff0d8; } a.list-group-item-success, button.list-group-item-success { color: #3c763d; } a.list-group-item-success .list-group-item-heading, button.list-group-item-success .list-group-item-heading { color: inherit; } a.list-group-item-success:hover, button.list-group-item-success:hover, a.list-group-item-success:focus, button.list-group-item-success:focus { color: #3c763d; background-color: #d0e9c6; } a.list-group-item-success.active, button.list-group-item-success.active, a.list-group-item-success.active:hover, button.list-group-item-success.active:hover, a.list-group-item-success.active:focus, button.list-group-item-success.active:focus { color: #fff; background-color: #3c763d; border-color: #3c763d; } .list-group-item-info { color: #31708f; background-color: #d9edf7; } a.list-group-item-info, button.list-group-item-info { color: #31708f; } a.list-group-item-info .list-group-item-heading, button.list-group-item-info .list-group-item-heading { color: inherit; } a.list-group-item-info:hover, button.list-group-item-info:hover, a.list-group-item-info:focus, button.list-group-item-info:focus { color: #31708f; background-color: #c4e3f3; } a.list-group-item-info.active, button.list-group-item-info.active, a.list-group-item-info.active:hover, button.list-group-item-info.active:hover, a.list-group-item-info.active:focus, button.list-group-item-info.active:focus { color: #fff; background-color: #31708f; border-color: #31708f; } .list-group-item-warning { color: #8a6d3b; background-color: #fcf8e3; } a.list-group-item-warning, button.list-group-item-warning { color: #8a6d3b; } a.list-group-item-warning .list-group-item-heading, button.list-group-item-warning .list-group-item-heading { color: inherit; } a.list-group-item-warning:hover, button.list-group-item-warning:hover, a.list-group-item-warning:focus, button.list-group-item-warning:focus { color: #8a6d3b; background-color: #faf2cc; } a.list-group-item-warning.active, button.list-group-item-warning.active, a.list-group-item-warning.active:hover, button.list-group-item-warning.active:hover, a.list-group-item-warning.active:focus, button.list-group-item-warning.active:focus { color: #fff; background-color: #8a6d3b; border-color: #8a6d3b; } .list-group-item-danger { color: #a94442; background-color: #f2dede; } a.list-group-item-danger, button.list-group-item-danger { color: #a94442; } a.list-group-item-danger .list-group-item-heading, button.list-group-item-danger .list-group-item-heading { color: inherit; } a.list-group-item-danger:hover, button.list-group-item-danger:hover, a.list-group-item-danger:focus, button.list-group-item-danger:focus { color: #a94442; background-color: #ebcccc; } a.list-group-item-danger.active, button.list-group-item-danger.active, a.list-group-item-danger.active:hover, button.list-group-item-danger.active:hover, a.list-group-item-danger.active:focus, button.list-group-item-danger.active:focus { color: #fff; background-color: #a94442; border-color: #a94442; } .list-group-item-heading { margin-top: 0; margin-bottom: 5px; } .list-group-item-text { margin-bottom: 0; line-height: 1.3; } .panel { margin-bottom: 20px; background-color: #fff; border: 1px solid transparent; border-radius: 4px; box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05); } .panel-body { padding: 15px; } .panel-heading { padding: 10px 15px; border-bottom: 1px solid transparent; border-top-right-radius: 3px; border-top-left-radius: 3px; } .panel-heading > .dropdown .dropdown-toggle { color: inherit; } .panel-title { margin-top: 0; margin-bottom: 0; font-size: 16px; color: inherit; } .panel-title > a, .panel-title > small, .panel-title > .small, .panel-title > small > a, .panel-title > .small > a { color: inherit; } .panel-footer { padding: 10px 15px; background-color: #f5f5f5; border-top: 1px solid #ddd; border-bottom-right-radius: 3px; border-bottom-left-radius: 3px; } .panel > .list-group, .panel > .panel-collapse > .list-group { margin-bottom: 0; } .panel > .list-group .list-group-item, .panel > .panel-collapse > .list-group .list-group-item { border-width: 1px 0; border-radius: 0; } .panel > .list-group:first-child .list-group-item:first-child, .panel > .panel-collapse > .list-group:first-child .list-group-item:first-child { border-top: 0; border-top-right-radius: 3px; border-top-left-radius: 3px; } .panel > .list-group:last-child .list-group-item:last-child, .panel > .panel-collapse > .list-group:last-child .list-group-item:last-child { border-bottom: 0; border-bottom-right-radius: 3px; border-bottom-left-radius: 3px; } .panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child { border-top-right-radius: 0; border-top-left-radius: 0; } .panel-heading + .list-group .list-group-item:first-child { border-top-width: 0; } .list-group + .panel-footer { border-top-width: 0; } .panel > .table, .panel > .table-responsive > .table, .panel > .panel-collapse > .table { margin-bottom: 0; } .panel > .table caption, .panel > .table-responsive > .table caption, .panel > .panel-collapse > .table caption { padding-left: 15px; padding-right: 15px; } .panel > .table:first-child, .panel > .table-responsive:first-child > .table:first-child { border-top-right-radius: 3px; border-top-left-radius: 3px; } .panel > .table:first-child > thead:first-child > tr:first-child, .panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child, .panel > .table:first-child > tbody:first-child > tr:first-child, .panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child { border-top-left-radius: 3px; border-top-right-radius: 3px; } .panel > .table:first-child > thead:first-child > tr:first-child td:first-child, .panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child, .panel > .table:first-child > tbody:first-child > tr:first-child td:first-child, .panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child, .panel > .table:first-child > thead:first-child > tr:first-child th:first-child, .panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child, .panel > .table:first-child > tbody:first-child > tr:first-child th:first-child, .panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child { border-top-left-radius: 3px; } .panel > .table:first-child > thead:first-child > tr:first-child td:last-child, .panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child, .panel > .table:first-child > tbody:first-child > tr:first-child td:last-child, .panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child, .panel > .table:first-child > thead:first-child > tr:first-child th:last-child, .panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child, .panel > .table:first-child > tbody:first-child > tr:first-child th:last-child, .panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child { border-top-right-radius: 3px; } .panel > .table:last-child, .panel > .table-responsive:last-child > .table:last-child { border-bottom-right-radius: 3px; border-bottom-left-radius: 3px; } .panel > .table:last-child > tbody:last-child > tr:last-child, .panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child, .panel > .table:last-child > tfoot:last-child > tr:last-child, .panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child { border-bottom-left-radius: 3px; border-bottom-right-radius: 3px; } .panel > .table:last-child > tbody:last-child > tr:last-child td:first-child, .panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child, .panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child, .panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child, .panel > .table:last-child > tbody:last-child > tr:last-child th:first-child, .panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child, .panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child, .panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child { border-bottom-left-radius: 3px; } .panel > .table:last-child > tbody:last-child > tr:last-child td:last-child, .panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child, .panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child, .panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child, .panel > .table:last-child > tbody:last-child > tr:last-child th:last-child, .panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child, .panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child, .panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child { border-bottom-right-radius: 3px; } .panel > .panel-body + .table, .panel > .panel-body + .table-responsive, .panel > .table + .panel-body, .panel > .table-responsive + .panel-body { border-top: 1px solid #ddd; } .panel > .table > tbody:first-child > tr:first-child th, .panel > .table > tbody:first-child > tr:first-child td { border-top: 0; } .panel > .table-bordered, .panel > .table-responsive > .table-bordered { border: 0; } .panel > .table-bordered > thead > tr > th:first-child, .panel > .table-responsive > .table-bordered > thead > tr > th:first-child, .panel > .table-bordered > tbody > tr > th:first-child, .panel > .table-responsive > .table-bordered > tbody > tr > th:first-child, .panel > .table-bordered > tfoot > tr > th:first-child, .panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child, .panel > .table-bordered > thead > tr > td:first-child, .panel > .table-responsive > .table-bordered > thead > tr > td:first-child, .panel > .table-bordered > tbody > tr > td:first-child, .panel > .table-responsive > .table-bordered > tbody > tr > td:first-child, .panel > .table-bordered > tfoot > tr > td:first-child, .panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child { border-left: 0; } .panel > .table-bordered > thead > tr > th:last-child, .panel > .table-responsive > .table-bordered > thead > tr > th:last-child, .panel > .table-bordered > tbody > tr > th:last-child, .panel > .table-responsive > .table-bordered > tbody > tr > th:last-child, .panel > .table-bordered > tfoot > tr > th:last-child, .panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child, .panel > .table-bordered > thead > tr > td:last-child, .panel > .table-responsive > .table-bordered > thead > tr > td:last-child, .panel > .table-bordered > tbody > tr > td:last-child, .panel > .table-responsive > .table-bordered > tbody > tr > td:last-child, .panel > .table-bordered > tfoot > tr > td:last-child, .panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child { border-right: 0; } .panel > .table-bordered > thead > tr:first-child > td, .panel > .table-responsive > .table-bordered > thead > tr:first-child > td, .panel > .table-bordered > tbody > tr:first-child > td, .panel > .table-responsive > .table-bordered > tbody > tr:first-child > td, .panel > .table-bordered > thead > tr:first-child > th, .panel > .table-responsive > .table-bordered > thead > tr:first-child > th, .panel > .table-bordered > tbody > tr:first-child > th, .panel > .table-responsive > .table-bordered > tbody > tr:first-child > th { border-bottom: 0; } .panel > .table-bordered > tbody > tr:last-child > td, .panel > .table-responsive > .table-bordered > tbody > tr:last-child > td, .panel > .table-bordered > tfoot > tr:last-child > td, .panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td, .panel > .table-bordered > tbody > tr:last-child > th, .panel > .table-responsive > .table-bordered > tbody > tr:last-child > th, .panel > .table-bordered > tfoot > tr:last-child > th, .panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th { border-bottom: 0; } .panel > .table-responsive { border: 0; margin-bottom: 0; } .panel-group { margin-bottom: 80px; } .panel-group .panel { margin-bottom: 0; border-radius: 4px; } .panel-group .panel + .panel { margin-top: 5px; } .panel-group .panel-heading { border-bottom: 0; } .panel-group .panel-heading + .panel-collapse > .panel-body, .panel-group .panel-heading + .panel-collapse > .list-group { border-top: 1px solid #ddd; } .panel-group .panel-footer { border-top: 0; } .panel-group .panel-footer + .panel-collapse .panel-body { border-bottom: 1px solid #ddd; } .panel-default { border-color: #ddd; } .panel-default > .panel-heading { color: #333333; background-color: #f5f5f5; border-color: #ddd; } .panel-default > .panel-heading + .panel-collapse > .panel-body { border-top-color: #ddd; } .panel-default > .panel-heading .badge { color: #f5f5f5; background-color: #333333; } .panel-default > .panel-footer + .panel-collapse > .panel-body { border-bottom-color: #ddd; } .panel-primary { border-color: #337ab7; } .panel-primary > .panel-heading { color: #fff; background-color: #337ab7; border-color: #337ab7; } .panel-primary > .panel-heading + .panel-collapse > .panel-body { border-top-color: #337ab7; } .panel-primary > .panel-heading .badge { color: #337ab7; background-color: #fff; } .panel-primary > .panel-footer + .panel-collapse > .panel-body { border-bottom-color: #337ab7; } .panel-success { border-color: #d6e9c6; } .panel-success > .panel-heading { color: #3c763d; background-color: #dff0d8; border-color: #d6e9c6; } .panel-success > .panel-heading + .panel-collapse > .panel-body { border-top-color: #d6e9c6; } .panel-success > .panel-heading .badge { color: #dff0d8; background-color: #3c763d; } .panel-success > .panel-footer + .panel-collapse > .panel-body { border-bottom-color: #d6e9c6; } .panel-info { border-color: #bce8f1; } .panel-info > .panel-heading { color: #31708f; background-color: #d9edf7; border-color: #bce8f1; } .panel-info > .panel-heading + .panel-collapse > .panel-body { border-top-color: #bce8f1; } .panel-info > .panel-heading .badge { color: #d9edf7; background-color: #31708f; } .panel-info > .panel-footer + .panel-collapse > .panel-body { border-bottom-color: #bce8f1; } .panel-warning { border-color: #faebcc; } .panel-warning > .panel-heading { color: #8a6d3b; background-color: #fcf8e3; border-color: #faebcc; } .panel-warning > .panel-heading + .panel-collapse > .panel-body { border-top-color: #faebcc; } .panel-warning > .panel-heading .badge { color: #fcf8e3; background-color: #8a6d3b; } .panel-warning > .panel-footer + .panel-collapse > .panel-body { border-bottom-color: #faebcc; } .panel-danger { border-color: #ebccd1; } .panel-danger > .panel-heading { color: #a94442; background-color: #f2dede; border-color: #ebccd1; } .panel-danger > .panel-heading + .panel-collapse > .panel-body { border-top-color: #ebccd1; } .panel-danger > .panel-heading .badge { color: #f2dede; background-color: #a94442; } .panel-danger > .panel-footer + .panel-collapse > .panel-body { border-bottom-color: #ebccd1; }"}],"posts":[{"title":"Dijkstra's Algorithm in 5 steps with Python","slug":"dijkstra-algorithm-python","date":"2022-01-11T08:01:34.000Z","updated":"2022-01-12T13:27:13.064Z","comments":true,"path":"2022/01/11/dijkstra-algorithm-python/","link":"","permalink":"https://rogerspy.gitee.io/2022/01/11/dijkstra-algorithm-python/","excerpt":"1. 前言Dijkstra’s 是最广为人知的图算法之一，同时也是最难发音和拼写的图算法。Dijkstra’s 算法是最短路径算法，在它的基础上还衍生出很多其他变种。本文将介绍两种 Dijkstra’s 算法，并以邻接表为例用 python 实现。","text":"1. 前言Dijkstra’s 是最广为人知的图算法之一，同时也是最难发音和拼写的图算法。Dijkstra’s 算法是最短路径算法，在它的基础上还衍生出很多其他变种。本文将介绍两种 Dijkstra’s 算法，并以邻接表为例用 python 实现。 Dijkstra’s 算法伪代码如下： 创建一个“距离”列表，元素个数等于图节点数。每个元素初始化无穷大； 将起始节点的“距离”设置为 0； 创建一个“访问”列表，同样将元素个数设定为图节点数。将每个元素设置成 Fasle，因为我们还没有开始访问节点； 遍历所有节点： 再次遍历所有节点，然后从还没有访问的节点中挑选出距离最小的节点； 将节点设置成已访问； 将“距离”列表中的距离设置成相应的距离数值。 原始的“距离”列表现在应该已经包含了到每个节点的最短路径，或者如果节点无法到达的话距离为无穷大。 2. 邻接表图 假设你已经装了 numpy。 首先创建一个有 5 个节点的邻接表： 123456789import numpy as npgraph = &#123; 0: [(1, 1)], 1: [(0, 1), (2, 2), (3, 3)], 2: [(1, 2), (3, 1), (4, 5)], 3: [(1, 3), (2, 1), (4, 1)], 4: [(2, 5), (3, 1)]&#125; 3. 用 python 实现原生 Dijkstra’s首先先实现原生的 Dijkstra’s 算法，这种实现的算法复杂度是 $O(n^2)$。创建一个函数接收两个参数：邻接表和根节点。 首先创建一个距离列表，初始化为无穷大： 123456def naive_dijkstras(graph, root): n = len(graph) # 将距离列表中的所有元素初始化成无穷大 # 这里无穷大使用的是 np.Inf，而不是设置成一个很大的数 # 因为一个很大的数可能造成内存泄露 dist = [np.Inf for _ in range(n)] 第二步，将根节点的距离设置成 0： 1dist[root] = 0 第三步，创建一个“访问”列表，将所有元素初始化为 False 1visited = [False for _ in range(n)] 第四步有三部分： ① 遍历所有节点然后挑选出距离最近的节点。如果遍历了所有的可用节点还没有找到最近的那个，那就跳出循环： 1234567891011# 遍历所有节点for _ in range(n): u = -1 # 初始节点设置成 -1 for i in range(n): # 如果节点 i 还没有被访问，我们不需要对它进行处理 # 或者如果它的距离小于 “start” 节点的时候 if not visited[i] and (u == -1 or dist[i] &lt; dist[u]): u = i # 访问了所有节点或者该节点无法到达 if dist[u] == np.Inf: break ② 将距离最近的节点添加到“访问”列表中： 1visited[u] = True ③ 将已访问的节点的距离设置成可用的最短距离： 123for v, l in graph(u): if dist[u] + 1 &lt; dist[v]: dist[v] = dist[u] + 1 最后，返回“距离”列表。 1return dist 完整的代码如下： 12345678910111213141516171819202122232425262728def naive_dijkstras(graph, root): n = len(graph) # 将距离列表中的所有元素初始化成无穷大 # 这里无穷大使用的是 np.Inf，而不是设置成一个很大的数 # 因为一个很大的数可能造成内存泄露 dist = [np.Inf for _ in range(n)] # 将根节点的距离设置成 0 dist[root] = 0 # 创建一个“访问”列表，将所有元素初始化为 False visited = [False for _ in range(n)] # 遍历所有节点 for _ in range(n): u = -1 # 初始节点设置成 -1 for i in range(n): # 如果节点 i 还没有被访问，我们不需要对它进行处理 # 或者如果它的距离小于 “start” 节点的时候 if not visited[i] and (u == -1 or dist[i] &lt; dist[u]): u = i # 访问了所有节点或者该节点无法到达 if dist[u] == np.Inf: break # 将节点设置成已访问 visited[u] = True # 将已访问的节点的距离设置成可用的最短距离 for v, l in graph(u): if dist[u] + l &lt; dist[v]: dist[v] = dist[u] + l return dist 运行上面的代码： 1234print(naive_dijkstras(graph,1))# 结果为[1, 0, 2, 3, 4] 4. 用 python 实现 Lazy Dijkstra’s原生版的 Dijkstra’s 我们已经实现了，现在我们来尝试 Lazy Dijkstra’s。为什么叫 “Lazy Dijkstra’s”?因为我们不再遍历所有的节点（上面第四步），这样我们可以更加高效的处理稀疏图（所谓稀疏图就是并非图中的每个点都与其他点相连）。这种实现的算法复杂度是 $O(n\\times\\log(n))$。 假设你已经装了 heapq。 前三步和之前是一样的： 12345def lazy_dijkstras(graph, root): n = len(graph) dist = [Inf for _ in range(n)] dist[root] = 0 visited = [False for _ in range(n)] 从第四步开始就与之前不同了： 首先给根节点插入一个距离 0： 1pq = [(0, root)] 将前面第四步的①和②合并： 12345while len(pq) &gt; 0: _, u = heapq.heappop(pq) if visited[u]: continue visited[u] = True 第四步的第三部分基本与之前一致： 1234for v, l in graph[u]: if dist[u] + l &lt; dist[v]: dist[v] = dist[u] + l heapq.heappush(pq, (dist[v], v)) 最后，返回“距离”列表。 完整代码如下： 12345678910111213141516def lazy_dijkstras(graph, root): n = len(graph) dist = [Inf for _ in range(n)] dist[root] = 0 visited = [False for _ in range(n)] pq = [(0, root)] while len(pq) &gt; 0: _, u = heapq.heappop(pq) if visited[u]: continue visited[u] = True for v, l in graph[u]: if dist[u] + l &lt; dist[v]: dist[v] = dist[u] + l heapq.heappush(pq, (dist[v], v)) return dist 5. ReferenceDijkstra’s Algorithm in 5 Steps with Python","categories":[{"name":"博客转载","slug":"博客转载","permalink":"https://rogerspy.gitee.io/categories/博客转载/"}],"tags":[{"name":"Dijkstra's Algorithm","slug":"dijkstra-s-algorithm","permalink":"https://rogerspy.gitee.io/tags/dijkstra-s-algorithm/"},{"name":"Graph Algorithm","slug":"graph-algorithm","permalink":"https://rogerspy.gitee.io/tags/graph-algorithm/"}]},{"title":"预训练语言模型：CVT","slug":"ptm-cvt","date":"2021-09-30T14:06:02.000Z","updated":"2022-01-17T10:51:02.433Z","comments":true,"path":"2021/09/30/ptm-cvt/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/30/ptm-cvt/","excerpt":"之前介绍的预训练模型都是将预训练过程和下游特定任务分成两阶段进行训练， Cross-View Training 将着来年各个阶段合并成一个统一的半监督学习过程：bi-LSTM 编码器通过有标注数据的监督学习和无标注数据的无监督学习同时训练。","text":"之前介绍的预训练模型都是将预训练过程和下游特定任务分成两阶段进行训练， Cross-View Training 将着来年各个阶段合并成一个统一的半监督学习过程：bi-LSTM 编码器通过有标注数据的监督学习和无标注数据的无监督学习同时训练。 1. 前言同时使用标注数据和无标注数据进行模型训练，这种训练方式是典型的半监督学习。CVT 引入半监督学习中的自学习机制（self-training）用于神经网络序列建模。 假设标注数据集和无标注数据集分别为 $D_{l}$ 和 $D_u$，经典的自学习机制过程如下： 首先从 $D_l$ 中训练一个模型 $M$； 然后将从 $D_u$ 中抽取部分数据 $D’_u$ 出来，用 $M$ 进行预测：$y’=M(D’_u)$； 将 $M$ 的预测结果 $y’$ 与 $D’_u$ 视为新的标注数据 $(D’_u, y’)$ 放进 $D_l$ 中； 重复上面的步骤，知道所有数据都变成 $D_l$。 自学习机制的缺点也很明显：一旦在第二步中出错，在以后的训练中错误会越来越深。在 CV 领域人们提出给无标注数据加噪声的方法，使模型泛化性得到了有效的提升。但是对于 NLP 这种离散序列数据来说，如何加噪声就变得很棘手了。 受多视角学习（multi-view learning） 的启发，CVT 增加了额外的预测模块用来对无标注数据进行预测。 2. Cross-View Training2.1 Method $D_l = \\{(x_1, y_1), (x_2, y_2),…,(x_N, y_N)\\}$ 表示标注数据； $D_u = \\{x_1, x_2,…,x_M\\}$ 表示无标注数据； $p_\\theta(y|x_i)$ 表示模型参数为 $\\theta$ 时，输入 $x_i$ 模型的输出结果。 在有标注的数据上，所有的模型参数都以标准的监督学习方式进行更新，模型的损失函数是标准的交叉熵损失函数： \\mathcal{L}_{\\text{sup}}(\\theta) = \\frac{1}{|D_l|} \\sum_{x_i,y_i \\in D_l} \\text{Cross-Entropy}(y_i, p_\\theta(y|x_i)) 在无标注的数据上： ① 首先用原始预测模块（primary prediction models）对无标注数据进行预测得：$p_\\theta(y|x_i)$； ② 然后用 $k$ 个附加预测模块（auxiliary prediction modules）将 $p_\\theta(y|x_i)$ 作为 ground truth，用加噪声的无标注数据进行预测，然后计算损失： \\mathcal{L}_{\\text{CVT}}(\\theta) = \\frac{1}{D_u} \\sum_{x_i\\in D_u} \\sum_{j=1}^k KL(p_\\theta(y|x_i), p_\\theta^j(y|x_i^j)) 最后，整个模型的损失为： \\mathcal{L} = \\mathcal{L}_{\\text{sup}} + \\mathcal{L}_{\\text{CVT}} 2.2 Multi-Task Learning对多任务同时进行训练时，CVT 增加了几个相应的原始预测模块。所有原始预测模块共享句子表示编码器。进行监督学习时，模型随机选择一个任务进行训练。此时，模型的句子表示编码器和任务预测器的参数会随着训练更新，与选定任务无关的预测器的参数不会更新。比如，同时训练分类和序列标注时，当模型随机选择分类任务进行训练时，序列标注的预测器参数不会随训练更新。 当进行 CVT 学习时，模型的所有参数都会更新。比如训练分类任务和序列标注任务时，首先用原始预测模块分别预测类别 $c_1$ 和输出序列 $s_1$，然后以此为 ground truth，对 $x_i$ 进行加噪声，利用加噪声后的 $x_i^j$ 再分别预测类别 $c_1^j$ 和输出序列 $s_i^j$，然后分别计算 $(c_1, c_1^j)$ 和 $(s_1, s_1^j)$ 的损失，然后利用后向传播，对参数进行更新。 多任务学习可以使模型泛化能力得到加强，同时可以得到一个副产物：将所有无标注数据进行标注得到标注数据。 3. Cross-View Training Models由于 CVT 依赖的附加预测模块需要对输入进行加噪声，即限制输入的“视角”。下面我们介绍一些特定任务下，加噪声的方法。 需要注意的是：当原始预测模块有 dropout 的时候，在进行监督学习时可以让 dropout 正常工作，但是在进行无监督训练时 dropout 需要关闭。 3.1 Bi-LSTM 句子编码 输入： $x_i = [x_i^1, x_i^2, …, x_i^T]$； 词向量：$v = \\text{word embedding}(x_i) + \\text{CNN}(\\text{char}(x_i))$： $\\text{layer}-1 \\text{bi-LSTM}$：$h_1=\\text{bi-LSTM}(v)=[\\overrightarrow{h}{_1^1} \\oplus \\overleftarrow{h}{_1^1}, \\overrightarrow{h}{_1^2} \\oplus \\overleftarrow{h}{_1^2} …, \\overrightarrow{h}{_1^T} \\oplus \\overleftarrow{h}{_1^T}]$ ； $\\text{layer}-2 \\text{bi-LSTM}$：$h_2=\\text{bi-LSTM}(h_1)=[\\overrightarrow{h}_2^1 \\oplus \\overleftarrow{h}{_2^1}, \\overrightarrow{h}_2^2 \\oplus \\overleftarrow{h}{_2^2} …, \\overrightarrow{h}{_2^T} \\oplus \\overleftarrow{h}{_2^T}]$； 3.2 序列标注 序列标注任务（比如词性标注、命名实体识别）中，模型对序列中的每个词进行分类，预测模块包含一个全连接层和一个 softmax 层： \\begin{equation} \\nonumber \\begin{aligned} p(y^t|x_i) &= \\text{NN}(h_1^t \\oplus h_2^t) \\\\ &= \\text{softmax}(U\\cdot \\text{ReLU}(W(h_1^t \\oplus h_2^t)) + b) \\end{aligned} \\end{equation}在进行额外预测任务时，只给第一层 bi-LSTM 输入单向序列。因为这样的话，模型只观察到部分序列，就必须像语言模型那样对“未来”词进行预测： p{_\\theta}^\\text{fwd}(y^t|x_i) = \\text{NN}^\\text{fwd}(\\overrightarrow h{_1^t}(x_i))\\\\ p{_\\theta}^\\text{bwd}(y^t|x_i) = \\text{NN}^\\text{bwd}(\\overleftarrow h{_1^t}(x_i))\\\\ p{_\\theta}^\\text{futher}(y^t|x_i) = \\text{NN}^\\text{future}(\\overrightarrow h{_1^t}(x_i))\\\\ p{_\\theta}^\\text{past}(y^t|x_i) = \\text{NN}^\\text{past}(\\overleftarrow h{_1^t}(x_i))其中 forward 表示模型还没看到右侧的信息做出的预测，future 表示该词没有右侧或者该词本身信息做出的预测，两者的区别在于 forward 表示待预测的词右侧是有下文的，而 future 表示的是待预测的词右侧没有下文。 3.3 Dependency Parsing依存句法分析任务中，句子中的词被当做是图的节点。词与词之间用有向边进行连接，形成一棵用来描述语法结构的树。$y_i^t = (u, t, r)$ 表示 $x_i^u$ 与 $x_i^t$ 相连，他们的关系是 $r$。 p_\\theta((u,t,r)|x_i) \\propto e^{s(h_1^u(x_i) \\oplus h_2^u(x_i), h_1^t(x_i) \\oplus h_2^t(x_i), r)}其中 \\begin{equation} \\nonumber \\begin{aligned} s(z_1, z_2, r) = \\text{ReLU}(W_\\text{head}z_1 + b_\\text{head})\\cdot (W_r+W) \\cdot \\text{ReLU}(W_\\text{dep}z_2+b_\\text{dep}) \\end{aligned} \\end{equation}额外预测任务： p_\\theta^\\text{fwd-fwd}((u,t,r)|x_i) \\propto e^{s^\\text{fwd-fwd}(\\overrightarrow h{_1^u}(x_i), \\overrightarrow h{_1^t}(x_i), r)}\\\\ p_\\theta^\\text{fwd-bwd}((u,t,r)|x_i) \\propto e^{s^\\text{fwd-bwd}(\\overrightarrow h{_1^u}(x_i), \\overleftarrow h{_1^t}(x_i), r)}\\\\ p_\\theta^\\text{bwd-fwd}((u,t,r)|x_i) \\propto e^{s^\\text{bwd-fwd}(\\overleftarrow h{_1^u}(x_i), \\overrightarrow h{_1^t}(x_i), r)}\\\\ p_\\theta^\\text{bwd-bwd}((u,t,r)|x_i) \\propto e^{s^\\text{bwd-bwd}(\\overleftarrow h{_1^u}(x_i), \\overleftarrow h{_1^t}(x_i), r)}\\\\每一个句子都会丢失一部分上下文。 3.4 Sequence-to-Sequence Learning 源序列：$x_i = x_i^1,…x_i^T$； 目标序列：$y_i=y_i^1,…,y_i^K$； 注意力得分：$\\alpha_j \\propto e^{h^jW_\\alpha h^t}$； 注意力加权的源序列编码：$c_t = \\sum_j\\alpha_jh^j$； 隐状态：$a_t=\\tanh(W_a[c_t, h_t])$； 预测输出：$p(y_i^t|y_i^{&lt;t}, x_i)=\\text{softmax}(W_sa_t)$。 两个附加预测解码器，LSTM 权重共享，但是注意力权重和 softmax 权重是不同的： 对第一个解码器的注意力权重采用 dropout; 让第二个解码器预测目标序列的下一个词，而不是当前词： p_\\theta^\\text{future}(y_i^t|y_i^{","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"Language Model","slug":"language-model","permalink":"https://rogerspy.gitee.io/tags/language-model/"},{"name":"CVT","slug":"cvt","permalink":"https://rogerspy.gitee.io/tags/cvt/"}]},{"title":"预训练语言模型：Pre-trained seq2seq","slug":"ptm-pre-trained-seq2seq","date":"2021-09-17T07:57:24.000Z","updated":"2022-01-14T13:53:22.228Z","comments":true,"path":"2021/09/17/ptm-pre-trained-seq2seq/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/17/ptm-pre-trained-seq2seq/","excerpt":"之前我们介绍过 seq2seq 模型，通常用作机器翻译，通过编码器（encoder）对源语言进行编码，然后通过解码器（decoder）对编码器的结果进行解码，得到目标语言。原始的 seq2seq 模型是使用平行语料对模型从头开始进行训练，这种训练方式需要大量的平行语料。Prajit Ramachandran 提出一种方法，可以大幅降低平行语料的需求量：先分别使用源语言和目标语言预训练两个语言模型，然后将语言模型的权重用来分别初始化编码器和解码器，最终取得了 SOTA 的结果。","text":"之前我们介绍过 seq2seq 模型，通常用作机器翻译，通过编码器（encoder）对源语言进行编码，然后通过解码器（decoder）对编码器的结果进行解码，得到目标语言。原始的 seq2seq 模型是使用平行语料对模型从头开始进行训练，这种训练方式需要大量的平行语料。Prajit Ramachandran 提出一种方法，可以大幅降低平行语料的需求量：先分别使用源语言和目标语言预训练两个语言模型，然后将语言模型的权重用来分别初始化编码器和解码器，最终取得了 SOTA 的结果。 1. Method1.1 Basic Procedure给定输入序列 $x_1, x_2, …, x_m$，seq2seq 的目的是最大化： p(y_n, y_{n-1}, ..., y_1|x_1, x_2,...x_m) = \\prod_{t=1}^n p(y_t|y_{t-1},...,y_1;x_1, x_2,...,x_m)seq2seq 模型是使用编码器（RNN）将 $x_1, x_2, …, x_m$ 表示成一个隐向量，然后将隐向量传递给解码器进行序列解码。我们的方法是将编码器和解码器都当做 RNN 语言模型进行使用大量的语料进行预训练。 两个语言模型训练完成以后，将两个语言模型的权重用来初始化编码器和解码器。为了方便起见，解码器的 $\\text{softmax}$ 使用目标语言的语言模型的 $\\text{softmax}$ 进行初始化。 1.2 Monolingual language modeling losses使用语言模型初始化 seq2seq 以后，再用平行语料进行 fine-tuning。根据 Goodfellow et al. 2013 的研究，fine-tuning 过程很容易造成灾难性遗忘（catastrophic forgetting），使得模型在语言模型上的性能急剧下降，损害模型的泛化能力。 为了保证模型在平行语料上不会过拟合，在fine-tuning 阶段继续训练语言模型任务，seq2seq 和 语言模型任务的损失等权相加作为最终损失。 1.3 Other improvements to the model预训练和损失叠加机制能大幅提升模型性能，但是我们发现另外两个可以小幅提升模型能力的技巧： 残差连接； 多层注意力。 2. Experiments Reference Unsupervised Pretraining for Sequence to Sequence Learning, Prajit Ramachandran, Peter J. Liu and Quoc V. Le 2017, arxiv: 1611.02683 An empirical investigation of catastrophic forgetting in gradient-based neural networks, Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. 2013. arXiv preprint arXiv:1312.6211","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"Language Model","slug":"language-model","permalink":"https://rogerspy.gitee.io/tags/language-model/"},{"name":"pre-trained seq2seq","slug":"pre-trained-seq2seq","permalink":"https://rogerspy.gitee.io/tags/pre-trained-seq2seq/"}]},{"title":"预训练语言模型：Data noising smoothing","slug":"ptm-data-noising-as-smoothing","date":"2021-09-15T13:12:22.000Z","updated":"2022-01-14T07:55:02.504Z","comments":true,"path":"2021/09/15/ptm-data-noising-as-smoothing/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/15/ptm-data-noising-as-smoothing/","excerpt":"数据噪化（data noising）是一种非常有效的神经网络正则化的有段，通常被用在语音和视觉领域，但是在离散序列化数据（比如语言模型）上很少应用。本文尝试探讨给神经网络语言模型加噪声与 n-gram 语言模型中的平滑之间的联系，然后利用这种联系设计出一种噪声机制，帮助我们对语言进行建模。","text":"数据噪化（data noising）是一种非常有效的神经网络正则化的有段，通常被用在语音和视觉领域，但是在离散序列化数据（比如语言模型）上很少应用。本文尝试探讨给神经网络语言模型加噪声与 n-gram 语言模型中的平滑之间的联系，然后利用这种联系设计出一种噪声机制，帮助我们对语言进行建模。 1. 前言给定一个序列：$X=(x_1, x_2, …, x_T)$，词表 $V$。我们可以对序列进行建模： p(X)=\\prod_{t=1}^T p(x_t|x_{","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"Language Model","slug":"language-model","permalink":"https://rogerspy.gitee.io/tags/language-model/"},{"name":"data noising","slug":"data-noising","permalink":"https://rogerspy.gitee.io/tags/data-noising/"}]},{"title":"深入理解 einsum：实现多头注意力机制","slug":"einsum-mhsa","date":"2021-09-12T02:45:06.000Z","updated":"2022-01-12T08:37:38.374Z","comments":true,"path":"2021/09/12/einsum-mhsa/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/12/einsum-mhsa/","excerpt":"Einsum 表示法是对张量的复杂操作的一种优雅方式，本质上是使用特定领域的语言。 一旦理解并掌握了 einsum，可以帮助我们更快地编写更简洁高效的代码。","text":"Einsum 表示法是对张量的复杂操作的一种优雅方式，本质上是使用特定领域的语言。 一旦理解并掌握了 einsum，可以帮助我们更快地编写更简洁高效的代码。 Einsum 是爱因斯坦求和（Einstein summation）的缩写，是一种求和的方法，在处理关于坐标的方程式时非常有效。在 numpy、TensorFlow 和 Pytorch 中都有相关实现，本文通过 Pytorch 实现 Transformer 中的多头注意力来介绍 einsum 在深度学习模型中的应用。 1. 矩阵乘法假设有两个矩阵： A = \\left[\\begin{matrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{matrix} \\right] ,\\quad B = \\left[\\begin{matrix} 7 & 8 \\\\ 9 & 10 \\\\ 11 & 12 \\end{matrix} \\right]我们想求两个矩阵的乘积。 第一步： 第二步： 第三步： 第四步： 2. Einstein Notation爱因斯坦标记法又称爱因斯坦求和约定（Einstein summation convention），基本内容是： 当两个变量具有相同的角标时，则遍历求和。在此情况下，求和号可以省略。 比如，计算两个向量的乘积， $\\color{red}{a}, \\color{blue}{b} \\in \\mathbb{R}^I$： \\color{green}{c} = \\sum_i \\color{red}{a_i}\\color{blue}{b_i}=\\color{red}{a_i}\\color{blue}{b_i}计算两个矩阵的乘积， $A$ $\\in \\mathbb{R}^{I\\times K}$，$B$ $\\in \\mathbb{R}^{K\\times J}$。用爱因斯坦求和符号表示，可以写成： \\color{green}{c}_{ij} \\color{black}= \\sum_k\\color{red}{A_{ik}}\\color{blue}{B_{kj}}=\\color{red}{A_{ik}}\\color{blue}{B_{kj}}在深度学习中，通常使用的是更高阶的张量之间的变换。比如在一个 batch 中包含 $N$ 个训练样本的，最大长度是 $T$，词向量维度为 $K$ 的张量，即 $\\color{red}{\\mathcal{T}}\\in \\mathbb{R}^{N\\times T \\times K}$，如果想让词向量的维度映射到 $Q$ 维，则定义一个 $\\color{blue}{W} \\in \\mathbb{R}^{K\\times Q}$: \\color{green}{C_{ntq}} = \\sum_k\\color{red}{\\mathcal{T}_{ntk}}\\color{blue}{W_{kq}}=\\color{red}{\\mathcal{T}_{ntk}}\\color{blue}{W_{kq}}在图像处理中，通常在一个 batch 的训练样本中包含 $N$ 张图片，每张图片长为 $T$，宽为 $K$，颜色通道为 $M$，即 $\\color{red}{\\mathcal{T}}\\in \\mathbb{R}^{N\\times T \\times K \\times M}$ 是一个 4d 张量。如果我想进行三个操作： 将 $K$ 投影成 $Q$ 维； 对 $T$ 进行求和； 将 $M$ 和 $N$ 进行转置。 用爱因斯坦标记法可以表示成： \\color{green}{C_{mqn}}=\\sum_t \\sum_k \\color{red}{\\mathcal{T}_{ntkm}} \\color{blue}{W_{kq}} = \\color{red}{\\mathcal{T}_{ntkm}} \\color{blue}{W_{kq}}需要注意的是，爱因斯坦标记法是一种书写约定，是为了将复杂的公式写得更加简洁。它本身并不是某种运算符，具体运算还是要回归到各种算子上。 3. einsum Numpy：np.einsum Pytorch：torch.einsum TensorFlow：tf.einsum 以上三种 einsum 都有相同的特性 einsum(equation, operands)： equation：字符串，用来表示爱因斯坦求和标记法的； operands：一些列张量，要运算的张量。 其中 口 是一个占位符，代表的是张量维度的字符。比如： 1np.einsum(&apos;ij,jk-&gt;ik&apos;, A, B) A 和 B 是两个矩阵，将 ij,jk-&gt;ik 分成两部分：ij, jk 和 ik，那么 ij 代表的是输入矩阵 A 的第 i 维和第 j 维，jk 代表的是 B 第 j 维和第 k 维，ik 代表的是输出矩阵的第 i 维和第 k 维。注意 i, j, k 可以是任意的字符，但是必须保持一致。换句话说，einsum 实际上是直接操作了矩阵的维度（角标）。上例中表示的是， A 和 B 的乘积。 3.1 矩阵转置 B_{ji} = A_{ij}12345678import torcha = torch.arange(6).reshape(2, 3)torch.einsum('ij-&gt;ji', [a])# 输出tensor([[ 0., 3.], [ 1., 4.], [ 2., 5.]]) 3.2 求和 b = \\sum_i\\sum_j A_{ij}=A_{ij}12345a = torch.arange(6).reshape(2, 3)torch.einsum('ij-&gt;', [a])# 输出tensor(15.) 3.3 列求和 b_j=\\sum_iA_{ij}=A_{ij}12345a = torch.arange(6).reshape(2, 3)torch.einsum('ij-&gt;j', [a])# 输出tensor([ 3., 5., 7.]) 3.4 行求和 b_i=\\sum_jA_{ij}=A_{ij}12345a = torch.arange(6).reshape(2, 3)torch.einsum('ij-&gt;i', [a])# 输出tensor([ 3., 12.]) 3.5 矩阵-向量乘积 c_i=\\sum_kA_{ik}b_k=A_{ik}b_k123456a = torch.arange(6).reshape(2, 3)b = torch.arange(3)torch.einsum('ik,k-&gt;i', [a, b])# 输出tensor([ 5., 14.]) 3.6 矩阵-矩阵乘积 C_{ij}=\\sum_kA_{ik}B_{kj}=A_{ik}B_{kj}1234567a = torch.arange(6).reshape(2, 3)b = torch.arange(15).reshape(3, 5)torch.einsum('ik,kj-&gt;ij', [a, b])# 输出：tensor([[ 25., 28., 31., 34., 37.], [ 70., 82., 94., 106., 118.]]) 3.7 点积 c = \\sum_ia_ib_i=a_ib_i123456a = torch.arange(3)b = torch.arange(3, 6)torch.einsum('i,i-&gt;', [a, b])# 输出：tensor(14.) 3.8 Hardamard 积 C_{ij} = A_{ij}B_{ij}1234567a = torch.arange(6).reshape(2, 3)b = torch.arange(6,12).reshape(2, 3)torch.einsum('ij,ij-&gt;ij', [a, b])# 输出：tensor([[ 0., 7., 16.], [ 27., 40., 55.]]) 3.9 外积 C_{ij}=a_ib_j12345678a = torch.arange(3)b = torch.arange(3, 7)torch.einsum('i, j-&gt;ij', [a, b])# 输出：tensor([[ 0., 0., 0., 0.], [ 3., 4., 5., 6.], [ 6., 8., 10., 12.]]) 3.10 Batch 矩阵乘积 C_{ijl}=\\sum_kA_{ijk}B_{ikl}=A_{ijk}B_{ikl}12345678910111213a = torch.randn(3,2,5)b = torch.randn(3,5,3)torch.einsum('ijk, jkl-&gt;ijl', [a, b])# 输出：tensor([[[ 1.0886, 0.0214, 1.0690], [ 2.0626, 3.2655, -0.1465]], [[-6.9294, 0.7499, 1.2976], [ 4.2226, -4.5774, -4.8947]], [[-2.4289, -0.7804, 5.1385], [ 0.8003, 2.9425, 1.7338]]]) 3.11 张量收缩假设有两个张量 $\\mathcal{A}\\in \\mathbb{R}^{I_1\\times \\dots\\times I_n}$ 和 $\\mathcal{B} \\in \\mathbb{R}^{J_1\\times \\dots \\times J_m}$。比如 $n=4, m=5$，且 $I_2=J_3$ 和 $I_3=J_5$。我们可以计算两个张量的乘积，得到新的张量 $\\mathcal{C}\\in\\mathbb{R}^{I_1\\times I_4 \\times J_1 \\times J_2 \\times J_4}$： C_{pstuv}=\\sum_q\\sum_r A_{pqrs}B_{tuqvr} = A_{pqrs}B_{tuqvr}123456a = torch.randn(2,3,5,7)b = torch.randn(11,13,3,17,5)torch.einsum('pqrs,tuqvr-&gt;pstuv', [a, b]).shape# 输出torch.Size([2, 7, 11, 13, 17]) 3.12 双线性变换 D_{ij}=\\sum_k\\sum_lA_{ik}B_{jkl}C_{il} = A_{ik}B_{jkl}C_{il}12345678a = torch.randn(2,3)b = torch.randn(5,3,7)c = torch.randn(2,7)torch.einsum('ik,jkl,il-&gt;ij', [a, b, c])# 输出tensor([[ 3.8471, 4.7059, -3.0674, -3.2075, -5.2435], [-3.5961, -5.2622, -4.1195, 5.5899, 0.4632]]) 4. einops尽管 einops 是一个通用的包，这里哦我们只介绍 einops.rearrange 。同 einsum 一样，einops.rearrange 也是操作矩阵的角标的，只不过函数的参数正好相反，如下图所示。 • NOTE 如果 rearrange 传入的参数是一个张量列表，那么后面字符串的第一维表示列表的长度。 1234qkv = torch.rand(2,128,3*512) # dummy data for illustration only# We need to decompose to n=3 tensors q, v, k# rearrange tensor to [3, batch, tokens, dim] and cast to tupleq, k, v = tuple(rearrange( qkv , 'b t (d n) -&gt; n b t d ', n=3)) 5. Scale dot product self-attention 第一步：创建一个线性投影。给定输入 $X\\in \\mathbb{R}^{b\\times t\\times d}$，其中 $b$ 表示 $\\text{batch size}$，$t$ 表示 $\\text{sentence length}$，$d$ 表示 $\\text{word dimension}$。 Q=XW_Q, \\quad K=XW_K, \\quad V=XW_V12345to_qvk = nn.Linear(dim, dim * 3, bias=False) # init only# Step 1qkv = to_qvk(x) # [batch, tokens, dim*3 ]# decomposition to q,v,kq, k, v = tuple(rearrange(qkv, 'b t (d k) -&gt; k b t d ', k=3)) 第二步：计算点积，mask，最后计算 softmax。 \\text{dot_score} = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}} \\right)1234567# Step 2# Resulting shape: [batch, tokens, tokens]scaled_dot_prod = torch.einsum('b i d , b j d -&gt; b i j', q, k) * self.scale_factorif mask is not None: assert mask.shape == scaled_dot_prod.shape[1:] scaled_dot_prod = scaled_dot_prod.masked_fill(mask, -np.inf)attention = torch.softmax(scaled_dot_prod, dim=-1) 第三步：计算注意力得分与 $V$ 的乘积。 \\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}} \\right)V1torch.einsum('b i j , b j d -&gt; b i d', attention, v) 将上面三步综合起来： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import numpy as npimport torchfrom einops import rearrangefrom torch import nnclass SelfAttention(nn.Module): \"\"\" Implementation of plain self attention mechanism with einsum operations Paper: https://arxiv.org/abs/1706.03762 Blog: https://theaisummer.com/transformer/ \"\"\" def __init__(self, dim): \"\"\" Args: dim: for NLP it is the dimension of the embedding vector the last dimension size that will be provided in forward(x), where x is a 3D tensor \"\"\" super().__init__() # for Step 1 self.to_qvk = nn.Linear(dim, dim * 3, bias=False) # for Step 2 self.scale_factor = dim ** -0.5 # 1/np.sqrt(dim) def forward(self, x, mask=None): assert x.dim() == 3, '3D tensor must be provided' # Step 1 qkv = self.to_qvk(x) # [batch, tokens, dim*3 ] # decomposition to q,v,k # rearrange tensor to [3, batch, tokens, dim] and cast to tuple q, k, v = tuple(rearrange(qkv, 'b t (d k) -&gt; k b t d ', k=3)) # Step 2 # Resulting shape: [batch, tokens, tokens] scaled_dot_prod = torch.einsum('b i d , b j d -&gt; b i j', q, k) * self.scale_factor if mask is not None: assert mask.shape == scaled_dot_prod.shape[1:] scaled_dot_prod = scaled_dot_prod.masked_fill(mask, -np.inf) attention = torch.softmax(scaled_dot_prod, dim=-1) # Step 3 return torch.einsum('b i j , b j d -&gt; b i d', attention, v) 6. Multi-Head Self-Attention 第一步：为每一个头创建一个线性投影 $Q, K, V$。 12to_qvk = nn.Linear(dim, dim_head * heads * 3, bias=False) # init onlyqkv = self.to_qvk(x) 第二步：将 $Q, K, V$ 分解，并分配给每个头。 1234# Step 2# decomposition to q,v,k and cast to tuple# [3, batch, heads, tokens, dim_head]q, k, v = tuple(rearrange(qkv, 'b t (d k h) -&gt; k b h t d ', k=3, h=self.heads)) 第三步：计算注意力得分 1234567# Step 3# resulted shape will be: [batch, heads, tokens, tokens]scaled_dot_prod = torch.einsum('b h i d , b h j d -&gt; b h i j', q, k) * self.scale_factorif mask is not None: assert mask.shape == scaled_dot_prod.shape[2:] scaled_dot_prod = scaled_dot_prod.masked_fill(mask, -np.inf)attention = torch.softmax(scaled_dot_prod, dim=-1) 第四步：注意力得分与 $V$ 相乘 12# Step 4. Calc result per batch and per head hout = torch.einsum('b h i j , b h j d -&gt; b h i d', attention, v) 第五步：将所有的头合并 1out = rearrange(out, \"b h t d -&gt; b t (h d)\") 第六步：线性变换 123self.W_0 = nn.Linear( _dim, dim, bias=False) # init only# Step 6. Apply final linear transformation layerself.W_0(out) 最终实现 MHSA： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import numpy as npimport torchfrom einops import rearrangefrom torch import nnclass MultiHeadSelfAttention(nn.Module): def __init__(self, dim, heads=8, dim_head=None): \"\"\" Implementation of multi-head attention layer of the original transformer model. einsum and einops.rearrange is used whenever possible Args: dim: token's dimension, i.e. word embedding vector size heads: the number of distinct representations to learn dim_head: the dim of the head. In general dim_head&lt;dim. However, it may not necessary be (dim/heads) \"\"\" super().__init__() self.dim_head = (int(dim / heads)) if dim_head is None else dim_head _dim = self.dim_head * heads self.heads = heads self.to_qvk = nn.Linear(dim, _dim * 3, bias=False) self.W_0 = nn.Linear( _dim, dim, bias=False) self.scale_factor = self.dim_head ** -0.5 def forward(self, x, mask=None): assert x.dim() == 3 # Step 1 qkv = self.to_qvk(x) # [batch, tokens, dim*3*heads ] # Step 2 # decomposition to q,v,k and cast to tuple # the resulted shape before casting to tuple will be: # [3, batch, heads, tokens, dim_head] q, k, v = tuple(rearrange(qkv, 'b t (d k h) -&gt; k b h t d ', k=3, h=self.heads)) # Step 3 # resulted shape will be: [batch, heads, tokens, tokens] scaled_dot_prod = torch.einsum('b h i d , b h j d -&gt; b h i j', q, k) * self.scale_factor if mask is not None: assert mask.shape == scaled_dot_prod.shape[2:] scaled_dot_prod = scaled_dot_prod.masked_fill(mask, -np.inf) attention = torch.softmax(scaled_dot_prod, dim=-1) # Step 4. Calc result per batch and per head h out = torch.einsum('b h i j , b h j d -&gt; b h i d', attention, v) # Step 5. Re-compose: merge heads with dim_head d out = rearrange(out, \"b h t d -&gt; b t (h d)\") # Step 6. Apply final linear transformation layer return self.W_0(out) Reference Einstein Summation in Numpy, OLEXA BILANIUK A basic introduction to NumPy’s einsum, Alex Riley EINSUM IS ALL YOU NEED - EINSTEIN SUMMATION IN DEEP LEARNING, Tim Rocktäschel Understanding einsum for Deep learning: implement a transformer with multi-head self-attention from scratch, Nikolas Adaloglou","categories":[{"name":"博客转载","slug":"博客转载","permalink":"https://rogerspy.gitee.io/categories/博客转载/"}],"tags":[{"name":"einsum","slug":"einsum","permalink":"https://rogerspy.gitee.io/tags/einsum/"},{"name":"MHSA","slug":"mhsa","permalink":"https://rogerspy.gitee.io/tags/mhsa/"}]},{"title":"预训练语言模型：context2vec","slug":"ptm-context2vec","date":"2021-09-09T15:31:32.000Z","updated":"2022-01-12T08:37:38.399Z","comments":true,"path":"2021/09/09/ptm-context2vec/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/09/ptm-context2vec/","excerpt":"上下文的向量表示在许多 NLP 任务中都有至关重要的作用，比如词义消歧、命名实体识别、指代消解等等。以前的方法多是直接用离散上下文词向量组合，缺乏对上下文整体的优化表示方法。本文提出一种双向 LSTM 模型，有效学习句子上下文表征。","text":"上下文的向量表示在许多 NLP 任务中都有至关重要的作用，比如词义消歧、命名实体识别、指代消解等等。以前的方法多是直接用离散上下文词向量组合，缺乏对上下文整体的优化表示方法。本文提出一种双向 LSTM 模型，有效学习句子上下文表征。 1. 简介通常词向量能获得单个词的语义语法信息，在训练词向量的时候是通过优化与任务无关的目标函数。为了推理出一个具体的词，好的上下文向量表示也是必须的。比如： 我找不到【星期五】了。 其中【星期五】可能是个人，可能是一个宠物等等。我们必须借助“我找不到【】了”才能确定“星期五”并不是一个表示日期的词。 通常上下文的表示有两种方式： 无监督。使用上下文的词向量组成一个序列输入到模型，或者直接使用上下文词向量相加求平均。这种方式缺乏对上下文整体表征的优化。 监督学习。通过标注数据根据具体的任务训练上下文表征。这种方式有两个缺点：① 依赖标注数据，通常标注数据是很难得的；② 训练出来的上下文表征依赖具体的任务，很可能并没有学习到目标词与上下文的依赖关系。 context2vec 通过在大规模的无标注数据上训练神经网络模型，直接对整个上下文和目标词进行编码，能够获得他们的依赖关系。将训练好的模型应用于下游的任务也获得了很好的表现。 2. Context2vec 模型 Context2vec 的主要目标是学习一个通用的与任务无关嵌入模型，用来表示目标词上下文的变长序列向量表示。我们借鉴了 word2vec 的 CBOW 模型，利用上下文来预测目标词。与 CBOW 不同的是，我们将原来的上下文向量求平均操作替换成了双向 LSTM 模型，如上右图所示。 John [submitted] a paper 用双向 LSTM 作为特征抽取器； 一个 LSTM 输入句子序列是从左向右；另一个 LSTM 输入序列是从右向左； 将目标词左侧（“John”）的 left-to-right 特征与目标词右侧（“a paper”）的 right-to-left 特征拼接起来； 将拼接后的特征输入到 MLP 中，我们的目标是让 MLP 的输出等于 [submitted] 的向量。 采用 Word2vec 中的负采样方法训练神经网络参数，这样就能学到上下文向量和目标词向量。 3. 形式化分析定义：lLS 表示 left-to-right LSTM，rLS 表示 right-to-left LSTM。给定句子 $w_{1:n}$ 和目标词 $w_i$，那么双向 LSTM 的输出为： biLS(w_{1:n}, i)=\\text{lLS}(l_{1:i-1})\\oplus\\text{rLS}(r_{n:i+1})其中 $l$ 和 $r$ 分别表示句子中从左到右和从右到左的词向量。注意在本模型中句子的第 $0$ 个位置和第 $n+1$ 个位置分别表示 $\\text{BOS}$ 和 $\\text{EOS}$。我们并没有将目标词传入到 LSTM 中去。接下来： \\text{MLP}(x) = L_2(\\text{ReLU}(L_1(x)))其中 $\\text{ReLU}$ 表示激活函数，$L_i$ 表示线性变换。令 $c=(w_1, …, w_{i-1}, w_{i+1}, …, w_n)$ 表示句子的上下文词向量。 \\vec{c}=\\text{MLP}(\\text{biLS}(w_{1:n}, i))令目标词 $w_i$ 的词向量为 $\\vec{t}$： S=\\sum_{t,c}\\left( \\log\\sigma(\\vec{t}\\cdot \\vec{c})+\\sum_{i=1}^k\\log\\sigma(-\\vec{t}\\cdot\\vec{c})\\right)其中 $\\sum_{c,t}$ 表示对训练语料中的每个 $(t,c)$ 对求和，$t_1, …, t_k$ 表示负采样的样本。负采样的概率分布为： p_\\alpha(t) \\propto (\\#t)^\\alpha$0\\le\\alpha\\le1$ 表示一个平滑系数，$\\alpha$ 越大越容易采样到罕见词。$#$ 表示统计个数。 Levy &amp; Goldberg (2014) 证明了将上式用于单字上下文时是可以优化的，当 \\vec{t}\\cdot\\vec{c}=\\text{PMI}_\\alpha(t,c)-\\log(k)其中 $\\text{PMI}(t,c)=\\log\\frac{p(t,c)}{p_\\alpha(t)p(c)}$ 表示目标词 $t$ 与 上下文 $c$ 的点互信息。 Levy &amp; Goldberg (2014) 的分析适用于两个随机变量的共现矩阵。在我们这里，上下文不是单字而是一个目标词的完整句子表达。据此，我们可以将模型得到的上下文向量视作所有可能的目标词与可能句子上下文的 $\\text{PMI}$ 的矩阵分解。 最终我们注意到 $\\alpha$ 越大，则目标词越偏向罕见词。 4. 模型验证为了验证模型的质量，我们提出三种相似度矩阵： target-to-context context-to-context target-to-target 所有的相似度都用 $\\cos(\\cdot)$ 计算。 4.1 target-to-context 当 $\\alpha$ 取不同的值的时候，目标词的结果： 4.2 context-to-context 4.3 target-to-target 5. 与语言模型的关系从我们对模型的介绍，以及 target-to-context 实验结果的分析可以看出，我们的模型和基于 LSTM 的语言模型很像。主要的区别在于 LSTM 语言模型给定目标词，优化模型的联合概率。然而 context2vec 的目标是学习通用的向量表示。我们采用了 Word2vec 的学习框架，但是我们利用 $\\vec{t}\\cdot\\vec{v}$ 近似点互信息，而不是 $\\log p(t|c)$。 Reference context2vec: Learning Generic Context Embedding with Bidirectional LSTM, Oren Melamud, Jacob Goldberger, Ido Dagan. 2016 Neural Word Embedding as Implicit Matrix Factorization, Omer Levy, Yoav Goldberg. 2014","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"context2vec","slug":"context2vec","permalink":"https://rogerspy.gitee.io/tags/context2vec/"}]},{"title":"预训练语言模型-Semi-supervised Sequence Learning","slug":"ptm-semi-supervised-sequence-learning","date":"2021-09-07T15:01:19.000Z","updated":"2022-01-12T08:37:38.403Z","comments":true,"path":"2021/09/07/ptm-semi-supervised-sequence-learning/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/07/ptm-semi-supervised-sequence-learning/","excerpt":"之前我们介绍了 Word Embedding，将词转换成稠密向量。词向量中包含了大量的自然语言中的先验知识，word2vec 的成功证明了我们可以通过无监督学习获得这些先验知识。随后很多工作试图将句子、段落甚至文档也表示成稠密向量。其中比较有代表性的，比如：","text":"之前我们介绍了 Word Embedding，将词转换成稠密向量。词向量中包含了大量的自然语言中的先验知识，word2vec 的成功证明了我们可以通过无监督学习获得这些先验知识。随后很多工作试图将句子、段落甚至文档也表示成稠密向量。其中比较有代表性的，比如： 有监督学习 Recurrent Convolutional Neural Networks for Text Classification Convolutional Neural Networks for Sentence Classification 无监督学习 Distributed Representations of Sentences and Documents Skip-Thought 、Quick-thoughts、InferSent 等等。纯粹的有监督学习是通过分类任务去学习网络参数，最终得到句子向量表示。纯粹的无监督学习是通过预测上下文，比如 skip-thought 利用了 word2vec 的思想，通过预测上下文句子来学习句子表示。 本文要介绍的这篇论文则是首先尝试使用大规模无标注数据进行预训练，然后将整个句子的向量序列作为有监督任务的初始化值的方法。该方法开创了后来的与训练语言模型+微调下游任务的 NLP 模型训练模式。 1. Sequence autoencoders 序列自编码器与机器翻译的 seq2seq 架构很相似，主要有两点不同： seq2seq 是有监督模型，序列自编码器是无监督模型 seq2seq 输出是目标语言序列，而序列自编码器输出是输入的句子本身，所以叫做自编码器。 这个模型中，编码器（绿色部分）和解码器（红色部分）的权重是一样的。 序列自编码器的一个重要性质就是可以使用大量无标注的数据训练语言模型，这对有限标注数据任务非常有帮助。 2. Recurrent language models 将序列自编码器，去掉编码器我们就可以得到 LSTM。在我们的任务中，我们使用序列自编码器对 LSTM 的权重进行初始化，我们将使用语言模型初始化后的 LSTM 称之为 LM-LSTM。 我们再将 LM-LSTM 用于下游的分类任务。通常情况下，LSTM 使用最后一个隐层的输出来预测输入的标签。但是在我们的实验中也尝试了使用 LSTM 每一步输出线性递增组合的方式预测标签，这样我们可以将梯度传递到更靠前的位置上，减轻梯度消失带来的问题。 另外，我们还尝试了将序列自编码器和下游监督学习模型一起训练的方法，称之为“联合训练”。 3. Experiments IMDB 数据集实验结果 Rotten Tomatoes 数据集实验结果 20 newsgroups 数据集实验结果 DBpedia character level classification CIFAR-10 object classification Reference Semi-supervised Sequence Learning, Andrew M. Dai, Quoc V. Le, 2015, arxiv:1511.01432 Semi-supervised Sequence Learning, PaperWeekly, Zhihu","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"半监督语言模型","slug":"半监督语言模型","permalink":"https://rogerspy.gitee.io/tags/半监督语言模型/"}]},{"title":"数据结构与算法：优先队列（priority queue）","slug":"ds-priority-queue","date":"2021-09-04T17:12:16.000Z","updated":"2022-01-12T08:37:38.364Z","comments":true,"path":"2021/09/05/ds-priority-queue/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/05/ds-priority-queue/","excerpt":"本文介绍优先队列，并用 Python 实现。","text":"本文介绍优先队列，并用 Python 实现。 1. 简介优先队列是一种特殊的队列类型，队列中每个元素都包含一个优先级值。每个元素根据优先级的大小进行处理，即优先级越高，对应的元素越早处理。 但是，如果两个元素的优先级一样的话，根据他们在队列中的先后进行处理。 1.1 分配优先级通常情况下，元素值本身就是优先级。比如，元素值越高则优先级越高，或者元素值越低优先级越高。当然，我们也可以根据具体需要来设置优先级。 1.2 优先队列与常规队列的区别在常规队列中，遵守先进先出规则；而在优先队列中，根据优先级删除值，首先删除优先级最高的元素。 1.3 优先队列的实现方式优先队列的实现有多种方式，比如数组、链表、堆以及二叉树等。其中堆更加高效，所以下面我们以堆实现的优先队列为例进行介绍。因此，在此之前需要先了解堆数据结构：max-heap and mean-heap。 不同实现方式的复杂度对比： Operations peek insert delete Linked List O(1) O(n) O(1) Binary Heap O(1) O(log n) O(log n) Binary Search Tree O(1) O(log n) O(log n) 2. 优先队列的基本操作优先队列的基本操作包括：插入、删除、查询。 2.1 插入通过下面的步骤向优先队列中插入元素（max-heap）: 在树的末尾插入元素 将树进行堆化 在优先队列中（max-heap）插入元素的算法如下： 123456If there is no node, create a newNode.else (a node is already present) insert the newNode at the end (last node from left to right.) heapify the array 对于 Min heap，上面的算法中 parentNode 永远小于 newNode。 2.2 删除通过下面的步骤从优先队列中删除元素（max heap）： 选择要删除的元素 与最后一个元素位置进行交换 删除最后一个元素 将树进行堆化 从优先队列中删除元素的算法： 123456If nodeToBeDeleted is the leafNode remove the nodeElse swap nodeToBeDeleted with the lastLeafNode remove noteToBeDeleted heapify the array 对于 Min Heap，上面算法中的 childNodes 一直 currentNode。 2.3 查询对于 Max heap，返回最大元素；对于 Min heap，返回最小值。 对于 Max heap 和 Min heap 来说，都是返回根节点： 1return rootNode 2.4 选取最大值最小值抽取最大值返回从最大堆中删除后具有最大值的节点，而抽取最小值则返回从最小堆中删除后具有最小值的节点。 3. Python 实现优先队列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# Priority Queue implementation in Python# Function to heapify the treedef heapify(arr, n, i): # Find the largest among root, left child and right child largest = i l = 2 * i + 1 r = 2 * i + 2 if l &lt; n and arr[i] &lt; arr[l]: largest = l if r &lt; n and arr[largest] &lt; arr[r]: largest = r # Swap and continue heapifying if root is not largest if largest != i: arr[i], arr[largest] = arr[largest], arr[i] heapify(arr, n, largest)# Function to insert an element into the treedef insert(array, newNum): size = len(array) if size == 0: array.append(newNum) else: array.append(newNum) for i in range((size // 2) - 1, -1, -1): heapify(array, size, i)# Function to delete an element from the treedef deleteNode(array, num): size = len(array) i = 0 for i in range(0, size): if num == array[i]: break array[i], array[size - 1] = array[size - 1], array[i] array.remove(size - 1) for i in range((len(array) // 2) - 1, -1, -1): heapify(array, len(array), i)arr = []insert(arr, 3)insert(arr, 4)insert(arr, 9)insert(arr, 5)insert(arr, 2)print (&quot;Max-Heap array: &quot; + str(arr))deleteNode(arr, 4)print(&quot;After deleting an element: &quot; + str(arr)) 5. 优先队列的应用 Dijkstra 算法 实现栈结构 操作系统中的负载平衡和中断处理 Huffman 编码的数据压缩 ReferencePriority Queue","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://rogerspy.gitee.io/tags/数据结构/"},{"name":"queue","slug":"queue","permalink":"https://rogerspy.gitee.io/tags/queue/"}]},{"title":"数据结构与算法：循环队列（circular-queue）","slug":"ds-circular-queue","date":"2021-09-04T16:00:33.000Z","updated":"2022-01-12T08:37:38.347Z","comments":true,"path":"2021/09/05/ds-circular-queue/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/05/ds-circular-queue/","excerpt":"本文介绍循环队列，并用 Python 实现循环队列。","text":"本文介绍循环队列，并用 Python 实现循环队列。 1. 简介循环队列是常规队列（简单队列）的变种，是将队列中最后一个元素与第一个元素相连。因此，循环队列看起来像下图的样子： 循环队列是为了解决简单队列的限制。在常规队列中，经过一系列的出队入队操作之后，会有一些空位置。 上图中 0 和 1 的位置会被空置，除非等到队列重置。 2. 循环队列的基本操作循环队列通过循环递增的方式工作，即当我们递增指针并到达队列的末尾时，我们又从队列的开头开始。其中递增是通过模除队列的尺寸，即： 1if REAR + 1 == 5 (overflow!), REAR = (REAR + 1)%5 = 0 (start of queue) 具体过程如下： 两个指针 FRONT 和 REAR FRONT 追踪队列中第一个元素 REAR 追踪队列中最后一个元素 初始化 FRONT 和 REAR 为 -1 2.1 Enqueue 检查队列是否是满队列 对于第一个元素，设置 FRONT 的值为 0 循环增加 REAR ，如果 REAR 到末尾，下一步就从头开始 在 REAR 指向的位置添加新元素 2.2 Dequeue 检查队列是否为空 返回 FRONT 指向的值 FRONT 循环加 1 对于最后一个元素，重置 FRONT 和 REAR 为 -1 然而，检查满队列的时候，有一个新问题： 第一种情况：FRONT=0 &amp;&amp; REAR=size-1 第二种情况：FRONT=REAR+1 第二种情况下，REAR 因为循环递增而从 0 开始，并且其值只比 FRONT 时，队列已满。 3. Python实现循环队列1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# Circular Queue implementation in Pythonclass MyCircularQueue(): def __init__(self, k): self.k = k self.queue = [None] * k self.head = self.tail = -1 # Insert an element into the circular queue def enqueue(self, data): if ((self.tail + 1) % self.k == self.head): print(\"The circular queue is full\\n\") elif (self.head == -1): self.head = 0 self.tail = 0 self.queue[self.tail] = data else: self.tail = (self.tail + 1) % self.k self.queue[self.tail] = data # Delete an element from the circular queue def dequeue(self): if (self.head == -1): print(\"The circular queue is empty\\n\") elif (self.head == self.tail): temp = self.queue[self.head] self.head = -1 self.tail = -1 return temp else: temp = self.queue[self.head] self.head = (self.head + 1) % self.k return temp def printCQueue(self): if(self.head == -1): print(\"No element in the circular queue\") elif (self.tail &gt;= self.head): for i in range(self.head, self.tail + 1): print(self.queue[i], end=\" \") print() else: for i in range(self.head, self.k): print(self.queue[i], end=\" \") for i in range(0, self.tail + 1): print(self.queue[i], end=\" \") print()# Your MyCircularQueue object will be instantiated and called as such:obj = MyCircularQueue(5)obj.enqueue(1)obj.enqueue(2)obj.enqueue(3)obj.enqueue(4)obj.enqueue(5)print(\"Initial queue\")obj.printCQueue()obj.dequeue()print(\"After removing an element from the queue\")obj.printCQueue() 4. 循环队列时间复杂度基于数组实现的循环队列，其 enqueue 和 dequeue 时间复杂度都是 $O(1)$。 5. 循环队列的应用 CPU 任务调度 内存管理 任务堵塞管理 ReferneceCircular Queue Data Structure","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://rogerspy.gitee.io/tags/数据结构/"},{"name":"queue","slug":"queue","permalink":"https://rogerspy.gitee.io/tags/queue/"}]},{"title":"数据结构与算法：队列（queue）","slug":"ds-queue","date":"2021-09-04T14:21:26.000Z","updated":"2022-01-12T08:37:38.364Z","comments":true,"path":"2021/09/04/ds-queue/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/04/ds-queue/","excerpt":"本文介绍队列数据结构，并用 Python 代码实现。","text":"本文介绍队列数据结构，并用 Python 代码实现。 1. 简介队列是一个非常有用的数据结构。它与电影院外排队买票是一样的，先排先买。队列也是如此，遵循先进先出（First In First Out，FIFO）原则。 如上图所示，1 排在 2 前面，也会在 2 之前被删除。 在编程的术语中，将元素添加进队列中的操作叫做 “enqueue”，从队列中删除的操作叫做 “dequeue”。 2. 队列的基本操作 Enqueue：向队列中添加元素 Dequeue：从队列中删除元素 IsEmpty：判断队列是否为空 IsFull：判断队列是否为满队列 Peek：获取队列最前面的元素而不删除该元素 定义两个指针 FRONT 和 REAR FRONT 追踪队列中第一个元素 REAR 追踪队列中最后一个元素 初始化 FRONT 和 REAR 都为 -1 2.1 Enqueue 操作 检查队列是否为满序列 对于第一个元素，设置 FRONT 为 0 REAR 索引加 1 在 REAR 指向的位置处添加新元素 2.2 Dequeue 检查队列是否为空 返回 FRONT 指向的元素 FRONT 的索引加 1 对于最后一个元素，重新设置 FRONT 和 REAR 为 -1 3. Python 实现队列1234567891011121314151617181920212223242526272829303132333435363738# Queue implementation in Pythonclass Queue: def __init__(self): self.queue = [] # Add an element def enqueue(self, item): self.queue.append(item) # Remove an element def dequeue(self): if len(self.queue) &lt; 1: return None return self.queue.pop(0) # Display the queue def display(self): print(self.queue) def size(self): return len(self.queue)q = Queue()q.enqueue(1)q.enqueue(2)q.enqueue(3)q.enqueue(4)q.enqueue(5)q.display()q.dequeue()print(\"After removing an element\")q.display() 4. 队列的限制如下图所示，经过一系列的入队和出队，队列的尺寸减小了。但是我们只能在队列重置（所有的元素都出队）的时候设置 0 和 1 索引。 对于队列的一种变种——循环队列来说，由于入队时尾指针向前追赶头指针；出队时头指针向前追赶尾指针，造成队空和队满时头尾指针均相等。因此，无法通过条件front==rear来判别队列是”空”是”满”。 5. 队列的时间复杂度Enqueue 和 dequeue 操作在使用数组实现的队列中复杂度都是 $O(1)$。如果你用python中的 pop(n) 方法，那时间复杂度可能是 $O(n)$，取决于你要删除的元素的位置。 6. 队列的应用 CPU 调度，硬盘调度。 当两个进程之间异步传输数据时，队列用于消息同步。 处理实时系统的中断。 呼叫中心电话系统使用队列将呼叫他们的人按顺序排列。 ReferenceQueue Data Structure","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://rogerspy.gitee.io/tags/数据结构/"}]},{"title":"数据结构与算法：队列类型","slug":"ds-types-queue","date":"2021-09-04T05:15:12.000Z","updated":"2022-01-12T08:37:38.373Z","comments":true,"path":"2021/09/04/ds-types-queue/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/04/ds-types-queue/","excerpt":"本文介绍不同类型的队列数据结构。","text":"本文介绍不同类型的队列数据结构。 1. 简介队列就像排队买票，先到先得。有四种不同的队列： 简单队列（simple queue） 循环队列（circular queue） 优先队列（priority queue） 双端队列（double ended queue，deque） 2. 简单队列在一个简单的队列中，插入发生在后面，移除发生在前面。 它严格遵循 FIFO（先进先出）规则。 更详细内容，查看 数据结构与算法：队列（queue）。 3. 循环队列循环队列是指，最后一个元素指向第一个元素，形成一个循环链。 与简单队列相比，循环队列的主要优点是更好的内存利用率。 如果最后一个位置已满而第一个位置为空，我们可以在第一个位置插入一个元素。 此操作在简单队列中是不可能的。 更详细的内容，查看 数据结构与算法：循环队列（circular-queue）。 4. 优先队列优先级队列是一种特殊类型的队列，其中每个元素都与一个优先级相关联，并根据其优先级进行处理。 如果出现具有相同优先级的元素，则按照它们在队列中的顺序进行处理。 更详细的内容，查看 数据结构与算法：优先队列（priority queue）。 5. 双端队列在双端队列中，可以从前面或后面执行元素的插入和删除。 因此，它不遵循 FIFO（先进先出）规则。 更详细的内容，查看 数据结构与算法：双端队列（deque）。 ReferenceTypes of Queues","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://rogerspy.gitee.io/tags/数据结构/"},{"name":"queue","slug":"queue","permalink":"https://rogerspy.gitee.io/tags/queue/"}]},{"title":"数据结构与算法：栈（stack）","slug":"ds-stack","date":"2021-09-04T04:16:52.000Z","updated":"2022-01-12T08:37:38.365Z","comments":true,"path":"2021/09/04/ds-stack/","link":"","permalink":"https://rogerspy.gitee.io/2021/09/04/ds-stack/","excerpt":"本文介绍栈（stack）数据结构，并用 python 代码实现。","text":"本文介绍栈（stack）数据结构，并用 python 代码实现。 1. 简介栈是一个线性数据结构，遵循后进先出（Last In First Out，LIFO）的原则。这就意味着最后插入的元素会先被删除。 就像叠盘子一样， 你可以在最上面放一个新盘子 拿盘子的时候也是从最上面开始拿 如果想要最下面的盘子，你就必须先把上面所有的盘子先拿走。这就是栈的基本工作方式。 2. 栈的 LIFO 原则用编程的术语来说，在栈最上面放置一个元素称之为 “push”，删除元素叫做 “pop”。 3. 栈的基本操作 push：在栈上面添加一个元素 pop：从栈中删除一个元素 isEmpty：判断栈是否为空 isFull：判断栈是否是一个满栈 peek：获取栈最上层的元素而不删除它 用 TOP 指针来追踪栈中最上层的元素 初始化栈的时候，我们设置设置指针为 -1，这样我们就可以通过判断 TOP==-1 来检查栈是否为空 当往栈里 push 数据的时候，我峨嵋你增加 TOP 的值，将新元素放置在 TOP 指定的位置 删除元素的时候，返回 TOP 指向的值，然后减小 TOP 值 向栈 push 数据的时候应该先检查栈是否已满 删除数据的时候，应该检查栈是否为空 4. 用 Python 实现栈1234567891011121314151617181920212223242526272829303132333435# Stack implementation in python# Creating a stackdef create_stack(): stack = [] return stack# Creating an empty stackdef check_empty(stack): return len(stack) == 0# Adding items into the stackdef push(stack, item): stack.append(item) print(\"pushed item: \" + item)# Removing an element from the stackdef pop(stack): if (check_empty(stack)): return \"stack is empty\" return stack.pop()stack = create_stack()push(stack, str(1))push(stack, str(2))push(stack, str(3))push(stack, str(4))print(\"popped item: \" + pop(stack))print(\"stack after popping an element: \" + str(stack)) 5. 栈的时间复杂度对于基于数组的栈实现，push 和 pop 操作都是常数时间，即 $O(1)$。 6. 栈的应用尽管栈是非常简单的数据结构，但是它非常有用，最常见的应用如： 词倒置。将词中的每个字符方法栈中，然后一个一个删除就可以了。因为栈是 LIFO 的，删除的时候就可以将词中的字符倒置过来。 编译器中，计算比如 2+4/5*(7-9) 的表达式的时候，用栈将表达式转化成前缀或者后缀的形式。 浏览器中，后退按钮用栈存储了所有你浏览过的网址（URL），每次你浏览一个新的网站的时候，它就会被加入到栈中，当你回退的时候，现在的网页就会被删除，然后回到倒数第二个页面。 ReferenceStack Data Structure","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://rogerspy.gitee.io/tags/数据结构/"},{"name":"stack","slug":"stack","permalink":"https://rogerspy.gitee.io/tags/stack/"}]},{"title":"知识图谱：知识建模（三）RDFS/OWL 词汇表","slug":"kg-rdf-vocabulary","date":"2021-08-26T14:11:35.000Z","updated":"2022-01-12T08:37:38.382Z","comments":true,"path":"2021/08/26/kg-rdf-vocabulary/","link":"","permalink":"https://rogerspy.gitee.io/2021/08/26/kg-rdf-vocabulary/","excerpt":"前面的文章介绍了知识建模，我们提到知识建模使用的是 RDF 知识表示法，而 RDFS 本质上是一个标准化语义词汇表。所以本文总结一些常用的 RDFS/OWL 的语义词汇。","text":"前面的文章介绍了知识建模，我们提到知识建模使用的是 RDF 知识表示法，而 RDFS 本质上是一个标准化语义词汇表。所以本文总结一些常用的 RDFS/OWL 的语义词汇。 0. 絮絮叨叨0.1 RDF/XML在正式介绍 RDFS/OWL 词汇之前，相信很多小伙伴在看知识建模的时候就会有很多疑问。为什么一定要用 RDF？XML 好像也能胜任这份工作，RDF 和 XML 的区别是什么？RDF 标榜的让计算机理解语义体现在哪里？等等一系列的疑问。当然回答这些问题并不是本文的目的，本文只是总结 RDFS/OWL 的词汇。要想弄明白 RDF 到底是怎么一回事，这里推荐一些必读的书籍/文献，希望能帮助到有疑问的人。 Where are the Semantics in the Semantic Web?, Michael Uschold Why RDF model is different from the XML model, Tim Berners-Lee A developer’s guide to semantic web, Liyang Yu XML+RDF——实现Web数据基于语义的描述, 周竞涛、王明微 0.2 IRI, URI, URL, URN 的区别 URL Uniform Resource Locator，统一资源定位符。是用于在网络中传播和访问互联网资源的一个地址，只有通过特定的地址才能够访问的指定的资源或者网页，简而言之就是我们所说的网址，当然这样有些不太恰当，但是确实最容易被理解的，就如你必须通过 https://www.baidu.com 才能访问百度搜索页面，通过其他的链接都是不行的，这个地址就被称之为 URL。 URI Uniform Resource Identifier，统一资源标识符。也可以理解为标识、定位资源的字符串。字符集仅限于 US-ASCII 中（额外加一个百分号 %）， 不包括某些保留字符。URI 可用作定位器、名称或两者。 如果 URI 是定位器，则它描述了资源的主要访问机制。 如果一个 URI 是一个名称，它通过给它一个唯一的名称来标识一个资源。 许多人容易将 URL 和 URI 两者混淆，其实两者非常相似，但是也有所不同。URL 包含相对地址和绝对地址，URI 就属于绝对地址，所以 URL 包含 URI，简单的举例就是很多的网站可能都有 /about 这个路径，但是不同的域名或者 IP 访问到的就是不同的资源页面，所以这就只是一个标识，并不能标识其具体未知或者唯一性。 IRI Internationalized Resource Identifier，国际化资源标识符。和 URI 类似，区别在于 URI 使用的字符集有限制，所以没有办法兼容不同的文字语言，所以 IRI 就引入了 Unicode 字符来解决这个兼容问题，最后就有了国际化资源标识符（IRI）。 URN Uniform Resource Name，统一资源名称。旨在用作持久的，与位置无关的资源标识符。URN 可以提供一种机制，用于查找和检索定义特定命名空间的架构文件。尽管普通的 URL 可以提供类似的功能，但是在这方面，URN 更加强大并且更容易管理，因为 URN 可以引用多个 URL。子凡举个最简单的例子大家就明白了，那就是：磁力链接，它就是 URN 的一种实现，可以持久化的标识一个 BT 资源，资源分布式的存储在 P2P 网络中，无需中心服务器用户即可找到并下载它。 总结一下： • SUMMARY • IRI ⊃ URI • URI ⊃ URL • URI ⊃ URN • URL ∩ URN = ∅ 下面就进入今天的正题——RDFS/OWL 词汇表。本文摘自 《语义网技术体系》 [瞿裕忠，胡伟，程龚 编著] 2015年版 这本书。想查看完整版词汇表，可前往这两个网页： RDF Schema 1.1 OWL Web Ontology Language 再啰嗦一句，除了以上两个 RDF 词汇表，还有一个 FOAF 词汇表在对人物进行建模的时候通常会用到。但是这里就不再介绍，想了解更多可自行前往。 1. 序言RDF Schema（下文简称 RDFS） 是 RDF 词汇表的一个扩展版本（RDF 本身是一个知识表示模型，但同时也是一个词汇表）。RDFS 承认有许多技术可以用来描述类和属性的含义，例如 OWL。 本文中定义的语言由一组 RDF 资源组成，这些资源可用于在特定于应用程序的 RDF 词汇表中描述其他 RDF 资源。核心词汇 rdfs 非正式地称为命名空间中定义。该命名空间由 IRI 标识： 1http://www.w3.org/2000/01/rdf-schema# 并且通常与前缀相关联 rdfs:。本规范还使用前缀 rdf:来指代 RDF 命名空间： 1http://www.w3.org/1999/02/22-rdf-syntax-ns# 为了方便和可读性，本规范使用缩写形式来表示 IRI。形式 prefix:suffix 的名称应该被解释为一个 IRI，它由与后缀连接的前缀相关联的 IRI 组成。 2. RDFS资源可以被分成不同的组，这些组称之为“类”（classes）。每个类别下包含的成员称之为“实例”。比如“人”是一个类，“张三”是一个“人”的实例。通常我们把 RDF 和 RDFS 合写成 RDF(S) 或 RDF/S。 下面分别介绍 RDF(S) 的核心词汇。 2.1 Classes资源可以分成不同的组，这些组就称之为“类”，组内的成员就称之为类的“实例”。我们用 IRI 来标识类，然后用 RDF 属性来描述类。两个不同的类可能有相同的实例，比如“张三”既可以是“导演”这个类，也可以是“演员”这个类。一个类也可能是他自己的实例。 名词解释：“类的外延” 与一个类别相关的集合，我们称之为类的外延。类的外延集合中的每个成员都是类的实例。举个例子： 类：食物 类的外延：a = {鸡，鸭，鱼，肉} 类的实例：鸡，鸭，鱼，肉 例子中，“食物”作为一个类别，表示一个抽象概念。跟这个类别相关的一个集合 a 表示“食物”的外延，相对类来说类的外延是具体的概念。但是要注意 a 作为一个集合整体出现。而 a 中的每一个元素称之为实例。 当我们说“鸡肉是一种食物”的时候，实际上是表明“鸡肉”是“食物”这个概念的外延集合中的一员。 \\text{instance} \\in a \\rightarrow class 2.1.1 rdf:Resource所有 RDF 描述的事物都是资源，即都是 rdfs:Resource 的实例。这是所有事物的类，其他所有类都是它的子类。rdfs:Resource 也是 rdfs:Class 的实例。 2.1.2 rdf:Class对应“类”的概念，即资源的类。当定义一个新类的时候，表示该类的资源必须有一个 rdf:type 属性，属性值是 rdfs:Class。比如定义“导演”是一个新类，那么我们必须定义： 1导演 rdf:type rdfs:Class 注意，如上所述，一个实例可能属于多个类，所以类成员是不互斥的。rdfs:Class 是 rdfs:Class 是实例。 2.1.3 rdf:Literalrdf:Literal 表示类或属性的字面量类型，比如数字、字符串等。rdfs:Literal 是 rdfs:Class 的实例，同时也是 rdfs:Resource 的子类。 2.1.4 rdfs:Propertyrdfs:Property 是 RDF 属性类，同时也是 rdfs:Class 的实例。 2.2. Properties在 RDF 中，RDF 属性表示 subject 资源和 object 资源之间的关系。为了下文解释方便，我们这里写下三元组的一般形式： 1subject predicate object 2.2.1 rdfs:rangerdfs:range 是 rdfs:Property 的一个实例，用来指明一个属性的值域。例如三元组： 1p rdfs:range c 表示 p 是 rdfs:range 的一个实例， c 是 rdfs:Class 的一个实例。上面的三元组描述的是一个 predicate 是 p 的 object 是 c 的实例。 2.2.2 rdfs:domainrdfs:domain 是 rdfs:Property 的一个实例，用来指明一个属性的定义域。例如三元组： 1p rdfs:domain c 表示 p 是 rdfs:Property 的一个实例，c 是 rdfs:Class 的实例。上面的三元组描述的是一个 predicate 是 p 的 subject 是 c 的实例。 其中，如果 p 有不止一个 rdfs:domain ，那么其对应的所有 subject 都是 c 的实例。 举个例子： 12345人 吃 食物 吃 rdf:type rdfs:Property吃 rdfs:domain 人吃 rdfs:range 食物 翻译过来就是，“吃”表示一种属性（关系），它的主语是“人”，宾语是“食物”。 2.2.3 rdf:typerdf:type 是 rdf:Property 的一个实例，用于描述一个资源是类的实例，例如： 1R rdf:type C 表示 C 是 rdfs:Class 的子类，并且 R 是 C 的实例。用一句通俗易懂的话就是，R 是一种 C，比如 人 rdf:type 生物 表示“人是一种动物”。实际上 rdf:type 表示 “is-a” 的关系，可以简写成 a。 2.2.4 rdfs:subClassOfrdfs:subClassOf 是 rdfs:Property 的一个实例，用来指明一个类的所有实例也是另一个类的实例，比如： 1C1 rdfs:subClassOf C2 描述的是，C1 是 rdfs:Class 的一个实例，C2 是 rdfs:Class 的一个实例，并且 C1 是 C2 的一个子类。rdfs:subClassOf 是可传递的，即如果 a 是 b 的子类，b 是 c 的子类，那么 a 也是 c 的子类。 rdfs:subClassOf 的 rdfs:domain 是 rdfs:Class。rdfs:subClassOf 的 rdfs:range 是 rdfs:Class。 2.2.5 rdfs:subPropertyOfrdfs:subPropertyOf 是 rdfs:Property 的一个实例，用来指明与一个资源相关的所有属性也与另一个资源相关，比如： 1P1 rdfs:subPropertyOf P2 描述了 P1 是 rdfs:Property 的一个实例，P2 也是 rdfs:Property 的一个实例，并且 P1 是 P2 的一个子属性。rdfs:subPropertyOf 是可传递性的。 rdfs:subPropertyOf 的 rdfs:domain 是 rdf:Property。rdfs:subPropertyOf 的 rdfs:range 是 rdf:Property。 除了上面介绍的词之外， RD(S) 还有很多其他有用的词汇，这里不一一列举。下图展示了 RDF(S) 各个词汇之间的关系： 2.2.6 RDFS 词汇总结2.2.6.1 Classes Class name comment rdfs:Resource The class resource, everything. rdfs:Literal The class of literal values, e.g. textual strings and integers. rdf:langString The class of language-tagged string literal values. rdf:HTML The class of HTML literal values. rdf:XMLLiteral The class of XML literal values. rdfs:Class The class of classes. rdf:Property The class of RDF properties. rdfs:Datatype The class of RDF datatypes. rdf:Statement The class of RDF statements. rdf:Bag The class of unordered containers. rdf:Seq The class of ordered containers. rdf:Alt The class of containers of alternatives. rdfs:Container The class of RDF containers. rdfs:ContainerMembershipProperty The class of container membership properties, rdf:_1, rdf:_2, …, all of which are sub-properties of ‘member’. rdf:List The class of RDF Lists. 2.2.6.2 Properties Property name comment domain range rdf:type The subject is an instance of a class. rdfs:Resource rdfs:Class rdfs:subClassOf The subject is a subclass of a class. rdfs:Class rdfs:Class rdfs:subPropertyOf The subject is a subproperty of a property. rdf:Property rdf:Property rdfs:domain A domain of the subject property. rdf:Property rdfs:Class rdfs:range A range of the subject property. rdf:Property rdfs:Class rdfs:label A human-readable name for the subject. rdfs:Resource rdfs:Literal rdfs:comment A description of the subject resource. rdfs:Resource rdfs:Literal rdfs:member A member of the subject resource. rdfs:Resource rdfs:Resource rdf:first The first item in the subject RDF list. rdf:List rdfs:Resource rdf:rest The rest of the subject RDF list after the first item. rdf:List rdf:List rdfs:seeAlso Further information about the subject resource. rdfs:Resource rdfs:Resource rdfs:isDefinedBy The definition of the subject resource. rdfs:Resource rdfs:Resource rdf:value Idiomatic property used for structured values. rdfs:Resource rdfs:Resource rdf:subject The subject of the subject RDF statement. rdf:Statement rdfs:Resource rdf:predicate The predicate of the subject RDF statement. rdf:Statement rdfs:Resource rdf:object The object of the subject RDF statement. rdf:Statement rdfs:Resource 3. OWL由于 RDFS 的表达能力较弱，W3C 2004 年又发布了 Web Ontology Language（OWL）进一步提供更加丰富的知识表示和推理能力。OWL 以描述逻辑为理论基础，可以将概念和属于用结构化的形式表示出来。通过 RDF 中的链接可以是本体分布在不同的系统中，充分体现了其标准化，开放性，扩展性以及适应性。现在 OWL 已经是 W3C 推荐的本体建模标准。OWL 的命名空间是： 1http://www.w3.org/2002/07/owl# OWL 提供 3 中表达能力不同的子语言：OWL Full，OWL DL，OWL Lite。其中任意一个都可以映射成一个完整的 RDF 图。 OWL Full。完全兼容 RDFS，但超出经典一阶逻辑的范畴。与 OWL Full 相关的推理工具现在还在探索中。 OWL DL。是 OWL Full 的一个子集，表达能力相对较强，可以有效的支持逻辑推理，但不是完全兼容 RDFS。 OWL Lite。在 OWL DL 的基础上对允许使用公理做了进一步的限制。 到了 2012 年，W3C 对原先版本的 OWL 进行了修订，发布新的 OWL 版本——OWL 2。OWL 2 对 OWL 向后兼容，包含了 3 个指定的概图： OWL 2 EL。允许以高效的多项式时间算法对类型的可满足性检查、分类和实例检查并进行推理，特别适合使用含有大量属性或类本体的应用。 OWL 2 QL。允许使用传统的关系数据库实现查询问答，特别适合使用大量实例数据并且以查询问答作为主要推理任务的应用。 OWL 2 RL。允许以一种比较直接的方式，使用基于规则的推理引擎，在不牺牲太多的表达能力的情况下实现大规模推理。 3.1 OWL Document一般情况下，描述本体的文档都包含本体本身的信息。一个本体是一个资源，可以采用 OWL 和其他命名空间属性进行描述。这些描述被称为本体头部，通常位于本体文档的开始部分。 1234567891011&lt;?xml version=&quot;1.0&quot;?&gt;&lt;rdf:RDF xmlns=&quot;http://www.semanticweb.org/qiuji/ontologies/2017/9/untitled-ontology-2#&quot; xml:base=&quot;http://www.semanticweb.org/qiuji/ontologies/2017/9/untitled-ontology-2&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot; xmlns:owl=&quot;http://www.w3.org/2002/07/owl#&quot; xmlns:xml=&quot;http://www.w3.org/XML/1998/namespace&quot; xmlns:untitled-ontology-22=&quot;http://www.semanticweb.org/ontologies/2017/9/untitled-ontology-2#&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema#&quot; xmlns:untitled-ontology-2=&quot;http://www.semanticweb.org/qiuji/ontologies/2017/9/untitled-ontology-2#&quot; xmlns:rdfs=&quot;http://www.w3.org/2000/01/rdf-schema#&quot;&gt; &lt;owl:Ontology rdf:about=&quot;http://www.semanticweb.org/ontologies/2017/9/untitled-ontology-2&quot;/&gt; 3.1.1 owl:imports允许引用另一个包含定义的 OWL 本体，并将其含义作为定义本体的一部分。每个引用都包含一个 URI，它指向被导入的本体。 123456789@prefix : &lt;http://example.com/pwl/families/&gt; .@prefix otherOnt: &lt;http/example.org/otherOntologies/families/&gt; .@prefix owl: &lt;http://www.w3.org/2002/07/owl#&gt; .@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;&lt;http://example.com/pwl/families/&gt; rdf:type owlOntology ; owl:imports &lt;http/example.org/otherOntologies/families.owl&gt; . 另外，还可以在本体头部添加有关版本的一些信息。相关属性包括：owl:versionInfo，owl:priorVersion，owl:backwardCompatibleWith，owl:incompatibleWith 等等。 3.2 OWL Classes与 RDFS 类似， OWL 也有“类”的概念，也是表示我们对资源的分组，也有“类的外延”等概念。需要注意的是，在OWL 中，类的外延中的元素称之为个体（individual），和在 Protege 建模工具菜单栏中的 individual 是同一概念，都表示实例。 • NOTE OWL DL 和 OWL DL 中的资源不能同时是个体（individual）和类（class），即 class 和 individual 是互斥的。 另外，rdfs:Class 和 rdfs:Property 是被禁止使用的。 从上面的介绍来看，OWL 被设计出来主要是对 RDFS 的逻辑推理能力进行补强。要进行推理我们首先要有一些公理。在 OWL 中采用“类描述”对 OWL 类进行解释描述，然后将 OWL 组合成类公理。 3.2.1 类描述（class description）类描述通过类名或通过指定未命名匿名类的类外延来描述 OWL 类。OWL 中有 6 中不同的类描述： 类标识符（URI） 穷举组成一个类的个体（enumeration） 属性限制（property restriction） 多个类描述的交集（intersection） 多个类描述的并集（union） 一个类描述的补集（complement） 类标识符相当于通过类名（URI）来描述一个类；穷举表示一个类包含可穷举的个体；一个类中的所有个体都要满足特定的属性限制。对于 4、5、6 来说，可以认为是逻辑与（AND）或（OR）非（NOT）操作。 3.2.1.1 owl:Classowl:Class 表示一个明明资源是一个类别，比如： 1ex：Human rdf:type owl:Class . 其中 ex 表示本体的命名空间。下面的例子我们都用 RDF/XML 语法进行举例，所以上面的例子改写成： 1&lt;owl:Class rdf:ID=&quot;Human&quot;/&gt; • NOTE OWL Lite 和 OWL DL 中 owl:Class 必须用在所有的类描述上。 • NOTE 在 OWL Lite 和 OWL DL 中owl:Class 是 rdfs:Class 的子类。这个关系说明 在 RDFS 中，并不是所有的类在 OWL DL(Lite) 都是合法的。但是在 OWL Full 中二者是等价的。 OWL 类标识符是预先定义好的，即 owl:Thing / owl:Nothing。owl:Thing 是所有 OWL 类的父类，而 owl:Nothing 是所有类的子类（可以认为就是空集）。 3.2.1.2 owl:oneOfowl:oneOf 用来表示类描述中的穷举，它的值必须是类的实例。为了方便，我们可以用 rdfs:parseType=&quot;Collection&quot; ，例如： 12345678910&lt;owl:Class&gt; &lt;owl:oneOf rdf:parseType=&quot;Collection&quot;&gt; &lt;owl:Thing rdf:about=&quot;#Eurasia&quot;/&gt; &lt;owl:Thing rdf:about=&quot;#Africa&quot;/&gt; &lt;owl:Thing rdf:about=&quot;#NorthAmerica&quot;/&gt; &lt;owl:Thing rdf:about=&quot;#SouthAmerica&quot;/&gt; &lt;owl:Thing rdf:about=&quot;#Australia&quot;/&gt; &lt;owl:Thing rdf:about=&quot;#Antarctica&quot;/&gt; &lt;/owl:oneOf&gt;&lt;/owl:Class&gt; • NOTE OWL Lite 没有穷举。 3.2.1.3 owl:Restriction属性限制是一类特殊的类描述。它用来描述所有个体都满足一定限制条件的匿名类。OWL 有两种属性限制：值限制和基数限制。 所谓值限制指的是，限制属性的值域。 所谓基数限制指的是，限制属性的个数。 OWL 还提供了全局基数限制：owl:FunctionalProperty 和 owl:InverseFunctionalProperty。 owl:Restriction 是 owl:Class 的子类。一个限制类应该有一个三元组用 owl:onProperty 来连接属性和限制。 值限制 owl:allValuesFrom：用来限制一个类的所有个体是否在指定的值域内。比如： 1234&lt;owl:Restriction&gt; &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt; &lt;owl:allValuesFrom rdf:resource=&quot;#Human&quot; /&gt;&lt;/owl:Restriction&gt; owl:someValuesFrom：用来限制一个类的所有个体中，至少有一个个体来源于指定的值域。比如： 1234&lt;owl:Restriction&gt; &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt; &lt;owl:someValuesFrom rdf:resource=&quot;#Physician&quot; /&gt;&lt;/owl:Restriction&gt; owl:hasValue：用来限制一个类的所有个体中，至少有一个（语义上）等于指定的值。比如： 1234&lt;owl:Restriction&gt; &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt; &lt;owl:hasValue rdf:resource=&quot;#Clinton&quot; /&gt;&lt;/owl:Restriction&gt; • NOTE “语义上等价于”的意思是，V 不一定是指定的值，但是 V 和指定的值 V1 之间有一个 owl:sameAs的关系。 基数限制 owl:maxCardinality：用来限制一个类包含了最多 N 个语义不同的个体，其中 N 就是基数限制的值。比如： 1234&lt;owl:Restriction&gt; &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt; &lt;owl:maxCardinality rdf:datatype=&quot;&amp;xsd;nonNegativeInteger&quot;&gt;2&lt;/owl:maxCardinality&gt;&lt;/owl:Restriction&gt; owl:minCardinality：用来限制一个类至少包含 N 个语义不同的个体，其中 N 就是基数限制的值。 比如： 1234&lt;owl:Restriction&gt; &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt; &lt;owl:minCardinality rdf:datatype=&quot;&amp;xsd;nonNegativeInteger&quot;&gt;2&lt;/owl:minCardinality&gt;&lt;/owl:Restriction&gt; • NOTE 一个类中的所有实例都要有 N 个属性。 owl:cardinality：用来限制一个类必须要有 N 个语义不同的个体，不能多也不能少。其中 N 就是基数限制的值。比如： 1234&lt;owl:Restriction&gt; &lt;owl:onProperty rdf:resource=&quot;#hasParent&quot; /&gt; &lt;owl:cardinality rdf:datatype=&quot;&amp;xsd;nonNegativeInteger&quot;&gt;2&lt;/owl:cardinality&gt;&lt;/owl:Restriction&gt; 3.2.1.4 Intersection, union and complement owl:intersectionOf：连接一个类和一个类描述的列表，表示这个类的外延中的个体同时也是列表中所有类描述的外延成员。比如： 12345678910111213141516&lt;owl:Class&gt; &lt;owl:intersectionOf rdf:parseType=&quot;Collection&quot;&gt; &lt;owl:Class&gt; &lt;owl:oneOf rdf:parseType=&quot;Collection&quot;&gt; &lt;owl:Thing rdf:about=&quot;#Tosca&quot; /&gt; &lt;owl:Thing rdf:about=&quot;#Salome&quot; /&gt; &lt;/owl:oneOf&gt; &lt;/owl:Class&gt; &lt;owl:Class&gt; &lt;owl:oneOf rdf:parseType=&quot;Collection&quot;&gt; &lt;owl:Thing rdf:about=&quot;#Turandot&quot; /&gt; &lt;owl:Thing rdf:about=&quot;#Tosca&quot; /&gt; &lt;/owl:oneOf&gt; &lt;/owl:Class&gt; &lt;/owl:intersectionOf&gt;&lt;/owl:Class&gt; owl:intersectionOf 可以看成逻辑连词。 owl:unionOf：表示一个个体至少会出现在列表中的一个类中。比如： 12345678910111213141516&lt;owl:Class&gt; &lt;owl:unionOf rdf:parseType=&quot;Collection&quot;&gt; &lt;owl:Class&gt; &lt;owl:oneOf rdf:parseType=&quot;Collection&quot;&gt; &lt;owl:Thing rdf:about=&quot;#Tosca&quot; /&gt; &lt;owl:Thing rdf:about=&quot;#Salome&quot; /&gt; &lt;/owl:oneOf&gt; &lt;/owl:Class&gt; &lt;owl:Class&gt; &lt;owl:oneOf rdf:parseType=&quot;Collection&quot;&gt; &lt;owl:Thing rdf:about=&quot;#Turandot&quot; /&gt; &lt;owl:Thing rdf:about=&quot;#Tosca&quot; /&gt; &lt;/owl:oneOf&gt; &lt;/owl:Class&gt; &lt;/owl:unionOf&gt;&lt;/owl:Class&gt; owl:complementOf：连接一个类和一个类描述，表示类外延中的个体不属于类描述的外延。比如： 12345&lt;owl:Class&gt; &lt;owl:complementOf&gt; &lt;owl:Class rdf:about=&quot;#Meat&quot;/&gt; &lt;/owl:complementOf&gt;&lt;/owl:Class&gt; 3.2.2 类公理类描述通过类公理组合在一起用来定义一个类。这句话说起来很拗口，其实描述的道理很简单。就相当于我们要炒一盘菜，需要一些原材料（类描述），然后通过一些原则（类公理）将这些原料组合在一起形成一盘菜（类）。 OWL 提供了 3 个词汇，将类描述组合起来： rdfs:subClassOf owl:equivalentClass owl:disjointWith 3.2.2.1 rdfs:subClassOf class\\ description \\quad \\text{rdfs:subClassOf} \\quad class\\ description这里的 rdfs:subClassOf 和 RDFS 中的一样。比如： 123&lt;owl:Class rdf:ID=&quot;Opera&quot;&gt; &lt;rdfs:subClassOf rdf:resource=&quot;#MusicalWork&quot; /&gt;&lt;/owl:Class&gt; 3.2.2.2 owl:equivalentClass class\\ description\\quad \\text{owl:equivalentClass}\\quad class\\ descriptionowl:equivalentClass 表示两个类描述有相同的类外延。最简单的形式是，两个命名类别是等价的。比如： 123&lt;owl:Class rdf:about=&quot;#US_President&quot;&gt; &lt;equivalentClass rdf:resource=&quot;#PrincipalResidentOfWhiteHouse&quot;/&gt;&lt;/owl:Class&gt; • NOTE owl:equivalentClass 的两个类并不表示两个类是等价的。 比如上例中，“美国总统” 这个概念和“白宫的主要居民”这个概念并不一样。真正的语义等价应该用 owl:sameAs。 3.2.2.3 owl:disjointWith class\\ description\\quad \\text{owl:disjointWith}\\quad class\\ descriptionowl:disjointWith 表示两个类描述没有公共的个体，或者说两个类描述是互斥的。比如： 123&lt;owl:Class rdf:about=&quot;#Man&quot;&gt; &lt;owl:disjointWith rdf:resource=&quot;#Woman&quot;/&gt;&lt;/owl:Class&gt; 3.3 Properties OWL 有两种属性：对象属性（object property）和数据类型属性（datatype property）。对象属性用来连接两个实例，而数据类型属性连接一个实例和寿哥数据类型的字面量。换成比较容易理解的话就是，对象属性表示两个实体之间的关系，数据类型属性就是实体和属性之间的关系。比如 12小明 父亲 大明小明 生日 1990/1/1 其中“父亲”就是对象属性，“生日”就是数据类型属性。 OWL 中支持的属性机构包括： RDFS ：rdfs:subPropertyOf, rdfs:domain 和 rdfs:range 与其他属性相关的： owl:equivalentProperty 和 owl:inverseOf 全局基数限制：owl:FunctionalProperty 和 owl:InverseFunctionalProperty 逻辑属性： owl:SymmetricProperty 和 owl:TransitiveProperty 3.3.1 owl:equivalentPropertyowl:equivalentProperty 表示两个属性有相同的属性外延。类似 owl:equivalentClass。 3.3.2 owl:inverseOf属性是有方向的，从定义域指向值域。owl:inverseOf 表示反向属性，即原属性的定义域和值域互换。比如： 123&lt;owl:ObjectProperty rdf:ID=&quot;hasChild&quot;&gt; &lt;owl:inverseOf rdf:resource=&quot;#hasParent&quot;/&gt;&lt;/owl:ObjectProperty&gt; 3.3.3 owl:FunctionalPropertyowl:FunctionalProperty 表示对于实例 $x$ 来说，只有唯一的 $y$ 值。比如： 123456&lt;owl:ObjectProperty rdf:ID=&quot;husband&quot;&gt; &lt;rdfs:domain rdf:resource=&quot;#Woman&quot; /&gt; &lt;rdfs:range rdf:resource=&quot;#Man&quot; /&gt;&lt;/owl:ObjectProperty&gt;&lt;owl:FunctionalProperty rdf:about=&quot;#husband&quot; /&gt; 3.3.4 owl:InverseFunctionalPropertyowl:InverseFunctionalProperty 表示与 owl:FunctionalProperty 相反的意思，即对于值 $y$ 只能有一个 实例 $x$ 与之对应。比如： 1234&lt;owl:InverseFunctionalProperty rdf:ID=&quot;biologicalMotherOf&quot;&gt; &lt;rdfs:domain rdf:resource=&quot;#Woman&quot;/&gt; &lt;rdfs:range rdf:resource=&quot;#Human&quot;/&gt;&lt;/owl:InverseFunctionalProperty&gt; 3.3.5 owl:TransitivePropertyowl:TransitiveProperty 表示属性的可传递性。如果 $(x,y)$ 是 P 的实例，$(y,z)$ 也是 P 的实例，那么 $(x,z)$ 也是 P 的实例。比如： 1234&lt;owl:TransitiveProperty rdf:ID=&quot;subRegionOf&quot;&gt; &lt;rdfs:domain rdf:resource=&quot;#Region&quot;/&gt; &lt;rdfs:range rdf:resource=&quot;#Region&quot;/&gt;&lt;/owl:TransitiveProperty&gt; 3.3.6 owl:SymmetricPropertyowl:SymmetricProperty 表示如果 $(x,y)$ 是 P 的实例，那么 $(y,x)$ 也是 P 的实例。比如： 1234&lt;owl:SymmetricProperty rdf:ID=&quot;friendOf&quot;&gt; &lt;rdfs:domain rdf:resource=&quot;#Human&quot;/&gt; &lt;rdfs:range rdf:resource=&quot;#Human&quot;/&gt;&lt;/owl:SymmetricProperty&gt; 3.4 Individuals个体分为两种： 类的成员和个体的属性值 个体身份 3.4.1 类的成员和个体属性值123456789&lt;Opera rdf:ID=&quot;Tosca&quot;&gt; &lt;hasComposer rdf:resource=&quot;#Giacomo_Puccini&quot;/&gt; &lt;hasLibrettist rdf:resource=&quot;#Victorien_Sardou&quot;/&gt; &lt;hasLibrettist rdf:resource=&quot;#Giuseppe_Giacosa&quot;/&gt; &lt;hasLibrettist rdf:resource=&quot;#Luigi_Illica&quot;/&gt; &lt;premiereDate rdf:datatype=&quot;&amp;xsd;date&quot;&gt;1900-01-14&lt;/premiereDate&gt; &lt;premierePlace rdf:resource=&quot;#Roma&quot;/&gt; &lt;numberOfActs rdf:datatype=&quot;&amp;xsd;positiveInteger&quot;&gt;3&lt;/numberOfActs&gt; &lt;/Opera&gt; 3.4.2 个体身份通常我们会给不同的事物取不同的名字，但是我们并不能保证不重名。比如“苹果”既可以是电子产品，也可以是水果。为了对个体的身份进行区分或合并，OWL 也设计了一套词汇： owl:sameAs：表明是相同的个体，只是名字不同 owl:differentFrom：表明是两个不同的个体 owl:AllDifferent：表明列表中所有的个体都不相同 123&lt;rdf:Description rdf:about=&quot;#William_Jefferson_Clinton&quot;&gt; &lt;owl:sameAs rdf:resource=&quot;#BillClinton&quot;/&gt;&lt;/rdf:Description&gt; 12345678910&lt;Opera rdf:ID=&quot;Don_Giovanni&quot;/&gt;&lt;Opera rdf:ID=&quot;Nozze_di_Figaro&quot;&gt; &lt;owl:differentFrom rdf:resource=&quot;#Don_Giovanni&quot;/&gt;&lt;/Opera&gt;&lt;Opera rdf:ID=&quot;Cosi_fan_tutte&quot;&gt; &lt;owl:differentFrom rdf:resource=&quot;#Don_Giovanni&quot;/&gt; &lt;owl:differentFrom rdf:resource=&quot;#Nozze_di_Figaro&quot;/&gt;&lt;/Opera&gt; 12345678910&lt;owl:AllDifferent&gt; &lt;owl:distinctMembers rdf:parseType=&quot;Collection&quot;&gt; &lt;Opera rdf:about=&quot;#Don_Giovanni&quot;/&gt; &lt;Opera rdf:about=&quot;#Nozze_di_Figaro&quot;/&gt; &lt;Opera rdf:about=&quot;#Cosi_fan_tutte&quot;/&gt; &lt;Opera rdf:about=&quot;#Tosca&quot;/&gt; &lt;Opera rdf:about=&quot;#Turandot&quot;/&gt; &lt;Opera rdf:about=&quot;#Salome&quot;/&gt; &lt;/owl:distinctMembers&gt;&lt;/owl:AllDifferent&gt; 4. 结语关于 RDFS 和 OWL 的词汇总结我们就介绍这么多。当然，这些都只是一小部分，要想看完整版的推荐看 w3c 的官方文档。我们总结出来的这些词汇是比较常用的，同时也是有助于帮助不了解本体，不了解知识建模的同学对这些东西有一个大体的概念。其实本体建模就是在构建一套逻辑体系，这套逻辑体系帮助计算机进行逻辑推理。而无论是 RDFS 还是 OWL 亦或是其他众多我们没有介绍的词汇表都是在尝试将这样一个逻辑体系进行标准化。先阶段计算机的逻辑推理能力仍然处于很弱的阶段，说明我们现在的工作仍然很初级。我们这里总结的相关内容也许在不久的将来就会过期，失效甚至被推翻。但是了解这些知识也有助于我们对未来的发展有一个清晰的认知。 Reference RDF Schema 1.1 OWL Web Ontology Language IRI, URI, URL, URN and their differences, JAN MARTIN KEIL 浅谈什么是 URL、URI、IRI、URN 及之间的区别, 张子凡 语义网技术体系 [瞿裕忠，胡伟，程龚 编著] 2015年版 知识图谱-浅谈RDF、OWL、SPARQL, 吕不韦","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://rogerspy.gitee.io/categories/知识图谱/"}],"tags":[{"name":"KG","slug":"kg","permalink":"https://rogerspy.gitee.io/tags/kg/"},{"name":"knowledge-modelling","slug":"knowledge-modelling","permalink":"https://rogerspy.gitee.io/tags/knowledge-modelling/"}]},{"title":"预训练语言模型：CoVe","slug":"ptm-cove","date":"2021-08-25T13:55:11.000Z","updated":"2022-01-17T02:20:37.593Z","comments":true,"path":"2021/08/25/ptm-cove/","link":"","permalink":"https://rogerspy.gitee.io/2021/08/25/ptm-cove/","excerpt":"上一篇文章我们介绍了预训练词向量，它的缺点很明显：一旦训练完，每个词的词向量都固定下来了。而我们平时生活中面临的情况却复杂的多，一个最重要的问题就是一词多义，即同一个词在不同语境下有不同的含义。CoVe（Contextual Word Vectors）同样是用来表示词向量的模型，但不同于 word emebdding，它是将整个序列作为输入，根据不同序列得到不同的词向量输出的函数。也就是说，CoVe 会根据不同的上下文得到不同的词向量表示。","text":"上一篇文章我们介绍了预训练词向量，它的缺点很明显：一旦训练完，每个词的词向量都固定下来了。而我们平时生活中面临的情况却复杂的多，一个最重要的问题就是一词多义，即同一个词在不同语境下有不同的含义。CoVe（Contextual Word Vectors）同样是用来表示词向量的模型，但不同于 word emebdding，它是将整个序列作为输入，根据不同序列得到不同的词向量输出的函数。也就是说，CoVe 会根据不同的上下文得到不同的词向量表示。 1. 神经网络机器翻译 上图是一个经典的 attention seq2seq 模型： 源语言 $x = [x_1, x_2, …, x_n]$; 目标语言：$y = [y_1, y_2, …, y_m]$; 用 GloVe 将源语言的词转换成词向量； 编码器是 bi-LSTM，输出一个隐状态序列： \\begin{equation} \\nonumber \\begin{aligned} h &= [h_1, h_2, ..., h_n] \\\\ &= \\text{bi-LSTM}(\\text{GloVe}(x)) \\end{aligned} \\end{equation}其中 $h_t = [\\overrightarrow{h_t}; \\overleftarrow{h_t}]$，$\\overrightarrow{h_t}=\\text{LSTM}(x_t, \\overrightarrow{h}_{t-1})$；$\\overleftarrow{h_t}=\\text{LSTM}(x_t, \\overleftarrow{h}_{t-1})$。 注意力加持的解码器： \\begin{equation} \\nonumber \\begin{aligned} \\text{decoder hidden state:} \\quad s_t &= \\text{LSTM}([z_{t-1};\\tilde{h}_{t-1}], s_{t-1}) \\\\ \\text{attention weights:} \\quad \\alpha_t &= \\text{softmax}(H(W_1s_t+b_1)) \\\\ \\text{context-adjusted hidden state:} \\quad \\tilde{h}_t &= \\tanh(W_2[H^\\top \\alpha_t; s_t]+b_2) \\\\ \\text{decoder output: } \\quad p(y_t|H, y_1, ..., y_{t-1}) &=\\text{softmax}(W_{out}\\tilde{h}_t+b_{out}) \\end{aligned} \\end{equation} seq2seq 训练完成之后，将编码器的输出作为 CoVe 用于下游任务。 2. CoVe 在下游任务中的应用seq2seq 编码器的隐状态作为下游任务的语义向量： \\text{CoVe}(x) = \\text{bi-LSTM}(\\text{GloVe}(x))论文中提出将 GloVe 和 CoVe 进行拼接用于问答和分类任务。GloVe 是通过词共现比例学习到的向量，因此它没有句子上下文。而 CoVe 是通过处理文本序列学习到的向量，本身就具有上下文信息： v = [\\text{GloVe}(x);\\text{CoVe}(x)] 给定下游任务，首先将输入的词用上面的方法转化成向量，然后输入到特定任务模型中进行训练。 3. 总结CoVe 的缺点是显而易见的： 因为预训练过程是有监督训练，所以训练效果严重依赖标注数据（平行语料）； CoVe 的性能受限于特定任务的模型结构。 Reference Learned in Translation: Contextualized Word Vectors， Bryan McCann，James Bradbury，Caiming Xiong，Richard Socher. 2017 Generalized Language Models, Jan 31, 2019 by Lilian Weng","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"Language Model","slug":"language-model","permalink":"https://rogerspy.gitee.io/tags/language-model/"},{"name":"词向量","slug":"词向量","permalink":"https://rogerspy.gitee.io/tags/词向量/"}]},{"title":"知识图谱：知识建模（二）构建本体的方法论","slug":"kg-build-ontology-method","date":"2021-08-23T02:52:56.000Z","updated":"2022-01-12T08:37:38.379Z","comments":true,"path":"2021/08/23/kg-build-ontology-method/","link":"","permalink":"https://rogerspy.gitee.io/2021/08/23/kg-build-ontology-method/","excerpt":"1. 什么是本体？“本体”（ontology）的概念来源于哲学对本体论的研究。随着人工智能（AI）的发展，科学家们将“本体”这一概念引入到计算机领域。不同的文献对本体有着不同的定义，甚至有些定义是相互矛盾的。为了方便起见，我们将本体定义为：本体是一系列词汇，这些词汇包括机器可读的概念定义和概念之间的关系。","text":"1. 什么是本体？“本体”（ontology）的概念来源于哲学对本体论的研究。随着人工智能（AI）的发展，科学家们将“本体”这一概念引入到计算机领域。不同的文献对本体有着不同的定义，甚至有些定义是相互矛盾的。为了方便起见，我们将本体定义为：本体是一系列词汇，这些词汇包括机器可读的概念定义和概念之间的关系。 Classes： 类别，或者概念（concepts）表示具体领域内的一些抽象概念，比如“酒”，“人”等。Class 是本体的核心。 Subclasses：表示，大类别下面的子类。比如“酒”的子类包括“白酒”、“红酒”等。 Instances：实例，表示抽象概念下的具体事物。比如“白酒”的实例包括“红星二锅头”、“飞天茅台”等。 Properties：属性，表示的是概念的不同特征和属性。OWL 中的 property 实际上表示的就是关系。主要包括两种关系：object property 和 data property 。Object property 表示两个实体之间的关系，比如小明和小红是兄妹关系，其中“兄妹”就是“小明”和“小红”两个实体的 object property；data property 表示实体属性，比如小明的年龄是12岁，其中“姓名”就是“小明”这个实体的 data property。除此以外， W3C 还规定了一种标注属性（annotation property），它表示一些实体的注释元信息，用来对实体进行注释说明。 slots：槽，可以认为就是实体具体属性，比如“小明的年龄是12岁”，其中 “年龄” 就是一个 slot，而 “12岁” 就是 slot value。 总结一下，本体需要包含以下要素： 定义本体类别 构建各类别之间的层级关系（父类 -&gt; 子类） 定义 slot 以及可接受的值，比如年龄 slot 必须是数字 在实例中对 slot 进行填充 2. 为什么需要本体？ 共享人类或者计算机理解的信息结构。假设多个的网页包含不同的医疗信息，如果这些网页能够共享相同的本体，那么计算机可以轻易从这些网页抽取有用信息提供给用户。不仅如此，计算机还可以聚合不同来源的信息，准确回答用户的问题。 领域知识的复用。举个例子，很多地方都会需要时间信息，包括时间段、时间点、相对时间等等。如果有人能够构建一个关于时间的本体，那么其他人就可以轻易将这个本体应用到自己的领域。另外，当我们自己构建本体的时候，也可以使用已有的本体知识在上面进行扩充或者缩减等。 明确领域假设。相当于我们将某一领域内的知识点利用一些假设关系相互串联起来，使我们对整个领域有更加清晰准确的认识，尤其是对一些新人。 将领域知识与可操作性的知识分离。这就有点类似于我们在设计一款产品的时候，我们将具体的产品和组件分离开来（模块化）。比如手机，多年前的手机充电器，基本上是一个品牌甚至同一个品牌的不同型号手机就有一个充电器，充电器不同共用，相当于手机和充电器是深度绑定的。后来为了解决这种深度绑定带来的各种问题，业内开始制定统一标准实现充电器与手机分离，一个充电器可以使用不同的充电器，而一个充电器可以给不同的手机充电。其中充电器标准就可以认为是领域知识本体，而手机就是可操作数据。 领域知识分析。当我们要复用和扩展领域知识的时候，这些领域知识元素就会变得非常有价值，说白了其实还是避免重复造轮子。 通常定义领域的本体并不是我们的最终目的。开发本体类似于定义一组数据及其结构以供其他程序使用。 解决问题的方法、独立于领域的应用程序和软件代理使用从本体构建的本体和知识库作为数据。 例如，在本文中，我们开发了葡萄酒和食物的本体以及葡萄酒与膳食的适当组合。 然后，该本体可以用作一套餐厅管理工具中某些应用程序的基础：一个应用程序可以为当天的菜单创建葡萄酒建议或回答服务员和顾客的查询。 另一个应用程序可以分析酒窖的库存清单，并建议扩展哪些葡萄酒类别以及为即将到来的菜单或食谱购买哪些特定的葡萄酒。 3. 如何构建本体？现实中，并没有一个标准的、统一的本体构建方法。本文只是讨论一种比较通用的方法：先构建比较粗糙、大粒度的本体，然后不断的迭代细化。 在详细介绍构建本体的流程之前，我们先强调本体设计时的一些规则，虽然看起来有些教条，但是在很多情况下这些规则确实能帮助我们。 没有一个标准的、统一的本体构建方法。最好的方法就是根据实际业务需求去构建。 本体构建是一个需要不断迭代的过程 本体中的概念和关系必须是一些比较相近的对象（无论是物理上还是逻辑上）。这些对象可能是某领域内描述性句子中的名词或者动词。 接下来，我们以构建酒类和食物领域的本体为例，介绍构建本体的方法。 3.1 第一步、确定本体的领域和范围构建本体的第一步是确定领域和范围，因此我们需要回答下面几个问题： 我们要构建什么领域的本体？ 这些本体用来做什么？ 这些本体可以回答什么问题？ 谁会使用这些本体？ 在本体设计过程中，这些问题的答案可能会发生变化，但是任何时候这些问题都可以帮助我们限定本体范围。 考虑酒类和食物的例子。首先我们已经确定要构建酒类和食物的本体了，我们的目的是用这些本体来推荐一些好的食物和酒的搭配。 那么显然，不同酒类的概念，食物类型的概念，以及酒和食物的搭配就必须包含在我们的本体中。同时，在我们的本体中不太可能包括管理酒厂库存或餐厅员工的概念，即使这些概念与酒和食物的概念有些相关。 如果我们的本体是用来帮助酒类杂志文章进行自然语言处理，那么词性、同义词等自然语言信息可能就会变得非常重要。如果本体用于帮助餐厅顾客决定订购哪种酒，我们需要包括零售定价信息。如果用于酒品买家储存酒窖，则可能需要批发定价和可用性信息。如果本体描述语言不同于本体用户语言，我们可能需要提供语言之间的映射。 能力问题（competency questions）确定本体范围的方法之一就是勾勒出基于本体的知识库能够回答的问题（Gruninger and Fox 1995）。这些问题能帮助我们确定我们是否有足够的信息去回答这些问题，本体粒度都不够，覆盖的范围全不全。只需要一些大致的问题即可，无需穷举。 在我们的例子中，我们可能包含以下能力问题： 当我挑选酒品的时候应该考虑什么？ Cabernet Sauvignon 适合搭配海鲜吗？ 什么酒与烤肉最配？ 酒类的哪些特点会影响与食物的搭配？ 特定的酒的香气或者酒本身会随着时间发生变化吗？ Napa Zinfandel 最好的年份？ 从上面的问题中可以总结出，在我们的本体中石少应该包含：不同酒的特点、酒的类型、年份（及其品质的好坏）、食物分类以及酒和食物的搭配。 3.2 第二步、现有本体的复用程序员的圣经之一就是“不要重复造轮子”。查找已有的可用本体是一件非常重要的事情。网上有很多相关的资源，下面列举一些比较重要的资源（大多是英文的资源，中文开放本体资源目前还比较少）： OpenKG OpenKG是最大的中文开放知识图谱库，其中包含了很多本体。 地址：http://openkg.cn/home Protege Ontology Library 地址：https://protegewiki.stanford.edu/wiki/Protege_Ontology_Library Ontolingua ontology library 地址：http://www.ksl.stanford.edu/software/ontolingua/ DAML ontology library 地址：http://www.daml.org/ontologies/ UNSPSC 地址：https://www.unspsc.org RosettaNet 地址：https://www.rosettanet.org DMOZ 地址：https://www.dmoz.org 实际上现在确实有酒类开放实体可用，但是我们假设不存在，从头构建一个酒类本体。 3.3 第三步、枚举本体中的重要对象当提到一个对象的时候你会讨论些什么？这些对象有什么属性？关于这个对象你会说些什么？思考这些问题对我们构建本体是非常有用的。我们可以把这些对象写成一个列表记录下来，比如提到“酒”，你会想到“葡萄”、“酿酒厂”、“原产地”、“酒的颜色”、“口感”、“含糖量”、“酒精含量”等等。而提到“食物”，我们通常会想到“鱼”、“虾“、”肉“、”蛋“、”奶“等等。起初，对于对象的一个综合理解更重要，无需过于关注概念和关系之间的相互覆盖。 3.4 第四步、定义类和类的层级结构有几种不同的方法定义类的层级结构（Uschold &amp; Gruninger 1996）： 自上而下的方法是先定义领域内最通用的顶层概念，然后依次向下扩展。比如，我们先定义两个类别：“酒”和“食物”。然后定义酒的子类：白酒、红酒、玫瑰酒等等。然后对红酒进一步分类：Syrah，Red Burgundy，Cabernet Sauvignon 等等。对“食物”也是如此。 自下而上的方法是先定义一些具体的类别，然后讲这些类别聚合成更加通用的类别。比如“衡水老白干”和“红星二骨头”可以聚合成“白酒”。另外，“拉菲”，“桃乐丝”可以聚合成“红酒”。而“白酒”和“红酒”可以聚合成“酒”。 上下结合的方法是先定义一些比较重要的类，然后向上聚合和向下扩展。相当于将上面两种方法结合在一起。 这三种方法中，没有一种是一定比其他两种更好的方法。最终采取哪种方法取决于开发人对领域的认知。如果开发人员对领域有着系统性的了解，那么采取自上而下的方法应该是首选。通常对于大多数的开发人员来说，上下结合的方法是比较适合的，因为多数人对领域都是有一定的了解而又了解不深。所以可以通过先构建一些比较通用的本体，然后再从实例中进行总结向上补充的方法会比较合适。 比如，多数人都知道酒可以分成“白酒”、“红酒”、“鸡尾酒”等，经常看广告也可以知道“白酒”有“酱香型”、“浓香型”对于其他的香型不太了解。而对于具体的酒进行总结归类，就可以发现，原来“酒鬼酒”是馥郁香型的，那么我们就可以将“馥郁香型”补充到酒类香型的层级上去。 无论是那种方法，都是从定义类开始的。第三步中，我们列举出了一些对象，现在我们可以从列表中的选择那些用于描述独立存在的对象作为类别，以这些对象作为锚点构建层级关系。一个重要的假设如下： 如果类别 A 是类别 B 的父类，那么属于 B 类的所有实例也同样是类别 A 的实例。 3.5 第五步、定义类的属性——slots单纯的类别不足以为回答能力问题提供足够的信息，一旦我们用以上的方法定义了类别之后，需要为这些类别提供额外的信息，比如酒的颜色、口感、含糖量、产地等。这些信息就是类别的属性。 通常，一下集中类型的对象可以成为本体的属性： 内秉属性，比如：颜色、口感、含糖量等； 外部属性，比如：产地、酒名等； 子结构，如果一个对象是结构化的，那么它的实体结构和抽象结构都可以成为它的属性； 与其他对象的关系。比如，酒的厂家、酒的原料等。 所有子类都要继承父类的属性。比如“酒”的属性包括“厂家”、“颜色”、“口感”、“含糖量”、“产地”等，那么“酒”的子类“白酒”也要继承这些属性。因此，定义 slots 的时候通常是附加在具有该属性的最顶级类别上。 3.6 第六步、定义 slots 的刻面slots 的刻面包括 slots 基数、数据类型、定义域和值域等。比如酒的名称（name）是一个字符串类型的数据，酒厂生产（produces）酒，这些酒是具体的酒的实例，因此其对应的数据类型应该是实例（instance）。 基数（cardinality） slot 基数定义了一个 slot 可以有多少个值。有些 slot 只能至多有一个值，而有些则可以有多个值。比如一种酒只能有一种颜色，却可以有多个产地。 有些系统会规定 slot 基数的最大值和最小值。最小值 N 表明该 slot 至少有 N 个值，比如葡萄酒的原料葡萄 slot 最小值为 1，表明该种葡萄酒的原料中至少包含一种葡萄。最大值 M 表明该 slot 最多有 M 个值。比如葡萄酒的原料葡萄 slot 最大值为 2，表明该种葡萄酒最多有两种不同品种的葡萄酿制而成。如果最大值最小值都是 1，说明这种葡萄酒就是 1 种葡萄酿制而成的。所有时候将最大值设置成 0 也是非常有用的，表明对于某些特定的子类没有任何值满足条件。 数据类型 数据类型定义了 slot 的数据类型。 字符串（string）：最简单，最常用的数据类型。 数字（number）：数值类型的 slot，比如年龄、价格等。 布尔型（boolean）：yes 或者 no，true 或者 false 等 可枚举（enumerated）：给定 slot 可取到的值的列表，比如酒的口味可以是 [“重”，“中等”，“清淡”] 中的任意一种，而不能超过这三种的范围。 实例类型（instance）：slot 允许定义两个单独实体的关系，但是必须定义清楚哪些类别的实体是可以作为 slot 的值。比如“酒”这个类别，可以作为 “produces” 的值。 定义域和值域 允许使用实例类型作为 slot 的类别称之为值域，比如 “酒” 作为 “produces” 的 slot 值，“酒” 就是 “produces” 的值域。简单来说，就是 $x \\rightarrow y$，其中 $y$ 的所有实例数据类型的取值就是值域。 而定义域就是 slot 描述的对象。比如 “酿酒厂”，“produces”，“酒”，其中 “酿酒厂” 就是定义域。是简单来说，就是 $x \\rightarrow y$，其中 $x$​ 的取值范围就是定义域。 确定定义域和值域的规则是相似的： 找到最通用的类或者最具代表性的类别； 另一方面，不要将定义域和值域定义得范围太大，定义域中所有的值都可以被 slot 描述，值域中的所有值应该是 slot 的潜在填充值。不要选择过于笼统的类别，而是应该选择涵盖所有填充值的类别。 比如，“酿酒厂”，“produces” 的值域不应该是所有“酒” 的子类（“白酒”，“啤酒”，“红酒”等），而直接就是“酒”。同时，也不应该将“酒”进一步泛化到 “THING”。 具体来讲： 如果 slot 的值域或者定义域包括一个类别以及该类别下的子类，那么将其子类全部删掉 比如，一个 slot 的值域包括“酒”和“红酒”，那么应该将“红酒”删掉，因为“红酒”是“酒”的子类。 如果 slot 的值域或者定义域包含了 A 类的所有子类，但不包含 A 类本身，那么值域应该只包含 A 类本身而不包括其子类。 比如，一个 slot 的值域是“白酒”、“红酒”、“啤酒”等，我们可以将值域设为“酒”本身。 如果 slot 的值域或者定义域包含类别 A 中除少数子类以外的所有子类，那么我们应该考虑将类别 A 本身进行重新定义。 将一个 slot 挂在到一个类别上，和将该类别设为 slot 的定义域是完全等价的。一方面，我们应该尽可能泛化，另一方面我们应该保证 slot 对应的类别确实有相应的属性。总之一句话，我们既要一个都不差，也要避免张冠李戴。 3.7 第七步、构建实例最后一步就是根据我们建立的类别层级结构构建实例。定义一个实例需要： 选择一个类别； 创建该类的单一实例 填充 slot 值 比如，我们创建一个 飞天茅台 的实体用来表示 “白酒” 的实例。它的属性如下： 酒精度：53% 颜色：无色透明 香气：幽雅细腻 口味：回味悠长 产地：贵州省仁怀市 生产商：贵州茅台酒股份有限公司 4. 定义类别和类别层级结构本节讨论定义类别和类别层级结构时需要注意的点和容易出现的错误。对于任意领域来说都没有一个唯一正确的层级结构。我们所定义的层级结构依赖于我们要怎样使用本体，应用中必要的细节，个人喜好以及有时候可能还需要与其他模型进行兼容。但是我们还是要讨论一些开发层级结构时的一些指南，当我们开发完新的层级结构以后，回过头重新审视我们的定义是否满足这些指南，可以帮助我们避免很多错误。 4.1 保证类别层级结构的正确性 “is-a” 关系 如果类别 A 中的所有实例同时也是类别 B 的实例，此时我们就说类别 A 是类别 B 的子类，我们就可以定义关系（A，is-a，B）。比如，（“茅台酒”，“is-a”，“白酒”）。另一个也可以表示这种关系的是 “kind-of”，（“茅台酒” ，“kind-of”，“白酒”），（“肉”，“kind-of”，“食物”）等等。 单一的酒不是所有酒的子类 一个常见的错误是，在层级结构中包含同一个概念的单数版本和复数版本，然后令单数版本是复数版本的子类。比如，定义 “wine” 是 “wines” 的子类。然而这种关系是错误的。为了避免这种情况发生，在给类别命名的时候最好都采用单数形式或者都采用复数形式（第六节中讨论类别命名）。 层级关系的可传递性 满足以下条件的关系是可传递的： 如果 B 是 A 的子类，C 是 B 的子类，那么 C 也是 A 的子类。 比如，我们定义一个类别是 “酒”，然后定义 “白酒” 是 “酒” 的子类。然后再定义 “茅台酒” 是 “白酒” 的子类。那么可传递性表示 “茅台酒” 也是 “酒” 的一个子类。有时候我们会区分直接子类和间接子类。直接子类表示在层级结构中两个类别之间没有其他子类，即某一类别与其父类直接相连。而间接子类就是需要一个中间子类再与父类相连。实际上该子类也是中间父类的直接子类。 类别层级结构的演化 随着定义域的变化，要维护一个不变的层级结构可能会是一件很困难的事。比如通常我们见到的 “茅台酒” 是无色透明的，所以我们将 “茅台酒” 定义为 “白酒” 的子类。但是有可能在未来的某一天，酒厂发明了一种新的酿酒技术使得酒变成了黄色或者红色。此时，我们再将 “茅台酒” 归类到 “白酒” 里面可能就不太合适了。（这个例子实际上并不是很典型，一个比较典型的例子是组织结构的本体。组织结构的变动是很频繁的，一些部门今天还在，明天可能就取消了。） 类别及其名字的区别 区分类别和它的名字是至关重要的，通常也很难被注意到。 类别代表的是某一领域内的概念本身，而不是代表这个概念的几个单词。 我们选择的术语不同，其类别名就会发生变化，但实际上不同的术语表示的是同一个概念。比如 “克劳修斯表述”，“开尔文表述”，“熵增定律” 等等虽然名字不同，但都表示 “热力学第二定律” 这一概念。只是各自的名字不同罢了。再比如 “飞人乔丹”，“乔帮主” 都可以表示 “迈克尔·乔丹” 这个概念。 现实情况下，我们应该遵循以下规则： 表示相同概念的同义词不可代表不同的类别 同义词仅仅是相同概念的不同术语而已，因此，我们不能使用同义词来命名不同的类别。很多本体系统允许将同义词与表示类别名称相关联。比如，我们可以定义 “same_as” 关系，将“熵增定律”、“克劳修斯表述”和“开尔文表述”都关联到“热力学第二定律”上。如果不允许这种关联，则应该在类别文档中列出同义词。 避免类别套娃 类别层级结构中的循环指的是，类别 A 是类别 B 的子类的同时，类别 B 又是 类别 A 的子类，即两个类别互为子类和父类。是在构建层级结构的时候，我们应该避免出现这种情况。一旦出现这种情况就说明 A 和 B 是等价的：A 的所有实例也是 B 的实例，同时 B 的所有实例也是 A 的实例。 4.2 分析同级类别 层次结构中的同级类别 同级类别（siblings）指的是具有相同直接父类的类别。 除了根节点，所有同级类别必须处于同一层。 如图所示，“红酒”、“白酒”、“玫瑰酒” 同级别，“五粮液”、“鸭溪窖酒”、“贵阳大曲” 是同级别。 多少是太多？多少是太少？ 并没有一个硬性指标规定一个类别至少应该有多少个直接子类。但是很多结构比较规范的本体中的类别通常有 2 个到 12 个直接子类。因此，我们可以有以下经验： 如果一个给定类别只有一个直接子类，可能是本体建模有问题，或者本体不完全； 如果一个给定类别的子类过多（超过 12 个），可能需要一些中间类别重新归类 比如上图，如果我们构建的本体，“酒” 只有 “白酒” 一个直接子类，说明我们丢了 “红酒”、“玫瑰酒”等其他酒品。而如果把所有白酒都挂到 “白酒” 下面可能说明，我们对 “白酒” 的分类过于粗糙。因此，我们可以对 “白酒” 再进一步细分成 “酱香型”、“浓香型”、“清香型”等等。然后，再将对应的白酒挂上去。 4.3 多继承大多数知识表示系统都允许多继承：一个类别可以同时是多个类别的子类。比如，“啤酒”既可以是 “酒” 的直接子类，也可以是 “食物” 本体中 “调味料” 的直接子类。因此，“啤酒” 可以有两个父类：“酒” 和 “调味料”。“啤酒” 的所有实例同时也是 “酒” 和 “调味料” 的实例。当然，“啤酒” 也会同时继承 “酒” 和 “调味料” 的一些属性。 4.4 什么时候应该（不应该）引入新的类别？本体构建最难的部分应该就是什么时候引入新的类别，或者什么时候通过不同的属性值加以区分。也就是说，对于一个新的对象，我们是把它归到已有的类别然后给予不同的属性，还是新建一个类别？如果新建过多类别，会造成类别过多，甚至会出现彼此嵌套。而如果是新加属性加以区分的话 ，又会造成属性过于复杂。如何找到一个平衡点并不容易。 为了寻找这样一个平衡点，我们可以设定一些规则： 一个子类通常需要满足以下条件之一： 有一些父类不具备的属性； 与父类的限制条件不同； 与父类参与的关系类型不同 比如，“烤肉” 有一个属性 “几分熟”，但是其父类 “肉” 通常不会有这个属性。或者 “白酒” 的颜色限制为 “无色透明”（或者 “微黄透明”），而 “酒” 没有这个限制。换句话说，当我们想要描述的对象无法通过父类来描述的时候，就需要定义新的子类。 实际情况下，每个子类都应该有新的 slot，或者有新的 slot 值，又或者要覆盖原有的继承自父类的刻面。 有时候，没有新的属性的时候也可以引入新子类： 术语层级结构不需要引入新的属性 比如，电子病历系统基础的本体可以包括对各种疾病的分类。这个分类可能只是没有属性（或者有相同属性集）的术语层级结构。比如，“糖尿病”、“心脏病”、“高血压” 都是不带属性的，但是我们还是应该将这些术语分成不同的类，而不应该看成属性。 另一个无新增属性而要新建类别的情况是——约定俗成。某些领域内的对象，在领域专家眼中通常是区分对待的，我们构建的本体系统应该反映出领域专家对该领域的看法。因此，这种情况下，还是需要新增子类。 最后，我们不应该为每个附加的限制创建一个子类。比如，我们可以构建 “红酒”、“白酒”、“玫瑰酒” 的分类，但是不能构建 “扬州酒”、“贵州酒”、“法国酒” 等，单独根据产地属性的类别。 4.5 新的类别或者属性值？当我们对一个领域进行建模的时候，通常需要考虑将某些对象定义为属性还是类别的问题。 我们是要定义 “白酒”、“红酒” 作为 “酒” 的子类，还是要将 “白酒”、“红酒” 作为 “酒” 的 “颜色” 属性值？这通常取决于我们构建的本体的范围。“白酒” 在你的领域内重要性如何？如果 “白酒” 只是为我们提供一些边缘信息，或者与其他对象没有很重要的关系，那么我们就不应该将 “白酒” 作为一个类别来对待。 如果有不同 slot 的概念会变成其他类别的不同 slot 的限制，那么我们应该新建一个类别。否则我们就在属性中加以区分即可。 换句话说就是，如果 slot 的值发生了变，会使得类别也发生变化的话，那么我们应该新建一个类别。 比如，“红啤”、“白啤”、“黑啤” 等，这几种酒确实不是同一种酒。 如果领域内对对象的区分非常重要，并且我们将具有不同值的对象视为不同种类的对象，那么我们应该创建一个新类 同时我们还应该注意： 一个实例所属的类别不应该时常发生变动 通常情况下，当我们用外部属性而不是内秉属性来划分类别的时候，实例所属的类别经常会发生变化。比如，“热牛奶” 和 “常温牛奶” 并不应该分成两个类别，而是应该把温度设置成 “牛奶” 的属性。 另外，数字、颜色、地点通常应该是属性而不是类别。但是，对于 “酒” 来说，颜色应该是一个很重要的分类标准，所以在 “酒” 的分类中颜色应该属于类别而不是属性。 另一个人体解剖学本体的例子。当我们表示 “肋骨” 的时候，是否应该将肋骨分成 “左侧第一根肋骨”、“左侧第二根肋骨” 等？或者我们将肋骨的顺序和位置当成属性？如果在我们的本体中每根肋骨承载的信息非常不同的话，我们么确实应该为每根肋骨构建一个类别。比如，如果我们想要对肋骨不同位置的邻接信息建模，以及运动过程中每根肋骨所起的作用，或者不同肋骨保护的不同器官等等，这时候我们就需要对每根肋骨新建一个类别。如果我们只是对人体解剖学进行大致建模，那么我们只需要构建一个 “肋骨” 的类别，然后把 “位置” 和 “顺序” 作为属性即可。 4.6 实例还是类别？决定一个对象是类别还是实例，还是取决于我们构建的本体的潜在应用场景。类别结束实例开始的位置决定了本体的细节粒度。比如，“酸奶” 应该算是一个类别，还是实例？如果作为类别，它下面还有 “成都老酸奶”、“青海老酸奶” 等更细粒度的类别，如果 “酸奶” 作为实例，那么就不需要区分 “成都老酸奶” 和 “青海老酸奶”了。 要确定本体的细节粒度，可以回到本体构建步骤的第一步——我们想要利用这个本体回答什么问题？ 知识库中，单实例是粒度最细的概念。 比如，如果我们关心的是是否易消化，那么 “酸奶”、“纯牛奶” 就可以作为实例，而如果还要考察 “酸奶” 的制作工艺，口味特点等。那么 “酸奶” 就需要成为一个类别。 另外，如果满足以下条件，则可以将实例转化成类别： 如果一个概念天然有层级结构，那么我们应该把它当成类别。 比如，“地球有七个大洲”，我们可以把 “七大洲”（“亚洲”，“欧洲”，…） 当成 “地球” 的实例，但是 “七大洲” 是由不同国家组成的。因此，通常我们把每个大洲作为类别，而不是实例。 需要注意的是，只有类别有值域。在知识表示系统中，不存在 “subinstance” 的概念。因此，如果我们还想对一个概念进行细分，即使概念本身没有任何实例，也要把它当成类别，而不是实例。 4.7 限制本体范围 本体系统不需要包括领域内所有的信息：我们不需要细化或者泛化超过实际需求的本体。 比如，如果我们的用处是酒和食物的单配，那么我们就不需要知道如何酿酒和如何烹饪。 本体系统不需要包含所有的属性以及不同类别之间的区别。 本体系统不需要包含所有的关系 4.8 无交集子类如果两个类别的实例中没有公共实例，我们就认为这两个类别是无交集类别。比如 “红酒” 和 “白酒” 就是无交集类别：没有一种酒即是红酒又是白酒。在构建本体系统的时候，我们可以指定两个类别是无交集类别。指定无交集类别的好处是可以使本体更好进行验证——如果不指定的话，我们要看两个类别是否有交集还要将两个类别的实例全部读取出来，然后求交集看是否为空。不仅浪费空间还浪费时间。 同时，如果我们指定 “红酒” 和 “白酒” 是无交集类别的话，在进行建模的时候，如果创建了一个多继承子类，父类中包括了 “红酒” 和 “白酒”，那么系统可以很快识别出建模错误。 5. 定义属性——更多细节本节主要讨论可逆属性和属性默认值。 5.1 互逆属性（slot）一个 slot 的值可能依赖于另一个 slot 的值。比如，（wine，produced_by，winery）和（winery，produces，wine）这两个关系就是互逆关系。如果在本体系统中将两个关系都存下来，会显得整个本体冗杂。当我们知道某种酒的生产厂家是某某某的时候，我们就可以推断出某某某厂家生产了某种酒。从知识获取的角度来说，明确这种互逆关系对知识获取来说是很方便的。知识获取系统可以自动填写互逆关系的值，以确保知识库的一致性。 比如，当我们明确了 “produced_by” 和 “produces” 是互逆关系之后，当我们填写了 “茅台酒 produced_by 贵州茅台酒股份有限公司” 以后，系统可以自动填写 “贵州茅台酒股份有限公司 produces 茅台酒”。 5.2 默认属性值（slot value）许多基于框架的系统允许指定默认属性值。如果多数实例的特定属性是相同的，那么我们可以给这个属性指定一个默认值。然后，每次往该类别下添加有该属性的实例的时候，系统可以自动填充属性值。如果我们默认的属性值与该实例的实际属性值不符，我们还可以手动修改。 比如，如果多数白酒都是 53° 的，那么我们在 “酒精度数” 中可以默认为 53°。如果有些白酒不是 53°，还可以手动改成其他度数。 需要注意的是，默认属性值与属性值是不同的，默认属性值是可以修改的，而属性值是不可修改的。即如果我们定义了 “白酒” 的酒精度是 53°，那么所有 “白酒” 的子类和实例的酒精度都是 53°，这个度数在任意子类和实例中都不可修改。 6. 名字包含什么？ 本节讨论对概念命名规则，主要集中在英文名称中会出现的一些问题，比如大小写、分隔符、单复数等。这些问题在中文中都基本不会出现。但是就个人而言，还是建议使用英文进行知识建模。众所周知，现在很多系统对中文的支持并不是十分友好，使用中文建模的话很可能出现各种意想不到的问题，因此，能用英文建模的就尽量使用英文建模吧。 为本体中的概念设定一些命名规则，不仅可以使本体更容易理解，还能够帮助我们避免一些常见的建模错误。命名方法有很多，实际应用的时候可以选择合适的方法。但是，我们要： 定义一种类别和属性的命名规范，然后遵守它。 在知识表示系统中，我们可以考虑以下特征用于对概念进行命名： 本体中是否存在同名的类别、属性、实例？比如 “酿酒厂” 既是类别又是属性？ 本体系统大小写敏感吗？比如，系统是否人为 “Wine” 和 “wine” 是同一个概念？ 名称中允许出现什么样的分隔符？空格、逗号、星号等等？ 6.1 大小写与分隔符首先，如果我们在本体中保证概念名称的大小写一致性能够大幅提升本体的可读性。比如，通常的做法是大写类别名称，小写属性名称（假设大小写敏感）。 当概念名称中有不止一个词的时候，我们需要在词与词之间添加分隔符。通常分隔符有以下几种选择： 空格 词与词之间没有分隔符，而是将每个词的首字母大写，比如 “MealCourse” 使用下划线或者连接符，比如 “meal_course”，“meal-course” 等 在使用空格的时候，需要考虑你所使用的本体建模工具是否支持空格，以及你构建出来的本体是否会与其他本体系统交互使用，如果有交互，需要交互的本体系统是否支持空格。因此，虽然用空格作为分隔符更符合人类的习惯，但是需要考虑的因素比较多，更建议使用后两种方案。 6.2 单数还是复数？一个类别的名称代表的是一些列对象的集合。所以，建议使用复数作为类别的名称。但是无论使用单数还是复数，都要在整个本体中保持一致，不要出现在这里是单数，淡了另一处就变成了复数。甚至有些本体建模工具会要求用户指定概念名称的单复数。 6.3 前缀和后缀的规则有些知识库会建议使用前缀或者后缀还区分类别名和属性名。属性名中常用的两种前缀或者后缀：“has-” 或者 “-of”。比如 “has-maker” 或者 “*maker-of”。通过这种方式区分类别名和属性名可以提高可读性。 6.4 命名中的一些其他考量 不要在概念名称中出现 “class”、“property”、“slot” 等词汇 避免使用缩写 对直接子类进行命名的时候，要么所有子类都包含父类的名称，要么都不包含父类的名称。不要出现有些子类包含父类有些不包含的情况。比如 “red wine” 和 “*white” 7. 其他可参考资料 WonderTools? A comparative study of ontological engineering tools, Duineveld, A.J., Stoter, R., Weiden, M.R., Kenepa, B. and Benjamins, V.R. (2000). Knowledge sharing and reuse. Gómez-Pérez, A. (1998). Ontologies: Principles, Methods and Applications, Uschold, M. and Gruninger, M. (1996). Ontolingua tutorial. Farquhar, A. (1997). An Environment for Merging and Testing Large Ontologies. McGuinness, D.L., Fikes, R., Rice, J. and Wilder, S. (2000). 8. 总结本文描述了构建本体的方法和步骤。讨论了构建过程中需要注意的问题。但是我们需要记住一点： 对于任意领域来说都没有一个唯一正确的方法 本体的构建是一个创造的过程，即使是以相同的目的和应用场景构建相同领域的本体，不同的人都会得到不同的本体。主要能满足我们的需求，就是好的本体。 ReferenceOntology Development 101: A Guide to Creating Your First Ontology. Natalya F. Noy and Deborah L. McGuinness","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://rogerspy.gitee.io/categories/知识图谱/"}],"tags":[{"name":"ontology","slug":"ontology","permalink":"https://rogerspy.gitee.io/tags/ontology/"},{"name":"KG","slug":"kg","permalink":"https://rogerspy.gitee.io/tags/kg/"}]},{"title":"双数组前缀树","slug":"double_array_trie","date":"2021-08-16T12:34:43.000Z","updated":"2022-01-12T08:37:38.329Z","comments":true,"path":"2021/08/16/double_array_trie/","link":"","permalink":"https://rogerspy.gitee.io/2021/08/16/double_array_trie/","excerpt":"前缀树（trie）又叫字典树，顾名思义通过字符串的前缀进行查找、匹配的数据结构。Trie 树的应用场景主要包括：分词、词频统计、字符串查询和模糊匹配、字符串排序等。Trie 树大幅降低重复字符串的比较，所以执行效率非常高。","text":"前缀树（trie）又叫字典树，顾名思义通过字符串的前缀进行查找、匹配的数据结构。Trie 树的应用场景主要包括：分词、词频统计、字符串查询和模糊匹配、字符串排序等。Trie 树大幅降低重复字符串的比较，所以执行效率非常高。 1. Trie 树简介前缀树是将字符串存储在一棵树结构内，该树是将字符串的公共前缀作为父节点。以下图为例： 假设有三个词，分别是“茶叶”、“茶树”、“走廊”。将这三个词存储在 Trie 树里如上图所示。“茶树”和“茶叶”有公共前缀“茶”，所以“茶”作为“叶”和“树”的父节点。而“走廊”和前两个词无公共前缀，所以独立成一个分支。另外 root 节点表示根节点，所有词的匹配、查找都是从根节点开始的。而 null 为叶节点表示从根节点 root 到 叶子节点 null 的路径组成一个完整的词。Trie 树具有以下几个特点： 具有相同前缀的词必须位于同一个路径下。“叶”和“树”要共用一个父节点“茶”。 Trie 树中的词只可共用前缀，不可共用词的其他部分。比如，现在有一个新词“卖茶”，虽然都有“茶”，但是它并不是“卖茶”的前缀，所以“卖茶”要与“茶叶”和“茶树”在不同的分支上。 Trie 树中任何一个完整的词，都必须是从根节点开始至叶子节点结束，这意味着对一个词进行检索也必须从根节点开始，至叶子节点才算结束。 2. 搜索 Trie 树的时间复杂度在 Trie 树中搜索一个字符串，会从根节点出发，沿着某条路径向下逐字比对字符串的每个字符，直到抵达底部的叶子节点才能确认字符串为该词，这种检索方式具有以下两个优点： 公共前缀的词都位于同一个串内，查词范围因此被大幅缩小（比如首字不同的字符串，都会被排除）。 Trie 树实质是一个有限状态自动机（Deterministic Finite Automaton, DFA），这就意味着从 Trie 树 的一个节点（状态）转移到另一个节点（状态）的行为完全由状态转移函数控制，而 状态转移函数本质上是一种映射，这意味着：逐字搜索 Trie 树时，从一个字符到下一个字符比对是不需要遍历该节点的所有子节点的。 确定的有限自动机 M 是一个五元组： M = (\\Sigma, Q, \\delta, q_0, F)其中， $\\Sigma$ 是输入符号的有穷集合； $Q$ 是状态的有限集合； $\\delta$ 是 $Q$ 与 $\\Sigma$ 的直积 $Q × \\Sigma$ 到 $Q$ (下一个状态) 的映射。它支配着有限状态控制的行为，有时也称为状态转移函数。 $q_0 \\in Q$ 是初始状态； $F$ 是终止状态集合，$F \\subseteq Q$； 可以把 DFA 想象成一个单放机，插入一盘磁带，随着磁带的转动，DFA 读取一个符号，依靠状态转移函数改变自己的状态，同时磁带转到下一个字符。 这两个优点相结合可以最大限度地减少无谓的字符比较，使得搜索的时间复杂度理论上仅与检索词的长度有关：$O(m)$，其中 $m$ 为检索词的长度。 3. Trie 树的缺点综上可知， Trie 树主要是利用词的公共前缀缩小查词范围、通过状态间的映射关系避免了字符的遍历，从而达到高效检索的目的。这一思想有赖于字符在词中的前后位置能够得到表达，因此其设计哲学是典型的“以信息换时间”，当然，这种优势同样是需要付出代价的： 由于结构需要记录更多的信息，因此 Trie 树的实现稍显复杂。好在这点在大多数情况下并非不可接受。 Trie 型词典不仅需要记录词，还需要记录字符之间、词之间的相关信息，因此字典构建时必须对每个词和字逐一进行处理，而这无疑会减慢词典的构建速度。对于强调实时更新的词典而言，这点可能是致命的，尤其是采用双数组实现的 Trie 树，更新词典很大概率会造成词典的全部重构，词典构建过程中还需处理各种冲突，因此重构的时间非常长，这导致其大多用于离线；不过也有一些 Trie 可以实现实时更新，但也需付出一定的代价，这个缺点一定程度上影响了 Trie 树的应用范围。 公共前缀虽然可以减少一定的存储空间，但 Trie 树相比普通字典还需表达词、字之间的各种关系，其实现也更加复杂，因此实际空间消耗相对更大（大多少，得根据具体实现而定）。尤其是早期的“Array Trie”，属于典型的以空间换时间的实现，（其实 Trie 本身的实现思想是是以信息换时间，而非以空间换时间，这就给 Trie 树的改进提供了可能），然而 Trie 树现今已经得到了很好的改进，总体来说，对于类似词典这样的应用，Trie 是一个优秀的数据结构。 4. Trie 树的几种实现Trie 树实现:一般的链表指针方式，三数组实现，双数组实现，HAT，burst trie 等。 链表指针方式 即每个节点对应一个字符，并有多个指针指向子节点，查找和插入从根节点按照指针的指向向下查询。这种方案，实现较为简单，但指针较多，较为浪费空间；树形结构，指针跳转，对缓存不够友好，节点数目上去之后，效率不够高。 Hash Trie 树以及 Burst trie 是将 trie 树和其他数据结构，比如 HashMap，结合起来，提高效率。但主要用于键值查找，对于给定一个字符串匹配其前缀这种场景不适用。 三数组实现 利用三个数组（分别叫做 base, next, check）来实现状态的转移，将前缀树压缩到三个数据里，能够较好的节省内存；数组的方式也能较好的利用缓存。 双数组实现 是在三数组的基础上，将 base 数组重用为 next 数组，节省了一个数组，并没有增加其他开销。与三数组相比，内存使用和效率进一步提升。 综上，双数组 trie（Double Array trie，简称为 DATrie）的实现有明显的优势，以下讨论 DATrie 的细节（只介绍构造和查询，删除节点不常用，而且比较复杂，暂时略过）。 5. Double-Array Trie 树5.1 DATrie 构造方法 数组表示 trie 树的状态转移，父节点跳转到子节点转化为父状态跳转到子状态。 利用两个数组 base, check表示状态的转移： base 数组的索引用来表示状态 base 数组里存的数据称为 offset check 数组里存的数据是父状态的索引 check 与base 大小相同，一一对应，用于保存父状态，以及解决冲突 状态 S 接收到字符 c 后转移到状态 T: S \\overset{c}{\\to} T满足： 123check[base[S] + c] = Sbase[S] + c = Tbase[T] = base[S] base 数组的索引为 0，1，…, base[s], …, S, …, T，均表示 trie 树的状态 从 S 状态接收到 c 跳转到 T, 则表示为 base 数组索引为 S 的内容 base[S] 为基地址，加上跳转偏移 c，得到下一个 T 状态在 base 的索引 T=base[S] + C check 数组对应 T 的内容 check[T] 为跳转过来的父状态，即 S。 5.2 DATrie 查询 从 base 数组索引 0 开始，初始状态为 S=base[0]，其中偏移的基地址为 base[S] 接受到 c，则跳转到 base 数组索引 T=base[S] + c，检查此时 check 数组的 check[T] == S，为真跳转到 3，否则匹配失败。 如果 base[T] == LEAF_VALUE （这里 LEAF_VALUE 用来表示叶子节点的特殊值），则匹配完成；否则，令 S = T, 跳转到 2。 状态更新的伪码如下： 1234567T := base[S] + cif check[T] = S then next state := Telse failendif 5.3 举个例子 假定输入两个前缀为 ‘ab’ , ‘ad’ ，将字母 a-z 映射为数字 1，2，3,…, 26. 这里用 -1 代表数组元素为空，-2 代表叶子节点，-3 代表根节点 状态如下： 初始状态 输入 ‘a’ （’ab’） base[0]+a，由状态 0 跳转到状态 2。check[2] 为 -1，说明为空，更新为父状态 0；base[2]更新为跳转过来的 base, 即 base[0] 的值 1。 输入 ‘b’ （’ab’） base[2]+b，由状态 2 跳转到状态 3，check[3]为 -1，说明为空，更新为父状态 2；由于字符串结束，将 base[3] 更新为 -2，代表叶节点。 输入 ‘a’（’ad’） 图中 base 和 check 的状态不会变化。 根据 base[0]+a，从状态 0 跳转到 2。check[2] 不为空，但check[2] 的值 0 与其父状态 S=0 相等，则无需更新，进入状态 2，等待输入下一个字符。这个过程相当于一个查询过程。 输入 ‘d’ （’ad’） base[2]+d，由状态 2 跳转到状态 5，check[5] 为 -1，说明为空，更新为父状态 2；由于字符串结束，将 base[5] 更新为 -2，代表叶节点。 5.4 解决冲突DATrie 不可避免会出现冲突。仍以上面的例子说明，继续插入 ‘ca’： 输入 ‘c’（’ca’） 状态由 0 跳转到状态 4，check[4] 空闲，将 check[4] 赋值为 0，base[4] 赋值为1。 输入 ‘a’ （’ca’） 根据 base[4]+4 状态从4跳转到2， 但是 check[2] 非空，并且 check[2]=0 不等于父状态 4，此时发生冲突。 解决冲突 挪动以 4 为父状态状态转移，查找对应 base，check 的连续的空闲空间以放入状态。这里只有最新的输入 ‘a’ 带来的状态转移以 4 为父状态。base[6], check[6] 有空闲。 修改 base[4], 使其能够根据输入跳转到空闲空间，即 base[4] = 6 - a = 5。 重新插入 ‘a’，如下图 6. Trie 树的压缩双数组 Trie 树虽然大幅改善了经典 Trie 树的空间浪费，但是由于冲突发生时，程序总是向后寻找空地址，导致数组不可避免的出现空置，因此空间上还是会有些浪费。另外， 随着节点的增加，冲突的产生几率也会越来越大，字典构建的时间因此越来越长，为了改善这些问题，有人想到对双数组 Trie 进行尾缀压缩，具体做法是：将非公共前缀的词尾合并为一个节点（tail 节点），以此大幅减少节点总数，从而改善树的构建速度；同时将合并的词尾单独存储在另一个数组之中（Tail array）， 并通过 tail 节点的 base 值指向该数组的相应位置，以 {baby, bachelor, badge, jar} 四词为例，其实现示意图如下: 速度：减少了 base， check 的状态数，以及冲突的概率，提高了插入的速度。 内存：状态数的减少的开销大于存储 tail 的开销，节省了内存。 删除：能很方便的实现删除，只需将 tail 删除即可。 7. 总结 Trie 树是一种以信息换时间的数据结构，其查询的复杂度为 $O(m)$。 Trie 的单数组实现能够达到最佳的性能，但是其空间利用率极低，是典型的以空间换时间的实现。 Trie 树的哈希实现可以很好的平衡性能需求和空间开销，同时能够实现词典的实时更新。 Trie 树的双数组实现基本可以达到单数组实现的性能，同时能够大幅降低空间开销；但是其难以做到词典的实时更新。 对双数组 Trie 进行 tail 改进可以明显改善词典的构建速度，同时进一步减少空间开销。 Reference 小白详解 Trie 树, xu_zhoufeng Double-Array Trie（双数组字典树）, huangwei1024 前缀树匹配(Double Array Trie), minzhan’s blog 双数组前缀树（Double-Array Trie）, 两片","categories":[{"name":"博客转载","slug":"博客转载","permalink":"https://rogerspy.gitee.io/categories/博客转载/"}],"tags":[{"name":"双数组前缀树","slug":"双数组前缀树","permalink":"https://rogerspy.gitee.io/tags/双数组前缀树/"},{"name":"数据结构","slug":"数据结构","permalink":"https://rogerspy.gitee.io/tags/数据结构/"}]},{"title":"预训练语言模型：Word Embedding","slug":"ptm-word-embedding","date":"2021-08-11T13:27:18.000Z","updated":"2022-01-12T08:37:38.404Z","comments":true,"path":"2021/08/11/ptm-word-embedding/","link":"","permalink":"https://rogerspy.gitee.io/2021/08/11/ptm-word-embedding/","excerpt":"词嵌入（word embedding）是一种用稠密向量来表示词义的方法，其中每个词对应的向量叫做词向量（word vector）。词嵌入通常是从语言模型中学习得来的，其中蕴含着词与词之间的语义关系，比如 “猫” 和 “狗” 的语义相似性大于 “猫” 和 “计算机” 。这种语义相似性就是通过向量距离来计算的。","text":"词嵌入（word embedding）是一种用稠密向量来表示词义的方法，其中每个词对应的向量叫做词向量（word vector）。词嵌入通常是从语言模型中学习得来的，其中蕴含着词与词之间的语义关系，比如 “猫” 和 “狗” 的语义相似性大于 “猫” 和 “计算机” 。这种语义相似性就是通过向量距离来计算的。 1. 简介1.1 词表示法简史自然语言文本在很长时间里并没有一个统一的表示法，用于计算机进行计算。通常人们给每个词分配一个 id，将词作为离散符号输入计算机系统。 查字典 最直接的方法是创建一个词表，每个词分配一个唯一的 ID，比如： 我， 0 是， 1 谁， 2 … One-hot 编码 同样是先建立一个词表，然后给词表中的每个词分配一个大小为词表大小的向量来表示词。每个词对应的向量中，只有一个位置的数字为 1，其他位置上的数字全部是 0。词与词的 one-hot 向量两两正交。整个词表就是一个 $1\\times (N+1)$ 的矩阵，其中 $N$ 表示词表大小，额外的 1 表示 UNK ，即不在词表中的词的统一标识。比如： 我，[1, 0, 0, 0, …] 是，[0, 1, 0, 0, …] 谁，[0, 0, 1, 0, …] … Distributional 表示法 以上两种方法存在着一下几个问题： 正交。词与词之间的语义丢失，我们没有办法从向量表示中得到词与词之间的关联性， 维度爆炸。通常一个词表会有几万个词，如果用 one-hot 表示，那么整个词表的 one-hot 就是一个几万乘几万的矩阵，极大地消耗了计算机资源。 矩阵稀疏。one-hot 矩阵中，除了特定位置上的数字是 1， 其余位置全部是 0，造成整个矩阵极端稀疏化，运算过程中极大地浪费了算力， 因此，人们提出了分布式表示法，希望通过稠密向量来获得词嵌入矩阵。而得到稠密向量的方法就是我们下面要介绍的。 1.2 发展里程碑 2003 年 —— 前馈神经网络语言模型 2003 年 Bengio 等人提出前馈神经网络语言模型（FFNNLM），该模型的一个重要副产物就是词向量。相当于提出了一种利用语言模型训练词向量的方法，同样为后来的 Word2vec 打下了基础。 2005 年 —— 层级 Softmax Morin &amp; Bengio 提出层级 softmax 思想。给定大小为 $V$ 的词表，通过一棵二叉树计算输出词的概率分布，将计算复杂度从 $O(V)$ 降到 $O(\\log(V))$。这一思想成为后来 word2vec 模型的重要组成部分。 2010 年 —— Noise Contrastive Estimation Gutmann &amp; Hyvarinen 提出噪声对比估计（NCE）方法。其基本思想是：一个好的模型可以利用逻辑回归从噪声中识别有用数据。后来 NCE 被 Mnih &amp;Teh 用于语言模型。后来 Word2vec 中的负采样技术就是 NCE 的简化版。 2013 年 —— word2vec Mikolov 等人提出 word2vec 模型，使得大规模训练词向量成为现实。Word2vec 包含两个模型：skip-gram 和 CBOW。为了加速计算，word2vec 将 softmax 替换成层级 softmax，二叉树用的是哈夫曼树（Huffman tree）。 2013 年 —— 负采样 Mikolov 等人对原来的 word2vec 模型进行了优化，提出负采样的方法。负采样是噪声对比估计的简化版，比层级 softmax 更简单、更快。 2014 年 —— GloVe Pennington 等人基于词共现的方法，提出另一种训练词向量的方法：Glove。与 word2vec 相比，两个模型表现相差不大，而 GloVe 更容易并行化训练。 接下来我们介绍两种主要的训练词嵌入的方法： Context-based：给定上下文，设计模型预测中心词。 Count-based：统计文本中词的共现矩阵，然后利用矩阵分解的方法对矩阵进行降维。 2. Context-based: Word2Vec2013 年 Mikolov 等人提出一种模型 —— Word2Vec。该模型包含两种架构：Continuous Bag-of-Words（CBOW） 和 Continuous Skip-gram（Skip-gram），然后在随后的文章中提出了两种模型训练的优化方法：hierarchical softmax（层级 softmax） 和 negative sampling（负采样）。Mikolov 等人不是第一个提出连续向量表示词的人，但是他们提出的 word2vec 模型是第一个能应用在大规模语料上的模型，具有非常重要的意义。 假设有一个固定大小的滑动窗口，沿着句子从头到尾滑动取片段，每个窗口中中心词即为目标词（target），其他的词为上下文（context）。举个例子（假设已经分词）： 天才 就是 百分之一 的 灵感 加 百分之九十九 的 汗水。 滑动窗口（size=5） target context [天才, 就是, 百分之一] 天才 就是, 百分之一 [天才, 就是, 百分之一, 的] 就是 天才, 百分之一,的 [天才, 就是, 百分之一, 的, 灵感] 百分之一 天才, 就是, 的, 灵感 … … … [灵感, 加, 百分之九十九, 的, 汗水] 百分之九十九 灵感, 加, 的, 汗水 [加, 百分之九十九, 的, 汗水] 的 加, 百分之九十九, 汗水 [百分之九十九, 的, 汗水] 汗水 百分之九十九, 的 2.1 Skip-Gram ModelSkip-gram 模型的核心思想是通过中心词预测上下文，即： p(w_{i-2}, w_{i-1}, w_{i+1}, w_{i+2}|w_i)Skip-gram 模型采用的是一个浅层神经网络来计算这个概率分布。该一共只有三层：输入层、投影层（隐藏层）、输出层。模型结构如下图： 假设上下文中的词相互独立，则： p(w_{i-2}, w_{i-1}, w_{i+1}, w_{i+2}|w_i) = p(w_{i-2}|w_i)\\cdot p(w_{i-1}|w_i) \\cdot p(w_{i+1}|w_i)\\cdot p(w_{i+2}|w_i)相当于训练样本的（target，context）对拆解成 $2m$个（target，context word）对，其中 $m$ 表示滑动窗口除中心词外一半大小（很多地方会直接把 $m$ 定义为窗口大小），context word 表示上下文中每个词。例如，中心词为 “百分之九十九”，那么训练样本就是： （百分之九十九，灵感） （百分之九十九，加） （百分之九十九， 的） （百分之九十九， 汗水） 此时，上面的模型结构则等效于下图： 模型的输入是中心词，输出是上下文词之一。 假设词表 $\\mathcal{V}$​​​​​ 的大小为 $V=|\\mathcal{V}|$​​​​​，中心词在词典中的索引为 $i$​​​​​，上下文对应的词在词表中的索引为 $j$， $N$ 表示词向量 $\\boldsymbol{v}_i$ 的维度，即 $\\boldsymbol{v}_i \\in \\mathbb{R}^N$​​​​​。 关于模型的一些细节： $\\boldsymbol{x}$​​​ 和 $\\boldsymbol{y}$​​​ 都是 one-hot 编码，编码中 $i$​ 和 $j$​ 对应的位置为 1，其余位置全部为 0，$\\boldsymbol{x},\\boldsymbol{y} \\in \\mathbb{R}^{1\\times V}$​。​​​ 首先，将输入 $\\boldsymbol{x}$​​ 与一个 $\\boldsymbol{W}$​​ 矩阵相乘得到隐藏层 $\\boldsymbol{h}$​​，其中 $\\boldsymbol{W}\\in \\mathbb{R}^{V\\times N}$​​​​​​​ ，则 $\\boldsymbol{h}\\in \\mathbb{R}^{1\\times N}$​​。实际上 $\\boldsymbol{h}$​ 相当于 $\\boldsymbol{W}$​ 的第 $i$​ 行： [0, ..., 1, ..., 0] \\times \\left[ \\begin{matrix} w_{00}, w_{01}, ..., w_{0N} \\\\\\\\ \\vdots \\\\\\\\ w_{i0}, w_{i1}, ..., w_{iN} \\\\\\\\ \\vdots \\\\\\\\ w_{V0}, w_{V1}, ..., w_{VN} \\end{matrix} \\right] = \\left[w_{i0}, ...,w_{ii}, ..., w_{iN}\\right] 用 $\\boldsymbol{h}$​ 与另一个矩阵 $\\boldsymbol{W’}\\in \\mathbb{R}^{N\\times V}$​​ 相乘得到一个 $1\\times V$ 的向量 $\\boldsymbol{h’}$。 将 $\\boldsymbol{h’}$ 进行归一化即可得到 $\\boldsymbol{y}$​ 的 one-hot 概率分布： \\boldsymbol{y} = \\mathrm{softmax}(\\boldsymbol{h'}) $\\boldsymbol{y}$ 中概率最大的位置 $j$ 即对应词表第 $j$ 个词： w_j = \\mathcal{V}_{j=\\arg \\max (\\boldsymbol{y})}比如： 假设 $\\mathcal{V}=[我，的，灵感，天才，…]$ $\\boldsymbol{y} = [0.1, 0.2, 0.3, 0.2, 0.15, 0.05]$ $\\boldsymbol{y}$​ 中最大概率为 0.3，对应的索引是 2，即 $j=2$​​， 则 $w_j = \\mathcal{V}_2 = 灵感$​。 模型中有两个矩阵 $\\boldsymbol{W}$ 和 $\\boldsymbol{W’}$​，非别对应着中心词的向量编码和上下文的向量编码。在自然语言处理应用中，一般使用中心词向量作为词的表征向量，即 $\\boldsymbol{W}$ 就是我们最终得到的 word embedding。 2.2 CBOW Model连续词袋模型（CBOW）模型与 skip-gram 模型正相反，CBOW 是利用上下文来预测中心词，即： p(w_i|w_{i-2},w_{i-1},w_{i_1},w_{i+1})模型结构如下图所示： 由于 CBOW 模型的输入有多个，所以我们将得到的 context 向量取平均，然后使用和 skip-gram 一样的方法来计算中心词的概率分布。 \\boldsymbol{h} = \\frac{1}{2m}\\sum \\boldsymbol{x}_i \\cdot \\boldsymbol{W}2.3 Loss/object Functions无论是 skip-gram 模型还是 CBOW 模型，模型参数就是中心词向量和上下文词向量对应的嵌入矩阵 $\\boldsymbol{W}$​​​​ 和 $\\boldsymbol{W’}$​​​。给定输入词 $w_I$​​​ ，其在 $\\boldsymbol{W}$​​​ 中对应的向量为 $\\boldsymbol{v}_I$​​​​（即 $\\boldsymbol{h}$​​）。$\\boldsymbol{W’}$​​ 中每一列对应的词向量为 $\\boldsymbol{v’}_j$​​​​​​。输出词 $w_O$​​ 对应的词向量为 $\\boldsymbol{v’}_o$​​。 通过最小化损失函数对模型进行训练，下面以 skip-gram 为例介绍一些常用的损失/目标函数。 2.3.1 标准 Softmax（Full Softmax）用数学语言来描述上面的模型，即对于单个样本我们的目标函数为： p(w_O|w_I) = \\frac{\\exp(\\boldsymbol{v'}_O^\\mathsf{T} \\cdot \\boldsymbol{v}_I)}{\\sum_{j=1}^V\\exp(\\boldsymbol{v'}_j^\\mathsf{T} \\cdot \\boldsymbol{v}_I)}从上式可以看出，对于任意单一样本，我们都需要对全词表进行指数求和，然而当 $V$ 非常大的时候（实际情况下 $V$​ 通常会有几万到几十万），计算将会变得非常复杂，根据 2.3.3 节关于交叉熵损失函数的介绍中，我们也可以看出进行后向传播的时候，计算过程同样是需要计算完整词表。因此，Morin and Bengio 等人在 2005 年的时候，提出了层级 Softmax，采用二叉树来加速计算。 2.3.2 层级 Softmax（Hierarchical Softmax） 由于标准的 softmax 的计算复杂度较高，所以人们就不断思考对其进行优化。2001 年 Goodman 提出基于分类思想的加速方案。简单来说，假设我们词表中有 10000 个词，在传统的方法是在这 10000 个词上做 softmax 获得每个词的概率分布，然后取出概率最大的词，这样我们需要计算 10000 次。如果我们将这 10000 个词进行分类，假设分成 100 个类别，每个类别 100 个词。这个时候我们的计算过程是，先用一个 softmax 计算下一个词是属于什么类别，然后再用一个 softmax 计算概率最大的类别中的词的概率分布，这样我们只需要两个 100 次的计算量，计算速度直接提升 50 倍。 基于这个思想，Morin &amp; Bengio 于 2005 年提出层级 softmax 的方法：使用平衡二叉树来构建这种分类关系，能够将计算复杂度降到 $O(\\log_2(|\\mathcal{V}|))$。由于他们利用的是先验知识（wordnet 中的 is-a 关系）来构建二叉树，最终的而效果并不理想。随后 Mnih &amp; Hinton 采用 boostrapping 的方法，从一个随机树开始自动学习一棵平衡二叉树。 直到 2013 年 Mikolov 等人提出使用 Huffman 树来代替平衡二叉树，使得层级 softmax 在效果和效率上都达到了新的高度。 2.3.2.1 Huffman 树Huffman 树是一个用于数据压缩的算法。计算机中所有的数据都是以 0 和 1 进行存储的，最简单的数据编码方式是 等长编码。假设我们的数据中有 6 个字母，那么我们要将这些字母区分开，就至少需要三位二进制数来表示，$2^3=8&gt;6$，如果数据中的字符数更多，那就需要更长的二进制数进行编码。然而我们希望用尽可能少的二进制数对数据进行编码，尤其是实际生活中，有些字符使用频率非常高，另一些字符很少使用。我们希望使用频率高的字符编码长度更短，这样就可以节省存储空间了。所以这里就涉及到 变长编码。 比如，给定一个字符串 aabacdab，包含了 8 个字符，我们发现这个这个字符串中包含了 4 个不同的字符 a、b、c、d，分别对应的频率为 4、2、1、1。由于 a 的频率大于 b，b 的频率大于 c 和 d。所以，我们可以给 a 分配一个 1 位的编码长度，b 分配 2 位的编码长度，c 和 d 分配 3 位的编码长度： 1234a: 0b: 11c: 100d: 011 所以，aabacdab 就被编码成了 00110100011011（0|0|11|0|100|011|0|11）。但是这个编码会有问题，那就是歧义性。因为我们不仅需要编码，还需要解码。当我们把数据存储到计算机以后，还需要从计算机中将数据读取出来。读取数据的过程就是解码的过程。如果我们用上面的编码进行存储解码的时候，会出现不同的解码方式： 12340|011|0|100|011|0|11 adacdab0|0|11|0|100|0|11|011 aabacabd0|011|0|100|0|11|0|11 adacabab… 为了避免解码歧义，我们需要保证编码满足 “前缀规则”：任意编码不能是其他编码的前缀。在上例中，0 是 011 的前缀，所以才会出现解码歧义性问题。 Huffman 树就是用来做这种变长编码的数据结构，构造过程如下： 计算字符频率 根据词频对字符进行排序，并按升序进行排列，得到序列 Q： 创建一个空节点 z。节点 z 的左子节点是频率最低的字符，右子节点是频率第二低的字符。节点 z 的频率为左右子节点字符频率之和 从 Q 中删除两个上一步中两个频率最低的字符，然后将两者频率之和添加到 Q 中。 重复 3-4 两步 将左侧的边赋值为 0，右侧的边为 1。 这样就构建好了一棵 Huffman 树。Huffman 编码就是找到从根节点到对应的字符之间的路径，然后将路径上的边对应的值拼接在一起。比如，上例中的 A、B、C、D 的编码分别为：11、100、0、101。 解码过程就是按照编码找到相应的路径： 2.3.2.2 基于 Huffman 树的层级 softmaxWord2vec 中是预先统计语料中的词频，根据词频构建起一棵 Huffman 树。 Huffman 树的每个叶子节点是词表中的一个词，每个除叶子节点和根节点以外的节点都表示一个二分类的概率，这个概率用来决定去往左右子节点的路径。 如上图所示，每个叶子结点（白圈）表示一个词表中的词 $w_i$，每个非叶子节点（灰圈）表示该路径上的概率。每个词都有一条唯一可达的路径，$n(w_i, j)$ 表示 $w_i$ 的路径上 第 $j$ 个节点。比如 $w_2$ 的路径就是 $n(w_2,1)n(w_2,2)n(w_2,3)w_2$。这条路径就对应 Huffman 编码。$w_2$ 的概率就是这条路径上每个节点的概率累积： p(w_O \\vert w_I) = \\prod_{j-1}^{L(w_O)-1} p(n(w_O,j))其中 $L(w_O)$ 表示 $w_O$ 的路径长度（Huffman 编码长度）。由于这是一个二叉树，相当于 $p(n(w_O,j))$ 是一个二分类，所以可以使用 $\\sigma$ 函数进行计算： p(w_O \\vert w_I) = \\prod_{j=1}^{L(w_O)-1} \\sigma({\\mathbb{I}_{\\text{turn}} \\cdot\\boldsymbol{v'}_{n(w_O, j)}}^{\\top} \\cdot \\boldsymbol{v}_{w_I})其中 $v’_{n(w_O,j)}$ 表示 $n(w_,j)$ 节点对应的向量，$\\mathbb{I}_{\\text{turn}}$ 表示特殊的标识函数：如果 $n(w_O,j+1)$ 是 $n(w_O,j)$ 的左子节点，则 $\\mathbb{I}_{\\text{turn}}=1$ ，否则为 $\\mathbb{I}_{\\text{turn}}=-1$。比如，上图中，我们要计算 $w_2$ 的概率： P(w_2 \\mid w_I) = \\sigma(\\boldsymbol{v'}_{n(w_2,1)}^\\top \\boldsymbol{v}_I) \\cdot \\sigma(\\boldsymbol{v'}_{n(w_2,2)}^\\top \\boldsymbol{v}_I) \\cdot \\sigma(-\\boldsymbol{v'}_{n(w_2,3)}^\\top \\boldsymbol{v}_I)内部节点的向量 $\\boldsymbol{v’}_{n(w_i, j)}$ 可以通过训练得到。由 $\\sigma(\\cdot)$ 的定义： \\sigma(z) = \\frac{1}{1+\\exp(-z)}可知，整个概率的计算都无需遍历整个词表，只需计算 $\\log_2(V)$ 次 $\\sigma(\\cdot)$ 即可，相当于将计算复杂度降低到了 $\\log_2(V)$，大幅提升了计算效率。 由于 $\\sigma(x)+\\sigma(-x)=1$，给定中心词 $w_I$，生成词典 $\\mathcal{V}$ 中任意词的体哦阿健概率之和也满足： \\sum_{w\\in \\mathcal{V}} p(w|w_I)=1由于 Huffman 树是用来对数据进行压缩编码的，其主要思想是高频的词距离根节点越近，那么它的路径就会越短，所需要计算的 $\\sigma(\\cdot)$ 函数的次数也会越少。所以相比平衡二叉树，Huffman 树的计算更有效率。 需要注意的是，我们在训练过程中，由于已知我们需要预测的词是哪一个，所以只需要计算对应的词的概率，然后进行优化即可。但是在推理过程中，我们并不知道哪个词是最优解，所以还是需要遍历整个词表。所以基于 Huffman 树的 word2vec 加速了训练过程而没有加速推理过程。 2.3.3 交叉熵（Cross Entropy）交叉熵用于度量两个概率（$p$ 和 $q$​​）分布间的差异性信息的一个指标。计算公式如下： H(p, q) = -\\sum_xp(x)\\log q(x)当交叉熵用于损失函数的时候，我们需要度量的是真实标签概率分布（$\\boldsymbol{y}_{true}$）和模型输出标签概率分布（$\\boldsymbol{y}_{pred}$）之间的差异，即： H(\\boldsymbol{y}_{true}, \\boldsymbol{y}_{pred}) = -\\sum \\boldsymbol{y}_{true}\\cdot \\log(\\boldsymbol{y}_{pred})在我们的情况下，$\\boldsymbol{y}_{true}$​ 中只有 $y_{i=O}=1$​，其余位置 $y_j$​ 全部是 0，$\\boldsymbol{y}_{pred} = p(w_i|w_I)$​。也就是说，我们只需要计算 $w_i=w_O$​ 位置的交叉熵即可，如下图所示。 \\mathcal{L}_{\\theta} = H(y_i, w_i) = -\\sum_{i=1}^{V}y_i\\log p(w_i|w_I) \\overset{i=O}{=} -\\log p(w_O|w_I)式中 $\\theta$ 表示我们需要训练的参数。如上面介绍的，交叉熵是用来度量两个分布的差异性的指标。对于我们的模型来说，当然是 $\\boldsymbol{y}_{ture}$ 和 $\\boldsymbol{y}_{pred}$​ 的差异越小越好。所以我们模型训练最终的目的是最小化交叉熵。 将 $p(w_O|w_I)$ 的 full softmax 公式代入交叉熵损失函数中得到： \\mathcal{L}_{\\theta} = -\\log \\frac{\\exp(\\boldsymbol{v'}_{O}^\\mathsf{T} \\cdot \\boldsymbol{v}_I)}{\\sum_{j=1}^V\\exp(\\boldsymbol{v'}_{j}^\\mathsf{T} \\cdot \\boldsymbol{v}_I)}=-\\boldsymbol{v'}_{O}^\\mathsf{T} \\cdot \\boldsymbol{v}_I + \\log \\sum_{j=1}^V \\exp(\\boldsymbol{v'}_{j}^\\mathsf{T} \\cdot \\boldsymbol{v}_I)使用随机梯度下降算法对模型开始训练，需要计算损失函数的梯度。为了简化，我们令 $z_{IO}=\\boldsymbol{v’}_{O}^\\mathsf{T} \\cdot \\boldsymbol{v}_I$​ 及 $z_{Ij}=\\boldsymbol{v’}_{j}^\\mathsf{T} \\cdot \\boldsymbol{v}_I$​。 \\begin{equation} \\nonumber \\begin{aligned} \\nabla_\\theta \\mathcal{L}_\\theta &= \\nabla_\\theta(-z_{IO}+\\log\\sum_{j=1}^V\\exp(z_{Ij}))\\\\\\\\ &= -\\nabla_\\theta z_{IO} + \\nabla_\\theta(\\log \\sum_{j=1}^V \\exp(z_{Ij})) \\\\\\\\ &= -\\nabla_\\theta z_{IO} + \\frac{1}{\\sum_{j=1}^V\\exp(z_{Ij})} \\sum_{j=1}^V \\exp(z_{Ij}) \\cdot \\nabla_\\theta z_{Ij} \\\\\\\\ &= -\\nabla_\\theta z_{IO} + \\sum_{j=1}^V \\frac{\\exp(z_{Ij})}{\\sum_{j=1}^V\\exp(z_{Ij})} \\cdot \\nabla_\\theta z_{Ij} \\\\\\\\ &= -\\nabla_\\theta z_{IO} + \\sum_{j=1}^V p(w_j|w_I) \\cdot \\nabla_\\theta z_{Ij} \\\\\\\\ &= -\\nabla_\\theta z_{IO} + \\mathbb{E}_{w_j \\sim Q(\\bar{w})} \\cdot \\nabla_\\theta z_{Ij} \\end{aligned} \\end{equation}将 $z_{IO}$ 和 $z_{Ij}$ 代回原式，根据下面两式： \\nabla_\\theta z_{IO} = \\frac{\\partial (\\boldsymbol{v'}_{O}^\\mathsf{T} \\cdot \\boldsymbol{v}_I)}{\\partial \\boldsymbol{v}_I} = \\boldsymbol{v'}_{O} ,\\quad \\nabla_\\theta z_{Ij} = \\frac{\\partial (\\boldsymbol{v'}_{j}^\\mathsf{T} \\cdot \\boldsymbol{v}_I)}{\\partial \\boldsymbol{v}_I} = \\boldsymbol{v'}_{j} \\\\\\\\可得： \\nabla_\\theta \\mathcal{L}_\\theta = -\\boldsymbol{v'}_{O} + \\mathbb{E}_{w_j \\sim Q(\\tilde{w})} \\cdot \\boldsymbol{v'}_{j}上式中 $Q(\\tilde{w})$​ 表示噪声概率分布。根据上式，输出词的词向量越大，损失越小；而其他词的词向量越小，则损失越小。因此，交叉熵损失函数会使模型将正确的输出更加凸显，而对错误的输出进行压制，从而使参数达到最优。 2.3.4 Noise Contrastive Estimation噪声对比估计（NCE）是通过简单的逻辑回归来区分目标词和非目标词的。 给定输入词 $w_I$，正确的输出词是 $w_O$。同时，我们可以从噪声词分布 $Q(\\tilde{w})$ 中进行采样得到 $N$ 个负样本词： \\tilde{w}_1,\\tilde{w}_2,\\dots,\\tilde{w}_N \\sim Q(\\tilde{w})此时，我们的样本就成了 $w_O$ 为正样本，$\\tilde{w}_1,\\tilde{w}_2,\\dots,\\tilde{w}_N$ 为负样本，然后再用一个二分类器进行分类： \\mathcal{L}_\\theta = - \\left[ \\log p(d=1 \\vert w_O, w_I) + \\sum_{i=1, \\tilde{w}_i \\sim Q}^N \\log p(d=0|\\tilde{w}_i, w_I) \\right]$d$ 表示二分类器的输出标签。 当 $N$ 足够大时，根据大数定理可得: \\mathcal{L}_\\theta = - \\left[ \\log p(d=1 \\vert w_O, w_I) + N\\mathbb{E}_{\\tilde{w}_i \\sim Q} \\log p(d=0|\\tilde{w}_i, w_I) \\right]为了计算概率分布 $p(d=1 \\vert w_O, w_I)$，我们可以从联合概率 $p(d, w_j \\vert w_I), w_j \\in [w_O, \\tilde{w}_1, \\tilde{w}_2, \\dots, \\tilde{w}_N]$。我们有 $1/(N+1)$ 的概率得到 $w_j=w_O$，这个概率是一个条件概率 $p(w_j=w_O\\vert w_I)$，同时我们有 $N/(N+1)$ 的概率得到噪声词 $q(\\tilde{w}_{1:N})$。 p(d, w_j | w_I) = \\begin{cases} \\frac{1}{N+1} p(w_O \\vert w_I) & \\text{if } d=1 \\\\\\\\ \\frac{N}{N+1} q(\\tilde{w}_{1:N}) & \\text{if } d=0 \\end{cases}然后我们可以计算 $p(d=1 \\vert w, w_I)$ 和 $p(d=0 \\vert w, w_I)$： \\begin{equation} \\nonumber \\begin{aligned} p(d=1 \\vert w, w_I) &= \\frac{p(d=1, w \\vert w_I)}{p(d=1, w \\vert w_I) + p(d=0, w \\vert w_I)} \\\\\\\\ &\\overset{贝叶斯公式}{=} \\frac{p(w \\vert w_I)}{p(w \\vert w_I) + Nq(\\tilde{w})} \\end{aligned} \\end{equation} \\begin{equation} \\nonumber \\begin{aligned} p(d=0 \\vert w, w_I) &= \\frac{p(d=0, w \\vert w_I)}{p(d=1, w \\vert w_I) + p(d=0, w \\vert w_I)}\\\\\\\\ &\\overset{贝叶斯公式}{=} \\frac{Nq(\\tilde{w})}{p(w \\vert w_I) + Nq(\\tilde{w})} \\end{aligned} \\end{equation}最后，NCE 二分类器的损失函数为： \\begin{equation} \\nonumber \\begin{aligned} \\mathcal{L}_\\theta & = - \\left[ \\log p(d=1 \\vert w, w_I) + \\sum_{\\substack{i=1 \\\\\\\\ \\tilde{w}_i \\sim Q}}^N \\log p(d=0|\\tilde{w}_i, w_I) \\right] \\\\\\\\ & = - \\left[ \\log \\frac{p(w \\vert w_I)}{p(w \\vert w_I) + Nq(\\tilde{w})} + \\sum_{\\substack{i=1 \\\\ \\tilde{w}_i \\sim Q}}^N \\log \\frac{Nq(\\tilde{w}_i)}{p(w \\vert w_I) + Nq(\\tilde{w}_i)} \\right] \\end{aligned} \\end{equation}然而，我们会发现公式中仍然有 $p(w \\vert w_I)$ ，即仍然要对整个词表进行求和。为了方便，令 $Z(w_I)$ 为 $p(w\\vert w_I)$ 的分母。NCE 对于 $Z(w_I)$ 的处理有两种假设： 将 $Z(w_I)$ 视作常数。Mnih &amp; Teh, 2012 证明对于参数量很大的神经网络模型来说，将 $Z(w_I)$ 固定为 1 对每个 $w_I$ 仍是成立的。此时，上面的损失函数可以简化成： \\mathcal{L}_\\theta = - \\left[ \\log \\frac{\\exp({v'_w}^{\\top}{v_{w_I}})}{\\exp({v'_w}^{\\top}{v_{w_I}}) + Nq(\\tilde{w})} + \\sum_{\\substack{i=1 \\\\ \\tilde{w}_i \\sim Q}}^N \\log \\frac{Nq(\\tilde{w}_i)}{\\exp({v'_w}^{\\top}{v_{w_I}}) + Nq(\\tilde{w}_i)}\\right] 这种情况下，我们可以证明，当 $N \\to \\infty$ 时，$\\nabla_\\theta \\mathcal{L}_{NCE}=\\nabla_\\theta\\mathcal{L}_{entrpy}$。证明过程可参看 Mnih &amp; Teh, 2012。所以 NCE 的优化目标和交叉熵是一样的。作者还发现，当 $N=25$ 时，效果就已经与标准 softmax 效果差不多了，但是速度提升了 45 倍。 实际上 $Z(w_I)$ 到底取值是多少，不同作者都有过不同的尝试。但是从表现来看，不同点只是开始的时候收敛速度不同，最终的结果相差不大。 噪声分布 $Q(\\tilde{w})$ 是一个可调参数，在选择 $Q$ 的分布的时候应该考虑两点： ① 接近真实数据分布； ② 容易采样 将 $Z(w_I)$ 看作一个可训练的参数。 从实践来看，当训练语料比较小的时候，$Z(w_I)$ 直接设置为常数效果更好。当有足够语料的时候，$Z(w_I)$ 作为可训练的一个参数效果更好。 NCE 处理似乎是故意绕开了标准 Softmax 计算量最大的分母，但其背后有充分的理论推导和证明。如果直接在最大似然估计上用这两种假设（之一）是否可行？ 答案还真是不行。两种情况： 如果最大似然估计中的 $Z(w_I)$ 为常数，那么 $\\mathcal{L}_\\theta$ 的第二项 $\\log Z(w_I)$ 就是常数，这就意味着 $\\mathcal{L}_\\theta$ 的导数的第二项就为 0。也就是噪声词的词向量缺少约束，模型只需要让目标词的概率变大即可，最坏情况下预测所有词的概率为 1 即可。 如果 $Z(w_I)$ 为可训练的一个参数，这个参数没有和数据产生任何联系，只需要简单的变小，就可以让似然概率变大，得到一个完全与数据无关的结果，所以也不可行。 2.3.5 Negative SamplingMikolov 等人 2013 年提出的负采样方法是 NCE 的一个简化版变种。因为 word2vec 的目标是训练高质量的词向量，而不是对自然语言中的词进行建模。所以，Mikolov 等人在 NCE 的基础上进一步简化。 在 NCE 假设 $Z(w_I)=1$ 的基础上，进一步令 $N q(\\tilde{w})=1$，则 \\begin{equation} \\nonumber \\begin{aligned} p(d=1\\vert w, w_I) &= \\frac{p(w \\vert w_I)}{p(w \\vert w_I)+1} \\\\\\\\ &= \\sigma({v'_{w}}^\\top v_{w_I}) \\\\\\\\ p(d=0\\vert w, w_I) &= \\frac{1}{p(w \\vert w_I) + 1} \\\\\\\\ &= 1 - \\sigma({v'_{w}}^\\top v_{w_I}) \\\\\\\\ &= \\sigma(-{v'_{w}}^\\top v_{w_I}) \\end{aligned} \\end{equation}那么负采样的损失函数为： \\mathcal{L}_\\theta = - \\left[ \\log \\sigma({v'_{w}}^\\top v_{w_I}) + \\sum_{\\substack{i=1 \\\\ \\tilde{w}_i \\sim Q}}^N \\log \\sigma(-{v'_{\\tilde{w}_i}}^\\top v_{w_I}) \\right]因为 $Nq(\\tilde{w})=1$，所以 $q(\\tilde{w})=1/N$ 是一个均匀分布。这里的均匀采样并不是每个词采样概率相同，而是在总的语料中进行均匀采样。这就意味着，它实际上是按照每个词本身的词频来进行采样的，词频越高，采样的概率就越高。这种情况下，模型最终拟合的实际是词的互信息。详细解答看这里：“噪声对比估计”杂谈：曲径通幽之妙。互信息与条件概率的区别就类似：条件概率反映“我认识周杰伦，周杰伦却不认识我”，而互信息反映的是“你认识我，我也认识你”。所以，通常负采样的效果比层次 softmax 要好一些。 2.4 一些小技巧 Soft slide window。利用滑动窗口构建输入词和输出词样本对的时候，我们可以给距离较远的词更低的权重。比如，设置窗口就最大值 $s_{\\text{max}}$，然后每次训练时的真实窗口大小是从 $[1, s_{\\text{max}}]$ 中进行随机采样。因此，每个上下文词都有 $1/(d)$ 的概率被取到，其中 $d$ 表示到中心词的距离。 下采样高频词。极端高端的词可能由于太常见而无法得以区分（比如停用词）。而低频词可能会带有很重要的信息。为了平衡高频词和低频词，Mikolov 等人提出采样时对每个词施加一个采样概率 $1-\\sqrt{t/f(w)}$。其中 $f(w)$ 表示词频，$t$ 表示相关性阈值，通常取值为 $10^{-5}$。 先学词组。词组表示一个有意义的概念单元，而非简单的独立单词的组合。先学习这些词组将他们作为一个词单元来处理可以提升词向量的质量。比如基于 unigram 和 bigram 统计： s_{\\text{phrase}} = \\frac{C(w_i w_j) - \\delta}{ C(w_i)C(w_j)}其中 $C(\\cdot)$ 表示 unigram $w_i$ 或 bigram $w_iw_j$ 的数量，$\\delta$ 表示衰减阈值，防止过高频的词或词组。$s_{\\text{phrase}}$ 得分越高则采样几率越高。为了形成长于两个单词的短语，我们可以随着分数截止值的降低多次扫描词汇表。 3. Count-based: GloVeGloVe（The Global Vector）是 Pennington 等人于 2014 年提出的模型。 GloVe 结合了 矩阵分解和 skip-gram 模型。 众所周知，统计数量和共现可以表示词义。为了区分上下文的词嵌入 $p(w_O \\vert w_I)$，我们定义共现概率： p_{\\text{co}}(w_k \\vert w_i) = \\frac{C(w_i, w_k)}{C(w_i)}$C(w_i, w_k)$ 表示 $w_i$ 和 $w_k$ 的共现频率。假设有两个词 $w_i=”ice”$ 和 $w_j=”steam”$，第三个词 $\\tilde{w}_k=”solid”$ 与 $”ice”$ 相关，但是与 $”steam”$ 无关，我们希望： p_{\\text{co}}(\\tilde{w}_k \\vert w_i) > p_{\\text{co}}(\\tilde{w}_k \\vert w_j)因此 $\\frac{p_{\\text{co}}(\\tilde{w}_k \\vert w_i)}{p_{\\text{co}}(\\tilde{w}_k \\vert w_j)}$ 会非常大。而如果 $\\tilde{w}_k=”water”$ 与 $”ice”$ 和 $”steam”$ 都有关系，或者 $\\tilde{w}_k=”fashion”$ 与两者都没有关系，$\\frac{p_{\\text{co}}(\\tilde{w}_k \\vert w_i)}{p_{\\text{co}}(\\tilde{w}_k \\vert w_j)}$ 会接近 1。 以上描述给我们的直观感受就是，词义是通过共现概率分布的比例得到的，而非共现概率本身。所以，GloVe 模型是将第三个词的向量取决于另两个词之间的关系： F(w_i, w_j, \\tilde{w}_k) = \\frac{p_{\\text{co}}(\\tilde{w}_k \\vert w_i)}{p_{\\text{co}}(\\tilde{w}_k \\vert w_j)}确定 $F$ 的函数形式过程如下： $F(w_i, w_j, \\tilde{w}_k)$ 是考察 $i, j, k$ 三个词的相似关系，不妨单独考察 $i, j$ 两个词。在线性空间中，两个向量的相似性最简单的就是欧氏距离 $v_i, v_j$，所以 $F$ 可以是 F(w_i-w_j, \\tilde{w}_k) = \\frac{p_{\\text{co}}(\\tilde{w}_k \\vert w_i)}{p_{\\text{co}}(\\tilde{w}_k \\vert w_j)} $\\frac{p_{\\text{co}}(\\tilde{w}_k \\vert w_i)}{p_{\\text{co}}(\\tilde{w}_k \\vert w_j)}$ 是一个标量，而 $F$ 是作用在两个向量上的，向量与矢量之间的关系自然就可以想到内积，所以进一步确定 $F$ 的形式： F((w_i-w_j) \\top \\tilde{w}_k) = F(w_i\\top \\tilde{w}_k-w_j \\top \\tilde{w}_k) = \\frac{p_{\\text{co}}(\\tilde{w}_k \\vert w_i)}{p_{\\text{co}}(\\tilde{w}_k \\vert w_j)} 上式中，左边是差，右边是商。可以通过 $\\exp(\\cdot)$ 函数将两者结合在一起： \\exp(w_i\\top \\tilde{w}_k-w_j \\top \\tilde{w}_k) = \\frac{\\exp(w_i \\top \\tilde{w}_k)}{\\exp(w_j \\top \\tilde{w}_k)} = \\frac{p_{\\text{co}}(\\tilde{w}_k \\vert w_i)}{p_{\\text{co}}(\\tilde{w}_k \\vert w_j)} 现在只要让分子分母分别相等，上式就可以成立： \\exp(w_i \\top \\tilde{w}_k) = p_{co}(\\tilde{w}_k \\vert w_i) \\\\\\\\ \\exp(w_j \\top \\tilde{w}_k) = p_{co}(\\tilde{w}_k \\vert w_j) 只需要满足： {w_i}^\\top \\tilde{w}_k = \\log p_{\\text{co}}(\\tilde{w}_k \\vert w_i) = \\log \\frac{C(w_i, \\tilde{w}_k)}{C(w_i)} = \\log C(w_i, \\tilde{w}_k) - \\log C(w_i) 由于 $w_i$ 和 $\\tilde{w}_k$ 是向量，所以 $\\tilde{w}_k \\top w_i = w_i \\top \\tilde{w}_k$ ，这就意味着上式中 $i, k$ 是顺序不敏感的，但是右边交换 $i,k$ 的顺序结果就会不同。为了解决这个对称性问题，模型引入两个偏置项 $b_i, b_k$，则模型变成： \\log C(w_i, \\tilde{w}_k) = w_i \\top \\tilde{w}_k + b_i +\\tilde{b}_k 上面的公式只是理想状态下，实际上左右只能无限接近，所以损失函数定义为： \\mathcal{L}_\\theta = \\sum_{i=1, k=1}^V ({w_i}^\\top \\tilde{w}_k + b_i + \\tilde{b}_k - \\log C(w_i, \\tilde{w}_k))^2 根据经验，如果两个词共现次数越多，那么两个词在损失函数中的影响就应该越大，所以可以根据两个词共现的次数设计一个权重来对损失函数进行加权： \\mathcal{L}_\\theta = \\sum_{i=1, j=1}^V f(C(w_i,\\tilde{w}_k)) ({w_i}^\\top \\tilde{w}_k + b_i + \\tilde{b}_k - \\log C(w_i, \\tilde{w}_k))^2权重函数 $f(\\cdot)$ 应该有以下性质： ① $f(0)=0$，即如果两个词没有共现过，那么权重为 0； ② $f(x)$ 必须是一个单调递增的函数。两个词共现次数越多，反而权重越小违反了设置权重项的初衷； ③ $f(x)$ 对于共现次数过多的词对，不能有太大的值，比如停用词。 有了这三个性质，可以将 $f(x)$ 定义为： f(x) = \\begin{cases} (\\frac{x}{x_{\\text{max}}})^\\alpha,\\quad & \\text{if}\\quad x","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"词向量","slug":"词向量","permalink":"https://rogerspy.gitee.io/tags/词向量/"}]},{"title":"算法与数据结构（Python）：array","slug":"ds-array","date":"2021-08-09T14:21:24.000Z","updated":"2022-01-12T08:37:38.345Z","comments":true,"path":"2021/08/09/ds-array/","link":"","permalink":"https://rogerspy.gitee.io/2021/08/09/ds-array/","excerpt":"数组是一个容器，它容纳的元素应该是相同的数据类型。数组有两个重要概念： 元素 —— 存储的数组中的数据称为元素。 索引 —— 数组中每个元素所在的位置。","text":"数组是一个容器，它容纳的元素应该是相同的数据类型。数组有两个重要概念： 元素 —— 存储的数组中的数据称为元素。 索引 —— 数组中每个元素所在的位置。 1. 数组的表示 int 表示数组中数字的类型为整型 array 表示数组的名字 [10] 表示数组的尺寸，即数组中有多少个元素 {35, 33, 42, ...} 表示数组存储的数据 索引从 0 开始 数组的尺寸是 10，表示它可以存储 10 个元素 每个元素可以通过索引访问 2. 基本操作数组的基本操作包括： 遍历 —— 逐个获得数组中的元素 插入 —— 在指定的位置（索引）处添加一个元素 删除 —— 删除指定位置（索引）处的元素 搜索 —— 搜索指定位置（索引）处的元素 更新 —— 更新指定位置（索引）处的元素 python 内置的 array 模块可以用来创建数组： 123from array import *arrayName = array(typecode, [Initializerss]) 其中 typecode 用于定义数组中元素的数据类型，一些常用的 typecode 如下： typecode 表示 b 大小为1字节/ td&gt;的有符号整数 B 大小为1字节的无符号整数 C 大小为1字节的字符 i 大小为2个字节的带符号整数 I 大小为2个字节的无符号整数 F 大小为4字节的浮点 d 大小为8个字节的浮点 举个例子： 123from array import *array1 = array('i', [10,20,30,40,50]) 2.1 遍历12for x in array1: print(x) 输出 123451020304050 2.2 搜索123456# 方法一print(array1[0])print(array1[2])# 方法二print(array1.index(40)) 输出 12310303 2.3 插入12array1.insert(1,60)print(array1) 输出 1array('i', [10, 60, 20, 30, 40, 50]) 2.4 删除12array1.remove(40)print(array1) 输出 1array('i', [10, 60, 20, 30, 50]) 2.5 更新12array1[2] = 80print(array1) 输出 1array('i', [10, 60, 80, 30, 50]) ReferencePython-数组","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://rogerspy.gitee.io/tags/数组/"}]},{"title":"ROC-AUC原理及计算方法","slug":"roc-auc","date":"2021-07-29T15:26:19.000Z","updated":"2022-01-12T08:37:38.407Z","comments":true,"path":"2021/07/29/roc-auc/","link":"","permalink":"https://rogerspy.gitee.io/2021/07/29/roc-auc/","excerpt":"本文转载自知乎用户码农要术的文章 衡量指标篇：ROC-AUC。 1. 历史起源1941年，日军偷袭珍珠港，太平洋战争由此爆发。美军的雷达操作员（Radar operator）开始忙碌了起来，他们要识别出雷达屏幕上的光点是不是日本的战机。","text":"本文转载自知乎用户码农要术的文章 衡量指标篇：ROC-AUC。 1. 历史起源1941年，日军偷袭珍珠港，太平洋战争由此爆发。美军的雷达操作员（Radar operator）开始忙碌了起来，他们要识别出雷达屏幕上的光点是不是日本的战机。 因为光点也有可能是我方军舰，也有可能是噪声。为了衡量识别的性能，研究者们设计了ROC曲线（Receiver operating characteristic curve）。所谓 Receiver 就是雷达接收器，operating characteristic 则是表明雷达操作员（Radar operator）的识别能力。 后来，ROC曲线被应用到了医学领域，还有机器学习领域。虽然名字比较奇怪，但是从诞生之初，ROC 曲线的目的就是衡量分类的性能。AUC 是 ROC 曲线下的面积（ Area Under the ROC Curve），有一些优雅的性质，我们后面再说。 想讲清楚 ROC曲线，先要讲一下混淆矩阵。 2. 混淆矩阵先从两类开始说起，Positive 和 Negative，医学上叫阳性和阴性，机器学习称之为正例和负例。经过分类器的决策后，一般情况下，正例预测的有对有错，负例预测的也有对有错。这样数据会被划分成4部分：正例预测对（True Positive），正例预测错（False Negtative），负例预测对（True Negative），负例预测错（False Positive）。 3. 如何衡量分类器的好坏？如何衡量一个分类器是有效的，而不是随机结果？还是以雷达识别敌舰这个场景来说明。 3.1 两个假设 正负例等比例分布 分类器输出是离散值, 也就是 label 的集合 此时预测为正的结果可以划分成两部分：$TP$ 和 $FP$。比较两者关系，有如下结论： 如果分类器是随机抽样，那么模型的输出和正负例比例一致。也就是 $TP=FP$。这个时候向识别出来的敌舰(预测为正的样本)开炮就是无差别攻击。 如果 $TP&gt;FP$, 可以说分类器有一定的甄别能力，战争中可以做到伤敌一千，自损八百。 如果是 $TP&lt;FP$ ,则说明分类器太差了，都不如随机抽样。用在战争中可以做到伤敌八百，自损一千。 3.2 一个假设 分类器输出是离散值, 也就是 label 的集合 这个时候在用TP和FP的绝对值做对比就显得不公平, 举个例子，我方军舰10艘，敌方军舰100艘。预测并且击沉我方军舰 8 艘，敌方军舰 9 艘.绝对数量上确实是占优势，但是我方基本全军覆没，敌方绝大多数战力仍然保留。样本不均衡时，就得做归一化，看相对值。 这里引入两个概念：$TPR$ （True Positive Rate），$FPR$（False Positive Rate） TPR = \\frac{TP}{TP+FN} \\\\\\\\ FPR = \\frac{\\mathrm{FP}}{FP+TN}$TPR$ 就是正例中预测正确的比率。$FPR$ 就是负例预测错的比例。 $TPR$ 和 $FPR$，比较两者关系，有如下结论： 如果分类器是随机抽样，那么模型的输出和正负例比例一致。也就是 $TPR=FPR$。这个时候向识别出来的敌舰(预测为正的样本)开炮就是无差别攻击。 如果 $TPR&gt;FPR$, 可以说分类器有一定的甄别能力，战争中伤敌的比率高于自损的比率。 如果是 $TPR&lt;FPR$ ,则说明分类器太差，不如随机抽样。战争中伤敌的比率低于自损的比率。 把 $TPR$ 和 $FPR$ 可视化，在 “分类器输出是离散值, 也就是 label“ 的假设下，$TPR$ 和 $FPR$ 是确定的，在二维坐标系上就是一个点。这个点就是 ROC 曲线的雏形。如下图： 图中，E 点就是随机抽样 （$TPR=FPR$）。A，B，D点表示分类器有一定的甄别能力（$TPR&gt;FPR$）。其中 A 点对应的是一个完美的分类器，所有的正例被识别正确（$TPR=1$），所有的负例没有识别错误（$FPR=0$）。F 点就是分类器太差（$TPR&lt;FPR$），不如随机抽样。 3.3 另一个假设 分类器输出连续值 此时需要确定一个阈值来决定混淆矩阵和 $TPR$，$FPR$。 $TPR$ 的计算如下图所示： $FPR$ 的计算如下图所示： 对于同一个分类器，不同的阈值对应不同的 $TPR$ 和 $FPR$，遍历阈值，即可得到 ROC 曲线。如下图： 对于一个分类器，固定阈值，则得到一条 ROC 曲线。不同分类器会使预测的数据分布不同，在固定阈值的情况下，ROC 曲线变化如下图： 直观来看，分类器的区分度越好，ROC 曲线则越往左上角靠拢。AUC 就越大。怎么解释？ 4. AUC 的概率解释如果把 ROC 曲线看成是 $TPR$ 对 $FPR$ 的函数，$TPR=F(x)$ 我们对这个函数进行积分。如下图所示： AUC = \\int_{0}^1F(x)dx假设样本标签为 $y$，模型预测得分为 $s$，阈值为 $t$，正例的概率密度函数为 $f_1(s)$，负例的概率密度函数为 $f_0(s)$，则有 TPR = F(x) = \\int_t^\\infty f_1(s)ds = P(s>t|y=1) \\\\\\\\ FPR = x = \\int_t^\\infty f_0(s)ds = 1-\\int_{-\\infty}^t f_0(s)ds$x$ 是 $t$ 的积分上限函数，根据积分上限函数的性质，得到 \\frac{dx}{dt} = \\frac{d}{dt}(1-\\int_{-\\infty}^t f_0(s)ds) = -f_0(t) \\\\\\\\ dx = -f_0(t)dt = -P(s'=t|y'=0)dt则有 \\begin{equation} \\nonumber \\begin{aligned} AUC &= \\int_0^1F(x)dx \\\\\\\\ &= \\int_{\\infty}^{-\\infty} F(x)(-f_0(t))dt \\\\\\\\ &= \\int_{-\\infty}^{\\infty} F(x)f_0(t)dt \\\\\\\\ &= \\int_{-\\infty}^{\\infty} P(s>t|y=1)f_0(t)dt \\\\\\\\ &= \\int_{-\\infty}^{\\infty} P(s>t|y=1)\\times P(s/=t|y'=0)dt \\\\\\\\ &= \\int_{-\\infty}^{\\infty} P(s>s'\\ \\&\\ s'=t|y=1\\ \\&\\ y'=0)dt \\\\\\\\ &= P(s>s'|y=1\\ \\&\\ y'=1) \\end{aligned} \\end{equation}上面推导需要解释一下： 第二行，因为 $FPR$ 的取值范围从 0 到 1，对应着阈值是从大到小的变化。可以从动图中看出，只不过动图中阈值是从小到大，$FPR$ 是从 1 到 0。 第五行，$f_0(t)$ 的含义就是该样本为负例，得分为 $t$ 的概率。加引号是为了和正例区分。 第七行，该积分相当于是遍历阈值 $t$，同时负例得分和 $t$ 相同，也就是负例遍历所有可能的得分情况。 最终得到这么一个结论： AUC 的值，就是从样本中任意取一个正例和一个负例，正例得分大于负例得分的概率。 5. AUC 的一些性质从公式可以看出，$TPR$ 的计算只局限在正例中，$FPR$ 的计算只局限在负例中。正例（或负例）如果同分布的增加或者减小，对于 ROC 曲线来说没有区别，因为在正例（或负例）内部已经做了归一化。如下图所示。 但如果正例（或负例）的比例在变化的同时，分布也发生了变化，那么 ROC 和 AUC 也会随之变化。如下图 AUC 使用时，有几点需要注意： AUC 只关注预测的正负例的顺序关系，对于和 label 的拟合情况则不关注。比如正例得分都是 0.2，负例得分都是 0.1，AUC 很完美，但是 loss 就会比较大。 在非常不均衡的样本上，AUC 表现可能很好，但 precision 可能比较差。比如 $TP=80$，$FN=20$，$FP=200$，$TN=8000$，此时从 ROC 空间上看，效果还不错，但是 precision 低的可怜。","categories":[{"name":"博客转载","slug":"博客转载","permalink":"https://rogerspy.gitee.io/categories/博客转载/"}],"tags":[{"name":"ROC-AUC","slug":"roc-auc","permalink":"https://rogerspy.gitee.io/tags/roc-auc/"}]},{"title":"Data Structures With Python","slug":"data-structures-with-python","date":"2021-07-27T15:41:30.000Z","updated":"2022-01-12T08:37:38.324Z","comments":true,"path":"2021/07/27/data-structures-with-python/","link":"","permalink":"https://rogerspy.gitee.io/2021/07/27/data-structures-with-python/","excerpt":"对于编程和计算机科学来说，数据结构是主要的主题，几乎涉及所有计算机领域。 本文介绍 python 中的一些数据结构。","text":"对于编程和计算机科学来说，数据结构是主要的主题，几乎涉及所有计算机领域。 本文介绍 python 中的一些数据结构。 1. 什么是数据结构计算机科学中，数据结构是一种为了便于数据获取和修改的组织、管理和存储的形式。所有编程语言中，列表、字典和数组是最简单的数据结构。尽管语法不同，但是其内在的逻辑是相同的。因此，本文介绍的例子也适用于其它编程语言。 2. 字典、映射、哈希表Python 中的字典（dictionary）可以用来存储任意数据，每条数据都有一个关键词。映射（map）也被称为哈希表（hash table）、查找表（lookup table）或者关联数组（associative array）。它可以更轻松地组织与特定关键字关联的数据，并以更有条理的形式呈现。 比如，用字典来存储每个人的年龄： 12345data = &#123; 'Mark': 12, 'Alice': 23, 'David': 8&#125; 当我们想要查看特定的人的年龄时： 123data['Mark']# Output: 12 当然，你可以把数据写在同一行内，但是如果数据量比较大的时候，卸载一行看起来会比较乱。 2.1 OrderedDict, defaultdict, ChainMap 字典是无序的，如果我们想按照顺序来存储数据，显然原生的字典就无能为力了，这个时候就可以用 OrderedDict： 1234567import collections as csdict1 = cs.OrderedDict( Mark=12, Alice=23, David=8) 查看一下 dcit1： 123print(dict1)# Ouput: ([('Mark', 12), ('Alice', 22), ('David', 8)]) 当我们从字典里面取值的时候，遇到字典里并没有对应的 key 的时候，程序就会报错。这时 defaultdict 就派上用场了。defaultdict 的作用是在于，当字典里的key不存在但被查找时，返回的不是 keyError 而是一个默认值。 123456from collections import defaultdictdict1 = defaultdict(int)dict2 = defaultdict(set)dict3 = defaultdict(str)dict4 = defaultdict(list) defaultdict 接受 int, set, str, list 作为参数，也可以自定义函数作为参数。我们来看下，上面的例子中默认值分别是什么： 12345678910print(dict1[1]) print(dict2[1])print(dict3[1])print(dict4[1])# Output:0set()[] 说明 int 默认值是 0，set 默认值是空集合，str 默认值是空字符串，list 默认值是空列表。 当你有多个字典的时候，可以使用 ChainMap 将它们变成一个字典。 12345678910from collections import ChainMapdict1 = &#123;\"1\": 1, \"2\": 2&#125;dict2 = &#123;\"3\": 3, \"4\": 4&#125;main = ChainMap(dict1, dict2)print(main[\"3\"] , main[\"1\"])# Output:3 1 3. 数组型数据结构3.1 列表列表可以存储任意类型的数据。 1234567891011121314151617# from 0 to 10 valuearr = [1,2,3,4,5,6,7,8,9,10]# String Arrayarr1 = [\"a\" , \"b\" , \"c\"]# Get First Indexingarr1[0]# Get from 0 to 4arr[0:4]# Deleting Elementdel arr[0]# Adding Elementarr.append(11) 123print(a)# Output: [1, 2, 3, 4] 3.2 元组元组是另一个可以存储任意类型数据的数据结构。与列表不同的是，元组是不可变的。 123456789101112131415tuple = (1 , 2 , 3)tuple[0]# Output: 1tuple1 = (\"x\" , 1 , 1.25)tuple1[2]# Output: 1.25# you'll get errordel tuple[0]tuple[1] = \"y\"# 报错 3.3 array 数组python 的 array 模块存储的数据包括整型、浮点型等等，它的空间占用率会更低。因为 array 只接受相同类型的数据。 12345# Accessing arrayfrom array import array# use type codearr = array(\"f\" , [1.0 , 1.2]) 3.4 字符串——字符编码的数组字符串可以节省空间，因为它们被密集打包并专门处理特定的数据类型。 如果要保存 Unicode 文本，则应使用字符串。 123456str = \"55555\"emoji = \"😀\"print(str , emoji)# Outtput: 55555 😀 3.5 字节 &amp; 字节数组字节（Bytes）存储的是 0 到 255 的数字，如果超过了这个范围程序会报错。 123x = bytes([1 , 2 , 3])y = bytes([-1 , 2 , 3])z = bytes([100 , 200 , 300]) 123Output: b'\\x01\\x02\\x03'Output: errorOutput: error 4. 集合 &amp; 多数组数据结构4.1 集合集合中不能包含相同的数据，且集合存储的是无序的数据。 1234set = &#123;1 , 2 , 3&#125;set.add(4)set.remove(3) 4.2 Frozen Set原始的集合元素可增可删，如果我们不想让集合发生改变，可以使用 frozenset 方法： 1234frozen = frozenset(&#123;\"x\" , \"y\" , \"z\"&#125;)frozen.add(\"k\")# 报错 4.3 Countercounter 可以对多个集合进行合并，并且可以对每个元素进行计数，得到每个元素的个数。 1234567891011from collections import Countermerge = Counter()fruits = &#123;\"apple\" , \"banana\" , \"orange\"&#125;merge.update(fruits)print(merge)fruits1 = &#123;\"apple\" , \"banana\" , \"watermelon\"&#125;merge.update(fruits1)print(merge) 12&#123;'orange': 1, 'apple': 1, 'banana': 1&#125;)&#123;'apple': 2, 'banana': 2, 'orange': 1, 'watermelon': 1&#125;) 5. 堆栈堆栈是支持用于插入和删除的快速输入/输出语义 (LIFO) 的项目集合。与数组和列表不同，你不能做随机访问，你需要使用函数进行插入和删除。 5.1 list 实现堆栈你可以用 append 把数据加到最后，再用pop从 LIFO 队列中取出。 123456789101112stack = []stack.append(1)stack.append(2)stack.append(3)print(stack)stack.pop()stack.pop()print(stack) 12# Output: [1,2,3]# Output: [1] 5.2 deque 实现堆栈deque 与列表的区别还支持在固定时间添加和删除数组开头的元素。 因此，它比列表更有效、更快。 它还支持随机访问。 如果您尝试删除双端队列之间的数据，您可能会失去性能，主要原因是直到两端的所有元素都移动以腾出空间或填补空白。 1234567891011121314from collections import dequestack = deque()stack.append(\"a\")stack.append(\"b\")stack.append(\"c\")print(stack)print(stack.pop())print(stack.pop())print(stack) 12# Output: deque(['a', 'b', 'c'])# Output: deque(['a']) 6. Queues堆栈上的逻辑在这里略有不同，其中采用先进先出 (FIFO)，而在堆栈中采用先进后出。 我们这里可以使用栈中使用的 list和 deque 数据结构，也可以使用队列中的 Queue 类。 123456789101112queue = []queue.append(\"x\")queue.append(\"y\")queue.append(\"z\")print(queue)queue.pop(0)queue.pop(0)print(queue) 12# Output: ['x', 'y', 'z']# Output: ['z'] 6.1 deque1234567891011121314from collections import dequequeue = deque()queue.append(\"x\")queue.append(\"y\")queue.append(\"z\")print(queue)queue.popleft()queue.popleft()print(queue) 12# Output: deque(['x', 'y', 'z'])# Output: deque(['z']) 6.2 queue队列是一种结构，通过它我们可以确定队列可以容纳和存储多少数据。 它主要用于实现队列。 您可以通过将 max size 参数设置为 0 来创建无限队列，这符合 FIFO 规则。 12345678910111213141516from queue import Queuequeue = Queue(maxsize = 0)# Adding elementqueue.put(10)queue.put(20)queue.put(30)print(queue.queue)# Removing elementqueue.get()queue.get()print(queue.queue) 12# Output: deque([10, 20, 30])# Output: deque([30]) 7. 自定义数据类型要更可控，您只需要您自己。 不要害怕创建和使用自己的类。 创建复杂的类有时会很累，但它会提高您的工作效率。 当您想通过方法向记录对象添加业务逻辑和活动时，创建自定义类是一个极好的解决方案。 然而，这意味着这些东西不再只是数据对象。 123456789101112class Student: def __init__(self, name, note): self.name = name self.note = notex = Student(\"David\" , 55)y = Student(\"Mark\" , 35)# Access Dataprint(x.name , x.note)print(Student) 12# Output: David 55# Output: &lt;main.Student object at 0x7f53925c2400&gt; 8. ReferenceData Structures With Python – Big Guide","categories":[{"name":"博客转载","slug":"博客转载","permalink":"https://rogerspy.gitee.io/categories/博客转载/"}],"tags":[{"name":"Data Structure","slug":"data-structure","permalink":"https://rogerspy.gitee.io/tags/data-structure/"}]},{"title":"知识图谱：知识建模（一）不那么简要的知识建模简介","slug":"kg-data-modelling","date":"2021-07-23T13:45:32.000Z","updated":"2022-01-12T08:37:38.381Z","comments":true,"path":"2021/07/23/kg-data-modelling/","link":"","permalink":"https://rogerspy.gitee.io/2021/07/23/kg-data-modelling/","excerpt":"1. 序言1.1 什么是知识建模（语义建模）? 通过赋予数据指定的概念和数据之间的关系使数据包含语义。","text":"1. 序言1.1 什么是知识建模（语义建模）? 通过赋予数据指定的概念和数据之间的关系使数据包含语义。 本质上讲，我们是通过明确数据代表的概念以及概念之间的关系来对数据进行建模。这样一个知识模型必须同时被人类和计算机所理解。对于人类来说相对比较容易，因为我们可以通过文字和数字对任意我们想要的东西进行建模，更重要的是赋予计算机更多的思考。 1.2 我们为什么要知识建模？对于数据来说，上下文信息非常重要。比如 “苹果”，我们是在讨论苹果电子产品还是水果？作为人类，当给定上下文的时候，我们可以很轻易的判断我们在讨论什么。当我说，“昨天买的苹果真好吃！”没有人会觉得我啃了一部手机。这就是问题的关键，没有上下文，数据所携带的信息总是不明确的。知识模型就是赋予数据以意义，避免这种歧义。 另外，还可以通过概念之间的关系帮助我们发散思维，找到数据之间的关联性。比如，“张三”是“张四”的父亲，而“张四”又是“张五”的父亲。人类可以很轻易的发现“张三”和“张五”是祖孙关系，但是如果没有知识模型构建的数据之间的关系，那么计算机是无法得知“张三”与“张五”的关系的。 1.3 Led Zeppelin 乐队知识模型解释知识模型最好的方式就是举例子。下图展示了一个 Led Zeppelin 乐队简单的知识模型，包括一些与 Led Zeppelin 相关的概念和概念之间的关系。从图中我们可以看到， Led Zeppelin 是一个乐队，它有一张专辑叫做 “ Led Zeppelin IV”，这张专辑发布于 “1971年11月8日”，专辑中有一首歌叫做 “Black Dog”。“Jimmy Page” 是一个人，也是乐队的成员之一。当然这只是一小部分数据，我们仅仅用这部分数据作为一个例子进行介绍。 知识模型也可以将信息排列成层次结构。比如“唱片”和“歌曲”都是“具有创造性的作品”，同时“具有创造性的作品”还包括“书籍”、“电影”、“雕塑”等等。 上图中大多数的关系都是用实线箭头连接的，除了 “is a” 关系是用虚线箭头连接的。这是因为 “is a” 代表了一类特殊的关系——“rdf:type”。现在先不用管这啥，在后面的章节会介绍。 2. 知识模型基础虽然我么现在有了一张看起来很漂亮的图，但是如果计算机不能理解这张图，再漂亮也白搭。如何让计算机从图中抽取语义信息？下面我们就来介绍一个非常有用的工具——RDF。 2.1 理解 RDFRDF（Resource Description Framework），翻译成中文：“资源描述框架”。顾名思义，它是一个用来描述数据的框架。在 RDF 数据模型中，我们用三元组来描述数据。一个三元组包含：subject、object 和 predicate，我们可以简单理解为，一个三元组就是有最简单的“主谓宾”构成的事实描述。RDF 图就是将很多三元组组合起来，其中 subject 和 object 是节点，predicate 是边。 • NOTE predicate 的方向很重要！如有必要，我们可以在三元组中定义双向关系，如下图： 对于 RDF 来说，节点有三种类型： Resources：你想要描述的概念，比如 Led Zeppelin 乐队知识模型图中的矩形框中的内容。所有的概念都必须有一个唯一的标识符。 Literals：即字面量，所有的字面量必须是字符串、数字和日期，如 Led Zeppelin 乐队知识模型图中的圆形框中的内容。 Blank nodes：空节点表示没有唯一标识符的数据。 2.2 URI 所有的 resources 和 predicates 都必须有机器可读的唯一标识符。 为什么标识符的唯一性这么重要？比如，我们要对一个大型组织结构的雇员进行建模，其中可能有很多同名同姓的人，不考虑每个人的昵称的话，你怎么区分到底是财务室的张三，还是技术部的张三，又或者是食堂大厨张三？解决的办法就是每个人都分配一个唯一的标识符——Uniform Resource Identififiers（URIs）。 URI 是一个字符串，用来准确的辨认特定的资源。为了保证统一性，所有的 URI 都有预定义的语法规则。 URI 与我们平时上网的时候，各个网站的 URL 很像。URI 可以是层级结构的（hierarchical URIs），也可以是不透明的（opaque URI）。Hierarchical URI 会包含不同级别的信息，它可以编码资源的位置信息，即资源存放在模型中的哪个位置，或者共享资源的上下文信息。而 opaque URI 不会编码任何信息，它的后缀通常是随机字符串。 Hierarchical：&lt;http://mycompany.com/people/JediDepartment/LukeSkywalker &gt; Opaque：&lt;http://mycompany.com/AE04801 &gt; 上例中 hierarchical URI 是人类可读的。从中我们知道 Luke Skywalker 为 My Company 工作，他是 Jedi Department 部门的员工。Opaque URI 同样是代表的 Luke Skywalker，但我们很难从中读取到任何信息。这就意味着 Opaque URI 的隐私性非常强。Opaque URI 的另一个优点是，不需要经常更新。比如如果 Luke Skywalker 变更了工作，从 Jedi Department 部门调到财务部门。Opaque URI 不需要做任何变更，而 Hierarchical URI 就要跟着改变。 从上面的例子中，我们可以看到两种 URI 各有优劣势，那么什么样的 URI 是一个好的 URI 呢？对此 European Bioinformatics Institute 给出了几个性质，总结起来就是： 全局唯一性：一个 URI 决不能被两个不同的概念同时引用，即使两个概念是等价的。 持久性：在可预见的将来，URI 要保证可用性。 稳定性：一个 URI 决不能在不同的数据上重复使用，即使原来的版本已经删除了。 可解析性（不可引用性）：简单来说就是，当用户在自己的浏览器上点击 URI 的时候，我们希望浏览器能重定向到合适的文档。 在介绍 Skywalker 的时候，我随便造了一个 URI，用浏览器访问的时候会返回给你“404 Page Not Found”，也就是说这个 URI 不是一个好的 URI，因为它不满足上面第四个性质：可解析性。 下面我们回到 Led Zeppelin 的例子。我们用 URI 来表示三元组： 当我们点击上面的 URI 的时候，浏览器会给我们展示相关的资源页面，比如： 上面我们是将一个三元组用 URI 来表示，而我们要做的是将所有的三元组都用 URI 来表示。但是全部都用完整的 URI 的话显得多余，所以我们可以用前缀： 用 @prefix 作为定义前缀的开始； 选择前缀名； 描述前缀的命名空间； 以句号 . 结尾. @prefix&nbsp;&nbsp; prefix name&nbsp;&nbsp; :&nbsp;&nbsp; &lt; resource namespace &gt;&nbsp;&nbsp; . 比如： 1@prefix wd: &lt;https://www.wikidata.org/wiki/&gt;. 现在回到上面的例子： 1234@prefix wd: &lt;https://www.wikidata.org/wiki/&gt;.@prefix wdp: &lt;https://www.wikidata.org/wiki/Property&gt;&lt;wd:Q2331&gt; &lt;wdp:P527&gt; &lt;wd:Q16546&gt; 现在我们就可以将整个图用 URI 来表示了： 从图中我们可以看到，大多数的 URI 都是源自 Wikidata，少部分看起来有点奇怪，比如 schema、 rdf、rdfs。在介绍这几个比较奇怪的 URI 之前，我们再多说点关于空节点，即 “blank node” 的事情。 2.3 Blank node空节点表示没有 URI 或者没有 Literal 的资源。听起来好像空节点是非法节点，但是实际上 RDF 允许这种情况的存在。必须说明的是，空节点只能出现在节点上，边是不允许的。空节点的 URI 并非是未知的，而是匿名的。当你想要表示一个复杂的资源特征，但是又不知道特征的名字，比如具体地址的街道门牌号。又或者你希望保护一些信息的隐私。类似于 “&lt;张三&gt;，&lt;生日&gt;，&lt;*&gt;”，我告诉你张三有一个属性叫做生日，但是我不告诉你他的生日是多少。 2.4 RDFSRDFS 即 “RDF Schema”，本质上是一个知识建模的词表，用来表示 RDF 知识模型。RDFS 包含了一系列的属性和其他机制用于描述知识以及知识之间的关系。 在介绍 RDFS 之前需要搞清楚，我们为什么需要这样一个词表？在我们最初引入 Led Zeppelin 例子的时候，把虚线箭头以下的部分去掉似乎并不影响整体性。实际上这种知识建模的技术就是诞生于 20 世纪 60 年代的语义网络。语义网络有一定的优点，比如容易理解、相关概念容易聚类等。如上面例子展示的，对我们人类来说，整张图的概念很清晰，关系也很明确。但是这样一个图有一个非常严重的问题： 没有标准！ 节点和边的值没有标准，完全由用户自己定义。 多源数据融合困难。比如三元组1（鱼，住在，水里），三元组2（鱼，生活在，水里），对于我们人类来说，两个三元组描述的是同一个事实，应该融合成一个三元组。但是对于计算机来说，它无法理解“住在”和“生活在”是同一概念，所以就没有办法自动融合在一起。 无法区分概念和实例。比如在语义网络中（鱼，是，动物）中，“鱼”和“动物”是同级的概念。而我们很清楚，他们是有上下位关系的。 为了解决语义网络存在的各种缺点，所以 W3C 制定了统一的标准，而这些标准就是相当于是由权威机构发布一些词汇，用来标准化常见的概念。比如，语义网络中 鱼，是，动物 羊，是一种，动物 我们将 “是”、“是一种”统一成 rdf:type，其中 rdf 表示前缀，完整的 URI 为 http://www.w3.org/1999/02/22-rdf-syntax-ns#type。这样既完成了标准化，也实现了 URI。 2.4.1 RDFS 常用词汇下面我们就来介绍，RDFS 是如何构建标准化词表的。首先先介绍 “类” 的概念： 知识可以被分成很多组，这些组称之为“类（class）”，这些类的成员就是“实例（instance）”。类和实例可以通过 URI 加以区分，也可以通过 RDF 属性加以描述。比如 rdf:type 就是用来描述是个实例属于某个类别： 鱼，rdf:type，动物 类也可以有子类 “subclass”，所有子类的实例也是类的实例。 属性（property） 表示连接 subject 和 object 的边，即 predicate。 用 RDFS 中一些重要的 Schema： rdf:Class：定义类节点。比如 “Led Zeppelin”，“Led Zeppelin IV”，“Black Dog”，“Jimmy Page” 都是类。 rdfs:Literal：用于定义节点的字面量，即字符串或者数字等。比如 “1971/8/11”。 • NOTE rdfs:Literal 本身是一个类，同时也是 rdf:Class 的实例。 rdf:Property：属性，即连接节点的边，还可以通过 rdfs:subPropertyOf 定义子属性。有一个很特殊而又常用的属性 rdf:type 用来描述一个实体是一个类别的实例，特殊在于我们经常缩写成 a。 rdfs:domain 和 rdfs:range：用来指定 rdf:Property 的定义域和值域。 123456789&lt;hasMember&gt; a rdf:Property . &lt;hasMember&gt; rdfs:domain &lt;Band&gt; . &lt;hasMember&gt; rdfs:range &lt;Person&gt; .# 用自然语言描述就是:# &lt;hasMember&gt; 是一条边# 定义域（subject）是&lt;Band&gt;# 值域（object）是&lt;Person&gt;# 等效于： &lt;Band&gt; &lt;hasMember&gt; &lt;Person&gt; rdfs:subClassOf：定义类的子类，可以用来构建层级关系。比如， 1&lt;musician&gt; &lt;rdfsLsubClassOf&gt; &lt;Person&gt; rdfs:label 和 rdfs:comments：之前介绍的 RDFS 词汇使数据变成计算机可读，但是我们还是希望对人类也可读。rdfs:label 是给一个节点人类可读的名字，帮助我们理解该节点，对 opaque URI 尤其有用。rdfs:comment 给节点添加文本描述，有点类似于给代码加注释。比如： 12&lt;hasMember&gt; rdfs:label “has member” . &lt;hasMember&gt; rdfs:comment “Property relating a band to one of its band members” . 2.5 OWLRDFS 是节点和关系的标准化词汇表。随着技术的发展，人们发现 RDFS 的表达能力相当有限，因此提出了OWL。我们可以把 OWL 当做是 RDFS 的一个扩展，其添加了额外的预定义词汇。 OWL 也定义了类、属性和实例。不同于 RDFS，OWL 有更丰富，更严格的词汇表。这里可能会有一个疑问：既然 OWL 覆盖了 RDFS 大部分词汇，而且比 RDFS 表达能力更强，那我们为什么还要用 RDFS？ 这就有点像牛刀可以用来杀鸡，但是不提倡，道理是一样的。虽然 OWL 表达能力更强，但是同时要求也更严格。当我们构建的知识模型本身就比较简单的时候， RDFS 就足够了。 OWL 的好处是，它支持和集成了 RDFS 的元素。比如 在OWL 里你仍可以用 rdf:type、rdfs:range、rdfs:subPropertyOf 等。 另外， OWL 也定义了自己的词汇，这些词汇比 RDFS 更细致。可以对一些属性添加约束，比如 owl:allValuesFrom 可以定义类的取值范围。 1&lt;hasParent&gt; owl:allValuesFrom &lt;Human&gt; . OWL 也支持用一系列操作来描述知识。比如，owl:unionOf 可以用来表示类，比如水果，包含甜水果和不甜的水果。owl:unionOf 的 subject 也可以是空节点。 1&lt;Fruit&gt; owl:unionOf ( &lt;SweetFruit&gt; &lt;NonSweetFruit ) . 我们还可以用 OWL 定义反向关系。还记得上面 Darth Vader 和 Luke 的例子吗？我们可以通过 owl:inverseOf 来定义 “” 和 “” 是一对互逆关系： 1&lt;hasSon&gt; owl:inverseOf &lt;hasFather&gt; . OWL 中另一个重要的词汇是 owl:sameAs，它用来表示两个实体是相同的。比如： 1&lt;BillClinton&gt; owl:sameAs &lt;WilliamJeffersonClinton&gt; . 另一个用来表示两个类是等价的词汇是 owl:equivalentClass： 1&lt;USPresident&gt; owl:equivalentClass &lt;PrincipalResidentOfWhiteHouse&gt; . 说两个事情是等价的看起来有点多余，但是这确实是 OWL 的一大优势。用“等价”描述可以很轻松的引用外部知识模型和本体。比如，你可以说 wikidata 中的 Al Pacino 和 IMDB 中的 Al Pacino 是等价的。这个在帮助你构建知识模型的时候省掉很多工作。 最后， WOL 还可以定义两种不同的 property： Object property：实体与实体之间的关系（&lt;hasMember &gt;） Data propery：实体与属性的关系（&lt;birthDay &gt;） 3. 知识建模的步骤前面我们介绍了关于知识模型的理论，接下来就是如何用上面的理论一步一步从头构建一个知识模型。在实际的项目当中，不建议自己从头构建知识模型。现在有很多领域已经有专家、工程师构建好的知识模型，我们可以以此为基础进行开发。本文是为了介绍相关知识，所以介绍从头构建知识模型的内容。 这里我们主要介绍两点： RDF 知识模型的语法，或者更正式一点的说法——RDF 数据的序列化。 帮助我们进行知识建模的工具——Protege。 3.1 RDF 序列化RDF 是一种知识描述框架，本质上也是一种模型。而序列化就是要讲这种描述框架落到实处。就像算法本身只是一种数学模型，而要如何实现算法就具体依赖你使用什么编程语言。RDF 三元组的序列化就是使用“编程语言”把它实现出来。RDF 序列化方法有多种： RDF/XML：就是用XML的格式来表示 RDF 数据。之所以提出这个方法，是因为 XML 的技术比较成熟，有许多现成的工具来存储和解析 XML。然而，对于 RDF 来说，XML 的格式太冗长，也不便于阅读，通常我们不会使用这种方式来处理 RDF 数据。 N-Triples：即用多个三元组来表示 RDF 数据集，是最直观的表示方法。在文件中，每一行表示一个三元组，方便机器解析和处理。 Turtle：应该是使用得最多的一种 RDF 序列化方式了。它比 RDF/XML 紧凑，且可读性比 N-Triples 好。 RDFa：即“The Resource Description Framework in Attributes”，是 HTML5 的一个扩展，在不改变任何显示效果的情况下，让网站构建者能够在页面中标记实体，像人物、地点、时间、评论等等。也就是说，将 RDF 数据嵌入到网页中，搜索引擎能够更好的解析非结构化页面，获取一些有用的结构化信息。 Json-LD：即“JSON for Linking Data”，用键值对的方式来存储 RDF 数据。 我们以 Turtle 为例进行介绍，因为如上所述，它是目前用的最多的一种序列方法。Turtle 简称 TTL，表示 Time To Live。 Turtle为了解释 TTL，我们从 TTL 的官网 借来一个例子： 12345678910111213@base &lt;http://example.org/&gt; .@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .@prefix rel: &lt;http://www.perceive.net/schemas/relationship/&gt; .&lt;#green-goblin&gt; rel:enemyOf &lt;#spiderman&gt; ;&lt;#green-goblin&gt; a foaf:Person ; # in the context of the Marvel universe&lt;#green-goblin&gt; foaf:name &quot;Green Goblin&quot; .&lt;#spiderman&gt; rel:enemyOf &lt;#green-goblin&gt; ;&lt;#spiderman&gt; a foaf:Person ;&lt;#spiderman&gt; foaf:name &quot;Spiderman&quot;, &quot;Человек-паук&quot;@ru . 下面我们详细介绍这个例子。 1-5 行：定义前缀。任何好的 TTL 文件都是先定义前缀。其中 2-3 行是我们之前介绍的 rdf 和 rdfs，4-5 行是两个新词 foaf 和 rel。第 1 行 base 是比较特殊的前缀，它表示一个基础的 URI，所有 “&lt;&gt;” 内的内容都是属于它的命名空间。需要注意的是，每一行都必须有 “.” 作为结束。 7-9 行：描述了一条关于“&lt;#green-goblin&gt;”的知识。 &lt;#green-goblin&gt; 就是以 @base 为前缀的节点，等价于 &lt;http://example.org/#green-goblin&gt;。 rel:enemyOf 表示以 rel 为前缀的关系，等价于 &lt;http://www.perceive.net/schemas/relationship/enemyOf&gt;。后面的 &lt;#spiderman&gt; 和 &lt;#green-goblin&gt; 类似。 a 表示 rdf:type，后面的表示法都与之前类似。 这三行描述的信息是：Green Goblin 有一个敌人叫做 Spiderman，Green Goblin 是一个人，Green Goblin 的名字叫做 Green Goblin。 字符串用双引号表示。 注释用 “#” 。 每一个三元组都以 “空格 .” 结尾。 每一个三元组都写 &lt;#green-goblin&gt; 有点重复，显得笨重又耗时。我们可以用 predicate list 的方法，将有相同 subject 的描述组合在一起，每条 predicate-object 描述用 “;” 分割。然后最后一条 predicate list 用空格和句号结束。我们将 7-9 行和11-13 行改造如下： 123456789&lt;#green-goblin&gt; rel:enemyOf &lt;#spiderman&gt; ; a foaf:Person ; # in the context of the Marvel universe foaf:name &quot;Green Goblin&quot; . &lt;#spiderman&gt; rel:enemyOf &lt;#green-goblin&gt; ; a foaf:Person ; foaf:name &quot;Spiderman&quot;, &quot;Человек-паук&quot;@ru . 我们来看改造后的第 9 行。Spiderman 有两个名字，一个是英文名，另一个是俄文名。两个英文名之间用 “,” 分割。在俄文名的引号后面有一个语言标签 @ru。语言标签有两部分组成 @ 和 语言关键词。 除了上面的例子展示的一些语法，Turtle 还有一些其他语法。比如可以使用 xsd 里指定数据类型，比如日期、字符串、数字等。更详细内容可查看官网。 另外，如果你之前已经用一种序列化方法实现了一个知识模型，现在处于某种原因，你想换成另一种序列化方法。不要紧，可以试试这个小工具。 3.2 知识建模工具在我看来，有两种方法构建知识模型： 在文本编辑器中写三元组（手动或者自动）。 用工具创建三元组。 就个人而言，我更喜欢前者。因为这样我们可以完全掌控我们要构建的知识模型。更重要的是，不需要从头学习一个工具的使用。当然，这纯属是个人原因。如果你找到一款趁手的工具，完全没必要手写三元组。如果你要手写三元组的话，这里推荐一个 python 包 —— rdflib。 考虑使用工具的话，现在市面上的开源而又实用的工具只有 Protégé。 Protégé 是斯坦福大学开发的一款本体（本文提到的“本体”等效于“知识模型”）建模工具。包括网页版和桌面版。 基本上，Protégé 允许用户添加类、对象和数据属性和实例，不需要手写三元组。用过给类添加子类来构建层级结构。知识建模完成以后可以将文件保存成 OWL 文件。 3.3 按步骤构建知识模型斯坦福大学不仅开发了知识建模工具，还发表了一篇文章叫我们怎样进行知识建模——《Ontology Development 101 guide》。更详细的内容可以看另一篇文章：知识图谱：知识建模（二）构建本体的方法论，或者去看原文。 总的来说，知识建模有三大原则： 对于一个领域来说，没有一个唯一正确的建模方法。我们可以用不同的方法进行建模。最好的方法依赖于实际应用和需求。 本体构建（知识建模）需要不断迭代。 本体中的概念和关系应该接近你感兴趣的领域（物理上或逻辑上）。 具体步骤如下： 确定知识领域及范围，即应用场景。 确定知识模型的重要概念。 本体复用。 定义类，类的层级结构以及关系。 定义限制条件。 3.4 可视化知识模型无论你是怎么建模的，最后你都希望看下你建模出来的知识模型长什么样子。可视化工具有两种： Protege 自带的插件 OntoGraf。 在菜单中选择 Windows -&gt; Tabs -&gt; OntoGraf 网页工具 WebVOWL。 4. 知识模型查询在知识建模的时候，我们提到知识建模的目的是希望它能回答我们一些什么问题。现在，我们就要介绍一下我们该怎么像知识模型问问题。 4.1 SPARQLSPARQL 是 “SPARQL Protocol and RDF Query Language” 的首字母缩写。SPARQL 对 RDF 来说，就像 SQL 对关系型数据库一样。如果你会一点 SQL，那 SPARQL 学起来也会比较快。 我们用下面的例子做一个简单的介绍： 例 1： 数据： 12345@prefix schemaL &lt;http://schema.org&gt; .@prefix wd: &lt;http://www.wikidata.org/wiki/&gt; .wd:Q2331 schema:album wd:Q201940 .wd:Q2331 schema:album wd:Q209539 . 上面这两个三元组相当于：Led Zeppelin (wd:Q2331) 有两张专辑，分别是 wd:Q201940 和 Q209539。 Query： 1234567@prefix schemaL &lt;http://schema.org&gt; .@prefix wd: &lt;http://www.wikidata.org/wiki/&gt; .SELECT ?album_nameWHRER &#123; wd:Q2331 schema:album ?album_name .&#125; 这一条查询语句包括两部分： SELECT：定义我们要查询的变量（album_name），以 “?” 开头。 WHERE：定义了基本的匹配模式。 上面的查询语句返回结果是： 12wd:Q201940wd:Q209539 例 2： 数据： 123456@prefix schemaL &lt;http://schema.org&gt; .@prefix wd: &lt;http://www.wikidata.org/wiki/&gt; .@prefix wpd: &lt;http://www.wikidata.org/wiki/Property&gt; .wd:Q201940 a wd:208569; # Led Zeppelin IV 是一张专辑 wd:P1449 &quot;Led Zeppelin IV&quot; # 有一个名字叫做 “Led Zeppelin IV” 上面两条三元组的意思是：Led Zeppelin IV 是一张专辑，Led Zeppelin IV 的名字是 “Led Zeppelin IV”。现在我想查询所有叫做 “Led Zeppelin IV” 的专辑，那我可以用下面的查询语句： Query： 12345678@prefix schemaL &lt;http://schema.org&gt; .@prefix wd: &lt;http://www.wikidata.org/wiki/&gt; .@prefix wpd: &lt;http://www.wikidata.org/wiki/Property&gt; .SELECT ?albumWHERE &#123; ?alubm wd:P1449 &quot;Led Zeppelin IV&quot; .&#125; 同样，在 SELECT 语句中以 “?” 开头定义我们需要查询的变量，在 WHERE 中定义查询模式。最后返回结果： 1wd:Q201940 以上两个例子都是非常基础的查询语句。Stardog tutorial 是一份非常好的 SPARQL 教程，我们可以在这里找到更详细的介绍。 4.2 SPARQL endpoint前面我们已经将某一领域的知识建模完成了，存成了 .ttl 文件。实际上这个 .ttl 文件是一个文本文件。我们说知识查询需要用到 SPARQL 查询语言。但是对于一个文本文件来说，我们能做的似乎只有字符串匹配或者正则匹配。SPARQL 语句应该在哪里输入？又在哪里执行？在哪里输出结果？也就是说，现在我们的知识模型文件和知识查询之间形成了一个断层。填补这个断层的就是 endpoint。这里我们介绍三种 SPARQL endpoint： D2RQ SPARQL endpoint Apache jena SPARQL endpoint rdflib 4.2.1 D2RQ SPARQL endpointSPARQL endpoint 用于处理客户端的请求，可以类比web server提供用户浏览网页的服务。通过endpoint，我们可以把数据发布在网上，供用户查询。 D2RQ 是以虚拟 RDF 的方式访问关系型数据库的一个工具。也就是说，假设我们原来的数据是存储在关系型数据库中的，我们不需要把这些数据手动转成 RDF 型数据，就可以通过 D2RQ 使用 SPARQL 语句而不是 SQL 语句进行查询。 它的工作原理也很简单，就是 D2RQ 会根据关系型数据库的表结构生成一个 mapping 文件，然后 D2RQ 会根据这个 mapping 文件将 SPARQL 语句翻译成 SQL 语句，然后进行查询。这里隐藏着一个 D2RQ 很重要的一个功能：将关系型数据库的数据转化成 RDF 数据。这也是我们常用来批量生成 RDF 数据的方式。关于这个功能不是我们要介绍的，想了解更多可以去 D2RQ 的官网进行了解。 我们通过 D2RQ 中的 D2RQ server 功能来进行 SPARQL 查询。D2RQ server 架构图如下： 进入 D2RQ 目录，使用下面的命令启动 D2R Server: 12d2r-server.bat mapping.ttl # windowsd2r-server mapping.ttl # linux 其中 “mapping.ttl” 就是我们上面说的 mapping 文件。 这里多说两句： 以 mysql 关系型数据库为例。生成 mapping.ttl 的方式如下： 1generate-mapping -u root -o mapping.ttl jdbc:mysql:///demo generate-mapping 是转换命令 -u root 表示关系型数据库的用户名 -o mapping.ttl 表示输出 mapping 文件名，可自定义 jdbc:mysql:///demo 关系型数据库 生成 mapping 文件之后，根据我们用 protege 知识建模的时候生成的 .owl 文件对 mapping文件进行修改，得到我们最终要用的 mapping 文件。更多关于 mapping 的语法参看：The D2RQ Mapping Language。 此时，D2RQ 服务就启动的。我们有两种方式进行 RDF 查询： 浏览器中查询 命令行查询 Python 脚本查询 4.2.1.1 浏览器查询在浏览器中输入 “http://localhost:2020/ ”，可以看到如下页面： 点击页面右下角红框地方的链接，进入 endpoint。然后就可以进行查询了，如下图： 4.2.1.2 命令行查询使用 d2rq-query 工具进行命令行查询： 1d2r-query mapping.ttl &quot;SELECT * &#123; ?s ?p ?o &#125; LIMIT 10&quot; 或者加载一个查询文件，比如 query.sparql： 1d2r-query mapping.ttl @query.sparql 4.2.1.3 Python 脚本查询通常情况下，我们对 RDF 的查询是集成在代码中的。为了能在代码中进行查询，人们就开发了一个 python 库—— SPARQLWrapper。这是一个Python下的包装器，可以让我们十分方便地和endpoint进行交互。下面是通过SPARQLWrapper，向 D2RQ endpoint发送查询“巩俐参演的评分大于 7 的电影有哪些”，得到结果的代码： 123456789101112131415161718192021from SPARQLWrapper import SPARQLWrapper, JSONsparql = SPARQLWrapper(\"http://localhost:2020/sparql\")sparql.setQuery(\"\"\" PREFIX : &lt;http://www.kgdemo.com#&gt; PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; SELECT ?n WHERE &#123; ?s rdf:type :Person. ?s :personName '巩俐'. ?s :hasActedIn ?o. ?o :movieTitle ?n. ?o :movieRating ?r. FILTER (?r &gt;= 7) &#125;\"\"\")sparql.setReturnFormat(JSON)results = sparql.query().convert()for result in results[\"results\"][\"bindings\"]: print(result[\"n\"][\"value\"]) 运行结果： 12345678910111213142046Memoirs of a Geisha荆轲刺秦王大红灯笼高高挂霸王别姬活着唐伯虎点秋香秋菊打官司菊豆Hong gao liang画魂风月Piao Liang Ma MaThe Hand 4.2.2 Apache jena SPARQL endpoint Apache jena 严格来说是语义网框架，包括存储、查询和推理组件，架构图如下： 我们可以将 .ttl 数据存储到 jena 数据库中，然后通过 Fuseki 查询组件进行查询。操作流程同样是可以在浏览器端和命令行和通过调用 api 在代码里进行操作。这里我们不再详细介绍，在接下来的知识存储相关文章中进行详细介绍。 4.2.3 RDFLibRDFLib 是一个 python 包： 1234567891011121314import rdflibg = rdflib.Graph()g.parse(\"demo.ttl\") # 导入 ttl 文件knows_query = \"\"\"SELECT DISTINCT ?aname ?bnameWHERE &#123; ?a foaf:knows ?b . ?a foaf:name ?aname . ?b foaf:name ?bname .&#125;\"\"\"for row in qres: print(f\"&#123;row.aname&#125; knows &#123;row.bname&#125;\") 4.2.4 Wikidata Query Service如果你想快速体验 SPARQL 的话，wikidata 提供了一个服务——Wikidata Query Service： 4.3 更多 SPARQL 语法接下来，我们再介绍一些比较常用的 SPARQL 语法。 4.3.1 DISTINCT用于数据去重。 数据： 12345678910@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; ._:x foaf:name &quot;Alice&quot; ._:x foaf:mbox &lt;mailto:alice@example.com&gt; ._:y foaf:name &quot;Alice&quot; ._:y foaf:mbox &lt;mailto:asmith@example.com&gt; ._:z foaf:name &quot;Alice&quot; ._:z foaf:mbox &lt;mailto:alice.smith@example.com&gt; . Query： 12PREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;SELECT DISTINCT ?name WHERE &#123; ?x foaf:name ?name &#125; 返回结果： 1&quot;Alice&quot; 4.3.2 OPTIONAL通常的 query 语句只会返回匹配到的数据，OPTIONAL 可以返回一些匹配到的数据包含的额外信息： 数据： 12345678910@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; ._:a rdf:type foaf:Person ._:a foaf:name &quot;Alice&quot; ._:a foaf:mbox &lt;mailto:alice@example.com&gt; ._:a foaf:mbox &lt;mailto:alice@work.example&gt; ._:b rdf:type foaf:Person ._:b foaf:name &quot;Bob&quot; . Query： 12345PREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;SELECT ?name ?mboxWHERE &#123; ?x foaf:name ?name . OPTIONAL &#123; ?x foaf:mbox ?mbox &#125; &#125; 返回结果： 123&quot;Alice&quot; &lt;mailto:alice@example.com&gt;&quot;Alice&quot; &lt;mailto:alice@work.example&gt;&quot;Bob&quot; 4.3.3 UNION求并集。 数据： 1234567891011@prefix dc10: &lt;http://purl.org/dc/elements/1.0/&gt; .@prefix dc11: &lt;http://purl.org/dc/elements/1.1/&gt; ._:a dc10:title &quot;SPARQL Query Language Tutorial&quot; ._:a dc10:creator &quot;Alice&quot; ._:b dc11:title &quot;SPARQL Protocol Tutorial&quot; ._:b dc11:creator &quot;Bob&quot; ._:c dc10:title &quot;SPARQL&quot; ._:c dc11:title &quot;SPARQL (updated)&quot; . Query： 12345PREFIX dc10: &lt;http://purl.org/dc/elements/1.0/&gt;PREFIX dc11: &lt;http://purl.org/dc/elements/1.1/&gt;SELECT ?titleWHERE &#123; &#123; ?book dc10:title ?title &#125; UNION &#123; ?book dc11:title ?title &#125; &#125; 返回结果： 1234&quot;SPARQL Protocol Tutorial&quot;&quot;SPARQL&quot;&quot;SPARQL (updated)&quot;&quot;SPARQL Query Language Tutorial&quot; 4.3.4 FILTER过滤器。 数据： 12345678@prefix dc: &lt;http://purl.org/dc/elements/1.1/&gt; .@prefix : &lt;http://example.org/book/&gt; .@prefix ns: &lt;http://example.org/ns#&gt; .:book1 dc:title &quot;SPARQL Tutorial&quot; .:book1 ns:price 42 .:book2 dc:title &quot;The Semantic Web&quot; .:book2 ns:price 23 . Query： 12345PREFIX dc: &lt;http://purl.org/dc/elements/1.1/&gt;SELECT ?titleWHERE &#123; ?x dc:title ?title FILTER regex(?title, &quot;^SPARQL&quot;) &#125; 返回结果： 1&quot;SPARQL Tutorial&quot; 4.3.5 ORDER BY排序。 数据： 1234567891011@prefix dc: &lt;http://purl.org/dc/elements/1.1/&gt; .@prefix : &lt;http://example.org/book/&gt; .@prefix ns: &lt;http://example.org/ns#&gt; .@prefix schema: &lt;https://schema.org&gt; .:book1 dc:title &quot;SPARQL Tutorial&quot; .:book1 ns:price 42 .:book2 dc:title &quot;The Semantic Web&quot; .:book2 ns:price 23 .:book3 schema:name &quot;A data engineer&apos;s guide to semantic models&quot; .:book3 ns:price 0 . Query： 1234567PREFIX dc: &lt;http://purl.org/dc/elements/1.1/&gt;PREFIX schema: &lt;https://schema.org&gt; .SELECT ?titleWHERE &#123; &#123; ?x dc:title ?title&#125; UNION &#123;?x schema:name ?title&#125; &#125;ORDER BY DESC(?title) 返回结果： 123&quot;A data engineer&apos;s guide to semantic models&quot;&quot;SPARQL Tutorial&quot;&quot;The Semantic Web&quot; 4.3.6 LIMIT数据： 1234567891011@prefix dc: &lt;http://purl.org/dc/elements/1.1/&gt; .@prefix : &lt;http://example.org/book/&gt; .@prefix ns: &lt;http://example.org/ns#&gt; .@prefix schema: &lt;https://schema.org&gt; .:book1 dc:title &quot;SPARQL Tutorial&quot; .:book1 ns:price 42 .:book2 dc:title &quot;The Semantic Web&quot; .:book2 ns:price 23 .:book3 schema:name &quot;A data engineer&apos;s guide to semantic models&quot; .:book3 ns:price 0 . Query： 12345678PREFIX dc: &lt;http://purl.org/dc/elements/1.1/&gt;PREFIX schema: &lt;https://schema.org&gt; .SELECT ?titleWHERE &#123; &#123; ?x dc:title ?title&#125; UNION &#123;?x schema:name ?title&#125; &#125;ORDER BY DESC(?title)LIMIT 2 返回结果： 12&quot;A data engineer&apos;s guide to semantic models&quot;&quot;SPARQL Tutorial&quot; 更详细的 SPARQL 语法可参考之前提到的资源。 5. 结语到这里，我们的知识建模简介就结束了。但是对于我们来说，它才刚刚开始。学习这个理论是一个很好的开始，但最好的学习方法是将理论付诸实践。注意建议：当您决定构建一个模型时，尝试与一个团队一起构建模型。由于建模是如此的主观，所以把一群不同的思想家聚集在一起总是一个好主意。语义建模并不一定需要以语义模型开始和结束。 不管怎样，无论你可能读了多少。我希望我能让你对知识建模领域更了解一点，最重要的是，我希望你能对链接数据感到最小兴奋。毕竟，我们不需要更多的数据，我们需要更多有意义的数据。 Reference A DATA ENGINEER’S GUIDE TO SEMANTIC MODELLING, Ilaria Maresi, 2020 知识图谱基础之RDF，RDFS与OWL, SimmerChan 实践篇（三）：D2RQ SPARQL endpoint与两种交互方式, SimmerChan 实践篇（四）：Apache jena SPARQL endpoint及推理, SimmerChan","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://rogerspy.gitee.io/categories/知识图谱/"}],"tags":[{"name":"KG","slug":"kg","permalink":"https://rogerspy.gitee.io/tags/kg/"},{"name":"knowledge-modelling","slug":"knowledge-modelling","permalink":"https://rogerspy.gitee.io/tags/knowledge-modelling/"}]},{"title":"知识图谱：综述（三）Schema, Identity, Context","slug":"kg-survey-3","date":"2021-05-29T11:48:26.000Z","updated":"2022-02-15T03:01:19.485Z","comments":true,"path":"2021/05/29/kg-survey-3/","link":"","permalink":"https://rogerspy.gitee.io/2021/05/29/kg-survey-3/","excerpt":"接下来，我们介绍 Schema、Identity 和 Context。在上一章，我们将以节点和边组成的数据集合称之为“Data graph”，而真正意义上的知识图谱（knowledge graph）是经过了 Schema（数据模式）、Identity（数据一致性）、Context（上下文）、ontology（本体）和 rules（规则）等表示方法增强过的 data graph。本章我们讨论 Schema、Identity 和 Context。Ontology 和 rules 在后面章节讨论。","text":"接下来，我们介绍 Schema、Identity 和 Context。在上一章，我们将以节点和边组成的数据集合称之为“Data graph”，而真正意义上的知识图谱（knowledge graph）是经过了 Schema（数据模式）、Identity（数据一致性）、Context（上下文）、ontology（本体）和 rules（规则）等表示方法增强过的 data graph。本章我们讨论 Schema、Identity 和 Context。Ontology 和 rules 在后面章节讨论。 3. Schema, Identity, Context Fig 1. 示例知识图谱 3.1 Schema相比于关系型数据库的数据模型，图数据的一大优势就是不需要数据模式（schema）或者可以延后定义数据模式。但是给图数据制定数据模式可以规范一些更加高级的结构或者语义。接下来我们讨论三种图数据模式：semantic，validating，emergent。 3.1.1 Semantic schema语义模式的允许定义图中的高级项的意义，我们可以用这些项进行推理。 根据示例图谱，我们可以定义一些类别（class），比如 Event，City 等等，然后根据类别定义一些子类（subclass），从而形成一个层级结构： 有了这样一个层级结构，我们可以直接从数据中检索到（EID15，type，Food Festival），然后根据语义模式推理出（EID15，type，Festival），进一步推理出（EID15，type，Event），如下所示： 除了类别，我们还希望定义边上标签的语义，即属性（property）。回到示例图谱，我们可以认为 city 和 venue 是 location 的子属性（sub-property），或者 bus 和 flight 是 connections to 的子属性。这样，属性也可以形成一个层级结构。 更进一步，我们可以给属性定义定义域（domain）和值域（range）。定义域表示节点的类别，而边是从该节点扩展出来的。比如，定义 connections to 的定义域为 city，那么对于（Arica connections to Santiago）来说，我们可以推理出（Arica，type，city）。而值域同样表示节点的类别，而边是扩展到该节点上。比如，定义 connections to 的值域是 city，那么那么对于（Arica, connections, to Santiago）来说，我们可以推理出（Santiago，type，city）。 RDF Schema（RDFS）是定义语义模式的一个重要标准，在 RDFS 中我们可以定义类（class）、子类（subclass）、属性（property）、子属性（sub-property）、定义域（domain）和值域（range），并且可以将这些定义进行序列化。 下面给出一个例子： 由于 RDFS 的表达能力较弱，比如无法表示两个实体是同一实体（乔丹，same as，飞人），后来又衍生出另一个非常重要的语义模式——OWL（Web Ontology Language）。OWL 的语义表达能力更强，同时也支持 RDFS，在实际的工程中 OWL 的应用更加广泛。 无论是 RDFS 还是 OWL，包括 OWL 2 等所有的语义模式标准，本质上都是词表。这些词表被认为是语义模式的标准词表，我们用这个词表中的词进行语义建模实现了语义标准化，避免了利用自然语言进行语义建模的歧义性和多样性为后续的推理带来困扰，同时也为多图谱融合提供了方便。我们在后续的文章中进行详细讲解。 语义模式同时也满足一个知识图谱的重要假设——开放世界假设： 当前没有陈述的事情是未知的。 即，没有在知识图谱中描述的知识，我们认为是未知的，而不是不存在的。比如在我们的示例图谱中找不到（Viña del Mar，flight ，Arica）这样一条关系，这不代表在 Viña del Mar 和 Arica 之间是没有航班的，只能说明我们现在还不知道这两地之间有没有航班。 开放世界假设从逻辑上讲是很合理的，因为我们不可能在知识图谱中描述所有的知识，我们只需要描述我们所需要的知识就可以了。但是这样也会给我们带来一定的麻烦，在开放世界假设下，知识图谱无法回答“是”或“否”的问题。比如“在 Viña del Mar 和 Arica 之间有航班吗？”这样一个问题，知识图谱无法直接回答“有”或者“没有”。 相对于开放世界假设，还存在一个封闭世界假设： 没有描述的事情就是不存在的。 即，假设我们的图谱已经是完备的了，它包含了一切知识。 处于开放世界假设和封闭世界假设之间，还有一个局部封闭世界假设： 假设部分没有描述的事情真的不存在。 即，认为我们的图谱是部分完备的。比如假设我们的图谱中已经包含了所有航空公司的所有航线，在所有这些航线中都没有 Viña del Mar 和 Arica 之间的航班，那么我们就认为这两地之间确实没有航班。 3.1.2 Validating schema如果图谱中的数据多样性较高且存在大量不完备的信息，那么开放世界假设作为默认语义是比较合理的。但是在某些场景下，我们必须保证数据的完备性。比如我们必须保证示例图谱中每一项活动都至少有一个名字、举办地点、开始时间和结束时间，这样才能保证用户对这项活动有最基础的了解。为了保证这些数据的完备性，我们必须对图谱添加一些约束，而 validating schema 就是去验证图谱是否满足我们添加的约束的。 Semantic schema 用于从现有的知识中推理出新的知识 Validating schema 用于验证已有的知识的合法性 定义 validating schema 的标准方法是使用 shapes。 \\text{shape} = [nodes, constraints]其中的 $nodes$ 选取可以是一个类别的所有实例，或者某个属性的定义域或者值域，或者某条查询语句的结果等等。$constraints$ 就是作用在这些节点上的约束条件，比如给定属性上节点的数量，节点的数据类型等等。多个 shape 相互关联就形成了 shapes graph。 Shapes graph 可以用类似 UML 示意图来表示，如下图所示： 这个例子中包含 4 个 shape：Event、Venue、City 以及 Place，每个 shape 中都对该类别下的节点做出了限制，比如 Event 要求必须包含 name（数据类型是字符串类型）、start（数据类型是日期类型）、end（数据类型是日期类型） 和 type（任意类型）等。其中的 $[1..*]$ 表示可以有 $1-\\infty$ 个值，$[1..1]$ 表示只能有 1 个值，$[0..1]$ 表示要么没有值（即可以缺省），要么只能有一个值。 当我们定义了这样一个 shape graph之后，就可以通过递归的方法对数据进行检查，比如 EID15 包含定义的 4 个属性，与之相连的 Santa Lucía 必须属于 Venue 且 Santiago 属于 City。因为 City 属于 Place，就要求 Viña del Mar 和 Arica 也必须属于 Place 等等。而 EID16 就是一个不合法的节点，因为它缺少了 start 和 end。 当我们定义 shape graph 时，不可能知道每个节点包含的所有属性。这种情况下，open shape 允许节点存在在 shape graph 中未定义的属性，而 close shape 则不允许这种情况。比如我们在示例图谱中添加一个关系（Santiago，founder，Pedro de Valdivia），在我们定义的 shape graph 中没有包含 founder 这个属性，在 open shape 情况下，Santiago 仍然是一个合法的节点，但是在 close shape 情况下就变成了非法节点。 实际的查询语言通常还支持额外的特性：AND、OR、NOT 等操作。比如 $\\text{Venue}~ AND~ (NOT~ \\text{City})$ 表示 venue 不能是 City。但是这些额外的操作符的自由组合可能会造成语义问题，比如著名的理发师悖论： 假设有一个 shape 是（Barber，shave，Person），并且要求 $\\text{Person}~ AND~ (NOT~ \\text{Barber})$。现在给定（Bob，shave，Bob），其中 Bob 满足 （Bob,，type，Person），那么 Bob 满足（Bob，type，Barber）吗？ 如果满足，那么这条数据就是非法的，因为 $\\text{Person}~ AND~ (NOT~ \\text{Barber})$； 如果不满足，那么这条数据也是非法的，因为它不满足（Bob，type，Barber）。 为了避免这些悖论的产生，人们提出了各种方法，比如分层（ stratification）、部分赋值（partial assignments）、稳定模型（stable models）等。 虽然，Semantic schema 和 Validating schema 有不同的应用场景，但是二者也可以互补。我们可以利用 Semantic schema 对 shape 进行推理，也可以利用 Validating schema 对推理结果进行筛选。通常这种情况下需要用 open shape。 目前有两种验证模式语言：Shape Expressions (ShEx) 和 SHACL (Shapes Constraint Language)。更加详细的介绍可以看 Labra Gayo 等人的论文。 3.1.3 Emergent schema无论是 semantic schema 还是 validating schema 都需要领域专家来构建，但是通常我们不具备这样的条件。我们可以从图谱中抽取一些隐式结构形成 emergent schema。 用于定义 emergent schema 的框架是 quotient graphs，它可以根据一些等价关系划分数据图中的节点组，同时保留图的一些结构属性。比如示例图谱中，我们可以区分不同的 type，比如 event、name、venue、class、date-time、city 等。将每一个 type 的节点融合进一个节点然后保留边，最终形成 quotient graph，如下图所示： quotient graphs 的定义取决于如何选取节点和边，不同的 quotient graphs 展现出来的图结构不同。严格意义上来说，quotient graphs 是在模拟输入图谱，这就意味着当且仅当 $x \\in X, z \\in Z$，且 $x \\xrightarrow{y} z$ 时，$X \\xrightarrow{y} Z$ 才成立。然而示例图谱中 EID16 是没有开始和结束时间的，所以我们应该将上图换成： 将 event 分成两个节点来保存满足不同边的节点，这样的图叫做 bisimilarity。关于 bisimilarity 的一个比较严格的定义是：当存在 $X \\xrightarrow{y} Z$ 关系时，对于任意 $x \\in X$，必定存在 $z \\in Z$ 满足 $x \\xrightarrow{y} z$。 3.2 Identity在示例图谱中，我们有一个节点 “Santiago”，但是到底是哪个 Santiago？是 Santiago de Chile？Santiago de Cuba？Santiago de Compostela？甚至说是摇滚乐队 Santiago？从（Santa Lucía，city，Santiago）我们可以推出 Santiago 是一个城市而不是乐队，另一方面，这个图谱是关于智利的旅游图谱，那么我们可以推理出这里的 Santiago 应该是 Santiago de Chile。如果没有足够多的信息，节点的歧义性就会给后续的任务带来麻烦。为了避免节点的歧义性，首先要做的就是给节点分配全局统一的标识符，其次就是给节点添加外部链接标识符加以以区分。 3.2.1 Persistent identifiers假设我们想对比智利和古巴的旅游景点，我们收集了足够多的数据然后分别构建了图谱。当我们想要将两个图谱融合在一起的时候就会出现问题： 如图所示，两个图谱都有 Santiago 节点，我们如果直接合并的话，两个 Santiago 就会合并成一个。但是我们知道实际上两个 Santiago 是两个不同的地点。为了避免这种情况，我们可以给每个 Santiago 分配一个 Persistent identifiers（PIDs），每一个 PID 保证其全局唯一性。 除了全局唯一性，我们通常还需要在网页对图谱进行展示，所以 RDF 推荐使用 IRI 来表示实体和关系。比如： IRI 的形式与 URL 非常相近，如果我们把上面的 IRI 复制到浏览器的话，我们会发现进入到了维基百科的页面。那么 IRI 和 URL 有什么区别呢？URL 是用于信息资源的定位，所谓信息简单来说其实就是网页，比如 URL “https://www.wikidata.org/wiki/Q2887” 表示的是关于 “Santiago” 这个网页而不是 “Santiago” 这个实体。为了更进一步解释其中的区别，我们来看下面的例子： 与上面 IRI 表示法一模一样，但是如果这里是 URL 的话，实际上会给我们带来歧义：到底是 Santiago 这个城市是由 Pedro de valdivia 建立的，还是 “Santiago” 这个网页是 Pedro de valdivia 创建的？ 3.2.2 External identity links假设在我们的图谱中定义了 Santiago 节点为 chile:Santiago chile 是 “http://turismo.cl/entity/” 的缩写，这个节点定义相当于 “http://turismo.cl/entity/Santiago” 在另一个地理相关的图谱中定义了 Santiago 为 geo:SantiagoDeChile。两个节点实际上指得是同一座城市，但是由于命名不同，我们就灭哟哟办法直接知道这两个节点是相同的。如果我们对来弄个图谱进行融合的时候，会造成同一个实体有两个不同的节点。 将两个名称不同，但是表示同一实体的节点统一的方法有以下几种： 使用实体在图谱中信息的唯一性，比如地理坐标、邮政编码、成立时间等； 使用标识链接来声明本体实体与外部源中发现的实体是相同实体。在 OWL 中定义了 owl:sameAs 属性来关联两个实体。例如： 3.2.3 Datatypes思考一下示例图谱中左侧的两个日期：“2020-03-29T20:00:00” 和 “2020-03-22T12:00:00”，我们应该怎样分配 PID？直观上来说，我们给它们分配的 IRI 需要告诉我们特定的日期和时间，并且可以被机器或者软件识别，然后我们还可以对这些值进行排序，抽取我们需要的年份、月份等。 大多数图数据模型允许定义节点的数据类型。RDF 使用 XML Schema Datatypes (XSD)，表示为（$l, d$）对 ，其中 $l$ 表示词汇字符串，$d$ 表示数据类型。比如 1“2020-03-29T20:00:00” 就表示成 &quot;2020-03-29T20:00:00&quot;^^xsd:dateTime RDF 中数据类型节点被称为 “literals”，并且不允许有向外的边。RDF 中其他常用的数据类型还包括：xsdstring、xsd:integer、xsd:decimal、xsd:boolean 等等。 建立在图谱之上的应用可以通过识别这些数据类型，对其进行解析然后做排序、变换等等后续的处理。 3.2.4 Lexicalisation虽然通常 PID 的形式具有人类可解释性，但是 PID 本身不具有任何语义信息，比如 chile:Santiago。甚至有时候 PID 连人类可解释性都不具备，比如 wd:Q2887。这两种表示法分别称为显式表示和隐式表示，显式表示法有利于人类理解，而隐式表示有利于持久化，比如假设我，们用 wd:Q2887 表示某公司某部门的员工，如果该员工工作部门发生了变动，采用显式表示的话其对应的节点就需要改变，而如果采用隐式表示就无序改变。 由于 PID 具有任意性，所以通常会给节点添加一个人类可读的边作为标记，比如： 实际上可以将这种标记看成是编程语言中的注释，用来说明特定节点在真实世界中包含的信息。我们可以使用昵称或者注释来实现： 形如 &quot;Santiago&quot; 这样的节点通常是 literal，而不是标识符。不同的图谱会有不同的表示，比如 (Santiago, rdfs:label, &quot;City&quot;@en) 或者 (Santiago, rdfs:label, &quot;Ciudad&quot;@es) 表示不同语言下的注释。这种用人类可读的 labels，aliases，comments 来对节点进行注释的图谱，我们称之为 “ (multilingual) lexicalised knowledge graphs ”。 3.2.5 Existential nodes当建模不完整的信息时，我们在某些情况下可能知道图中必须存在一个特定的节点，与其他节点有特定的关系，但无法识别所讨论的节点。比如两个活动 chile:EID42 和 chile:EID43 有共同的活动地点，但是这个活动地点还没有公布。这种情况的一种处理方法就是忽略活动地点这个关系，但是这样我们会丢失一些信息： 活动是有活动地点这个属性的； 两个活动有相同的举办地点。 另一种处理方法就是创建一个新的 IRI，但是这样的话又无法区分未知地点和已知地点的区别。因此，一些图谱中允许空节点的存在，即所谓的 existential nodes： 在 RDF 中支持空节点的存在，即 blank nodes。Blank nodes 也被用来对复杂元素进行建模，比如 RDF list： 3.3 Context我们可以认为在某些特定情况下，图谱中的数据都是真实的。但是如果考虑时效性的话，Santiago 是从 1541 年成为一个城市的，而 Arica 到 Santiago 的航班是 1956 年开通的。考虑地理因素的话，示例图谱描述的是 chile。考虑数据来源的话，与 EID15 相关的数据来源于 2020 年 1 月 4 日的 Ñam 网页。因此，通过上面的例子，我们可以看到，图谱中的知识都是具有片面性的，只在某些特定情境下成立，这些特定情形我们称之为 context。现在我们就来介绍不同级别的 context 的不同表示方法。 3.3.1 Direct representation第一种表示方法就是把 context 当成图谱数据的一部分，用节点和边来表示，比如 EID15 关联的日期时间，我们就认为在这个时间上 （EID15，venueSanta Lucia） 是成立的。另一种方法就如我们在第二章介绍属性图那样，改变边的模式。虽然我们的例子中用的是比较随意的方法，但是实际上有一些特定的 context 已经有一些标准了，比如 Time Ontology 就对时刻、时间段等信息做出了规定。另外 PROV Data Model 规定了在 RDF 中如何表示数据来源。 3.3.2 Reification通常我们希望直接定义边本身的 context，比如 (Santiago, flight, Arica) 这个关系从 1956 年才成立。虽然我们可以用直接表示法，通过改变边的结构来加以声明，但是我们还是希望能有一种更加通用的方法来表示，这就是 Reification。 上图展示了三种 reification 方法。我们使用 $e$ 来表示任意标识符，表示可以与之关联到的边的 context 信息。（a）中定义了 $e$ 节点表示边和与之相连的节点（subject, predict, object）。（b）则是用 $e$ 代替目标节点，然后将原来的目标节点作为 $e$ 的值赋予给它。（c）用 $e$ 代替边，然后将 context 作为 $e$ 的标签。 3.3.3 Higher-arity representation （a）命名图的方法 （b）属性图的方法 （c） RDF*，RDF* 是 RDF 的扩展方法，它允许将整个三元组当成一个节点。 以上三种方法中，最灵活的就是命名图的方法。RDF* 方法是最不灵活的，比如 (Chile, president, M. Bachelet)，Bachelet 担任了两届总统，2006-2010 年 和 2014-2018 年，这种情况无法用 RDF* 来描述。 3.3.4 Annotations到目前为止我们讨论了图谱中的 context，但是还没有涉及到 context 的自动推理机制。比如假设 Santiago 到 Arica 之家只有夏季航班，我们要从 Santiago 到 Arcia 只能换一种途径。虽然直接将所有汽车、航班的日期全部表示在图谱中，或者写冗长复杂的查询语句也可以，但是这样的话可能会比较麻烦，甚至根本做不到。这个时候，我们可以考虑使用 annotations，它提供了 context 的数学定义和关键性操作符，可以帮助我们自动进行推理。 某些 annotations 是对特定领域的 context 进行建模，比如 Temporal RDF 对时间段建模： 表示 M. Bachelet 在 2006-2010 年期间担任 Chile 总统。Fuzzy RDF 对可信度进行建模： 表示 Santiago 有八成的可能性是属于 Semi-Arid 气候。 其他形式的 annotations 与领域无关，比如 Annotated RDF 允许将不同形式的 context 建模成 semi-rings：由定义域值（比如时间段）和 meet、join 两个操作符组成的代数结构： 如上图所示，$G$ 表示简化的时效值集合，（1-365）表示一年的 365 天，其中形如 $\\{[150,152]\\}$ 表示 $\\{150,151,152\\}$。$Q$ 表示从 Santiago 到活动举办地的航班，返回符合时效性的答案。为了推导出答案，我们需要以下几个步骤： 使用 meet 操作符找到同时满足 city 和 flight 的边。比如 Santiago 和 Punta Arenas 的时效性条件分别是 $\\{[150,152]\\}$ 和 $\\{[1,120],[220,365]\\}$，两个条件的交集为空，那么这个答案就会被过滤掉。 使用 join 操作符，将所有符合条件的结果求并集。比如我们可以在 $\\{[123, 125]\\}$ 参加 EID16，在 $\\{[276,279]\\}$ 参加 EID17。最后将两组结果合并得到最终的 context。 3.3.5 Other Contextual framework除了 annotations 以外，还有一些其他的模型也可以用来推理，比如 contextual knowledge repositories，允许在独立的图谱或者子图上计算 context。它不像 命名图那样，而是通过多维建模，每个图或者子图满足一个维度的条件。OnLine Analytic Processing (OLAP) 提出了基于数据块的模型，提出了 “slice-and-dice” 和 “roll-up” 等操作。更详细的内容可以参考 Contextualized Knowledge Repositories for the Semantic Web 和 Building a Conference Recommender System Based on SciGraph and WikiCFP。","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://rogerspy.gitee.io/categories/知识图谱/"}],"tags":[{"name":"KG","slug":"kg","permalink":"https://rogerspy.gitee.io/tags/kg/"},{"name":"survey","slug":"survey","permalink":"https://rogerspy.gitee.io/tags/survey/"}]},{"title":"知识图谱：综述（二）Data Graphs","slug":"kg-survey-2","date":"2021-05-27T03:50:44.000Z","updated":"2022-02-09T04:01:15.530Z","comments":true,"path":"2021/05/27/kg-survey-2/","link":"","permalink":"https://rogerspy.gitee.io/2021/05/27/kg-survey-2/","excerpt":"任何知识图谱的基础是首先将图应用于数据，从而产生初始数据图。我们现在讨论一些在实践中常用来表示数据图的图结构数据模型。 然后，我们讨论构成用于查询此类数据图的图查询语言基础的查询语言。","text":"任何知识图谱的基础是首先将图应用于数据，从而产生初始数据图。我们现在讨论一些在实践中常用来表示数据图的图结构数据模型。 然后，我们讨论构成用于查询此类数据图的图查询语言基础的查询语言。 2. Data Graphs2.1 Models抛开图数据不谈，假设现在旅游局还没有确定怎样对数据建模。他们首先会考虑的是关系型数据库来展示所需的数据，尽管还不知道具体需要获取什么数据，但是他们可以设计一个初始的数据模式（schema），比如活动表： \\text{Event(name, venue, type, start, end)}其中 name 和 start 一起作为主键。当他们开始往表格填充数据的时候会遇到各种各样的问题： 活动可能有多个名字（多语言）； 活动可能在多个场地举办； 活动举办的起始和结束时间未定； 活动可能包含多种类型等等。 随着数据变得更加多样化，他们需要增量式的解决建模问题，比如给活动添加 id，调整关系模式： \\text{EventName(id, name)}\\\\ \\text{EventStart(id, start)}\\\\ \\text{EventEnd(id, end)}\\\\ \\text{EventVenue(id, venue)}\\\\ \\text{EventType(id, type)}通过上面这种模式，旅游局可以给活动 0-n 个名字、场所和类型以及 0-1 个起始和结束时间（不需要在表格中用 null 或者空值表示）。这种方法要求旅游局不断的重新建模，重新加载数据，重建索引以适应新的数据源。 如果一开始就采用下面这种数据建模方式，我们会发现当有新的数据需要建模的时候，只需要很小的改动就可以实现多关系映射。我们仔细观察上面这种模式，实际上就可以认为是一种图数据结构：id 和 name 是实体，EventName 是关系，下面类似。 下面我们介绍三种常见的图数据模型。 2.1.1 Directed edge-labelled graphs有向边标记图（DELG）是一系列节点和连接节点的带标记的有向边组成的图，如下图所示。 在知识图谱中，节点用来表示实体，边用来表示实体之间的关系。 上图是关于 Events 的图数据信息，包含了两个 event：EID5 和 EID6，并分别展示了两个活动的 name，type，venue，start 和 end。如果我们想要添加信息，只需要添加节点和边；对于不完整的信息，只需要忽略特定节点和边即可，比如 EID6 并没有 start 和 end 信息。 用图对数据进行建模可以使集成新数据源更加流畅，不需要像关系型数据库那样需要提前设计对数据模式，一旦新数据结构不符合之前设计的数据模式又要重新建表。虽然其他的数据结构也可以方便添加新数据，比如树，但是树需要一个层级结构，而且图支持循环表示，如上图中的 Santiago, Arica 和 Viña del Mar 三个节点。 W3C 制定了一个标准的有向边标记图——RDF（Resource Description Framework）。RDF 定义了不同的节点类型，包括： IRIs：国际化资源标识符（Internationalized Resource Identifiers），允许对 Web 上的实体进行全局识别。 literals：字面量，允许表示字符串和其他数据类型，比如整数，日期等。 blank nodes：表示未分配标识符的匿名节点。 2.1.2 Graph dataset尽管我们可以通过对多个图取并集的方式将多图合并，但是通常管理多个图更符合实际需求，比如更新和细化单一来源的数据；区分可信数据和不可信数据等。一个图数据集由一系列命名图和一个默认图组成，每个命名图包括图本身和其对应的 ID，默认图不需要 ID。 上图给出一个例子，Events 和 Routes 表示两个命名图，默认图用来管理命名图中的元数据。需要指出的是命名图的名字可以作为图的节点，节点和边是可重复的，即不同图中的节点表示同一个实体，在进行图合并的时候可以利用这些节点。 2.1.3 Property graphs当我们对更加复杂的关系进行建模的时候可以引入属性图。比如如果我们的数据中包含了哪些公司提供了哪些航班的票价信息，可以使我们更好的了解城市之间的交通信息。这种情况下，我们就不能直接用： 而是需要添加新的航班节点，如下所示： 但是这样的话，我们就需要对原始的图进行大改。另一种方法就是将不同公司的航班信息用命名图的方式表示出来，但是如果命名图已经被用作他途，这种方式也会变得很麻烦。 属性图简单来说就是，节点和边都可以带标签，如下图所示： 属性图在常见的图数据库中是最常用的，比如 Neo4j。属性图可以在没有任何信息损失的情况下与有向边标记图和图数据集相互转化。 有向边标记图是更小巧的图数据模型； 属性图是更加灵活的图数据模型。 2.1.4 Other graph data models 前面我们介绍了最常见的三种图数据模型，还有一些更加复杂的模型，比如有些复杂节点包含孤立边或者嵌套图等。还有一些复杂边连接的是一个集合而不是节点对。在我们看来，知识图谱可以应用任意的图数据模型：通常情况下数据可以从一个模型转化为另一个模型，比如上面两图所示的例子。 近些年来，最流行的图数据模型就是前面介绍的三种模型，后面我们会详细介绍。 2.2 Querying就像关系型数据库需要 SQL 语言对数据进行检索一样，图数据同样需要检索语言。目前的图数据语言有很多，比如 SPAEQL 用于检索 RDF 数据，Cypher、Gremlin、G-CORE 等语言用于检索属性图。虽然不同语言的具体语法不尽相同，但是却存在一些共通性，包括（基本的）图模式（graph patterns）、关系运算符（relational operators）、路径表达式（path expressions）等等。 2.2.1 graph patterns每一种图数据的结构化查询语言核心都是图模式，它遵循与被查询的图数据相同的模型，另外还支持变量项。因此图数据模式中的术语分成两类：常量和变量。常量如 “Arica”，变量通常使用问号做前缀，比如 “?event”。 上图展示的是变量术语情况的例子。现在我们要查找 Food Festival 的举办地点，图模式通过将变量映射到图数据库中的常量，上图右侧展示可能的映射。 注意上图右表最后两行，同一个 event 对应两个相同的 venue，这种情况在有些应用中是可取的，但是有些情况确实不可取的。因此，为了评估图模式，人们提出一些语义标准，其中最重要的有两个： 基于同态的语义（homomorphism-based semantics），即不同的变量可以映射到相同的常量上。 基于同构的语义（isomorphism based semantics），即要求变量映射的节点或者边必须是唯一项。 不同的查询语言使用不同的语义标准，比如 SPARQL 基于同态语义，而 Cypher 在边上则基于同构语义。 2.2.2 Complex graph patterns图模式是将输入的图转化成表格，如上面的例子所示。因此，我们可以考虑使用关系代数实现这种转化，这样可以形成更复杂的检索。 关系代数由一元操作符和二元操作符组成，一元操作符接收一个输入表，二元操作符接收两个输入表。 一元操作符包括： 映射（$\\pi$）：输出表格的列； 筛选（$\\sigma$）：根据匹配条件输出行； 重命名列（$\\rho$）。 二元操作符包括： 并集（$\\cup$）：合并两个表的行成一个一个表； 差集（$-$）：从第一个表中移除出现在第二个表中的行； 合集（$\\Join$）：将其他表中满足联合条件的行扩充到第一个表中； 筛选和合集条件基本包含：等于（$=$）、小于等于（$\\le$）、非（$\\neg$）、析取（$\\lor$）等。 根据这些操作符，我们可以进一步定义一些操作符： 交集（$\\cap$）：输出两张表； 反合集（$\\rhd$，即不存在）：输出第一个表中不满足与第二个表的联合条件的行； 左联合（$\\lhd$，即可选）：输出合集但是保持第一个表中与第二个表没有冲突的行。 假设 $G(s, p,o)$ 表示一个图，那么上图的检索可以用关系代数表示： \\pi_{ev,vn1,vn2}(\\sigma(\\rho_{s\\rightarrow ev}(G \\Join \\rho_{p \\rightarrow p1, o \\rightarrow vn1}(G) \\Join \\rho_{p \\rightarrow p2, o \\rightarrow vn2}(G)))|\\text{condition})其中 $\\text{conditipon}= [p=\\text{type},o=\\text{Food Festival},p1=p2=\\text{venue}]$。 上图中，我们给出一个例子，其中加粗字体表示我们想要的最终结果，这个检索相当于连词查询。从右表中我们可以看到，前两行的结果是重复的，说明复杂图模式也会给出重复结果。针对这个问题，查询语言提供了两种语义： bag semantic：根据地层映射的多重性来保留副本； set semantic：移除结果中的重复项（DISTINCT）。 另一个例子，查找不在 Santiago 举办的 Food Festival 或者 Drinks Festival，若存在则返回它们的 name 和 start date。这条语句相当于一个一阶查询（first-order queries）。 2.2.3 Navigational graph patterns区分不同图查询语言的一个关键特性是：在查询语句中包含路径表达式的能力。路径表达式就是两个节点之间任意长度的路径。$\\text{query}(x,r,y)$，其中 $x,y$ 表示变量或者常量（甚至可以是相同的项），$r$ 表示路径。基础的路径表达式中 $r$ 是常量（边的标签），如果 $r$ 是一个表达式，那么 $r^-$（反转），$r^\\star$（0-$\\infty$）等等同样也是路径表达式。最后，如果 $r_1$ 和 $r_2$ 都是表达式，那么 $r_1 | r_2$ （析取） ，$r_1\\cdot r_2$（拼接）也是路径表达式。 通常情况下，我们么可以直接在查询语句中使用路径表达式，比如（Arica, bus*, ?city）。但是由于图是可循环的，所以路径也有可能是循环的，这就会造成有无数种路径的可能性。所以，通常只会返回最短路径或者没有重复节点或边的路径。 上图的例子表示，从 Arica 出发通过 bus 或者 flight 能够到达的举办 food festival 的城市。 当查询语句中包含多个路径时，可以使用我们在关系代数中介绍的那些操作符。 2.2.4 Other features到目前为止，我们介绍了一些查询语言的实践或者理论基础。但是在实际生产中，特定的查询语言还支持其他特性，比如聚合（GROUP BY, COUNT 等），更复杂的过滤器、数据类型操作符、远程查询、图数据更新、语义约束机制等等。 2.3 小结 图数据模型：有向边标记图、图数据集、属性图以及复杂图模型等； 图数据查询语言特性：图模式、复杂图模式、可导航图模式以及其他特性。","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://rogerspy.gitee.io/categories/知识图谱/"}],"tags":[{"name":"KG","slug":"kg","permalink":"https://rogerspy.gitee.io/tags/kg/"},{"name":"survey","slug":"survey","permalink":"https://rogerspy.gitee.io/tags/survey/"}]},{"title":"知识图谱：综述（一）前言","slug":"kg-survey-1","date":"2021-05-25T02:37:24.000Z","updated":"2022-02-09T03:51:13.489Z","comments":true,"path":"2021/05/25/kg-survey-1/","link":"","permalink":"https://rogerspy.gitee.io/2021/05/25/kg-survey-1/","excerpt":"目前，知识图谱在学术界和工业界都引起了重视。本人目前也开始负责知识图谱项目，因此从本文开始对知识图谱进行系统性的介绍。首先从综述入手可以使我们对知识图谱有一个整体的概念，然后对其中的每个细节进行深入介绍。本文来自论文《Knowledge Graphs》，是一篇长达 132 页（558篇引用）的综述，可谓干货满满，所以以这篇综述作为切入点。因为内容过长，所以我们将论文的每一章作为一篇博文，一共大概会有十几篇博文。","text":"目前，知识图谱在学术界和工业界都引起了重视。本人目前也开始负责知识图谱项目，因此从本文开始对知识图谱进行系统性的介绍。首先从综述入手可以使我们对知识图谱有一个整体的概念，然后对其中的每个细节进行深入介绍。本文来自论文《Knowledge Graphs》，是一篇长达 132 页（558篇引用）的综述，可谓干货满满，所以以这篇综述作为切入点。因为内容过长，所以我们将论文的每一章作为一篇博文，一共大概会有十几篇博文。 1. 简介尽管“知识图谱”首次出现在文献中是在1972年，但是现代意义上的知识图谱起源于2012年谷歌发布的“谷歌知识图谱”（Google Knowledge Graph），随后更进一步的知识图谱项目如雨后春笋般涌现出来。随着知识图谱在工业界的兴起，学术界也开始重视：越来越多的关于知识图谱的文献和书籍开始出现。 知识图谱的核心就是用图（graph）来表示数据，通常还会用一些明确表示知识的方法加以增强。使用基于图的知识表示方法相比于其他方法有很大的优势，比如关系型数据库或者非关系型数据库： 图可以为各领域提供简洁直观的抽象化概念，其中图的节点用实体表示，边则表示实体与实体之间的内在关系。 图允许维护人员推迟定义schema，允许数据以更灵活的方式发展，特别是在捕获不完整知识方面。（开放世界假设） 特定的图查询语言不仅支持鸟准的关系操作符（join，union，projection 等），还有导航操作符，通过递归查找任意路径长度的实体。 标准的知识表示形式，比如本体和规则，还可以用来进行知识的定义和语义推理。 大规模的图分析框架帮助我们进行各种图计算以获得各领域的新的见解。 各种知识表示技术的发展支持将机器学习技术直接应用于图数据上。 总之，知识图谱打开了一扇从不同数据源集成和抽取知识的大门。但是到目前为止，还没有一个统一的方法来描述知识图谱如何被使用，用到了什么技术，以及它们与现有的数据管理之间有什么联系。本文的目的就是全面介绍知识图谱： 数据模型基础以及如何对数据进行检索； 讨论知识表示方法（schema，identity 和 context） ； 讨论归纳和演绎的方法，使得知识更加明确； 介绍不同的用于创建和增强图结构数据的技术； 介绍知识图谱的质量评估以及如何进行改进； 讨论知识图谱发布的标准以及最佳实践； 提供一些已有的知识图谱项目的梗概。 1.1 知识图谱知识图谱的定义目前仍然存在争议，现有的定义从具体的技术性定义到更具包容性的一般性定义。本文采用如下定义： a knowledge graph as a graph of data intended to accumulate and convey knowledge of the real world, whose nodes represent entities of interest and whose edges represent relations between these entities. 知识图谱是一个数据图旨在积累和表达真实世界的知识，其中图的节点表示实体，边表示实体之间的关系。 知识指的是已知的东西，它可以是从外部源积累的或者抽取出来的，也可以是知识图谱本身提取出来的。知识可以由简单的陈述（simple statements）表示，比如“圣地亚哥是智利的首都”，也可以是量化描述（quantified statements），比如“所有的首都都是城市”。简单描述可以由知识图谱中的边来表示，但是要想实现量化描述就需要借助更加复杂的方法来表示知识，比如本体（ontology）或者规则（rules）。演绎方法可以用来推演更深层次的知识，比如“圣地亚哥是一个城市”。归纳方法可以用来积累和抽取知识。 归纳 其实就是知识图谱的构建； 演绎 其实就是知识图谱的推理。 知识图谱的数据来源通常是不同的，这就造成数据源的结构和粒度的不同。为了解决这些差异，知识模式（schema），知识一致性（identity）和上下文（context）的表示就至关重要。知识模式指的是知识图谱的高级结构，知识一致性指的是同一个知识的不同描述，上下文指的是在某一单元内知识的正确性。如上文所说，知识图谱的构建与优化需要：extraction，enrichment，quality assessment，refinement。 1.2 实践知识图谱是作为一个组织或领域中不断发展的知识共享基础，我们将知识图谱分成两类：开放知识图谱（ open knowledge graphs）和企业知识图谱（enterprise knowledge graphs）。开放知识图谱是发布在网络上，可供公开获取的知识图谱，企业知识图谱指的是面向企业用户的商业化知识图谱。 开放知识图谱 DBpedia, Freebase, Wikidata, YAGO 等。 企业知识图谱 Bing, Google, Airbnb, Amazon, eBay, Uber, Facebook, LinkedIn, Accenture, Banca d’Italia, Bloomberg , Capital One, Wells Fargo 等。 企业知识图谱通常用于搜索，推荐，个人助理，广告，商业分析，风险评估，自动化等方面。 1.3 运行实例为了更清晰的对知识图谱进行介绍，本文采用一个智利旅游相关的知识图谱作为实例进行讲解。这个知识图谱包括旅游景点，文化事件，服务以及商业介绍等内容，应用场景包括： 创建一个门户网站，允许用户搜索景点、即将到来的活动、以及相关服务等（多语言）; 深入了解关于季节、国籍等旅游人口统计数据； 分析游客对各种景点和活动的情感，包括正面的评价、对活动和服务的投诉总结、犯罪报告等; 了解旅游轨迹：游客参观的景点、活动等的顺序； 航班/巴士信息，以建议新的游览路线； 提供个性化的旅游地推荐等等。","categories":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://rogerspy.gitee.io/categories/知识图谱/"}],"tags":[{"name":"KG","slug":"kg","permalink":"https://rogerspy.gitee.io/tags/kg/"},{"name":"survey","slug":"survey","permalink":"https://rogerspy.gitee.io/tags/survey/"}]},{"title":"数据结构与算法：分治算法","slug":"ds-divide-and-conquer","date":"2021-05-22T08:21:41.000Z","updated":"2022-01-12T08:37:38.349Z","comments":true,"path":"2021/05/22/ds-divide-and-conquer/","link":"","permalink":"https://rogerspy.gitee.io/2021/05/22/ds-divide-and-conquer/","excerpt":"分治算法（divide and conquer）是一种解决大问题的策略，通过： 将一个大问题分解成小问题 解决小问题 蒋小问题的解合并在一起得到想要的答案","text":"分治算法（divide and conquer）是一种解决大问题的策略，通过： 将一个大问题分解成小问题 解决小问题 蒋小问题的解合并在一起得到想要的答案 分治思想通常应用在递归函数上。下面我们以一个数组的排序问题进行介绍。 给定一个数组 将数组分解 将子问题继续分解，直到每个分支只有一个元素 对分解后的元素进行排序，然后合并排序结果。这里我们边排序边合并。 时间复杂度 以合并排序算法为例，根据主定理： $T(n)=aT(n/b)+f(n)=2T(n/2)+O(n)$ $a=2$：每次将问题分解成两个子问题； $b=2$：每个子问题的规模是输入数据的一半； $f(n)=n$：分解和合并子问题的复杂度是线性增加的； $\\log_ba=1 \\Rightarrow f(n)=n^1=n$; 由主定理可得：$T(n)=O(n\\log n)$ ReferenceDivide and Conquer Algorithm","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://rogerspy.gitee.io/tags/算法/"},{"name":"divide-conquer","slug":"divide-conquer","permalink":"https://rogerspy.gitee.io/tags/divide-conquer/"}]},{"title":"24种二分类模型的评估方法","slug":"24-binary-class-evaluateion-metrics","date":"2021-04-28T09:06:47.000Z","updated":"2022-01-12T08:37:38.266Z","comments":true,"path":"2021/04/28/24-binary-class-evaluateion-metrics/","link":"","permalink":"https://rogerspy.gitee.io/2021/04/28/24-binary-class-evaluateion-metrics/","excerpt":"评估一个模型的好坏有很多指标，每个指标都有其优缺点。如何针对不同场合选取合适的评估指标是一个非常重要的工作。本文将会介绍一些用于分类模型的评估指标，然后介绍我们该如何选取。","text":"评估一个模型的好坏有很多指标，每个指标都有其优缺点。如何针对不同场合选取合适的评估指标是一个非常重要的工作。本文将会介绍一些用于分类模型的评估指标，然后介绍我们该如何选取。 1. 混淆矩阵（Confusion Matrix）混淆矩阵（混淆表）是一个用来评估分类模型的 $N\\times N$ 矩阵，其中 $N$ 表示类别数量。混淆矩阵通过对比真实的类别标签和模型预测的类别标签从整体上对模型进行评估。 1.1 二分类混淆矩阵对于二分类问题，混淆矩阵是一个 $2 \\times 2$ 的矩阵，如下所示： 目标标签有两个类别：Positive 和 Negative 每一列表示真实的标签类别（actual values） 每一行表示模型预测的标签类别（predicted values） 矩阵中的 TP、TN、FP、FN 分别表示什么呢？ True Positive（TP） 模型预测的标签和真实的标签相同 真实的标签是 Positive，模型预测的标签也是 Positive True Negative（TN） 模型预测的标签与真实的标签相同 真实的标签是 Negative，模型预测的标签也是 Negative False Positive（FP） 模型预测的结果与真实的标签不一致 真实的标签是 Negative，但模型预测的是 Positive 这种错误称之为 “第一类错误”（Type-I error） False Negative（FN） 模型预测的结果与真实的标签不一致 真实的标签是 Positive，但模型预测的是 Negative 这种错误称之为 “第二类错误”（Type-II error） 举例说明：假设有 1000 个样本，分类模型在这些样本上得到了下面这个混淆矩阵： 矩阵中不同的值表示： True Positive (TP) = 560，有 560个 正样本被模型正确预测了； True Negative (TN) = 330，有 330 个负样本被正确预测了； False Positive (FP) = 60，有 60 负样本被模型预测成了正样本； False Negative (FN) = 50，有 50 个正样本被模型预测成了负样本。 从混淆矩阵中可以看出，绝大多数的正样本和负样本可以被模型准确识别出来，说明这是一个还不错的分类模型。 1.2 多分类混淆矩阵有了二分类的混淆矩阵，我们可以把它扩展到多分类问题上。假设有三个类别：A,B,C。那么混淆矩阵应该是一个 $3 \\times 3$ 的矩阵： 对于每个类别的 TP、TN、FP、FN 的计算方式如下： \\begin{equation} \\nonumber \\begin{split} A:\\\\\\\\ & TP=Cell_1 \\\\\\\\ & TN=Cell_5+Cell_6+Cell_8+Cell_9 \\\\\\\\ & FP=Cell_2+Cell_3 \\\\\\\\ & FN=Cell_4+Cell_7 \\\\\\\\ B:\\\\\\\\ & TP=Cell_5 \\\\\\\\ & TN=Cell_1+Cell_3+Cell_7+Cell_9 \\\\\\\\ & FP=Cell_4+Cell_6 \\\\\\\\ & FN=Cell_2+Cell_8 \\\\\\\\ C:\\\\\\\\ & TP=Cell_9 \\\\\\\\ & TN=Cell_1+Cell_2+Cell_4+Cell_5 \\\\\\\\ & FP=Cell_7+Cell_8 \\\\\\\\ & FN=Cell_3+Cell_6 \\\\\\\\ \\end{split} \\end{equation}1.3 用 scikit-learn 计算混淆矩阵12345from sklearn.metrics import confusion_matrixpredict_class = y_pred_pos &gt; thresholdconfusion = metrics.confusion_matrix(true_class, predict_class)print(confusion) 输出的结果如下： 12[[330, 60] [50, 560]] 需要注意的是，scikit-learn 的混淆矩阵(0, 0) 位置是 TN，(1,1) 位置是 TP。 1.4 什么时候用？几乎在所有的分类问题上都可以使用，尤其是在了解具体数量而非归一化的比例的时候（通常是类别不平衡）。 2. 准确率（Accuracy）2.1 准确率定义准确率评估的是模型对样本正确分类的比例，计算方法如下： \\mathrm{accuracy}=\\frac{TP+TN}{TP+TN+FP+FN}2.2 用 scikit-learn 计算准确率12345678from sklearn.metrics import confusion_matrix, accuracy_score y_pred_class = y_pred_pos &gt; threshold tn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel() accuracy = (tp + tn) / (tp + fp + fn + tn) # or simply accuracy_score(y_true, y_pred_class) 2.3 准确率与阈值的关系 分类任务中，模型输出的是每个类别对应的概率。比如二分类，当正类别概率大于 50% 的时候，我们认为该样本是正样本，其中 50% 就是分类的阈值。阈值是可以人为设定的，比如可以规定当概率大于 70% 的时候才认为是正样本。 对于二分类模型，通常选择 0.5 作为阈值。阈值过大会造成 FN 过大，从而降低准确率。阈值太小会造成 FP 多大，同样会造成准确率过低。 2.4 什么时候用？ 各类别比较平衡 每个类别对我们来说同等重要 2.5 什么时候不能用？考虑一个场景：假设每 100 个人中就有 1 个人生病了，我们用一个分类模型对生病的人和没有生病的人进行分类。即使模型所有的输出都是没有生病那准确率也有 99%，但是这个模型却是很糟糕的一个模型。 仔细观察一下上面的数据分布，很容易发现问题：数据类别不平衡。也就是说，在类别不平衡的数据上评估分类模型的好坏是不可以使用准确率的。 3. 精准度（Precision）3.1 精准度定义精准度表示在模型预测为正样本的数据中，有多少是真正的正样本。比如用渔网捞鱼，这一网捞上来的有鱼有虾，其中是鱼的比例就是精准度。计算公式如下： \\mathrm{Precision} = \\frac{TP}{TP+FP}3.2 用 scikit-learn 计算精准度12345678from sklearn.metrics import confusion_matrix, precision_scorey_pred_class = y_pred_pos &gt; thresholdtn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()positive_predictive_value = tp/ (tp + fp)# or simplyprecision_score(y_true, y_pred_class) 3.3 精准度与阈值的关系 从这个解释中我们可以看出，阈值越高说明概率越大。从直觉上可以判断，概率越大说明可信度越高。那么样本被正确分类的可能性就越高。回到精准度的角度，精准度表示真正的正样本比例。如果阈值设定较高的话，正样本分类的正确率也会越高，精准度也会越高。极端情况下，把阈值设定成 100%，精准度也会达到最大。 3.4 什么时候用？ 单独使用精准度没有什么意义，通常会配合其他指标一起使用 当错误警报成本过高，或者当你认为每个预测为正样本的样例都值得一看的时候，可以针对精准度进行调整 4. 召回率（Recall）4.1 召回率定义召回率又叫真阳性率，表示有多少是真正的正样本被模型正确识别出来了。我们经常会听到某某产品出现了质量问题，厂家紧急召回的新闻。召回率就是说，市面上所有的问题产品，厂家召回了多少。另外一个例子，目前新冠肆虐，新冠的检测是通过咽拭子。召回率表示，通过咽拭子找到了多少新冠患者。 通过这两个例子我们可以对准确率，精确度和召回率加以区分。准确率关注的是所有类别的分类正确率，精确度是正样本的准确率，而召回率表示找到的正样本占总正样本的比例。 用公式表示如下： \\mathrm{recall} = \\frac{TP}{TP+FN}4.2 用 scikit-learn 计算召回率123456789from sklearn.metrics import confusion_matrix, recall_scorey_pred_class = y_pred_pos &gt; thresholdtn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()true_positive_rate = tp / (tp + fn)# or simplyrecall_score(y_true, y_pred_class) 4.3 召回率与阈值的关系 阈值设定越低，模型预测为正样本的门槛就越低，就越容易把所有的正样本找出来。所以召回率与阈值是一个负相关的关系。 4.4 什么时候用？ 单独使用召回率没有什么意义，通常会配合其他指标一起使用 但是有些情况，比如灾难预警、欺诈性交易等，即使收到一些错误预警，我们也必须谨慎对待。即在宁可信其有不可信其无的场景下，适当调整召回率是有必要的 5. F1 得分（F1-score）5.1 F1 得分定义通常情况下，我们想提高精准度就需要牺牲召回率，要想提高召回率就要牺牲精准度。从之前介绍的精准度、召回率和阈值的关系中我们就可以看出一些端倪。当然，一个理想的分类模型是精准度和召回率都可以达到很高，但是实际上却是比较困难。 为了综合评估精准度和召回率，我们可以使用 F1 得分： F1 = \\frac{1}{\\frac{1}{\\mathrm{Recall}}+\\frac{1}{\\mathrm{Precision}}} = \\frac{2\\times \\mathrm{Precision} \\times \\mathrm{Recall}}{\\mathrm{Precision}+\\mathrm{Recall}}从定义上看，我们可以认为 F1 得分是精准度和召回率的一个平均。 5.2 用 scikit-learn 计算 F1得分1234from sklearn.metrics import f1_scorey_pred_class = y_pred_pos &gt; thresholdf1_score(y_true, y_pred_class) 在实际情况中，精准度、召回率和 F1 得分都不会单独使用，而是综合一起来评估模型的好坏： 1234from sklearn.metrics import classification_reporty_pred_class = y_pred_pos &gt; thresholdclassification_report(y_true, y_pred_class) 我们会得到一个类似如下的结果： 12345678 precision recall f1-score support 1 1.00 0.67 0.80 3 2 0.00 0.00 0.00 0 micro avg 1.00 0.67 0.80 3 macro avg 0.33 0.22 0.27 3weighted avg 1.00 0.67 0.80 3 其中 support 是参与评估的总样本数，1,2,3 分别是类别标签。mirco avg，marco avg 和 weighted avg 的计算方式分别如下： micro avg: \\begin{equation}\\nonumber \\begin{split} \\mathrm{micro\\ avg\\ Precision} &= \\frac{TP1+TP2}{TP1+TP2+FP1+FP2} = \\frac{\\sum TP_i}{\\sum(TP_i+FP_i)} \\\\\\\\ \\mathrm{micro\\ avg\\ Recall} &= \\frac{TP1+TP2}{TP1+TP2+FN1+FN2} = \\frac{\\sum TP_i}{\\sum(TP_i+FN_i)} \\\\\\\\ \\mathrm{micro\\ avg\\ F1} &= \\frac{2\\times \\mathrm{micro\\ avg\\ Precision} \\times \\mathrm{micro\\ avg\\ Recall}}{\\mathrm{micro\\ avg\\ Precision} + \\mathrm{micro\\ avg\\ Recall}} \\end{split} \\end{equation}macro avg: \\begin{equation}\\nonumber \\begin{split} \\mathrm{macro\\ avg\\ Precision} &= \\frac{1}{n} \\sum \\mathrm{Precision}_i \\\\\\\\ \\mathrm{macro\\ avg\\ Recall} &= \\frac{1}{n} \\sum \\mathrm{Recall}_i \\\\\\\\ \\mathrm{macro\\ avg\\ F1} &= \\frac{1}{n} \\sum \\mathrm{F1}_i \\end{split} \\end{equation}weighted avg: 假设类别 1 有 4 个，类别 2 有 10 个。 \\begin{equation}\\nonumber \\begin{split} \\mathrm{weighted\\ avg\\ Precision} &= \\frac{4 \\times \\mathrm{Precision}_{1}+10 \\times \\mathrm{Precision}_{2}}{14} &= \\frac{\\sum(n_i\\times \\mathrm{Precision}_{i})}{\\sum n_i} \\\\\\\\ \\mathrm{weighted\\ avg\\ Recall} &= \\frac{4 \\times \\mathrm{Recall}_{1}+10 \\times \\mathrm{Recall}_{2}}{14} &= \\frac{\\sum(n_i\\times \\mathrm{Recall}_{i})}{\\sum n_i} \\\\\\\\ \\mathrm{weighted\\ avg\\ F1} &= \\frac{4 \\times F1_{1}+10 \\times F1_{2}}{14} &= \\frac{\\sum(n_i\\times F1_{i})}{\\sum n_i} \\end{split} \\end{equation}5.3 F1 得分与阈值的关系 精准度与阈值的关系是正相关，召回率与阈值的关系是负相关，F1 是精准度和召回率的综合平均值，所以当阈值过大或过小的时候都会对 F1 造成损失，所以要保证较高的 F1 得分，阈值必须在一个合理的范围内。 5.4 什么时候用？ F1 得分是常规分类问题的首选评估指标，但是通常也会配合准确率，精准度和召回率 6. F2 得分（F2-score）6.1 F2 得分定义F2 得分表示精准度和召回率的综合评价，与 F1 不同的是，F2 着重强调召回率： F2 = \\frac{5 \\times \\mathrm{Precision}\\times \\mathrm{Recall}}{4\\times \\mathrm{Precision+Recall}}6.2 用 scikit-learn 计算 F2 得分1234from sklearn.metrics import fbeta_scorey_pred_class = y_pred_pos &gt; thresholdfbeta_score(y_true, y_pred_class, 2) 6.3 F2 得分与阈值的关系 由于 F2 得分更强调召回率的作用，所以 F2 的性质也与召回率的性质相似，随着阈值的提高 F2 得分会有一个库快速的上升，然后短暂达到平衡，然后随着阈值的升高 F2 得分逐渐下降。 6.4 什么时候用？ 在注重召回率的场景下都可以使用 7. F-beta 得分（F-beta score）7.1 F-beta 定义既然有 F1 得分，有 F2 得分，那么我顶定义一个 $\\beta$ ，当 $\\beta=1$ 时，即为 F1 得分，当 $\\beta=2$ 时，即为 F2 得分。计算方法如下： F_{beta} = (1+\\beta^2)\\frac{\\mathrm{Precision}\\times \\mathrm{Recall}}{\\beta^2 \\times \\mathrm{Precision}+\\mathrm{Recall}}我肯可以通过调整 $\\beta$ 值来确定召回率在我们的评估指标中占有的比重。 7.2 用 scikit-learn 计算 F-beta 得分在上面计算 F2 得分的时候，我们就可以发现，用到了 fbeta_score 函数： 1234from sklearn.metrics import fbeta_scorey_pred_class = y_pred_pos &gt; thresholdfbeta_score(y_true, y_pred_class, beta) 7.3 F-beta 得分与阈值的关系 上图展示了不同 $\\beta$ 值时， F-beta 与阈值的关系。 8. 假阳性率（Type-I error）8.1 假阳性率定义假阳性率表示，我们预测的某事但没有发生。因此，假阳性率又可以叫做误报率。比如，本来没有大雨，但是天气预报却预报说有雨，说明天气预报误报了。我们可以将其视为模型发出的错误报警。 FPR = \\frac{\\mathrm{FP}}{FP+TN}8.2 用 scikit-learn 计算假阳性率12345from sklearn.metrics import confusion_matrixy_pred_class = y_pred_pos &gt; thresholdtn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()false_positive_rate = fp / (fp + tn) 8.3 假阳性率与阈值的关系通常一个好的模型假阳性率都比较低，但是我们还可以通过调节阈值来进一步降低假阳性率。因为在分母中包含真负样本（$TN$），当我们的数据不平衡时，假阳性率通常会很低。 显然，随着阈值的增大，假阳性率在降低。 8.4 什么时候用？ 很少单独使用假阳性率，通常是和其他指标一起使用； 如果误报会导致较严重的后果，可以通过调节阈值来降低。 9. 假阴性率（Type-II error）9.1 假阴性率定义假阴性率表示，当我们没有预测的事情却发生了。因此，假阴性率又可以叫做漏报率。比如，本来有一场大雨，但是天气预报没有预报，说明天气预报对这次大雨漏报了。 FNR = \\frac{FN}{TP+FN}9.2 用 scikit-learn 计算假阴性率12345from sklearn.metrics import confusion_matrixy_pred_class = y_pred_pos &gt; thresholdtn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()false_negative_rate = fn / (tp + fn) 9.3 假阴性率与阈值的关系 当我们提高阈值的时候，假阴性率也会随之升高。 9.4 什么时候用？ 通常与其他指标一起使用； 如果漏报的代价比较大的时候，就需要关注这个指标了。 10. 真阴性率（True negative rate）10.1 真阴性率定义真阴性率表示，在所有的负样本中有多少负样本被检测出来。 TNR = \\frac{TN}{TN+FP}10.2 用 scikit-learn 计算真阴性率12345from sklearn.metrics import confusion_matrixy_pred_class = y_pred_pos &gt; thresholdtn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()true_negative_rate = tn / (tn + fp) 10.3 真阴性率与阈值的关系 阈值越高，真阴性率越高。 10.4 什么时候用？ 通常与其他指标一起用； 当你确实希望确保你所说的每一句都是正确的时候，可以考虑该指标。比如，当一个医生对病人说 “你很健康” 的时候。 11. 负样本预测值（Negative Predictive Value）11.1 负样本预测值定义负样本预测值表示，模型预测的负样本有多少是真正的负样本，我们可以认为它是负类别的准确率。 NPV = \\frac{TN}{TN+FN}11.2 用 scikit-learn 计算负样本预测值12345from sklearn.metrics import confusion_matrixy_pred_class = y_pred_pos &gt; thresholdtn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()negative_predictive_value = tn/ (tn + fn) 11.3 负样本预测值与阈值的关系 阈值越高就会有越多的样本被预测为负样本，被误分类成负样本的几率就越高。但是对于非平衡数据集来说，一个较高的阈值通常负样本预测值表现也还不错。 11.4 什么时候用？ 当我们更加关注负样本的预测准确率时，可以考虑使用这一评估指标。 12. 假发现率（False Discovery Rate）12.1 假发现率定义假发现率表示，所有预测为正样本的数据中有多少是真正的正样本。 FDR = \\frac{TP}{TP+FP}12.2 用 scikit-learn 计算假发现率12345from sklearn.metrics import confusion_matrixy_pred_class = y_pred_pos &gt; thresholdtn, fp, fn, tp = confusion_matrix(y_true, y_pred_class).ravel()false_discovery_rate = fp/ (tp + fp) 12.3 假发现率与阈值的关系 阈值越高，假发现率越低。 12.4 什么时候用？ 通常和其他指标一起使用； 如果误报的代价过高，或者当你希望所有预测为正样本的数据都值得一看的时候，可以考虑该指标。 13. Cohen Kappa Metric13.1 Cohen Kappa 定义简单来说，Cohen Kappa 指的是你的模型比一个随机分类器好多少。 \\kappa = \\frac{p_0-p_e}{1-p_e} $p_0$ 表示模型预测结果，通常为准确率； $p_e$ 表示随机预测结果，通常为随机模型的准确率。 13.2 用 scikit-learn 计算 Cohen Kappa123from sklearn.metrics import cohen_kappa_scorecohen_kappa_score(y_true, y_pred_class) 13.3 Cohen Kappa 与阈值的关系 13.4 什么时候用？ Cohen Kappa 通常不会用在一般的文本分类上，而是在非平衡数据的分类模型上。 14. Matthews Correlation Coefficient （MCC）$MCC$ 表示真实标签和预测标签的相关性。 14.1 MCC 定义 MCC = \\frac{TP\\times TN-FP\\times FN}{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}14.2 scikit-learn 计算 MCC1234from sklearn.metrics import matthews_corrcoefy_pred_class = y_pred_pos &gt; thresholdmatthews_corrcoef(y_true, y_pred_class) 14.3 MCC 与阈值的关系 14.4 什么时候用？ 不平衡数据集 希望预测结果有更强的可解释性的 15. ROC 曲线ROC 曲线是一个图表，用于展示真阳性率（$TPR$）和假阳性率（$FPR$）之间的权衡。基本上，对于每个阈值，我们计算 $TPR$ 和 $FPR$ 并将其绘制在一张图表上。它代表的是分类器以多大的置信度将样本分类为正样本。 可以在 Tom Fawcett 的这篇文章中找到对 ROC 曲线和 ROC AUC 分数的广泛详细的讨论。 15.1 用 scikit-learn 计算 ROC1234from scikitplot.metrics import plot_rocfig, ax = plt.subplots()plot_roc(y_true, y_pred, ax=ax) 15.2 曲线图是什么样的？ 每个不同的阈值对应曲线上不同的点（即不同的混淆矩阵）。对于每个阈值，较高的 $TPR$ 和较低的 $FPR$ 越好，因此具有更多左上角曲线的分类器更好。从上图可以看出，在大约（0.15， 0.85）左右的位置（左上角黑色实线和黑色虚线焦点）二者取得平衡。因此该位置对应的阈值应该是最佳的分类阈值。 16. ROC-AUC 得分为了从 ROC 曲线上得到一个量化的指标，我们可以计算 ROC-AUC（Area Under the ROC Curve） 得分。 16.1 用 scikit-learn 计算 ROC-AUC123from sklearn.metrics import roc_auc_scoreroc_auc = roc_auc_score(y_true, y_pred_pos) 16.2 什么时候用？ 当你非常关心排序预测的时候，应该使用 ROC-AUC 得分而没有必要关注概率修正。 当你的数据严重不平衡的时候，不应该使用 ROC-AUC 作为评估指标。直观上来讲，当数据严重类别不平衡的时候， $FPR$ 会被严重拉低，因为大量的数据是 True Negative 的。 当正负样本的类别平衡的时候，可以使用 ROC-AUC 作为评估指标。 17. Precision-Recall CurvePRC 是一条融合了精准度和召回率的可视化曲线。对于每个阈值，计算相应的精准度和召回率，然后画在图上即可。Y 轴对应的值越高，则模型表现越好。 17.1 用 scikit-learn 计算 PRC1234from scikitplot.metrics import plot_precision_recallfig, ax = plt.subplots()plot_precision_recall(y_true, y_pred, ax=ax) 17.2 曲线长什么样？ 18. PR AUC 得分 | 平均精准度与 ROC-AUC 类似，我们也可以计算 Area Under the Precision-Recall Curve 以获得评估模型的量化指标。 18.1 用 sickit-learn计算 PR AUC123from sklearn.metrics import average_precision_scoreaverage_precision_score(y_true, y_pred_pos) 18.2 什么时候用？ 当你要在精准度和召回率之间做取舍的时候 当你要选择一个合适的阈值符合实际情况的时候 当你的数据严重不平衡的时候。就像之前讨论的那样，由于 PR AUC 主要关注点是正样本的类别，很少关注到负样本。所以在类别严重不平衡的时候可以使用 PR AUC 作为模型的评估指标。 当你更关注正样本而非负样本的时候，可以使用 PR AUC 作为模型的评估指标。 19. Log loss对数损失函数经常用来优化机器学习模型的参数。然后实际上它也可以作为模型的评估指标。 19.1 定义对数损失对数损失用来计算真实标签与预测标签之间的差别： \\mathrm{Logloss} = -(y_{\\mathrm{true}}\\times\\log(y_{\\mathrm{pred}})) + (1-y_{\\mathrm{true}})\\times\\log(1-y_{\\mathrm{pred}})观测到的正样本置信度越高，那么它与真实的正样本之间的差距就越小。但是这并不是一个线性关系，真实的关系如下图： 19.2 用 scikit-learn 计算对数损失123from sklearn.metrics import log_losslog_loss(y_true, y_pred) 19.3 什么时候用？ 几乎总是有一个性能指标可以更好地匹配我们的业务问题。 因此，我们可以使用对数损失作为模型的目标，并使用其他一些指标来评估性能。 20. Brier 得分20.1 Brier 得分定义 \\mathrm{Brierloss} = (y_{\\mathrm{pred}}-y_{\\mathrm{true}})^220.2 用 scikit-learn 计算 Brier 得分123from sklearn.metrics import brier_score_lossbrier_score_loss(y_true, y_pred_pos) 20.3 什么时候用？ 当你关心修正概率的时候 21. 累积收益表21.1 定义累积收益表简单来说，累积收益表（Cumulative gains chart）可以帮助我们判断使用当前模型的收益超过一个随机模型多少。 先对预测结果从高到低进行排序 对于每个百分数，我们计算大于这个百分数的真阳性样本比例。 21.2 用 scikit-learn 计算 CGC1234from scikitplot.metrics import plot_cumulative_gainfig, ax = plt.subplots()plot_cumulative_gain(y_true, y_pred, ax=ax) 21.3 CGC 看起来是什么样的？ 21.4 什么时候用？ 当你想选择最有希望与你进行交易的客户的时候，可以使用 CGC 作为评估指标。 它可以作为 ROC-AUC 指标的一个很好的额外补充。 22. Lift curve | lift chart22.1 定义 lift curveLift curve 基本上只是 CGC 的另一种表示形式： 首先对预测结果由高到低进行排序； 对于每个预测值，计算训练好的模型和随机模型达到该百分比概率的真阳性比例 计算上述比例，然后画图 它能告诉我们对于给定最大预测值，它比一个随机模型好多少。 22.2 用 scikit-learn 计算 lift curve123from scikitplot.metrics import plot_lift_curve fig, ax = plt.subplots() plot_lift_curve(y_true, y_pred, ax=ax) 22.3 什么时候用？ 当你想选择最有希望与你进行交易的客户的时候，可以使用 CGC 作为评估指标。 它可以作为 ROC-AUC 指标的一个很好的额外补充。 23. Kolmogorov-Smirnov plot23.1 定义 KS plotKS plot 帮助我们从预测结果中获得独立的正样本分布和负样本分布。 根据预测得分进行排序 对 [0.0, 1.0] 之间的每个截点计算相邻截点（depth）之间的数据中的真阳性和真阴性比例 画出计算出来的比例，y 轴表示 $positive(depth)/positive(all)$，$negative(depth)/negative(all)$，x 轴表示 depth KS plot有点类似于 CGC，但是CGC 只关注正样本，而 KS plot同时关注正负样本。 23.2 用 scikit-learn 计算 KS plot1234from scikitplot.metrics import plot_ks_statisticfig, ax = plt.subplots()plot_ks_statistic(y_true, y_pred, ax=ax) 24. Kolmogorov-Smirnov statistic24.1 定义 KS statistic如果我们想从 KS plot 中选择一个值作为指标，那么我们可以查看所有 KS plot 中所有阈值，然后找到正负样本分布距离最远的点。 如果有一个阈值，所有观测到的上方样本都是真阳性，而所有下方的样本都是真阴性，那么我们就找到了一个完美的 KS statistic 值：1.0 24.2 用 scikit-learn 计算 KS statistic1234from scikitplot.helpers import binary_ks_curveres = binary_ks_curve(y_true, y_pred_pos)ks_stat = res[3] 24.3 什么时候用？ 当你面对的是排序问题且你对正负样本都很关心的时候 可以作为 ROC-AUC 的补充指标 参考资料 24 Evaluation Metrics for Binary Classification (And When to Use Them) Everything you Should Know about Confusion Matrix for Machine Learning","categories":[{"name":"博客转载","slug":"博客转载","permalink":"https://rogerspy.gitee.io/categories/博客转载/"}],"tags":[{"name":"评估方法","slug":"评估方法","permalink":"https://rogerspy.gitee.io/tags/评估方法/"}]},{"title":"数据结构与算法：时间复杂度","slug":"ds-time-complexity","date":"2021-04-22T05:20:39.000Z","updated":"2022-01-12T08:37:38.372Z","comments":true,"path":"2021/04/22/ds-time-complexity/","link":"","permalink":"https://rogerspy.gitee.io/2021/04/22/ds-time-complexity/","excerpt":"就像做菜有好吃和不好吃一样，算法也有好的算法和不好的算法。那么我们怎么评价一个算法的好坏呢？ 1. 时间复杂度时间复杂度是用来估算算法需要执行的时间的。但是我们并不是直接用时间来估计，而是用一个函数。 时间复杂度不是算法需要执行多久，而是算法需要执行多少步。","text":"就像做菜有好吃和不好吃一样，算法也有好的算法和不好的算法。那么我们怎么评价一个算法的好坏呢？ 1. 时间复杂度时间复杂度是用来估算算法需要执行的时间的。但是我们并不是直接用时间来估计，而是用一个函数。 时间复杂度不是算法需要执行多久，而是算法需要执行多少步。 这种评估方法看起来很奇怪，为什么不直接用时间来评估呢？很显然，一个需要 10 秒的的算法肯定是不如只需要 1 秒的算法啊。事实并非如此，比如同一个排序算法，对 100 个元素进行排序和对 1000 个元素进行排序所用时间肯定是不同的，能说算法变坏了吗？算法运算的时间依赖于输入参数的大小。 如果一个排序算法的输入本来就已经排好了序，那么它的运算时间肯定要比乱序输入更快。即使输入参数大小相同，算法的运算时间也会有差异。 另外，CPU 运算波动，磁盘读写效率等等都会影响算法的运算时间。 所以，即使是同一个算法，它的运算时间也会有： 最长运算时间 最短运算时间 平均运算时间 而我们通常关心的是一个算法的最长运算时间（抱最好的希望，做最坏的打算）。所以我们对算法性能的分析要包含两方面的考虑： 忽略掉依赖于机器的因素； 关注运行时间的增长，而不是去检查真正的运行时间. 1.1 计算时间复杂度举个例子：找到一个数组中的最小数字。 1234567第一步：开始第二步：声明变量 min第三步：从输入数组中循环取值 3.1 对比从数组中取到的值 n 和 min 的大小 3.2 如果 n &lt; min 3.3 令 min = n第四步：返回 min 的值 假设 cpu 的运算是平稳没有波动的，每一步所需的时间相同。我们来看下上面的过程： 第一步：1 个操作； 第二步：1 个操作 第三步：这一步需要执行 $m$ （数组中有 $m$ 个元素）次，假设每一小步是 1 个操作，每一次循环就需要 4 个操作，那么这个循环就相当于需要 $4m$ 个操作 第四步： 1 个操作 总共需要 $4m+3$ 个操作。但是这个表达式太过于具体了，不能对比不同的算法。我们需要进一步简化时间复杂度的计算。 1.2 渐进分析1.2.1 符号表示为了更方便表示时间复杂度，我们使用渐进符号来表示。主要有三种符号： $O$ 符号：表示算法运算的上限，即表现最差的运算时间。 O(g(n)) = \\{f(n) ~|~ \\exists c>0, ~ n \\ge n_0,~ 0\\le f(n)\\le cg(n) \\}$O(g(n))$ 是函数 $f(n)$ 的集合。$f(n)$ 满足以下条件：存在一个正实数 $c$，使得当 $n$ 足够大时（大于一个阈值 $n_0$） ，所有的 $f(n)$ 都小于 $cg(n)$。 $\\Omega$ 符号：表示算法运算下限，即表现最好的运算时间。 \\Omega(g(n)) = \\{f(n)~ \\vert ~ \\exists c>0,~ n\\ge n_0,~ 0 \\le f(n) \\le cg(n) \\}$\\Omega(g(n))$ 是函数 $f(n)$ 的集合。$f(n)$ 满足以下条件：存在一个正实数 $c$，使得当 $n$ 足够大时（大于一个阈值 $n_0$），所有的 $f(n)$ 都大于 $cg(n)$。 $\\Theta$ 符号：表示算法运算时间的平均水平，即平均运算时间。 \\Theta(g(n)) = \\{f(n)~ \\vert ~ \\exists c_1,c_2>0,~ n \\gt n_0,~ 0 \\le c_1g(n) \\le f(n) \\le c_2g(n)\\}$\\Theta(g(n))$ 是函数 $f(n)$ 的集合。$f(n)$ 满足以下条件：存在正实数 $c_1,c_2$，使得当 $n$ 足够大时（大于一个阈值 $n_0$），所有的 $f(n)$ 都介于 $c_1g(n)$ 和 $c_2g(n)$ 之间。 1.2.2 渐进分析渐进分析遵循三个原则： 分析最坏的情况，即 $O(g(n))$。 不关心系数和低阶项。从上面我们对 $O(g(n))$ 的定义可以看出，系数相当于 $c$，而我们关心的是 $g(n)$。如前所说，对时间复杂度的分析更关注的是运行时间的增长。当 $n$ 足够大的时候，低阶项对运行时间的增长影响力越来越低，所以也不是我们关心的点。 分析当 $n$ 足够大的时候的运行时间。 渐进分析是将时间复杂度函数做无穷近似。比如上面的例子中 $4m+3$ 可以泛化成 $km+c$。忽略掉系数 $k$ 和低阶项 $c$，所以上面的算法时间复杂度为 $O(m)$。 $O$ 表示方程的阶（order）。常见的时间复杂度及其对比： $n$ $O(1)$ $O(\\log n)$ $O(n)$ $O(n \\log n)$ $O(n^2)$ $O(2^n)$ 1 &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec 10 &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec 100 &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec 40170 trillion years 1,000 &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec &gt; vigintillion years 10,000 &lt; 1 sec &lt; 1 sec &lt; 1 sec &lt; 1 sec 2 min &gt; centillion years 100,000 &lt; 1 sec &lt; 1 sec &lt; 1 sec 1 sec 3 hours &gt; centillion years 1,000,000 &lt; 1 sec &lt; 1 sec 1 sec 20 sec 12 days &gt; centillion years 1.3 非递归算法非递归算法时间复杂度计算步骤如下： 找到问题的输入数据规模，比如 2.1 节中的 $m$； 找出算法的基本操作，比如 2.1 节中的循环操作； 建立算法中涉及到的操作数求和表达式； 利用 $O$ 准则进行简化。 具体例子可以看 2.1 节的例子。 1.4 递归算法递归算法的时间复杂度有两种方法进行计算： 迭代法：每次运算只是将数据规模减一，比如斐波那契数列； 主定理：利用分治的思想，将问题拆解成几份，分别求解。 1.4.1 迭代法以斐波那契数列为例： 1234第一步：定义函数 fab(n)第二步：判断 n 是否为 0第三步：如果 n == 0，返回 1第四步：如果 n != 0, 返回 fab(n-1) * n 假设 fab(n) 需要执行 $C(n)$ 次，$C(n)$ 的计算公式为： C(n) = C(n-1)+1$C(n-1)$ 为 fab(n-1) 的运算次数，当 $n=0$ 时，fab(0) 直接返回值，所以只需要运算 1 次，即 $C(0)=1$。 \\begin{equation} \\nonumber \\begin{aligned} C(n) &= C(n-1)+1\\\\\\\\ &= [C(n-2)+1]+1\\\\\\\\ &= [C(n-3)+1]+2\\\\\\\\ & \\dots \\\\\\\\ &= C(n-i)+i \\\\\\\\ & \\dots \\\\\\\\ &= C(n-n)+n \\\\\\\\ &= n \\end{aligned} \\end{equation}所以这个算法的时间复杂度为 $O(n)$。 1.4.2 主定理当我们使用分治思想求解递归问题的时候，就可以用“主定理”（master theorem）的方法来计算时间复杂度。具体来说，当递归函数的时间复杂度计算公式满足： T(n)=aT(\\frac{n}{b})+f(n)其中： $n$：输入数据规模 $a$：将递归问题分解成子问题的个数 $n/b$：每个子问题的规模， $f(n)$：递归操作之外所需要的操作次数，包括问题分解和结果合并 $a$ 和 $b$ 是大于 $0$ 的常数，$f(n)$ 是渐进函数，即当 $n \\to \\infty$ 时 $f(n)&gt;0$。 上面的公式可以理解为：对于一个规模为 $n$ 的问题，我们把它分解成 $a$ 个子问题，每个子问题规模为 $n/b$ 指的是 $\\lfloor{n/b}\\rfloor$ 或者 $\\lceil{n/b}\\rceil$（$\\lfloor \\cdot \\rfloor$ 表示是向下取整，$\\lceil \\cdot\\rceil$ 表示向上取整），然后将问题的解通过 $f(n)$次操作整合到一起。 首先构建一棵递归任务分解树，观察每一层的变化： 第一层： 子问题的数目：$a^0$ 每个子问题的规模：$\\frac{n}{b^0}$ 合并子问题需要花费的操作次数：$f(n)$ 第二层： 子问题的数目：$a^1$ 每个子问题的规模：$\\frac{n}{b^1}$ 合并子问题需要花费的操作次数：$af(n/b)$ 第三层： 子问题的数目：$a^2$ 每个子问题的规模：$\\frac{n}{b^2}$ 合并子问题需要花费的操作次数：$a^2f(n/b^2)$ … 最后一层： 子问题的数目：$a^2$ 每个子问题的规模：$\\frac{n}{b^h}$ 合并子问题需要花费的操作次数：$a^hf(n/b^h)$ • NOTE 第一层，“合并子问题需要花费的操作次数”，实际上指的是要解决一个和原问题等规模的问题所需要的操作次数。因为第一层还没有对问题进行分解，也就谈不上合并子问题，上面的说法只是为了和下面保持一致。 树的高度 $h$ 对于分治递归方法，最后一层的每个子问题规模为 1，即 $\\frac{n}{b^h}=1$，由此可得 h = \\log_b n 叶子结点个数 叶子结点的个数即为最后一层子问题的数目 $a^h$。由上一步 $h = \\log_b n$ 可得，叶子结点的个数为 $a^{\\log_b n}$。根据换底公式 $x^{\\log_ny}=y^{\\log_nx}$ 可以将上式改写成 $n^{\\log_ba}$。注意每个子问题的划分都是 $n/b$ 的均匀划分，所以时间复杂度也应该用 $\\Theta$ 表示，即 \\Theta(n^{\\log_ba}) 合并子问题需要花费的操作次数总和 根据我们对每层递归树的分析可以发现，每层合并子问题需要的操作次数为 $a^if\\Big(\\frac{n}{b^i}\\Big)$，只需要将每层次数相加即可得到总次数： \\sum_{i=0}^{\\log_bn-1}a^if\\Big(\\frac{n}{b^i}\\Big) 有了递归操作总次数和分解合并操作总次数以后，根据递归函数时间复杂度公式可得 \\begin{equation} \\nonumber \\begin{aligned} T(n) &= aT(\\frac{n}{b})+f(n) \\\\\\\\ &= \\Theta(n^{\\log_ba})+\\sum_{i=0}^{\\log_bn-1}a^if\\Big(\\frac{n}{b^i}\\Big) \\\\\\\\ &= \\Theta(n^{\\log_ba})+g(n) \\end{aligned} \\end{equation}从中我们可以看出，整个递归的时间复杂度取决于 $f(n)$，分三种情况讨论： 如果右边第一项的阶数比第二项高， $T(n)$ 主要由第一项决定，这意味着递归树的时间主要消耗在子问题的递归上。根据时间复杂度分析“忽略低阶项”的原则： T(n) = \\Theta(n^{\\log_ba}) 如果右边第二项的阶数比第一项高， $T(n)$ 主要由第二项决定，这意味着递归树的时间主要消耗在对问题的分解和解的合并上，根据时间复杂度分析“忽略低阶项”的原则： T(n) = \\Theta(f(n)) 如果两部分的阶数相等，意味着递归树的总时间分布是均匀的，由两部分共同决定： T(n)=\\Theta(n^{\\log_b a} \\cdot \\log n) 1.4.3 主定理证明为了方便写证明过程，将以上三种情况用数学语言进行描述： $\\exists \\epsilon&gt;0 s.t. f(n)=O(n^{\\log_ba-\\epsilon})$，则 $T(n)=\\Theta(n^{\\log_ba})$。 证明： \\begin{equation} \\nonumber \\begin{aligned} f(n) &= O(n^{(\\log_ba)-\\epsilon}) \\\\\\\\ \\Rightarrow f(\\frac{n}{b^i}) &= O((\\frac{n}{b^i})^{(\\log_ba)-\\epsilon}) \\\\\\\\ &\\le c(\\frac{n}{b^i})^{(\\log_ba)-\\epsilon} \\\\\\\\ \\Rightarrow a^if(\\frac{n}{b^i}) &\\le c a^i(\\frac{n}{b^i})^{(\\log_ba)-\\epsilon} \\\\\\\\ &= cn^{(\\log_ba)-\\epsilon} \\cdot (\\frac{a}{b^{(\\log_ba)-\\epsilon}})^i\\\\\\\\ &= cn^{(\\log_ba)-\\epsilon} \\cdot (\\frac{a}{a^{(\\log_bb)}\\cdot b^ {-\\epsilon}})^i\\\\\\\\ &= cn^{(\\log_ba)-\\epsilon} \\cdot (b^\\epsilon)^i \\\\\\\\ \\Rightarrow \\sum_{i=0}^{\\log_bn-1}a^if\\Big(\\frac{n}{b^i}\\Big) &\\le \\sum_{i=0}^{\\log_bn-1} cn^{(\\log_ba)-\\epsilon} \\cdot (b^\\epsilon)^i \\\\\\\\ &= cn^{(\\log_ba)-\\epsilon} \\cdot \\sum_{i=0}^{\\log_bn-1}(b^\\epsilon)^i\\\\\\\\ &= cn^{(\\log_ba)-\\varepsilon} \\cdot \\frac{(b^\\varepsilon)^{\\log_bn}-1}{b^\\varepsilon-1} \\\\\\\\ &= cn^{(\\log_ba)-\\varepsilon} \\cdot \\frac{n^\\epsilon-1}{b^\\epsilon-1} \\\\\\\\ &= \\frac{c}{b^\\epsilon-1} \\left[ n^{\\log_ba}-n^{(\\log_ba)-\\epsilon} \\right] \\\\\\\\ &= O(n^{\\log_ba}) \\end{aligned} \\end{equation}由此可得 T(n) =\\Theta(n^{\\log_ba}) +O(n^{\\log_ba})由于上式右侧两部分的函数增长率相同，所以 T(n) = \\Theta(n^{\\log_ba}) 个人理解是，$\\Theta$ 表示的是平均水平，即它可能有更高的上限和更低的下限。而 $O$ 已经是上限了，当 $\\Theta$ 取上限的时候，阶数是要比 $O$ 更高的。所以，当 $\\Theta$ 和 $O$ 的增长率是相同的时候，复杂度取 $\\Theta$。 $\\exists \\epsilon&gt;0 s.t. f(n)=\\Omega(n^{\\log_ba+\\epsilon})$，且 $\\exists c&lt;1$。当 $n \\to \\infty$， $a\\, f(\\frac{n}{b})\\le c\\, f(n)$。此时 $T(n)=\\Theta(f(n))$。 证明： \\begin{equation} \\nonumber \\begin{aligned} af(\\frac{n}{b}) &\\le cf(n) \\\\\\\\ \\Rightarrow f\\Big(\\frac{n}{b}\\Big) &\\le \\frac{c}{a}f(n)\\\\\\\\ \\Rightarrow f\\Big(\\frac{n}{b^2}\\Big) &\\le \\frac{c}{a}f\\Big(\\frac nb\\Big)\\le\\Big(\\frac{c}{a}\\Big)^2f(n)\\\\\\\\ &\\vdots\\\\\\\\ f\\Big(\\frac{n}{b^i}\\Big) &\\le\\Big(\\frac{c}{a}\\Big)^if(n)\\\\\\\\ \\Rightarrow a^i\\, f\\Big(\\frac{n}{b^i}\\Big) &\\le c^i\\, f(n)\\\\\\\\ \\Rightarrow g(n) &\\le f(n)\\sum_{i=1}^{\\log_bn-1}\\\\\\\\ &\\le f(n)\\sum_{i=1}^\\infty c^i\\\\\\\\ &= \\frac{1}{1-c}f(n)\\\\\\\\ \\Rightarrow g(n) &= O(f(n))\\\\\\\\ g(n) &= f(n) + af(\\frac{n}{b})+ \\dots + a^{\\log_bn-1}f(\\frac{n}{b^{\\log_bn-1}}) \\\\\\\\ &\\ge f(n)\\\\\\\\ \\Rightarrow g(n) &= \\Omega(f(n)) \\end{aligned} \\end{equation}由 $g(n)=O(f(n))$ 和 $g(n)=\\Omega(f(n))$ 可得： g(n) = \\Theta(f(n))=\\Theta(n^{\\log_ba+\\epsilon})此时 T(n) = \\Theta(n^{\\log_ba})+\\Theta(n^{\\log_ba+\\epsilon})后者的阶数更高，所以 T(n) = \\Theta(f(n)) 如果 $f(n)=\\Theta(n^{\\log_ba})$，则 $T(n)=\\Theta(n{\\log_ba}\\cdot\\log n)$。 证明： \\begin{equation} \\nonumber \\begin{aligned} f(n) &= \\Theta(n^{\\log_ba}) \\\\\\\\ \\Rightarrow f(\\frac{n}{b^i}) &= \\Theta((\\frac{n}{b^i})^{\\log_ba}) \\\\\\\\ \\Rightarrow c_1(\\frac{n}{b^i})^{\\log_ba} &\\le f(\\frac{n}{b^i}) \\le c_2(\\frac{n}{b^i})^{\\log_ba}\\\\\\\\ \\Rightarrow a^i \\cdot c_1(\\frac{n}{b^i})^{\\log_ba} &\\le a^i \\cdot f(\\frac{n}{b^i}) \\le a^i\\cdot c_2(\\frac{n}{b^i})^{\\log_ba}\\\\\\\\ \\Rightarrow c_1n^{\\log_ba}(\\frac{a}{b^{\\log_ba}})^i &\\le a^if(\\frac{n}{b^i})\\le c_2n^{\\log_ba}(\\frac{a}{b^{\\log_ba}})^i\\\\\\\\ c_1n^{\\log_ba}(1)^i &\\le a^if(\\frac{n}{b^i})\\le c_2n^{\\log_ba}(1)^i\\\\\\\\ \\sum_{i=0}^{\\log_bn-1} c_1n^{\\log_ba}(1)^i &\\le \\sum_{i=0}^{\\log_bn-1}a^if(\\frac{n}{b^i})\\le \\sum_{i=0}^{\\log_bn-1} c_2n^{\\log_ba}(1)^i\\\\\\\\ c_1n^{\\log_ba}\\cdot \\log_bn &\\le g(n) \\le c_2n^{\\log_ba} \\\\\\\\ c_1n^{\\log_ba}\\frac{\\log n}{\\log b} &\\le g(n) \\le c_2 n^{\\log_ba} \\frac{\\log n}{\\log b}\\\\\\\\ \\frac{c_1}{\\log b} \\cdot n^{\\log_ba}\\cdot \\log n &\\le g(n) \\le \\frac{c_2}{\\log b} n^{\\log_ba} \\cdot \\log n \\\\\\\\ \\Rightarrow g(n) &= \\Theta(n^{\\log_ba}\\cdot \\log n) \\\\\\\\ \\Rightarrow T(n) &= \\Theta(n^{\\log_ba}) +\\Theta(n^{\\log_ba}\\cdot \\log b) \\end{aligned} \\end{equation}由于 $\\Theta(n^{\\log_ba}\\cdot \\log n)$ 是高阶项，所以 T(n) = \\Theta(n^{\\log_ba}\\cdot \\log n)1.4.4 主定律应用 T(n)=aT(\\frac{n}{b})+f(n) = \\begin{cases} \\Theta(n^{\\log_ba}), & \\text{if}\\quad f(n)=O(n^{\\log_ba-\\epsilon}) \\\\\\\\ \\Theta(n^{\\log_ba}\\cdot \\log n), &\\text{if}\\quad f(n)=\\Theta(n^{\\log_ba})\\\\\\\\ \\Theta(f(n)) , & \\text{if} \\quad f(n) = \\Omega(n^{\\log_ba+\\epsilon}) \\end{cases} $T(n)=3T(n/2)+n^2$ $a=3, b=2$，$f(n)=n^2$ $\\log_ba=\\log_23 \\approx 1.58 &lt; 2$ 即 $f(n)&lt;n^{\\log_23+\\epsilon}$ $T(n)=\\Theta (f(n))=\\Theta(n^2)$ 1.4.5 主定律的局限性主定律在以下情况下不可用： $T(n)$ 是非单调函数，比如 $T(n)=\\sin(n)$; $ f(n)$ 是非多项式，比如 $f(n)=2^n$; $a$ 不是常数，比如 $a=2n$； $a&lt;1$。 1.5 关于时间复杂度的讨论1.5.1 渐进分析有什么缺点？ 由于 渐近分析是假设 $n\\to \\infty$ 时才成立的，通常情况下 ，算法需要解决的问题规模不会这么大。此时，估算结果会与实际情况有所偏差。 由于渐近分析考虑的是时间增长率，忽略掉了低阶项和系数。所以无法区分增长率相同而系数不同的情况。比如 $f(n)=100n$ 和 $g(n)=n\\log_2n$ ，按照渐近分析，$f(n)$ 的复杂度要优于 $g(n)$。然而只有当问题规模达到宇宙原子总数量级的时候，这种情况才成立。而我们实际应用中问题规模通常是远小于这个量级。 1.5.2 为什么通常关心的是 $O(f(n))$？首先， $\\Omega(f(n))$ 对各种条件要求比较苛刻，所以我们主要讨论 $\\Theta(f(n))$ 和 $O(f(n))$。 当我们讨论 “平均” 情况的时候，意味着要对输入数据的分布作出假设。在做这种假设的时候需要大量的数据支持。这就意味着分析结果是不普适的，因为不同的数据有不同的分布。所以通常情况下，“平均” 分析结果并不准确。 “最坏” 的情况得到的结论容易组合，但“平均”不行，比如： 算法 1 在最坏的情况下执行 $n$ 次过程 1； 过程 1 在最坏的情况下执行 $m$ 次过程 2； 过程 2 执行若干次基本操作。 此时，我们就可以说算法 1 的最坏复杂程度为 $O(n\\times m)$。但是如果算法 1 是在平均情况下执行 $n$ 次过程 1，和 $m$ 次过程 2，我们却不能说算法 1 的复杂度是 $\\Theta(n\\times m)$。因为过程 1 的数据分布我们不清楚。 1.5.3 如何选择 $O(f(n))，\\Theta(f(n))，\\Omega(f(n))$？视情况而定。 对实时性要求不高的时候，可以考虑平均复杂度。 对实时性要求非常高的情况，就必须考虑最坏的情况了。比如汽车抱死系统，人命关天，时间就是生命。如果用平均复杂度，意味着系统平均反应速度很快，但是偶尔会比较慢。而这个“偶尔”就可能造成无法挽回的损失。 Reference DAS Introduction 算法复杂度分析的那些事, 跟小新一起玩编程 Data Structures and Algorithms (DSA) 算法分析中，为什么分析最坏情况而不是平均情况？ 关于&lt;&lt;算法导论&gt;&gt;上的主定理（Master Theorem）的证明 主定理的证明及应用举例","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://rogerspy.gitee.io/tags/数据结构/"},{"name":"时间复杂度","slug":"时间复杂度","permalink":"https://rogerspy.gitee.io/tags/时间复杂度/"}]},{"title":"数据结构与算法：数据结构简介","slug":"ds-data-structure-introduce","date":"2021-04-16T14:29:51.000Z","updated":"2022-01-12T08:37:38.347Z","comments":true,"path":"2021/04/16/ds-data-structure-introduce/","link":"","permalink":"https://rogerspy.gitee.io/2021/04/16/ds-data-structure-introduce/","excerpt":"1. 什么是数据结构数据结构是用来存储和组织数据的仓库，是一种计算机高效获取和更新数据的方式。根据你的项目需求，找到合适的数据结构至关重要。比如，你想存储序列数据，那么你可以将数据存储在 Array 数据结构中：","text":"1. 什么是数据结构数据结构是用来存储和组织数据的仓库，是一种计算机高效获取和更新数据的方式。根据你的项目需求，找到合适的数据结构至关重要。比如，你想存储序列数据，那么你可以将数据存储在 Array 数据结构中： 2. 数据结构类型基本上，数据结构有两种类型： 线性数据结构 非线性数据结构 2.1 线性数据结构线性数据结构中，数据是以一个数字接一个数字排列的形式组织起来的。典型的线性数据结构有： 2.1.1 数组 Array数组数据结构中，数据排列在连续内存中，所有的元素都有相同的数据类型。而数据的具体形式由不同的编程语言决定，比如 Python 中，可以用 list 和 array 来实现。 2.1.2 堆栈 Stack在堆栈数据结构中，数据以 LIFO 的原则进行存储，即后存进去的数据会先被删除。就像堆盘子，最后放上去的盘子会首先被拿下来。 2.1.3 队列 Queue与堆栈数据结构相反，队列数据结构是以 FIFO 原则进行数据存储，即先进先出。就像排队，先排队的人先取到票。 2.1.4 链表 Linked List链表中的每个元素都可以通过一系列的节点与其他元素相连，并且每个节点都包含元素本身以及下一个节点的地址。 2.2 非线性数据结构非线性数据结构中的数据是无序的，且一个元素可以与其他元素相连。非线性数据结构主要有两种： 图数据结构 树数据结构 2.2.1 图数据结构图数据结构中，每个节点称为“顶点”（vertex），顶点与顶点通过“边”相连。 常见的图数据结构包括： Spanning Tree and Minimum Spanning Tree Strongly Connected Components Adjacency Matrix Adjacency List 2.2.2 树数据结构与图类似，树也是由顶点和边将数据组合在一起的。但是在树结构中，两个顶点只能有一条边。 常见的树数据结构有： Binary Tree Binary Search Tree AVL Tree B-Tree B+ Tree Red-Black Tree 2.3 线性数据结构 vs 非线性数据结构 线性数据结构 非线性数据结构 数据按照一定顺序组织起来 数据是无序的 数据只有一层 数据有多个层级 只有一条路径可以遍历所有数据 通常需要多条路径遍历所有数据 内存使用率不高 不同的结构有不同的内存使用率 时间复杂度随数据量线性增加 时间复杂度保持不变 ReferenceData Structure and Types","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://rogerspy.gitee.io/tags/数据结构/"},{"name":"queue","slug":"queue","permalink":"https://rogerspy.gitee.io/tags/queue/"}]},{"title":"NL2SQL 综述","slug":"nl2sql-survey","date":"2021-04-14T08:58:38.000Z","updated":"2022-01-12T08:37:38.398Z","comments":true,"path":"2021/04/14/nl2sql-survey/","link":"","permalink":"https://rogerspy.gitee.io/2021/04/14/nl2sql-survey/","excerpt":"","text":"1. 简介当今社会，人们越来越多地开始和数据打交道，其中一个核心的问题是数据的存储。为了更好的存储和管理数据，通常会把数据存储在数据库中。对于数据库管理系统的用户来说，必须具备两方面的能力： 对于数据库的结构非常了解，比如表名、列名、实体关系等等； 熟悉数据库查询语言，比如 SQL。 虽然 SQL 语言并不复杂，但是对于非技术人员来说，这仍然是阻碍他们与数据进行交互的门槛。就像封面中的例子：“what ‘s the total number of songs originally performed by anna nalick？” 首先，我怎么知道有哪些数据可用？也就是说，我怎么知道我要去哪张表里查我想要的数据？ 其次，我怎么知道要去 Song choice 和 Original artist 这两列中去找？ 然后，如果我得到了 anna nalick 有多少首歌以后，我还想知道她和 Macy Gray 谁的歌更多怎么办？ 再然后，如果我想知道的不是 anna nalick 有多少首歌，而是每个歌手分别有多少首歌又怎么办？或者有哪些歌手的歌比 anna nalick 多？ $\\cdots$ 如果我们能让计算机（数据库）理解人类的语言，只需要像和人类一样交流就可以从数据库中得到我们想要的数据岂不是美哉？这就是 NL2SQL 想要达到的目标。NL2SQL（Natural Language to SQL）， 顾名思义是将自然语言转为 SQL 语句。它可以充当数据库的智能接口，让不熟悉数据库的用户能够快速地找到自己想要的数据。 1.1 NL2SQL 的一些实际应用场景通常数据交互的场景有三种： 企业内部数据管理。几乎所有企业都有大量数据需要存储和管理，多数企业会选择使用数据库，而对于这些企业来说，通常会雇佣专业技术人员来管理数据库。因此，企业内部数据管理对于 NL2SQL 的需求并不强烈； 个人用户数据管理。对于个人用户而言，很少有用户的数据量会多到需要用到数据库。因此，这种场景下似乎 NL2SQL 的作用也并不明显。 普通用户与企业数据之间的交互。比如订餐、订票、查天气、查公交地铁等等。在这些场景下，现在的技术手段是企业通过一些界面的选项引导用户一步一步查询到自己想要的数据。对于用户来说，这些操作繁复冗杂，而且需要一定的门槛。正是由于引导式操作的繁杂给社会带来了一些尴尬局面——移动互联网为年轻人提供了便利，但却给老年人带来了麻烦。同时，对于企业来说，如何引导设计查询页面，如何编写查询程序同样也是必须面对的问题。如果能够实现专用户直接使用自然语言进行信息查询，以上问题都会迎刃而解，这也是 NL2SQL 最大的意义所在。 2. NL2SQL 发展简史NL2SQL 虽然是最近才火起来的，但是实际上它的研究历史还是比较长的。早在上世纪六七十年代人们就提出了 NLIDB （Natural Language Interface to Database）概念并做了一些研究。但是受限于数据量和计算机的算力，当时主要的技术手段是模式匹配、语法树和语义语法等。 1960-70 年代 最早出现的 NLIDB 系统是有两个：BASEBALL，主要面向当时没搞过国内的棒球联赛；LUNAR，用来回答有关从月球带回来的岩石样本的问题。 它能够准确地回答 80％ 的查询，没有任何错误。 1970 年代 到了上世纪 70 年代末期，陆续出现了一些 NLIDB 系统：PLANES，该系统甚至能够响应不连贯或模糊的用户请求；LIFER/LADDER，通过语义语法系统分析用户请求；RENDEZVOUS，它是 IBM 实验室的 San José 开发的，可以帮助用户在模棱两可的情况下提出自己的请求 1980 年代 CHAT-80，采用语义语法技术处理自然语句，使得 CHAT-80 达到了当时最好的效果。它最大的问题仍然是只对特定领域的数据集有效。MASQUE， DIALOGIC，都是对 CHAT-80 的改进型系统，在处理效率上有了大幅的提升。 1990 年代 从 90 年代开始，人们的研究开始聚焦关系型数据库。也就是说 NLIDB 系统开始向 NL2SQL 方向聚焦，当然此时的方法仍然是只针对对特定领域的数据。MASQUE/SQL，就是此时开发出来用于处理商业数据库的系统。California Restaurant Query，Expedia Hotels，GeoQuery，Hollywood，JobQuery，SQ-HAL，SystemX 等等一系列系统如雨后春笋般相继出现。 2000 年后 如果说 70 年代是 NLIDB 系统的诞生的话，那么进入 2000 年以后可以算是该系统的第一次进化。一些新方法的提出使得 NLIDB 不再只对特定领域的数据有效（需要指出的是，此时的主要技术手段仍然是基于规则的）。PRECISE，是第一个采用插件式的 NLIDB 系统。它通过结合语法技术和数学方法，使得语义分析器完全独立于数据库的配置信息。但是它只能处理简单的句子，不能处理嵌套语句，主要是因为它假设自言语句中的词和数据库表格中的数据存在一一对应的关系。NALIX，用于处理 XML 数据库。 2010 至今 随着机器学习技术的发展，机器学习也开始应用于 NLIDB 系统。NaLIR，通过与用户的交互使得它能处理复杂的自然语句。ATHENA，通过特定领域的本体处理更加丰富的语义信息。SQLizer，将自然语句转成逻辑表达，然后通过迭代优化逻辑表达式。Templar，是一种使用查询日志进行映射和联接路径生成的优化技术。 以上的这些方法或者系统都是严重依赖人工设计规则。而近些年深度学习的发展为这一领域也带来了新的景象，尤其是最近两三年，基于深度学习的 NL2SQL 方法不断刷新着记录。本文主要是对基于深度学习的 NL2SQL 技术进行一个总结，并探索 NL2SQL 技术在 Excel 领域应用。 基于深度学习的 NL2SQL Seq2sql，SQLNet，TypeSQL，Coarse-to-Fine，IncSQL，X-SQL，STAMP，IRNet，SQLova，TRANX，SyntaxSQL … 3. 数据集 数据集 总语句 训练语句 验证语句 测试语句 总表数 WiKiSQL 80654 56355 8421 15875 26531 ATIS 5317 4379 491 447 25 Advising(query split) 4387 2040 515 1832 15 Advising(question split) 4387 3585 229 573 15 GeoQuery 880 550 50 280 7 Scholar 816 498 100 218 10 Patients 342 214 19 109 1 Restaurant 251 157 14 82 3 MAS 196 123 11 62 17 IMDB 131 82 7 42 16 YELP 128 80 7 41 7 Spider 9693 8659 1034 - 873 WTQ 9287 5804 528 2955 2102 WikiTableQuestions 22033 14152 3537 4344 2100 CSpider 8832 6831 95 1906 876 DuSQL 28763 22521 2483 3759 813 TableQA 54059 41522 4396 8141 5291 上表中列出了目前主要的一些数据及其统计信息，其中蓝色字体对应的数据为中文数据集，其他数据都是英文数据集。下面我们挑选几个应用最广泛的几个英文数据集和中文数据集进行简单的介绍。 ATIS (The Air Travel Information System)：ATIS 是一个年代较为久远的经典数据集，由德克萨斯仪器公司在1990 年提出。该数据集获取自关系型数据库 Official Airline Guide (OAG, 1990)，包含 25 张表以及 5000 次的问询，每次问询平均7轮，93% 的情况下需要联合 3 张以上的表才能得到答案，问询的内容涵盖了航班、费用、城市、地面服务等信息。总的来说， ATIS 数据集存在数据量少，标注简单，领域单一等问题。 WikiSQL：该数据集是 Salesforce 在 2017 年提出的大型标注 NL2SQL 数据集，也是目前规模最大的 NL2SQL 数据集。它是 Victor Zhong 等研究人员基于维基百科标注的数据。这个数据集一经推出就引起了学术界极大的关注。因为他对模型提出了新的挑战，研究人员也在此数据集的基础上研究出了大量的优秀模型。目前学术界的预测准确率可达 91.8%。但是 WiKiSQL 数据集是一个单表无嵌套的数据集，总的来说相对于实际场景还是偏于简单。 Spider：Spider 数据集是耶鲁大学于 2018 年新提出的一个较大规模的 NL2SQL 数据集。Spider 数据集虽然在数据数量上不如 WikiSQL，但 Spider 引入了更多的 SQL 用法，例如 Group By、Order By、Having、UNION、EXCEPT、INTERSECT、LIMIT 等高阶操作，甚至需要 Join 不同表，更贴近真实场景，所以 Spider 是目前最复杂的数据集。作者根据 SQL 语句的复杂程度（关键字个数、嵌套程度）分成 4 种难度，而以 Spider 的标准划分的话， WiKiSQL 只有 easy 难度。目前准确率最高只有 54.7%。 WikiTableQuestions：该数据集是斯坦福大学于 2015 年提出的一个针对维基百科中那些半结构化表格问答的数据集，表格中的数据是真实且没有经过归一化的，一个 cell 内可能包含多个实体或含义，比如「Beijing, China」或「200 km」；同时，为了很好地泛化到其它领域的数据，该数据集测试集中的表格主题和实体之间的关系都是在训练集中没有见到过的。 CSpider：CSpider 是西湖大学利用 Spider 作为源数据集进行问题翻译，并利用 SytaxSQLNet 作为基线进行评测的 NL2SQL 数据集。CSpider 只翻译了问题，而数据库仍然是英文的，因此它在传统的 NL2SQL 上增加了额外的一些挑战，比如中文问题和英文数据库的对应问题(question-to-DB mapping)、中文的分词问题以及一些其他的语言现象。 DuSQL：该数据集是百度基于现有数据集问题和实际应用需求构建的多领域、多表数据集，覆盖了更多的问题类型。 TableQA：TableQA 是一个大规模，跨领域的中文 NL2SQL 数据集。与现有的 NL2SQL 数据集不同，TableQA 不仅要很好地概括为不同问题和表模式的 SQL 框架，而且还要概括为条件值的各种表达式。实验结果表明，在 WikiSQL 上具有 95.1％ 的条件值精度的最新模型在 TableQA 上仅获得 46.8％ 的条件值精度和 43.0％ 的逻辑形式精度，这表明所提出的数据集具有挑战性且需要处理。 4. 技术路线 // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('main')); var data = { \"name\": \"NL2SQL\", \"children\": [ { \"name\": \"输入\", \"children\": [ {\"name\": \"自然语言问句处理\"}, {\"name\": \"数据库的用法\"}, {\"name\": \"附加信息的输入\"} ] }, { \"name\": \"技术方法\", \"children\": [ { \"name\": \"输入增强技术\", \"children\": [ {\"name\": \"标记、链接和匿名化\"}, {\"name\": \"数据库表头或数据\"} ] }, { \"name\": \"翻译技术\", \"children\": [ {\"name\": \"基于规则、基于深度学习\"}, {\"name\": \"处理数据库表头的方法\"}, {\"name\": \"生成 SQL 语句的方法\"} ] }, { \"name\": \"后处理技术\", \"children\": [ {\"name\": \"处理模型生成的 SQL 语句\"} ] }, { \"name\": \"训练\", \"children\": [ {\"name\": \"模型优化算法\"} ] } ] }, { \"name\": \"输出\", \"children\": [ {\"name\": \"SQL 语法合成\"} ] }, ] }; // 指定图表的配置项和数据 var option = { tooltip: { trigger: 'item', triggerOn: 'mousemove' }, series:[ { type: 'tree', data: [data], top: '1%', left: '10%', bottom: '1%', right: '25%', symbolSize: 7, label: { position: 'left', verticalAlign: 'middle', align: 'right', fontSize: 14 }, leaves: { label: { position: 'right', verticalAlign: 'middle', align: 'left' } }, emphasis: { focus: 'descendant' }, expandAndCollapse: false, animationDuration: 550, animationDurationUpdate: 750 } ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); // 刷新调整 window.onresize = function () { myChart.resize(); } 为了系统的介绍现在的 NL2SQL 方法，我们将模型分成三部分：输入、技术方法、输出。然后总结出不同模型在这三部分的处理方法。 4.1 输入 模型的输入一般从三个方面考虑： 自然语言问句 $q_{nl}$ 的预处理； 附加信息的输入； 数据库的处理。 现有的所有方法中，模型输入都会包含两部分：自然语言问句 $q_{nl}$ 和数据库 $D$，其中 $S_D$ 表示数据库中的表头，$V_D$ 表示表中每一列的数据集合。 4.1.1 自然语言问句预处理自然语言问句的预处理有不同的方法： 基于深度学习的模型，将（$q_{nl}$，$S_D$，$V_D$）转化成词向量是必备的步骤； 基于规则的模型，包含以下几种预处理方法： 将自然语言问句解析成句法树，比如 NaLIR； 将自然语言问句转化成逻辑表达式，比如 SQLizer； 单纯地只进行分词，比如 ATHENA； 4.1.2 数据库的处理模型对数据库的处理包含以下几种方法： 将 $D$ 作为模型的输入进行处理，这是最常见的做法； 只用 $D$ 来构建词表； 有些模型假设数据库只包含一张表； 通过字典将自然语句中的一些实体映射到本体上，然后通过本体关系找到可能需要 JOIN 的表； ”本体（ontology）“原本是一个哲学概念，后来被应用于计算机领域。这里不对这个概念做过多的介绍，简单举几个例子说明什么是本体，大家自行体会。 比如： “阿里巴巴”、“金山办公”、“姚明”等等的本体是“名字”； “2012年”、“周五”、“3月份”等的本体是“时间”； … 诸如此类的用来描述事物本质的概念称为“本体”。 只用 $S_D$ 或者使用 $S_D + V_D$。 4.1.3 附加信息输入通常使用的附加信息包括： 开放领域的知识库，比如 Freebase； 使用专业领域的字典； 提前构建的 $q_{nl}$ 中的词语与 SQL 关键词之间的映射字典； WordNet； 用于计算词相似度的预训练词向量矩阵。 4.2 技术方法：输入增强 输入增强有三种方法： 标签化（Tagging） 首先，找到 $q_{nl}$ 中的一些特殊词，比如 TypeSQL 通过字符串匹配找到 $q_{nl}$ 中包含在数据库或知识库中的实体；PT-MAML 是利用词相似度匹配的方法在 $q_{nl}$ 中找到包含在数据库中的 $V_D$。 然后，将这些词和数据库中实体之间建立联系； 然后，给 $q_{nl}$ 中的找到的词打上实体标签或者直接将这些词规范化到 $V_D$； 将每个词的标签转化成词向量拼接到每个词的词向量后面，或者将每个实体的类型加到 $q_{nl}$ 对应实体的位置之前； 将处理后的词向量序列输入到编码器中。 其实一句话总结就是，标签化增强技术是利用数据库中的实体对 $q_{nl}$ 中的实体进行增强。这样可以使模型更好的捕捉到 $q_{nl}$ 实体和数据库实体的对应关系，从而提高准确率。但是这严重依赖 $q_{nl}$ 实体与数据库实体的匹配技术（无论是字符串匹配还是词相似度匹配），理论上讲即使没有这一步模型也是可以自动学习到，但是这种做法可以提高训练效率，在小数据量上效果应该不错，但是上到大数据量上之后过拟合的风险会大大提高。（当然，这只是个人推断没有实验证据） 词链接（Linking） 所谓词链接技术就是计算 $q_{nl}$ 中每个词与数据库中的实体之间的相似度。词链接有两种方法： 使用词向量计算 $q_{nl}$ 中的词与数据库中的实体之间的相似度； 使用神经网络计算词与词之间的相似度。 词链接的相似度同时输入给 $q_{nl}$ 编码器和 $S_D$ 编码器。词链接技术与标签化技术的不同之处在于计算相似度的过程是可以跟随整个模型一起进行训练的。 词链接的技术要比标签化的方法更加合理，但这也意味着模型需要训练的参数量有所上升，训练和推理效率会受到影响。 匿名化（Anonymizing） 匿名化方法就是将 $q_{nl}$ 和 $q_{sql}$ 中的常数值替换成一些特殊符号，这样可以降低词表大小。比如 “city.state_name=’New York’” 替换成 “city.state_name=’@STATE’”。用 “@STATE” 来代替具体的城市。 4.3 技术方法：翻译技术 4.3.1 基于规则的方法现在的基于规则的方法通常是将 $q_{nl}$ 解析成一个树结构的中间表达，不同的模型生成的树不一样。 NaLIR 是将输入的依存句法树转化成另一种分析树。通过一个简单的算法来移动任意初始句法树的子树，然后使用一系列节点插入规则最终实现树结构的变换。 ATHENA 是构建一棵解释树（Interpretation tree），其中节点对应概念或者属性，边表示在本体库中概念或属性之间的关系。 SQLizer 是将经过预处理的自然语言问句转化成逻辑表达式。 4.3.2 基于深度学习的方法基于深度学习的方法接班架构都是“编码器—解码器”（encoder-decoder）结构的。2019 年之前的工作，通常都是使用 RNN 作为编码器对 $q_{nl}$ 进行编码。但是随着 Transformer 的特征提取能力逐渐被人们发掘，尤其是以 BERT 为代表的预训练语言模型技术被提出以后，使用预训练语言模型作为编码器逐渐成为主流。 下面我们从两个方面介绍基于深度学习的 $q_{nl} \\rightarrow q_{sql}$ 映射方法。 如何处理数据库 $S_D$ 在深度学习框架下，数据库通常有两个作用：作为输出词表的一部分（SaV）和作为输入（SaI）。 在 SaV 方法中，将数据库中所有的表名和列名添加到输出词表中。在解码过程中，解码器从输出词表中选择需要解码的词。 在 SaI 方法中，数据库中所有表名和列名都以输入的方式传递给模型。在解码过程中，解码器利用指针机制从输入中选择需要解码的词。 如何生成 $q_{sql}$ 在生成 $q_{sql}$ 方面，已有的深度学习模型可以分成三种： sequence-to-sequence：输入一个序列，输出一个序列，类似于机器翻译； sequence-to-tree：输入一个序列，输出一棵树； slot filling：所谓的槽填充就是，把 SQL 语句看成是一系列的槽，通过解码器对一个一个的槽进行填充。比如，我们预先设定一个 SQL 语句：“SELECT * FROM * WHERE *”，其中 “ * ” 就是我们要填充的内容。 4.4 技术方法：后处理 后处理通常有四种： 将之前匿名化的值进行还原； 对输出是树结构的模型来说，需要后处理将树结构的结果解析成 $q_{sql}$； JOIN 推理； 使用用户反馈对结果进行修正。 4.5 技术方法：训练NL2SQL 模型的训练方法是根据它采用的 AI 算法确定的，目前来说有以下几种： 最常见的深度学习模型采用监督学习训练算法； NSP 和 DBPal 模型通过预先设定的模板和释义技术（paraphrasing techniques）记性训练； Seq2SQL 和 STAMP 模型采用强化学习方法进行训练； PT-MAML 采用元学习方法训练； 4.6 输出 目前 NL2SQL 技术存在四个方面的缺陷： 预定义的语法模式或者槽类型（实体类型）； 启发式翻译规则； 语法覆盖能力有限的中间表达； 有限的训练数据。 所以目前的 NL2SQL 输出的 SQL 语句是有限制的。根据限制能力的不同可以分成： 不受限制的，这种模型通常是数据驱动类型的。缺点就是需要大量的训练数据，这也是目前几乎所有 AI 任务的痛点； 低限制的，这样的模型通常是基于规则的模型， 限制通常来源于连表查询和嵌套查询等； 非常受限的，这样的模型通常需要预定义语法模式和实体类型，一旦发现问题要进行改动的影响面会非常大，甚至可能需要重新设计模型结构，重新标注数据等等。 所有模型输出结果的方式是先生成一系列候选语句，然后对候选语句进行排序，选择排名最高的 SQL 语句。基于规则的模型会设计不同的排序算法，而基于深度学习的模型通常采用的是用 softmax 函数来计算得分，根据每一个候选语句的得分进行排序。 5. 评估方法 对于 NL2SQL 模型来说，一个非常重要的点就是，我们如何评估一个模型的好坏？目前的评估方法有四种： 字符串匹配，通过对比模型生成的 SQL 语句和给定的标准 SQL 语句，判断生成 SQL 语句的正确性。这种方法可能导致误判，比如 WHERE 条件中，$a \\mathrm{and} b$ 和 $b \\mathrm{and} a$ 是等价的，但是用字符串匹配的方式就会得到错误的评估。 解析树匹配，通过对比模型生成的 SQL 和标准 SQL 的解析树，判断生成 SQL 的正确性。这种方法相比字符串匹配的方式，误判率会低一些，但是仍然是有一定的限制。比如，一个嵌套 SQL 语句和一个非嵌套语句实际上是等效的，但是他们的解析树是不一样的，这样解析树匹配的时候就会造成误判。 结果匹配，通过对比两条 SQL 语句在数据库中的执行结果来判断生成的 SQL 是否正确。这种方式看起来比较合理，但是仍然不能排除两条不同的 SQL 会得到相同结果的可能性。 人工验证，人工验证的误判率是最低的，但是却是成本最高的方法，几乎无法应用于实际生产中。 多级验证（Multi-level），用于验证两条 SQL 语句是否等价，如下图所示： 该方法的核心思想就是：给定两条 SQL 语句，如果它们在任何数据库中的执行结果总是相同的，那么他们就是等价的，一旦出现一次不同的结果，那么他们就不是等价的。 在给定的数据库上面执行两条 SQL 语句，如果结果不同则直接认定模型生成的 SQL 有误。如果结果相同，则继续下一步。 如果第一部中的数据库比较小，数据比较少，两条不等价的 SQL 语句可能会产生相同结果。所以，作者提出使用数据库测试技术对比两条 SQL 语句的执行结果。 所谓数据库测试技术，实际上是为了检测数据库引擎是否存在bug的技术。具体做法就是生成大量的数据库实例，然后跑 SQL 语句。用在这里主要是通过生成大量的数据库实例来验证两条 SQL 语句是否有相同的执行结果。 用一个现成的验证器，验证两条语句是否等价，比如 Cosette。 如果验证器无法验证两条语句是否等价，那么使用 SQL语句重写技术对两条 SQL 语句进行重写。然后对比重写后的 SQL 语法结构。 如果重写后的 SQL 语法结构不等价，再使用人工验证。 在本文的实验中，数据库实例生成器用的是 EvoSQL，SQL 语句等价验证器用的是 Cosette，SQL 语句重写用的是 IBM DB2。 6. 实验结果 为了方便我们对实验结果进行分析，这里专门挑选出一些比较典型的错误案例。 6.1 不同评估方法的对比 首先定义一个表格中的变量。 $acc_{sem}$，表示利用语义等价评估方法得到的结果； $acc_{ex}$，表示利用 SQL 执行结果进行评估的方法的得到的结果； $acc_{str}$，表示利用字符串匹配方法得到的评估结果； $acc_{syn}$，表示利用解析树匹配的方法得到的评估结果。 这个实验的目的是对比同一个模型在相同的数据集上用不同的评估方法得到的评估结果。这里选取的模型是 NSP 模型，因为它能生成复杂的 SQL 语句。从表中我们可以看出，不同的评估方法得到的结果差别很大，如果考虑复杂的 SQL 语句的话，这个差别将会更大。 6.2 简单 SQL 语句实验结果 上表是用于验证简单 SQL 语句使用的数据集的统计数据。在所有数据集中，只有 WikiSQL、Patients和 WTQ 三个数据集包含了简单的 SQL 语句，将这三个数据集中的简单语句筛选出来形成新的数据集（加上 -s 后缀以示区别）。 上表中，左边的表表示不同模型的总的表现，右侧表示每个单项的准确率，其中 $acc_{sel}$ 表示 SELECT 列的准确率，$acc_{agg}$ 表示聚合函数的准确率，$acc_{wh, col},acc_{wh, op}, acc_{wh,val}$ 分别表示 WHERE 条件中的列，操作符和值的准确率。 6.2.1 模型泛化性从表中我们可以看出，基于规则的模型准确率都比较低。主要还是基于规则的方法有很大的限制性，比如 NaLIR，如果映射表中没有将 “longest” 映射成 $MAX$ 函数的方法，那么当自然问句中包含 “longest” 时就会出错。解决的办法就是尽可能的扩充映射表，但是这需要大量的人工工作。 NSP 作为基于深度学习的模型，其表现出来的水平较之其他深度学习模型差了很多。主要原因是它将 $S_D$ 作为输出词表的一部分，这样会有三个问题： 模型无法捕捉自然语言问句中的实体与数据表中实体之间的关系； 输出词表会很大，对解码器选择正确的输出造成困扰； 如果用于验证的语句中包含训练集中没有见过的实体，模型的处理效果就会很差。 而其他深度学习模型通常是将 $S_D$ 作为输入输送给模型进行处理，然后使用指针机制进行解码。这样就可以避免以上三个问题，最终的效果会好很多。 6.2.2 小数据集的模型鲁棒性另一方面，我们会发现 NSP 在 Patients 数据集上的效果意外得好。通过分析发现， Patients-s 数据集的训练样本是最少的，NSP 的效果好是否跟它的数据增强技术有关呢？为了验证这个猜测，我们将 Patient-s 数据集利用数据增强技术扩展到 500。对比所有深度学习模型的表现，我们发现所有模型表现都有所提升，但是 NSP 的提升还是尤为明显。通过分析我们发现可能有以下几个原因： 由于其他深度模型是通过指针机制从自然问句中找出实体，如果自然问句中没有数据表中对应的实体，那么这些模型就不能生成正确的 SQL 语句了。比如错误案例中 （B）所展示的，数据表中是 “flu”，而自然问句中是 “influenza”，通过指针机制无法从自然问句中找到 “flu” 这个实体，自然就无法生成正确的语句了。而 NSP 模型是将数据表中的实体作为输出词表的一部分进行解码的，这样就可以正确找到 “flu” 这个实体了。 另外与 NSP 类似的将数据表实体作为输出词表的一部分的模型，比如 SyntaxSQLNet, GNN 和 IRNet 在小数据集上的效果也不如 NSP，主要原因是 NSP 的释义技术的应用。比如错误案例（A）中 NSP 可以准确的将 “hospitalization period” 映射到 “length_of_stay”，而另外几个模型就不能做到。 6.2.3 自然语言复杂性自然语言的复杂性来源于多个方面： 语法多样性 领域多样性 目标 SQL 的多样性 句子数量 这里我们先讨论语法多样性和领域多样性。仔细看实验结果我们会发现，几乎所有的模型在 WTQ-s 数据集上的效果都比较差。主要是因为 WTQ-s 的数据集中自然语言问句比较多样，比如错误示例（C），不仅包含两个独立的条件，而且还有否定条件。这样的句子几乎现在所有的模型都不能处理。另外，如果数据表中的列名或者常数值比较复杂，也会导致问句比较复杂。比如错误示例（D）中列名是 “number of autos da fe”，这里面包含了非英文词汇，而这些词在词表中属于 OOV（Out of Vocabulary），导致模型无法准确辨别列名。 6.2.4 $q_{nl}$ 与 $S_D$ 的实体对齐$q_{nl}$ 与 $S_D$ 的实体对齐对准确率的影响非常之大。在 WikiSQL 数据集上 GNN 的总体准确率是最高的，而在单项预测上 GNN 在预测列名的准确率也是最高的，因为在 GNN 模型中使用了实体链接技术。而使用标签化技术的 TypeSQL-C 和 IRNet 在列名的预测上，准确率仅次于 GNN，他们的总体准确率也是如此。 在 WTQ-s 数据集上，IRNet 的总体准确率是最高的，在单项上 $acc_{wh, op}$ 和 $acc_{agg}$ 与其他模型的准确率相比相差不多，但是在 $acc_{wh, col}$ 和 $acc_{sel}$ 上的准确率高出其他模型一大截。细致的分析我们会发现， IRNet 在长列名和表中有相似列名的时候表现尤为突出。比如错误示例（D）中，IRNet 是唯一预测正确的模型。 从以上的分析中我们不难发现，列名的准确性在很大程度上影响了模型的准确性。要提高模型预测列名的准确性，实体对齐是一个很有效的方法。而实体链接和标签化各有优势。 6.2.5 学习算法的有效性在以上所有评估模型中，Seq2SQL 和 PT-MAML 分别采用了强化学习和元学习的方法。我们将这两个学习算法都改成监督学习以后发现，两个模型的准确率都有所下降。说明他们各自的学习算法都有利于发挥他们的能力，但是总体而言，强化学习和元学习在准确率上还是比其他深度学习模型准确率差一些。 6.3 复杂 SQL 语句实验结果 复杂 SQL 语句的实验只在上表中的六个模型上做的，因为其他模型都不支持 复杂 SQL 语句的生成。数据集排除了 WikiSQL，因为该数据集全部是简单 SQL 语句。总的来说，这些模型的准确率都很低。 6.3.1 基于规则的模型基于规则的模型准确率低，主要的原因和前面简单 SQL 的问题一样。但是 Templar 比较有意思，它的准确率在除 MAS 数据集之外的所有数据集上的表现和 NaLIR 相差不大。经过分析我们发现，主要是在 MAS 数据集上 Templar 总是无法正确进行实体映射。给定两个实体 $qf_1$ 和 $qf_2$，如果 $qf_2$ 在检索日志中出现的频率更高的话，Templar 选择 $qf_2$ 的概率更高，即使可能 $qf_1$ 的语义更符合 $q_{nl}$。比如错误案例（E），“area” 与 “domain.name” 的语义相似度比 “publication.title” 更高，但是 Templar 选择了后者。 6.3.2 泛化性SaI 方法总体效果强于 SaV 方法，主要原因还是输出词表的 OOV 问题。使用 SaI 方法的模型中， SyntaxSQLNet 的准确率比 GNN 和 IRNet 低很多，主要原因为后者使用了实体对齐技术。 6.3.3 小数据集上的模型鲁棒性在小数据集上的表现和简单的 SQL 的情况类似，但是对于复杂 SQL 下，迷行表现更加糟糕。基于 SaI 的深度学习模型甚至无法训练处一个有意义的模型出来。这也从侧面说明，要想训练一个能处理复杂语句的深度学习模型需要大量的训练数据。 6.3.4 生成 SQL 的覆盖面SyntaxSQLNet, GNN 和 IRNet 只能支持有限的 SQL，因为： SyntaxSQLNet 采用槽填充的方法，而槽的类型是预先定义的。预定义的槽类型严重限制了 SQL 语句的覆盖面。 GNN 和 IRNet 是基于语法的模型，他们的表现比 SyntaxSQLNet 要好一些，但是也只能支持部分 SQL 语法。比如，不支持 LIMITE、ORDER BY、GROUP BY 等等。 NSP 也面临着类似的问题，随着复杂度和多样性的提升 NSP 生成的 SQL 的错误率也随之提升。通过分析发现，NSP 的主要错误来源于表名和列名的预测错误，而这些错误中主要集中在需要连表查询的时候。 6.3.5 自然语言问句复杂度$q_{sql}$ 的复杂度随着 $q_{nl}$ 增加。目前所有的模型在面对复杂语句的时候准确率都非常低。 6.3.6 常数值的匿名化在 Advising（question split）数据集上 NSP 模型 $acc_{sem}$ 和 $acc_{val}$ 准确率相差近 35%，这个差距非常大。而 35% 非常接近 NSP 在 WikiSQL 上对常数值的预测准确率。看下错误示例（F）我们会发现， NSP 的错误点在于将 “751” 预测错误。说明 NSP 没有正确地将 “751”匿名化。这给我们两点启示： NSP 的匿名化技术还有待提升； 精准的映射常数值也是提升模型准确率的有效手段。 7. NL2SQL 未来的发展 上表总结了目前的模型能力，红色倒三角表示模型表现很差，“-” 表示一般，绿色正三角表示表现很好。从上表中我们可以看出，没有一个模型能在所有问题上达到哪怕一般般的水平。因为每个模型都这或这或那的局限性。 对于跨领域的模型适应能力，需要将数据表实体当成模型输入而不是输出，但是在特定领域下，SaV 的效果会比 SaI 好。对于数据表实体的编码研究会是一个有意思的课题。（ps：将数据表实体既当输入也当输出？） $q_{nl}$ 和 $S_D$ 实体对齐能有效提升准确率。但是目前的对齐方法还比较基础。字符串匹配的方式比词向量相似度的方法更加可靠，因为 $S_D$ 实体中可能包含很多词向量中没有的词。但是字符串匹配的方式容易造成过拟合，从实验结果中也可以看出来，IRNet 即使使用字符串匹配的方式，在 WTQ-s 数据集上的表现仍然很低，在更复杂的语句上准确率就更低了。 如何生成常数值也是一个具有挑战性的问题。即使使用匿名化技术，NSP 在 $V_D$ 比较多的情况下，表现也不尽如人意。 8. 总结本文总结了 2014年-2019 年之间的 NL2SQL SOTA 模型。并综合性的做了对比实验，从实验中我们发现了一些规律： 表名，列名的预测准确性很大程度上影响了生成 SQL 语句的准确性； 实体对齐技术能有效提升表名\\列名的准确性； 数据表实体作为输入和输出都有其优劣性，目前还没有同时作为输入输出的模型；理论上应该会有一定的提升； 匿名化技术对预测常数值有一定的帮助。 9. 参考资料 Analyza: Exploring Data with Conversation，Kedar Dhamdhere, Kevin S. McCurley, Ralfi Nahmias, Mukund Sundararajan, Qiqi Yan Natural language to SQL: Where are we today?，Hyeonji Kim, Byeong-Hoon So, Wook-Shin Han, Hongrae Lee Semantic Parsing with Syntax- and Table-Aware SQL Generation，Yibo Sun, Duyu Tang, Nan Duan, Jianshu Ji, Guihong Cao, Xiaocheng Feng, Bing Qin, Ting Liu, Ming Zhou The history and recent advances of Natural Language Interfaces for Databases Querying，Majhadi, Khadija; Machkour, Mustapha NL2SQL概述：一文了解NL2SQL 试试中国人自己的Spider吧！ Text-to-SQL Datasets and Baselines WIKISQL Spider CSpider Improving Text-to-SQL Evaluation Methodology，Catherine Finegan-Dollak, Jonathan K. Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, Dragomir Radev NaLIR: An Interactive Natural Language Interface for Querying Relational Databases，Fei Li，H. V. Jagadish Search-based test data generation for SQL queries，Jeroen Castelein, Maurício Aniche, Mozhan Soltani, Annibale Panichella, Arie van Deursen","categories":[{"name":"NL2SQL","slug":"nl2sql","permalink":"https://rogerspy.gitee.io/categories/nl2sql/"}],"tags":[{"name":"nl2sql","slug":"nl2sql","permalink":"https://rogerspy.gitee.io/tags/nl2sql/"}]},{"title":"推荐系统发展里程碑","slug":"recsys-milestone","date":"2021-04-13T02:35:12.000Z","updated":"2022-01-12T08:37:38.406Z","comments":true,"path":"2021/04/13/recsys-milestone/","link":"","permalink":"https://rogerspy.gitee.io/2021/04/13/recsys-milestone/","excerpt":"出处见水印","text":"出处见水印","categories":[{"name":"博客转载","slug":"博客转载","permalink":"https://rogerspy.gitee.io/categories/博客转载/"}],"tags":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://rogerspy.gitee.io/tags/推荐系统/"}]},{"title":"数据结构与算法：算法简介","slug":"ds-introduction","date":"2021-04-12T10:01:48.000Z","updated":"2022-01-12T08:37:38.363Z","comments":true,"path":"2021/04/12/ds-introduction/","link":"","permalink":"https://rogerspy.gitee.io/2021/04/12/ds-introduction/","excerpt":"在开始学习算法之前先说一些废话。 1. 一个算法拯救无数生命第二次世界大战期间，德军使用 AM 进行信息交流，任何掌握对应 AM 频率和摩斯码的人都可以对信号进行解码得到信息。但是由于信息是被加密的，所以需要对信息进行解密。有时候人们很幸运能够猜对，但是很快德军又换了密码。","text":"在开始学习算法之前先说一些废话。 1. 一个算法拯救无数生命第二次世界大战期间，德军使用 AM 进行信息交流，任何掌握对应 AM 频率和摩斯码的人都可以对信号进行解码得到信息。但是由于信息是被加密的，所以需要对信息进行解密。有时候人们很幸运能够猜对，但是很快德军又换了密码。 阿兰·图灵加入英军，帮助他们对德军密码进行破译。最初他们建造了一台机器进行计算，但是由于计算过于耗时，所以最开始这台计算机并没有多大用处。后来，图灵改变了原来的算法使得解码速度大幅提升。在后来的战争中，这台机器帮助英军破译了大量的德军密码，大大加速了战争的结束。 同一台机器从一个没什么用的废品，摇身一变成为拯救万民于水火的救世主，这就是算法的力量。 另一个很有说服力的例子是 “PageRank” 算法。PageRank 帮助谷歌从一众搜索引擎中脱颖而出，成为行业领军者，因为 PageRank 能够得到更好的搜索结果。 2. 什么是算法？算法就是计算机在完成任务过程中执行的步骤。就像人做菜，按照菜谱的步骤一步一步把各种调料和菜品烹饪成一道可口的菜，这个菜谱就是人在炒菜的时候的算法。对于计算机来说，算法就是一系列用于完成特定任务的指令。算法接收一系列输入，然后得到我们想要的输出。比如： 两个数字相加算法： 输入两个数字 使用 + 运算符对两个数字进行相加 输出结果 算法也有“好的”算法和“不好的”算法，就像菜有好吃和不好吃一样。好的算法速度更快，不好的算法更慢。如果算法运算太慢意味着更高的成本，甚至在一些任务上是无法完成运算的（相对人的生命）。 3. 为什么学习算法？计算机程序最宝贵的两种资源是时间和空间（内存）。 3.1 时间和空间（内存）都是有限的程序运行时间用下式计算： t = t_e \\times n其中 $n$ 表示指令数目，$t_e$ 表示运行每条指令需要的时间。$n$ 依赖于你编写的程序，而 $t_e$ 依赖于计算机硬件。 假设我们要计算 $1-10^{11}$ 的自然数之和。如果我们逐个数字相加，则需要 $10^{11}$ 次取值和 $10^{11}$ 次相加，即 $2\\times 10^{11}$ 次计算。假设计算机每秒计算 $10^8$ 次，要计算完这个程序，仍需 16 分钟。 有没有什么办法帮助提高运算效率？我们中学就学过一个等差数列求和公式： \\text{sum} = \\frac{n\\times (n+1)}{2}利用这个公式，我们只需要执行一次指令就可完成运算。 同样计算机内存并不是无限的，当你需要处理或者存储大量数据的时候，处理算法就需要考虑如何节省内存的使用。 3.2 可扩展性可扩展性意味着算法或系统处理更大规模的问题的能力。 假设我们现在要建一间 50 人的教室，最简单的方法是订一个房间，放上一个黑板，几支粉笔，几张桌子和椅子就好了。如果学生是 200 人呢？我们还可以用上面的方法，只是需要用到更大的房间，更多的桌椅。但是如果学生是 1000 人呢？我们就找不到足够大的房间和足够多的的桌椅了。这个时候原来的方法就失效了。 就像前面的例子，最初我们计算实数和的方法就是不可扩展的，因为随着数据量增大，需要消耗的时间已经超出了我们所能忍受的范围。 而第二种方法就是可扩展的，因为无论数据量有多大，我们都能在一次指令下完成计算。 4. 结语软件系统每天都会诞生许多新的方法和技术，而算法更像是其中的灵魂。当一个系统遇到瓶颈的时候，很可能通过优化其中的算法使整个系统性能得到提升。 但是同时也要注意，改善算法提升系统的可扩展性并不是唯一的方法。比如我们还可以通过分布式计算来实现。 ReferenceWhy Learn Data Structures and Algorithms?","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://rogerspy.gitee.io/tags/数据结构/"}]},{"title":"预训练语言模型-神经网络语言模型：CNNLM","slug":"neural-language-model-cnn","date":"2021-04-11T03:04:17.000Z","updated":"2022-01-12T08:37:38.384Z","comments":true,"path":"2021/04/11/neural-language-model-cnn/","link":"","permalink":"https://rogerspy.gitee.io/2021/04/11/neural-language-model-cnn/","excerpt":"神经网络三大神器：DNN、CNN、RNN。其中 DNN 和 RNN 都已经被用来构建语言模型了，而 CNN 一直在图像领域大展神威，它是否也可以用来构建语言模型呢？如果要用 CNN 构建语言模型应该怎么做？接下来我们从四篇论文看 CNN 构建语言模型的三种方法。","text":"神经网络三大神器：DNN、CNN、RNN。其中 DNN 和 RNN 都已经被用来构建语言模型了，而 CNN 一直在图像领域大展神威，它是否也可以用来构建语言模型呢？如果要用 CNN 构建语言模型应该怎么做？接下来我们从四篇论文看 CNN 构建语言模型的三种方法。 1. CNN 语言模型简单的 CNN 语言建模思路如下： 首先输入的词经过 embedding 层，将每个词转化成句子矩阵 $x_{1:n} \\in \\mathbb{R}^{n \\times k}$，其中 $n$ 表示句子长度，$k$ 表示词向量维度； 得到句子矩阵以后，用 $W \\in \\mathbb{R}^{w\\times k}$ 的卷积核对句子矩阵进行卷积运算，一共有 $k$ 个卷积核； 经过卷积之后得到一个新的矩阵，然后在新的矩阵上使用 ReLu​ 激活函数； 接下来使用 batch normalization，为了解决内部协方差飘移问题； 然后经过一个 DNN 层进行降维之后直接使用 softmax 层输出，而不经过最大池化层，因为最大池化层会使句子丢失位置信息。 以上就是最基本的 CNN 语言模型的结构。除此之外，还有几个变种： MLPConv 标准的 CNN 卷积操作是利用卷积核和特征矩阵进行线性变换。而 MLPConv 是在标准的卷积核后面接一个多层的 DNN 将原来的线性变换转化成非线性变换。需要注意的是，MLPConv 同样没有加入最大池化层。 Multi-Layer CNN 将多个同尺寸卷积核的卷积叠加在一起，如下图左侧。 COM 将不同尺寸的卷积核的卷积拼接在一起，如下图右侧。 2. Gated-CNN 语言模型2.1 $gen$CNN下图展示了 $gen$CNN 模型的大致结构： $\\beta$CNN 用来记忆序列中较早之前的信息； $\\alpha$CNN 用来处理距离需要预测的词最近的部分序列。 相对于传统 CNN，$gen$CNN 有两点不同： 部分权重共享策略； 用门控网络代替池化层。 接下来我们详细介绍一下模型的每一个部分。 2.1.1 $\\alpha$CNN: 卷积 $\\alpha$CNN 是部分共享权重的，在卷积单元中存在两种特征：Time-Flow 和 Time-Arrow，分别对应上图中的空心节点和实心节点。 Time-Flow：就是传统的 CNN，用来理解句子的整体时态结构； Time-Arrow：更像是基于 FFNN 的语言模型，用来理解句子的顺序。 假设输入句子 $\\pmb{x}=(x_1, \\cdots, x_T)$，第 $l$ 层的特征为： z_i^{(l, f)}(\\pmb{x}) = \\begin{cases} \\sigma(W_{TF}^{(l, f)} \\pmb{\\hat{z}}_i^{(l-1)} + b_{TF}^{(l, f)}) & f\\in \\mathrm{Time-Flow}\\\\\\\\ \\sigma(W_{TF}^{(l, f, i)} \\pmb{\\hat{z}}_i^{(l-1)} + b_{TF}^{(l, f, i)}) & f \\in \\mathrm{Time-Arrow} \\end{cases}其中： $z_i^{(l, f)}$ 表示第 $l$ 层网络第 $i$ 个位置的特征输出； $\\sigma(\\cdot)$ 表示 sigmoid 函数或者 Relu 函数； $W_{TF}^{(l, f)}$ 表示第 $l$ 层网络，$f\\in \\mathrm{Time-Flow}$ 的参数；$W_{TA}^{(l, f, i)}$ 表示第 $l$ 层网络第 $i$ 个位置，$f\\in \\mathrm{Time-Arrow}$ 的参数； $\\pmb{\\hat{z}}_i^{(l-1)}$ 表示第 $l-1$ 层第 $i$ 个位置的特征，令 $\\pmb{\\hat{z}}_i^{(0)}=[x_i^T, x_{i+1}^T, \\cdots,x_{i+k-1}^T]$，$k$ 表示窗口大小。 2.1.2 门控网络 假设有一个第 $l$ 层网络的特征矩阵，然后再第 $l+1$ 层上加门控（窗口大小为 2）。门控网络定义是一个二分类逻辑回归器： g_j^{(l+1, f)} = \\begin{cases} \\frac{1}{1+\\exp(-W_{gate}^{(l, f, j)}\\cdot\\bar{\\pmb{z}}_j^{(l)})} & f \\in \\mathrm{Time-Arrow} \\\\\\\\ \\frac{1}{1+\\exp(-W_{gate}^{(l, f)}\\cdot\\bar{\\pmb{z}}_j^{(l)})} & f \\in \\mathrm{Time-Flow} \\end{cases}其中 $\\bar{\\pmb{z}}_j$ 表示第 $j$ 个窗口中将 $\\hat{\\pmb{z}}_{2j-1}^{(l)}$ 和 $\\hat{\\pmb{z}}_{2j}^{(l)}$ 融合在一起的矩阵。 然后将得到的值与特征矩阵进行加权求和： z_j^{(l+1, f)} = g_j^{(l+1, f)}\\cdot z_{2j-1}^{(l, f)} + (1-g_j^{(l+1, f)}) \\cdot z_{2j}^{(j, f)}这样就得到了 $l+1$ 层的特征矩阵。 窗口为 2，是因为网络包含两种特征 Time-Flow 和 Time-Arrow，每个窗口位置 $j$ 都包含两个窗口，所以用 $2j-1$ 和 $2j$ 表示； 门控网络实际上是代替池化层做特征筛选，将卷积后的特征矩阵利用门控网络筛选出第 $j$ 个位置的特征到底是更偏向于结构信息还是更偏向于位置信息。 2.1.3 循环结构 就像之前介绍的那样，我们处理使用 $\\alpha$CNN 来获取当前信息以外，还会使用 $\\beta$CNN 来记录历史信息。$\\beta$CNN 只包含 Time-Flow 特征，得到 $\\beta$CNN 特征之后将它作为 $\\alpha$CNN 输入的第一个词输入给 $\\alpha$CNN。所有的 $\\beta$CNN 都是相同且循环对齐的，使得 $gen$CNN 能处理任意长度的句子。每个 $\\beta$CNN 后面加一个特殊的开关，当没有历史信息的时候就会把开关关掉。 实验中 $\\alpha$CNN 处理的句子长度为 $L_\\alpha=30\\sim40$，也就是说，如果句子长度短于 $L_\\alpha$ 的话，那么模型就只包含了 $\\alpha$CNN。实验中发现，90% 以上的句子可以只用 $\\alpha$CNN 就可以， 超过 99% 的句子只需要一个 $\\beta$CNN 就可以。实际上作者发现一个更大更深的 $\\alpha$CNN 比 更小的 $\\alpha$CNN 更多的 $\\beta$CNN 结构表现更好。 2.2 Gated-CNN 上图是 Gated CNN 模型的基本结构，大体上和传统的 CNN 语言模型区别不大，只是在 卷积之后加了一个门控机制： h_l(\\pmb{x}) = (\\pmb{x}\\cdot W +b) \\otimes \\sigma(\\pmb{x} \\cdot V + c)其中 $\\pmb{x} \\in \\mathbb{R}^{N\\times m}$ 表示词向量组成的句子矩阵或者上一层网络的输出，$W \\in \\mathbb{R}^{k\\times m\\times n}$, $b \\in \\mathbb{R}^n$, $V \\in \\mathbb{R}^{k\\times m\\times n}$, $c \\in \\mathbb{R}^{n}$ 表示模型参数，$\\sigma$ 为 sigmoid 函数，$\\otimes$ 表示元素级相乘。 其实这就相当于决定每个特征值有多少信息可以进入下一层网络，和 LSTM 中的遗忘门作用相同。 2.3 小结 从 LSTM 出发到门控 CNN，我们会发现所谓门控其实就是通过 sigmoid 函数控制特征的传递。 CNN 语言建模的关键在于不要使用池化层，因为池化层会丢失位置信息。 3. TCN 语言模型TCN 模型即所谓的 Temporal Convolution Networks，该模型基于两个基本原则： 网络输出一个和输入序列等长度的序列； 不会发生从未来到过去的信息泄露。 为了达到第一点原则，TCN 使用 1D 全连接卷积网络：每一个隐层的长度和输入层相同，并且使用零填充保证后续的隐层也能保持和之前序列长度相同。 为了达到第二点目的，TCN 使用因果卷积（causal convolutions, 如下左图），即 $t$ 时刻的输出仅为 $t$ 时刻及之前的序列的卷积结果。 \\mathrm{TCN} = 1D\\ \\mathrm{FCN} + \\mathrm{causal\\ convolutions}3.1 Dilated causal convolution为了使模型能够足够深，且能处理足够长的序列，TCN 没有使用标准的卷积网络，而是使用的空洞卷积（dilated causal convolution，如下右图）。 1D 空洞卷积的定义如下： 输入序列 $\\pmb{x} \\in \\mathbb{R}^{n}$，卷积核 $f:\\{0, \\cdots, k-1\\} \\rightarrow \\mathbb{R}$，在序列元素 $s$ 上的空洞卷积操作 $F$ 定义如下： F(s) = \\sum_{i=0}^{k-1}f(i)\\cdot \\pmb{x}_s +d\\cdot i其中 $d$ 是空洞步长（或者空洞卷积的扩张率），$k$ 是卷积核尺寸。 使用空洞卷积可以使得上层的节点感受野更大，这样也就可以引入更多的历史信息。一般 $d$ 随着层数的指数增加，即 $d=O(2^i)$，其中 $i$ 为层数。每层计算卷积时相隔 $d-1$ 个位置。 TCN 的视野取决于网络深度，卷积核大小和空洞卷积的步长。比如，如果我们需要依赖前 $2^{12}$ 个历史信息来预测下一个词的话，就需要至少 12 层网络。为了防止梯度消失，TCN 还使用了残差网路。 3.2 Residual connection 如上图所示，残差网络是训练深度模型常用的技巧，它使得网络可以以跨层的方式传递信息。TCN 构建了一个残差块来代替一层的卷积。一个残差包含两层的卷积和非线性映射，在每层中还加入了 WeightNorm 和 Dropout 来正则化网络。 3.3 TCN 的优点 并行性。当给定一个句子时，TCN可以将句子并行的处理，而不需要像RNN那样顺序的处理。 灵活的感受野。TCN的感受野的大小受层数、卷积核大小、扩张系数等决定。可以根据不同的任务不同的特性灵活定制。 稳定的梯度。RNN经常存在梯度消失和梯度爆炸的问题，这主要是由不同时间段上共用参数导致的，和传统卷积神经网络一样，TCN不太存在梯度消失和爆炸问题。 内存更低。RNN在使用时需要将每步的信息都保存下来，这会占据大量的内存，TCN在一层里面卷积核是共享的，内存使用更低。 3.4 TCN 的缺点 TCN 在迁移学习方面可能没有那么强的适应能力。这是因为在不同的领域，模型预测所需要的历史信息量可能是不同的。因此，在将一个模型从一个对记忆信息需求量少的问题迁移到一个需要更长记忆的问题上时，TCN 可能会表现得很差，因为其感受野不够大。 论文中描述的TCN还是一种单向的结构，在语音识别和语音合成等任务上，纯单向的结构还是相当有用的。但是在文本中大多使用双向的结构，当然将TCN也很容易扩展成双向的结构，不使用因果卷积，使用传统的卷积结构即可。 TCN毕竟是卷积神经网络的变种，虽然使用扩展卷积可以扩大感受野，但是仍然受到限制，相比 Transformer那种可以任意长度的相关信息都可以抓取到的特性还是差了点。TCN在文本中的应用还有待检验。 4. 总结 用 CNN 进行序列建模不要使用池化层，因为池化层会丢失位置信息； 门控 CNN 通常是用 sigmoid 函数进行信息控制； 空洞卷积可以扩展 CNN 的视野； 残差连接可以训练更深的网络。 5. Reference Convolutional Neural Network Language Models, Ngoc-Quan Pham and German Kruszewski and Gemma Boleda A Convolutional Architecture for Word Sequence Prediction, Mingxuan Wang, Zhengdong Lu, Hang Li, Wenbin Jiang, Qun Liu Language Modeling with Gated Convolutional Networks, Yann N. Dauphin, Angela Fan, Michael Auli, David Grangier Convolutional Sequence Modelling Revisited, Shaojie Bai, J. Zico Kolter, Vladlen Koltun","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"CNNLM","slug":"cnnlm","permalink":"https://rogerspy.gitee.io/tags/cnnlm/"},{"name":"Language Model","slug":"language-model","permalink":"https://rogerspy.gitee.io/tags/language-model/"}]},{"title":"Text-to-Viz：根据语言描述自动创建信息图表","slug":"text2viz","date":"2021-04-09T03:06:27.000Z","updated":"2022-01-12T08:37:38.421Z","comments":true,"path":"2021/04/09/text2viz/","link":"","permalink":"https://rogerspy.gitee.io/2021/04/09/text2viz/","excerpt":"1. 简介市面上的专业创建信息图表的工具虽然在努力平衡易用性和功能强大，但是这些工具通常是面向高级用户的，比如设计师、数据科学家等等。对于普通用户非常不友好。","text":"1. 简介市面上的专业创建信息图表的工具虽然在努力平衡易用性和功能强大，但是这些工具通常是面向高级用户的，比如设计师、数据科学家等等。对于普通用户非常不友好。 普通用户通常有以下几个特点： 他们偶尔才会创建信息图表，对各种图表工具并不熟悉； 他们的目标不是设计美观、复杂、令人印象深刻的图表，而是需要一个专业、高效、能够准确说明问题的图表； 他们几乎没有设计经验，不知道如何从头开始设计图表。但是，给他们一些好的模板，他们能快速挑选符合心意的图表。 为了解决这类用户的需求，我们希望能够从自然语言描述中自动创建图表。为了达成这一目标，我们需要解决两个主要问题： 准确理解给定的语句并从中提取适当的信息； 利用提取出的信息创建图表。 为了解决以上两个问题，我们使用的技术方案是： 信息抽取解决方案 收集大量的真实用户数据； 对收集到的数据进行人工标注（序列标注）； 利用标注数据训练一个基于 CRF 算法的模型（NER 模型）。 图表设计解决方案 利用从互联网上收集到的图表模板，分析其设计空间，提出了一套系统的设计方案。 本文提出的方法使用范围：适用于比例相关的语言描述，比如 “中国 2020 年 GDP 涨幅为 6%。” 2. 图表综述 一个合法图表单元应该具备以下四个特征： 至少能传达一条信息； 至少包含一个图形元素； 在视觉和语义上保持完整性和连贯性； 无法被拆分成更小的满足上面三个条件的单元。 上图中每个蓝色方框中表示一个图表单元。 根据从互联网上收集到的图表，我们将图表分成四类： 基于统计的图表：这是最主要的图表类型，这类图表通常包含，水平/垂直的柱状图、饼状图、甜甜圈图等； 基于时间线的图表：这类图表用来表示事件发展信息，通常包含，时间线、表格等； 基于过程的图表：这类图表用来告诉读者如何一步一步达到特定的目标，这类图表通常用在食谱或者操作手册上； 基于位置的图表：这类图表通常包含一个地图，地图上有一些标志、箭头、图例等信息。 在进一步分析基于统计的图表时，我们又将基于统计的图表细分成四个字类： 比例图表：用于表示某一部分占据总量的比例。通常在文本描述中会包含 “$n\\%$”、“$m/n$”、“$m$ 分之 $n$”、“百分之 $m$” 等表述。这类图通常时柱状图、饼状图、甜甜圈图等。 数量图表：用于表示总量，比如收入、人口、速度等。这类图表通常不会使用饼状图、甜甜圈图，而是使用横向/纵向柱状图、象形图（pictographs chart）等; 变化图表：虽然变化图表通常可以用比例图标或者数量图表来表示，但是实际上变化图表和之前两种图表并不相同。变化图表的文本描述中通常会包含 “增长”、“下降” 等词汇，而图表通常会有不同的颜色、图形等的一一对比； 排名图表：这类图表中通常会包含星星、奖牌、奖杯等图像，而文本描述中通常会出现序数词，“第一名”、“前十名”等等。 对于基于统计的图表，通常一个图表只包含一个信息，但是有些图表在一个单元内包含多个信息。根据包含的不同信息，我们将图表分成四类： 单实例图表：这种是最简单的 合成图表：这类图标指的是用多个子图表形成一个完整的图表。比如文字描述 “中国2013年的总人口是14亿，较 2012 年的 13.5 亿增长了 10%。” 这段文字中的粟裕偶数字都是用来描述中国总人口的。 对比图表：多个实例进行对比，通常会使用颜色、图标、尺寸、形状等进行区分； 累积图表：这种图表有点类似于对比图表，但是不同的是，不同的主体会形成一个较大的整体。比如 “中国生产了美国大选所需的所有美国国旗，其中义乌生产了 70%，上海生产了 30%。” 3. 比例相关的图表3.1 文字描述 从网上爬取了 10 万 PPT 数据； 利用规则从 10万 PPT 数据中抽取 5562 条描述语句； 主要规则包含： “$n\\%$”、“$m/n$”、“$m$ 分之 $n$”、“百分之 $m$” 等。需要注意的是，包含这些关键词的句子并不一定是比例图标，比如 “公司营收增长了 50%。”显然应该属于变化图表； 从 5562 条规则抽取的文本中，经过人工筛选得到 800 条比例图表相关语句； 我们对比了 PPT 里面的语句和文章当中的语句，我们发现PPT里面的句子更加精炼，因此，没有在训练数据中添加文章句子。 3.2 图表可视化图表可视化设计的四要素：布局、描述、图形、颜色。 布局 图表布局分两种： 单实例（最常见）。单实例的图表通常包含一个图形和一段描述性的语言。这样的图表通常采用的布局是网格布局，便于图形和描述性文字的对齐。 多实例。将多个实例组合成一个图表通常采用四种策略： 并排（side-by-side）。为了表示对比、层级或者其他逻辑关系，多个实例通常采用网格布局，包括平行、并列、循环、层级和堆积等（下图a）。 共享轴（share-axes）。这种布局通常是将多个实例进行对齐，然后放到一个通用的坐标系统下。通常用在带坐标轴的统计图表里，比如条形图、散点图等（下图b）。 共享中心（share-center）。这种布局将多个数字实例以同一个圆心排列成圆形或者扇形。通常用在饼状图、夜莺玫瑰走势图（Nightingale rose charts）等上（下图c）。 共享文本（share-context）。这种布局将图表上不同的区域使用相同的注释加以说明。通常用在注释图表中，将注释放在公共空白区域（下图a）。 文本描述 前面我们对比例图表的定义是，用来表示某一部分占据总数的比例。那么在比例图表的文本描述中就应该包含三个关键信息：数值、局部、整体，实际上图表设计师通常会在数值前面加上一个修饰词，比如 “大于”、“小于” 等。除了这四种类型（包括修饰词）的描述，我们还发现了下面一些通用形式的描述： 完整描述。 在描述中数字被省略了。比如，“40 percent of USA fresh water is used for agriculture” 中的 “40 percent” 被省略。（ps: 我没有找到合适的中文例子） 局部是一个动词词组。比如，“65% 的咖啡是在早餐中消费掉的”， 其中 “消费掉” 作为局部，是一个动词词组。 数值-整体组合。比如，“65% 的咖啡是在早餐中消费掉的” 中的 “65% 的咖啡” 就是一个数值-整体组合。 文本描述以数值为界被分割开了。比如，“中国只有”，“10%”，“的人有本科学历”（ps: 同样没找到比较合适的中文例子）。 图形 图形部分涉及两点：图形的选择和组合。图形设计主要考虑两点： 图形应该与原始的文本描述具有语义相关性； 图形的不同元素应该具有不同的作用。（ps: 不同的元素表示相同的信息的话容易造成混淆） 根据已有的比例图表，我们将最常使用的图形分成七大类：象形图（下图a）、装饰图（下图d）、圈图（下图c）、饼状图（下图o）、条形图（下图i）、填充图标（下图e）、缩放图标（下图g）。 颜色 颜色设计的通用规则是： 前景和背景颜色：背景颜色占据绝大多数区域；前景颜色更加多样；不同文本框的文本描述使用相同的颜色；图形元素可以使用一种或者多种颜色，视情况而定。比如，象形图、饼状图等至少需要两种颜色，而装饰图标只需要一种颜色。 数字高亮：常见的高亮方法包括尺寸、颜色和字体。 4. Text-to-Viz 技术实现方案系统包括两个主要模块：文本分析模块和可视化生成器模块。首先用户输入一段文本，然后文本分析模块对文本进行分析，从中抽取 修饰词、数字、局部、整体 等信息。然后将原始文本和从文本中抽取出的信息一同输入给可视化生成器模块。可视化生成器模块生成或者选取合适的 布局、描述、图形、颜色，然后将这些元素组合成一系列可用的图表。对生成的图表进行评估和打分，根据打分的高低进行排序，呈现给用户，让用户进行选择。 4.1 文本分析模块 预定义四种实体：修饰词（Modifier）、数字（Number）、局部（Part）、整体（Whole）（ps: B-M、I-M、B-N、I-N、B-P、I-P、B-W、I-W、O一共需要九个输出）。利用命名实体识别模型对这四种实体进行识别抽取。本文使用的命名实体识别模型是 CNN+CRF 模型。主要包括一下三步： 分词：“中国 GDP 上涨 6%。” -&gt; [”中国“，”GPD“，”上涨“，”6%“，”。“] 特征化：将分词后的结果映射成词向量序列 CNN+CRF：一维 CNN，$kernel_size=(9\\times m)$，本文中 $m=59$。 训练结果： 4.2 可视化生成模块 4.2.1 布局布局设计需要解决两个问题： 如何分割区域？ 每个区域需要填充什么样的信息？ 以上图为例，我们可以通过人为设计规则来解决以上两个问题： 如果用户的文本描述是以数值开头的，那么我们将区域分成上图 $2\\times 1$ 的形式； 区域1 填充象形图、图标、饼状图等； 区域2 填充文本描述中的数字信息； 区域3 填充删除数字信息后的用户输入文本 我们通过分析收集到的数据，预先定义了 20 套布局模板作为项目启动数据。然后针对每一套布局模板都制定了相关的规则。 4.2.2 描述基本的描述信息通过文本分析模块已经得到了，剩下一些补充描述我们利用 Stanford Parser 对用户文本进行语法分析得到一个语法树。然后根据不同的布局，从语法树中抽取不同的内容。 4.2.3 图形在我们的实现中，我们构建了一个图形库，包含 100 个图形，每个图形都人为添加一个或多个关键词用来表示该图形的语义信息。然后将局部和整体的内容进行行分词、删除停用词，然后用 word2vec 进行词义匹配，找个最合适图形。 4.2.4 颜色颜色生成考虑两方面： 所有选用的颜色组合起来应该是协调的； 如果搭配的颜色与文本描述的内容相搭就更好了，比如文本描述保护环境，我们选择绿色和蓝色。 在我们的颜色生成模块中，同样是人为构建了一套颜色系统，给每个颜色系统打上标签，包括前景、背景、高亮等。颜色系统设计可参考 Adobe 颜色 和 Coolors。然后根据标签设计规则，只当每种颜色系统的使用条件。 4.2.5 合成遍历所有生成的布局、描述、图形、颜色，将这四元素组合。比如，可视化生成模块生成结果如下： 布局 = [layout1, layout2] 描述 = [description1, description2, description3] 图形 = [graphic1, graphic2] 颜色 = [color1] 将上面的元素组合起来得到一个候选集： 123456789101112131415候选集 = [ [layout1, description1, graphic1, color1], [layout1, description1, graphic2, color1], [layout1, description2, graphic1, color1], [layout1, description2, graphic2, color1], [layout1, description3, graphic1, color1], [layout1, description3, graphic2, color1], [layout2, description1, graphic1, color1], [layout2, description1, graphic1, color1], [layout2, description1, graphic2, color1], [layout2, description2, graphic1, color1], [layout2, description2, graphic2, color1], [layout2, description3, graphic1, color1], [layout2, description3, graphic2, color1]] 得到候选集以后根据以下规则进一步处理： 用户的输入文本不满足布局模板所需要的元素。比如，某个布局模板需要修饰词（比如 ”大于“），但是在用户文本中没有出现修饰词，那么我们就将这个布局模板的组合删掉。比如将候选集中所有包含 layout1 的组合删掉。 抽出描述和图形，计算他们的横纵比，将他们缩放到一个合适的尺寸，放到布局模板中。这个问题可以通过 Badros 等人提出的方法去解决。 挑选合适的字体，然后将所有元素进行对齐。 4.2.6 重排综合考虑三种评分机制：语义得分、可视化得分和信息得分。 语义得分：由于图形和颜色的选取是通过标签语义匹配得到的，因此，得分越高说明匹配度越高。word2vec 计算词义距离 $\\alpha_s \\in [0,1]$，0 分说明语义和图形或者颜色毫无关系，1 分说明非常契合。 可视化得分：由于图形和描述的尺寸与布局不一定相称，所以可视化得分也是我们考虑的因素之一。我们通过计算可视化元素中空白区域的占比来衡量可视化得分： \\alpha_v = \\frac{所有非空白区域面积}{画布区域总面积} 信息得分：通过信息得分来衡量图表是否包含了用户描述的所有信息。定义如下： \\alpha_i = \\sum_{w\\in S} \\frac{I(w)}{|S|}其中 $S$ 表示用户描述文本中的所有非停用词，$I(w)$ 的定义如下： I(w) = \\begin{cases} 1 & 如果 w 作为图标或者词出现在了生成的图表中 \\\\ 0 & 不满足上面的条件 \\end{cases} 有了上面三种评分方式，候选集中每种组合方式最后的总得分为： \\alpha = w_s\\alpha_s + w_v\\alpha_v+w_i\\alpha_i默认情况下，令 $w_s=0.25,w_v=0.5, w_i=0.25$。 最后我们根据每种组合最后的得分对候选集中的图表进行重排，然后推荐给用户。 需要注意的是，我们要支持用户对图表进行编辑，改变布局、描述、图形、颜色等。 5. Text-to-Viz 实际效果","categories":[{"name":"论文解读","slug":"论文解读","permalink":"https://rogerspy.gitee.io/categories/论文解读/"}],"tags":[{"name":"text2viz","slug":"text2viz","permalink":"https://rogerspy.gitee.io/tags/text2viz/"},{"name":"nl2infographic","slug":"nl2infographic","permalink":"https://rogerspy.gitee.io/tags/nl2infographic/"}]},{"title":"随机梯度下降中隐式正则化的起源","slug":"Implicit_Regularization","date":"2021-04-05T16:01:32.000Z","updated":"2022-01-12T08:37:38.268Z","comments":true,"path":"2021/04/06/Implicit_Regularization/","link":"","permalink":"https://rogerspy.gitee.io/2021/04/06/Implicit_Regularization/","excerpt":"首先推荐两篇论文： Samuel L Smith, Benoit Dherin, David Barrett, Soham De (2021) On the Origin of Implicit Regularization in Stochastic Gradient Descent David G.T. Barrett, Benoit Dherin (2021) Implicit Gradient Regularization","text":"首先推荐两篇论文： Samuel L Smith, Benoit Dherin, David Barrett, Soham De (2021) On the Origin of Implicit Regularization in Stochastic Gradient Descent David G.T. Barrett, Benoit Dherin (2021) Implicit Gradient Regularization 1. 深度学习为什么起作用？为了理解为什么深度学习会如此有效，仅对损失函数或模型进行分析是不够的，这是经典泛化理论所关注的。 相反，我们用来寻找极小值的算法（即，随机梯度下降）似乎起着重要作用。 在许多任务中，强大的神经网络能够内插（interpolate）训练数据，即达到接近0的训练损失。 实际上，存在一些训练损失的最小值，它们在训练数据上几乎没有区别。 在这些最小值中，有一些也可以很好地泛化（即导致较低的测试误差），而另一些则可以任意严重地过度拟合。 那么似乎重要的不是优化算法是否迅速收敛到局部最小值，而是它希望达到那个可用的“虚拟全局”最小值。 似乎是我们用于训练深度神经网络的优化算法比其他算法更喜欢一些最小值，并且这种偏好会导致更好的泛化性能。 优化算法优先收敛到特定的最小值而避免其他最小值的情况称为隐式正则化。 2. 有限步长的影响分析帮助我们想象深度学习模型训练过程中发生的事情的新理论之一是神经正切核（neural tangent kernels）。在这个框架下，我们研究了在无限宽层（infinitely wide layers）、全批次（full batch）和无限小学习率（ infinitesimally small learning rate）的限制下的神经网络训练。尽管这个理论有用且具有吸引力。但是使用全批、无限小学习率进行模型训练是不切实际的。实际上太小的学习率并不是总是有用的，minibatch-SGD 中梯度更新的随机性似乎也很重要。 Smith et al. (2021) 等人在的做法不同的是，他们尝试针对小型（但不是无限小的）学习率来研究minibatch-SGD，这更接近实际。 允许他们研究这种情况的工具是从微分方程的研究中借来的，称为后向误差分析（backward error analysis），无下图所示： 假设有一个微分方程 $\\dot{\\omega} = f(\\omega)$，上图中黑色的曲线表示该微分方程 $\\omega_t$ 的运动轨迹，初始条件为 $\\omega_0$。我们通常没有办法直接进行求解，而是使用欧拉法对该微分方程进行近似： \\omega_{k+1} = \\omega_k + \\epsilon f(\\omega_k)这个近似是离散的，如上图绿色线所示。由于离散化带来的误差，对于有限的步长 $\\epsilon$ ，离散路径可能不完全位于连续的黑色路径所在的位置。误差随着时间积累，如图所示。后向误差分析的目标是找到一个不同的微分方程 $\\dot{\\omega}=\\widetilde f(\\omega)$，使得我们找到的近似离散路径位于新的微分方程路径附近。我们的目标是对 $\\widetilde{f}$ 进行反向工程使得离散化迭代能很好的用微分方程进行建模。 这个方法为什么有效？因为 $\\widetilde{f}$ 采用的形式可以揭示离散化算法行为的偏好，尤其是如果它对进入不同空间有隐含偏好的话。 损失函数 $C$ 的梯度下降中，原始的微分方程是 $f(\\omega)=-\\nabla C(\\omega)$。修正后的微分方程： \\dot{\\omega} = - \\nabla \\widetilde{C}_{GD}(\\omega) \\\\\\\\ \\widetilde{C}_{GD}(\\omega) = C(\\omega)+\\frac{\\epsilon}{4}\\lVert \\nabla C(\\omega)\\rVert^2因此，具有有限步长 $\\epsilon$ 的梯度下降就像运行梯度流一样，但是增加了用来惩罚损失函数梯度的惩罚项。第二项就是所谓的隐式梯度正则化。 3. 随机梯度在这个框架下分析 SGD 有点困难，因为随机梯度下降的轨迹是随机的。 因此，没有一个单一的要优化的离散轨迹，而是有一个不同轨迹的分布，如果要随机重排数据，则要遍历这些轨迹。如下图所示： 从起始点 $\\omega_0$ 开始，我们有多条路径。这些路径对应于不同的数据重排的方式（论文中假设 mini-batch 中的数据是固定的，而随机性来源于 mini-batch 的处理顺序）。路径最终在一个随机位置处结束，绿色点显示了轨迹可能最终在其处的其他随机端点。 绿色星号代表了随机轨迹终点分布的平均值。 Smith et al. (2021) 的目标是对微分方程反向工程使得图中橙色的轨迹靠近绿色线的平均轨迹： \\dot{\\omega} = - \\nabla \\widetilde{C}_{SGD}(\\omega) \\\\\\\\ \\widetilde{C}_{SGD}(\\omega) = C(\\omega) + \\frac{\\epsilon}{4m} \\sum_{k=1}^{m} \\lVert \\nabla\\hat{C}_k(\\omega) \\rVert^2其中 $\\hat{C}_k$ 表示第 $k$ 个 mini-batch 的损失函数，总共有 $m$ 个mini-batch。注意，这里与我们平时见到的梯度下降很类似，但是这里使用的是 mini-batch 梯度的平均数。另一个有趣的视角是看看 GD 和 SGD 的不同之处： \\widetilde{C}_{SGD} = \\widetilde{C}_{GD} + \\frac{\\epsilon}{4m} \\sum_{k=1}^m \\rVert \\nabla\\hat{C}_k(\\omega)-C(\\omega) \\rVert^2其中额外的正则项 $\\frac{\\epsilon}{4m} \\sum_{k=1}^m \\rVert \\nabla\\hat{C}_k(\\omega)-C(\\omega) \\rVert^2$，有点像 mini-batch 的总方差。直观来说，此正则化项将避免参数空间中在不同 mini-batch 上计算出的梯度变化太大。 重要的是 $C_{GD}$ 与 $C$ 有相同的最小值，但 $C_{SGD}$ 就不一定了。这就意味着，SGD 不仅与 full-batch GD 有不同的轨迹，而且可能会收敛到完全不同的解。 4. 与泛化的关系为什么隐式正则化效果可以避免 mini-batch 梯度方差过大？ 考虑下面两个局部极小值的插图： 就平均损失 $C$ 来说，左右两边是相同的：最小值相同，宽度相同。但是，在左侧情况下，最小值是几个 mini-batch 损失的平均值，这些损失看起来都一样，而它们本身也相对较宽。 在右边的最小值中，宽泛的平均损失最小值是许多尖峰小批量损失的平均值，所有这些都无法确定最小值的确切位置。 可以合理地预期左边最小值可以更好地泛化，因为损失函数似乎对我们正在评估的任何特定 mini-batch 不那么敏感。这样，损失函数也可能对数据点是在训练集中还是在测试集中不太敏感。 5. 总结总而言之，本文是对随机梯度下降的非常有趣的分析。 尽管有其局限性（作者并没有试图在本文中进行透明地隐藏和讨论），但它还是为分析有限步长优化算法提供了一种非常有趣的新技术。 论文写得很好，清楚地阐明了分析中一些乏味的细节。","categories":[{"name":"论文解读","slug":"论文解读","permalink":"https://rogerspy.gitee.io/categories/论文解读/"}],"tags":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/tags/nlp/"},{"name":"隐式正则化","slug":"隐式正则化","permalink":"https://rogerspy.gitee.io/tags/隐式正则化/"}]},{"title":"预训练语言模型-神经网络语言模型：LSTMLM","slug":"neural-language-model-lstm","date":"2021-03-30T16:01:32.000Z","updated":"2022-01-12T08:37:38.386Z","comments":true,"path":"2021/03/31/neural-language-model-lstm/","link":"","permalink":"https://rogerspy.gitee.io/2021/03/31/neural-language-model-lstm/","excerpt":"1. 简介Mikolov 等人提出的 RNN 语言模型解决了前馈神经网络语言模型的语序问题。但是由于 RNN 神经网络本身存在着长程依赖问题，导致 RNN 语言模型很难学到距离较远的信息。","text":"1. 简介Mikolov 等人提出的 RNN 语言模型解决了前馈神经网络语言模型的语序问题。但是由于 RNN 神经网络本身存在着长程依赖问题，导致 RNN 语言模型很难学到距离较远的信息。 比如：“我的家乡是广东，广东有很多好吃的，我最喜欢的是海鲜，我们的方言是粤语…” 假设有这样一个句子，我们想通过前文去预测 “粤语” 这个词，显然它是和 “广东” 相关联的信息。但是我们会发现 “广东” 在句子中距离 “粤语” 很远。RNN 很难学到这样远距离的信息，关于为什么会出现这样的情况可以参考 Hochreiter &amp; German (1991) 和 Bengio, et al. (1994) 两篇文章，简单来说就是因为 RNN 循环过程中时间步之间是连乘的关系，一旦出现较大或者较小的值，经过连乘就会发生梯度爆炸或者梯度消失的情况。出现这种情况以后模型就学不到什么东西了。 为了解决这个问题，Hochreiter &amp; Schmidhuber (1997) 提出了长短期记忆网络（Long Short Term Memory networks，即所谓的 LSTM 网络）。使用 LSTM 来构建语言模型可以避免由 RNN 带来的长程依赖问题。 2. LSTM 语言模型2.1 LSTM 神经网络简介长短期记忆网络（Long Short Term Memory networks），通常简称为“LSTM”，是一种特殊的RNN，它能够规避掉长期依赖学习问题。它是由 Hochreiter &amp; Schmidhuber (1997) 提出的，并且经过很多人的改进。 LSTM被设计出来用以解决长期依赖问题。长时间记住信息实际上是他们的默认行为，而不是他们努力学习的东西！(Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!) 所有的循环神经网络都有着重复模块的链式神经网络结构。标准的RNN的重复模块有非常简单的结构，比如单个 tanh 层。LSTM 也有这种类似的链式结构，但是重复模块却有着不同的结构，不同于单一网络层结构，LSTM 的基本结构如下图。 对比 RNN 的结构，我们会发现，LSTM 要复杂得多。简单来说，LSTM 通过三个门控来调节当前神经元中学习到的信息，避免梯度消失或者爆炸。 图中 $\\sigma$ 表示 sigmoid 函数： \\sigma(z) = \\frac{\\exp(z)}{\\sum_i \\exp(z)} \\in (0, 1)$\\tanh$ 表示 tanh 函数： \\tanh(x) = \\frac{\\exp(x)-\\exp(-x)}{\\exp(x)+\\exp(-x)} \\in [-1, 1] cell 状态：LSTM 最重要的就是 cell 状态 $\\vec{C}_t$，表示当前时间神经网络学习到的信息； 遗忘门：控制上一个 cell 中有多少信息会进入到当前的 cell； 输入门：控制输入层有多少信息会进入到当前 cell 中； 输出门：控制当前 cell 有多少信息可以用于输出。 2.2 LSTM 语言模型 从之前的神经网络语言模型中，我们会发现一些规律： 输入词是通过 1-of-K 编码的，其中 $K$ 是词表大小； 输出层通过 softmax 得到一个归一化的概率分布； 训练过程使用交叉熵损失函数，等价于最大似然估计。 Sundermeyer 等人也使用了相同的方法，用来你构建 LSTM 语言模型。首先将输入层的词经过一个投影层，转化成词嵌入（实际上就是 Embedding 过程），然后传递给 LSTM，最后经过 softmax 进行输出。 对于大规模的语言模型训练来说，softmax 层的计算消耗了大量的时间： a_i = \\sum_{j=1}^J \\omega_{ij} b_j其中 $J$ 表示 LSTM 隐层节点数，$\\omega_{ij}$ 表示 LSTM 层与输出层的权重，$i=1,…,V$ ，其中 $V$ 表示词表大小。 为了降低计算时间，Morin &amp; Bengio 、Goodman 提出将词进行分类，然后预测下一个词所在的类别，然后再预测具体的词： p(w_m|w_{1:m-1}) = p(w_m|c(w_m),w_{1:m-1})p(c(w_m)|w_{1:m-1})其中 $w_m \\in c(w_m)$，$c(w_m)$ 表示 $w_m$ 所在的类别。 2.3 AWD-LSTM 语言模型LSTM 作为 RNN 最优秀的变种之一，在进行语言建模的时候也有着相当优秀的表现。但是 作为神经网络，LSTM 也存在着泛化性问题。通常为了提高神经网络的泛化性，人们提出了各种各样的正则化策略。 AWD-LSTM 提出了一些正则化和优化策略，这些策略不仅高效，而且可以在不改变 LSTM 结构的条件下实现。它在语言建模上的优异表现使得它一度成为最优秀的语言模型。下面我们就介绍一下这个模型。 LSTM 数学公式： f_t=\\sigma(W_f\\cdot [h_{t-1}, x_t]+b_f) \\\\\\\\ i_t = \\sigma(W_i\\cdot[h_{t-1}, x_t]+b_i) \\\\\\\\ \\widetilde{C}_t = \\tanh(W_C\\cdot [h_{t-1}]+b_C) \\\\\\\\ o_t = \\sigma(W_o \\cdot [h_{h-1}, x_t] +b_o) \\\\\\\\ C_t = i_t * \\widetilde{C}_t + f_t * \\widetilde{C}_{t-1} \\\\\\\\ h_t = o_t * \\tanh(C_t) 2.3.1 weight-dropped LSTMDropout 是神经网络中常用的防止过拟合的方法，但是用在 RNN 型的网络中通常效果不佳。这与 Dropout 的原理有关，见下图中间： Dropout 会随机丢掉一些神经元，即将神经元节点置为零。这样 $h_t$ 接收到的 $h_{t-1}$ 就不完整了，会干扰 RNN 的长程依赖能力。为了解决这一问题，Wan 等人提出 DropConnect 技术，如上图右侧。不同于 Dropout 的丢掉神经元，DropConnect 是随机丢掉一些权重，完整的保留了神经元。用伪代码来说明如下： 1234567# Dropouth_1 = RNNCell(x)h_2 = Dropout(h_1)# DropConnecth_1 = RNNCell(x)h_2 = Dropout(h_1.weights) 这样就不会影响到 RNN 的长程依赖能力了。 LSTM 的权重参数包括 $[W_f, W_i, W_C, W_o, U_f, U_i, U_C, U_o]$，其中 $W^{*}$ 是与输入 $x_t$ 相关的， $U^{*}$ 是与隐状态相关的。LSTM 的梯度问题通常与隐状态有关（循环连乘带来的梯度消失或者爆炸），因此将 DropConnect 应用于 $U^{*}$ 上效果更好（当然，$W^{*}$ 和 $U^{*}$ 都用也行，只是考虑到以牺牲效率为代价换来的效果提升并不明显）。 2.3.2 Non-monotonically Triggered ASGD对于语言建模任务来说，传统的 SGD 优化算法比带动量的 SGD 变体效果更好。因此，作者在调研了一些传统 SGD 算法之后选定了 ASGD 算法。 所谓 ASGD 算法指的是 Averaged SGD 算法，它是 Polyak &amp; Juditsky 等人 1992 年提出的一种优化算法，经过了二十多年的研究发展，ASGD 已经非常成熟，无论是理论研究还是实际表现都非常出色。 ASGD 采取和 SGD 相同的更新步骤 ，不同的是传统 SGD 在更新权重的时候只考虑当前的轮次，而 ASGD 不仅考虑当前的的轮次还考虑之前的轮次，然后计算平均值。用伪代码来表示如下： 12345678910# 传统 SGDw_t= w_t_1 - lr * grad(w_t_1)# ASGDavg_fact = 1 / max(t - K, 1)if avg_fact != 1: w_t = avg_fact * (sum(w_t_1) + (w_t_1 - lr_t * grad(w_t_1)))else: w_t = w_t_1 - lr_t * grad(w_t_1) 其中 $K$ 表示在计算权重平均值之前权重更新的迭代的次数，也就是说，前 $K$ 轮的 ASGD 与 SGD 是完全相同的。 但是作者认为这种方法有两处不足： 学习率的调整原则不明确； 参数 $K$ 作为超参，其取值原则也不明确。$K$ 值太小会对效果产生负面影响；取值太大可能需要更多的迭代才能收敛。 因此，作者提出了 ASGD 的一种变体—— NT-ASGD，即非单调触发 ASGD（Non-monotonically Triggered ASGD），算法如下： 当模型评估指标多轮训练（$n$）后都没有提升的时候 ASGD 就会触发，实验发现 $n=5$ 的效果最好； 整个实验使用恒定的学习率。 2.3.3 其他正则化方法除了上面讨论到的两种技术，论文作者还使用了其他预防过拟合、提升数据效率的正则化技术。 2.3.3.1 可变长度反向传播序列一般在训练语言模型的时候，将整个语料看成一个连续的超长的句子，在预处理的时候会将句子截断成固定长度的 batch size 个序列。这样由于句子被截断，在后向传播的过程中神经网络学到的信息就不玩完整了。比如： 12345原始语料：“我是中国人。我爱北京天安门。”预处理后：[ &quot;我是中国人。我&quot;, &quot;爱北京天安门。&quot;] “我爱北京天安门。”这句话中的 “我” 就无法学到任何信息，因为它后面的内容被截断了。 为了解决这个问题，作者提出了使用可变长度的反向传播序列。首先以概率 $p$ 选取长度为 $bptt$ 的序列，然后以概率 $1-p$ 选取长度度为 $bptt/2$ 的序列。($p$ 是个超参数，实验中作者选用的 $p=0.95$)。 1base_bptt = bptt if np.random.random() &lt; 0.95 else bptt / 2 然后根据 $N(base\\_bptt, s)$ 得到序列长度，其中 $s$ 表示标准差，$N$ 表示正态分布。代码如下： 1seq_len = max(5, int(np.random.normal(base_bptt, 5))) 然后再根据 seq_len 改变学习率。因为当学习速率固定时，会更倾向于对短序列，所以需要进行缩放。 1lr2 = lr * seq_len / bptt 作者的这种做法其实还是引入了很多超参。其实还有一种更好的方法，可以在固定长度的 BPTT 下，不影响效果。 上面的例子中，“我是中国人。我爱北京天安门。”被分成了 [“我是中国人。我”, “爱北京天安门。”]。这是通常的做法。我们还可以用下面的这种方法： 原始语料：“我是中国人。我爱北京天安门。”预处理后：[ ​ “我是中国人。我”, ​ “是中国人。我爱”, ​ “中国人。我爱北”, ​ … ​ “爱北京天安门。” ] 2.3.3.2 变分 Dropout通常情况下，每次调用 Dropout 时取样一个新的 dropout mask。但是在 LSTM 中参数是共享的，作者希望在不同的时刻共享的参数也共享同一套 dropout mask，这就是 variational dropout，在隐层作者使用了共享mask 的 dropConnect，而在输入和输出中，作者使用共享 mask 的 variational dropout。但是请注意在不同的 mini-batch 中，mask 是不共享的，所以 mask 的共享和参数共享还是有区别的，dropout mask 的共享是在每一个迭代中发生的，不同的迭代输入的数据不同，为了体现数据的差异性，要保证 dropout mask 不一致。 2.3.3.3 嵌入 Dropout对嵌入层引入 Dropout，实际上是在词级上操作的，即随机将一些词给去掉，这些被去掉的词的向量值就全为 0，并且在前向和反向传播中都保持这样的操作。对其余没有丢掉的词，用 $\\frac{1}{1-p_e}$ 缩放其向量值，$p_e$ 为 Dropout 的比例。 2.3.3.4 权重绑定共享 embedding 层和 softmax 层，可以降低模型总参数。语言模型的最后输出也是 $|\\mathcal{V}|$ 维，是预测词表中每个词的概率，从模型设计上来看嵌入层和最后输出层的参数矩阵的维度是很容易保证一致的，而从语言模型的特性上来看两个矩阵之间也是有一定的联系，所以作者选择共享嵌入层和输出层的权重矩阵，这种方法在 seq2seq 中也经常用到。 2.3.3.5 减小嵌入尺寸减少语言模型的总参数量的最简单方法是降低词向量的尺寸，尽管这无助于缓解过拟合。论文作者修改了第一个和最后一个 LSTM 层的输入和输出维度，以和降低了的嵌入尺寸保持一致。 2.3.3.6 激活正则化和时域激活正则化常见的正则化技术除了 Dropout 以外还有 $L_2$ 正则化。坐着在模型中不仅用了 Dropout 还用了 $L_2$ 正则化，$L_2$ 正则化分成两部分： 对每个单独的 $h_t$ ，用于惩罚明显过大的值。这部分称之为 Activation Regularization： \\alpha L_2(m \\odot h_t)其中 $m$ 为 dropout mask，$\\alpha$ 为缩放系数。 对 $h_t$ 和 $h_{t+1}$ 之间的差值，用于惩罚隐状态变动过大，称之为 Temporal Activation Regularization。这一步很容易理解，$h_{t}$ 包含了之前的所有信息，$h_{t+1}$ 不仅包含了之前的所有信息，还包含了当前信息。一个通顺的句子包含的信息应该是平滑的，不会因为某个词的出现大规模改变隐状态。如果两个连续的隐状态之间出现了较大的差别很可能是训练过程出现了问题，所以通过 $L_2$ 正则化进行修正： \\beta L_2(h_t-h_{h+1}) 3. 总结本文介绍了 LSTM 语言模型，尤其着重介绍了 AWD-LSTM 语言模型。LSTM 作为在 Transformer 出现之前最优秀的序列建模的模型一直是 NLP 中的王者，实际上即使是 Transformer 在众多任务中的表现强于 LSTM，但是 LSTM 在序列位置捕捉能力上还是强于 Transformer。本文不仅包含了 LSTM 语言建模的思路 ，也介绍了多种非常有用的序列建模的优化方法。 4. Reference Morin, F., Bengio, Y.，Hierarchical Probabilistic Neural Network Language Model Goodman, J., Classes for fast maximum entropy training Martin Sundermeyer, Ralf Schluter, and Hermann Ney，LSTM Neural Networks for Language Modeling Stephen Merity, Nitish Shirish Keskar, Richard Socher，Regularizing and Optimizing LSTM Language Models Li Wan, Matthew Zeiler, Sixin Zhang, Yann Le Cun, Rob Fergus，Regularization of Neural Networks using DropConnect Yashu Seth, What makes the AWD-LSTM great? 语言模型系列（一）——AWD-LSTM","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/tags/nlp/"},{"name":"LSTMLM","slug":"lstmlm","permalink":"https://rogerspy.gitee.io/tags/lstmlm/"}]},{"title":"预训练语言模型-神经网络语言模型：RNNLM","slug":"neural-language-model-rnn","date":"2021-03-24T09:44:16.000Z","updated":"2022-01-12T08:37:38.387Z","comments":true,"path":"2021/03/24/neural-language-model-rnn/","link":"","permalink":"https://rogerspy.gitee.io/2021/03/24/neural-language-model-rnn/","excerpt":"1. 简介Bengio 等人使用前馈神经网络构建语言模型，解决了两个问题：参数维度爆炸和词与词之间的语义关系的问题。然我们看到使用神经网络构建语言模型存在的巨大潜力。但是前馈神经网络构建的语言模型同样也存在问题：他只能输入特定长度的上下文（窗口 $n$）。也就是说，它只能用固定长度内的信息来预测下一个词，这与 n-gram 模型有相同的问题。","text":"1. 简介Bengio 等人使用前馈神经网络构建语言模型，解决了两个问题：参数维度爆炸和词与词之间的语义关系的问题。然我们看到使用神经网络构建语言模型存在的巨大潜力。但是前馈神经网络构建的语言模型同样也存在问题：他只能输入特定长度的上下文（窗口 $n$）。也就是说，它只能用固定长度内的信息来预测下一个词，这与 n-gram 模型有相同的问题。 循环神经网络之前是专门用来处理序列化数据的，它对于输入长度没有限制。因此，Mikolov 等人于 2010 年提出基于 RNN 的语言模型。 2. 模型2.1 RNN 神经网络简介 上图是一个 RNN 神经网络结构图，$A$ 是神经网络的一部分，给定输入 $x_t$，输出 $h_t$。上一步的信息通过循环传递给下一步。 循环神经网络可以看做同一个网络的多次重复，每次传递一个信息给下一级。考虑以下，我们把它展开是什么样的： 这个链式特性说明循环神经网络与序列和列表有很大关系。它们是用于这种序列化数据的一种很自然的网络结构。 2.2 RNN 语言模型 上图为模型的基本结构。该模型采用最简单的循环神经网络结构。网络分成三部分：输入层、隐藏层和输出层。 $t$ 时刻的输入层为：$t$ 时刻的词向量 $C(w_t) \\in \\mathbb{R}^{1\\times m}$ 与 $t-1$ 时刻的隐状态 $s(t-1) \\in \\mathbb{R}^{1\\times n}$ 向量拼接在一起的向量，即 $x(t)=[C(w_t);s(t-1)]\\in \\mathbb{R}^{1\\times (m+n)}$； $t$ 时刻的隐藏层为： s(t) = f\\left(x(t) \\cdot U\\right) \\\\\\\\ f(x) = \\frac{1}{1+e^{-x}}其中 $U\\in \\mathbb{R}^{(m+n)\\times n}$ 表示一个权重矩阵。对于 $t=1$ 时，没有前一时刻的隐状态输出，所以需要对 $s(0)$ 进行初始化。这里采用的方法是令 $s(0)=[0.1,\\cdots,0.1]^{1\\times n}$，实际上只要赋值一个小量向量即可，在后续的模型更新优化过程中，初始化的向量重要性不高。 $t$ 时刻的输出层为： y(t) = g(s(t)\\cdot W) \\\\\\\\ g(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}其中 $W\\in \\mathbb{R}^{n\\times |\\mathcal{V}|}$ 为权重矩阵。 假设句子是：$\\langle 我，爱，北京，天安门\\rangle$ 我们可以将模型理解为下面的过程： $t=1$ 时，模型输入第一个字 $w_1=我$，将它和初始化隐向量 $s(0)$ 拼在一起传递给隐藏层。然后隐藏层对输入的信息进行处理得到 $s(1)$，然后将 $s(1)$ 传递给输出层，输出层来预测句子中第 2 个词 $w_2=爱$； $t=2$ 时，模型输入第二个字 $w_2=爱$，将它和上一步得到的隐向量 $s(1)$ 拼在一起传递给隐藏层。然后隐藏层对输入的信息进行处理得到 $s(2)$，然后将 $s(2)$ 传递给输出层，输出层来预测句子中第 3 个词 $w_3=北京$； $t=3$ 时，模型输入第二个字 $w_3=北京$，将它和上一步得到的隐向量 $s(2 )$ 拼在一起传递给隐藏层。然后隐藏层对输入的信息进行处理得到 $s(3)$，然后将 $s(3)$ 传递给输出层，输出层来预测句子中第 4 个词 $w_4=天安门$； 模型的每一步都将前面接受到的所有信息存储在隐藏状态里了，输出层是利用之前所有序列产生的隐藏状态来预测下一个词。这样就避免了前馈神经网络那样只能使用固定长度内的信息来预测下一个词。 损失函数定义为： \\mathrm{error}(t) = d(t) -y(t)其中 $d(t)$ 表示第 $t$ 步真实的词，$y(t)$ 表示模型输出的词。 作者还提出一个动态模型的概念：在测试阶段也要更新模型。作者认为在训练阶段同一批数据会多次更新参数，而经过多轮训练以后，再进行一次测试集的参数更新对模型本身影响不大，但是可能会提升某些不常见的句子的表现。比如训练集中经常出现 ”狗“ 的句子，但是很少出现 ”猫“，而在测试集中有 “猫”的类似的句子，这种情况下，使用动态模型可能会提升模型应对不常见句子的能力。 3. 模型优化为了提升模型的表现，将所有出现频率低于某一阈值的词全部替换成统一的编码，比如 $$。包括罕见词的概率计算如下： p(w_i(t+1)|w(t), s(t-1)) = \\begin{cases} \\frac{y_{}(t)}{C_{}} & 如果 w_i(t+1) 属于 \\\\\\\\ y_i(t) \\end{cases}其中 $C_{}$ 表示训练集中出现罕见词的总次数。 4. 实验结果 5. 总结基于 RNN 的语言模型解决了前馈神经网络语言模型的视野太短问题，但是由于 RNN 本身的梯度消失问题导致实际上语言模型能够建模的序列长度也是有限的。 6. ReferenceRecurrent neural network based language model. Tomas Mikolov , Martin Karafiat , Lukas Burget , Jan Honza Cernocky , Sanjeev Khudanpur， 2010","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/tags/nlp/"},{"name":"RNNLM","slug":"rnnlm","permalink":"https://rogerspy.gitee.io/tags/rnnlm/"}]},{"title":"预训练语言模型-神经网络语言模型：FFNNLM","slug":"neural-language-model-ffnnlm","date":"2021-03-21T01:41:40.000Z","updated":"2022-01-12T08:37:38.384Z","comments":true,"path":"2021/03/21/neural-language-model-ffnnlm/","link":"","permalink":"https://rogerspy.gitee.io/2021/03/21/neural-language-model-ffnnlm/","excerpt":"1. 简介统计语言模型中，无论是 n-gram 还是对数线性语言模型都面临一个非常严重的问题——维度爆炸。为了解决维度爆炸问题，Bengio &amp; Bengio 2000 年提出了一种使用分布式词特征表示的方法，也就是后来所说的词向量。","text":"1. 简介统计语言模型中，无论是 n-gram 还是对数线性语言模型都面临一个非常严重的问题——维度爆炸。为了解决维度爆炸问题，Bengio &amp; Bengio 2000 年提出了一种使用分布式词特征表示的方法，也就是后来所说的词向量。 在他们的方法中是将每个词利用神经网络映射到一个连续的向量空间中得到词向量。其实这种方法与对数线性语言模型使用不同特征表示词有异曲同工之妙，只是对数线性语言模型中的特征是人工构建，而且是离散化的。词特征的连续分布式表示相对离散化表示有两个显著的优点： 可以将向量维度压缩到很低； 可以计算词与词之间的距离，用以表示语义相似度。 随着技术的发展，原来的词向量表示维度还是太高。为了降维，人们又发展出了离散化词向量表示技术，但是这种离散化表示技术与对数线性语言模型中的词特征表示法已经不是同一个东西了。 比如，一个 2-d 的向量，离散化向量最多只能表示 4 个词：$[0, 0],[0,1],[1,0],[1,1]$，而连续分布向量则可以表示无数个词：$[0.1,0.2],[0.1, 0.3], [0.11,0.22],…$。所以要想表达更多的词，离散化向量就需要更多的维度，而连续分布向量就不需要。另外，我肯可以看到，离散化向量两两都是正交的，这就意味着两两之间的距离是相等的，也就是丢失了词义。再看连续分布向量，明显两两之间的距离并不相同，这样我们就可以利用这种差异来表示词与词之间的语义相似度。 其实这种将符号用一个连续向量表示的方法在很早之前就出现了，上世纪 80 年代的联结主义就曾使用过。到了 2000 年左右的时候，神经网络技术日渐成熟，人们就利用神经网络将不同的符号表示成连续向量来表示不同的符号之间的关系。 而使用神经网络直接对语言进行建模也是很早就出现了，当时的人们更加关注于每一个词在语言中扮演的角色。利用神经网络对条件概率进行建模的方式首先出现在对词的建模上，即给定前面的字母来预测后一个字母。 最早使用神经网络对语言模型进行条件概率建模的是徐伟，在其 2000 年的论文《Can Artificial Neural Networks Learn Language Models?》提出了一种构建 2-gram 语言模型的方法，但是由于没有隐藏层，且只是二元语言模型，因此限制了其模型泛化能力和上下文语义捕捉能力。 第一个具有现代意义上的真正神经网络语言模型是 Bengio 等人提出的 Feedforward Neural Network Language Model, （FFNNLM）。接下来我们就从这篇文章开始，介绍几个具有代表性的神经网络语言模型。 2. FFNN 语言模型2.1 神经模型假设有一个训练集 $X$，训练集中每一句话 $x_i \\in X$ 是由词序 $\\langle w_1, w_2, …, w_T \\rangle$ 组成，其中 $w_t \\in \\mathcal{V}$，$\\mathcal{V}$ 表示词表。词表通常很大，但是是有限的。我们的目标是构建一个模型： f(w_t, ..., w_{t-n+1}) = p(w_t|w_{1:t-1})使得训练集中的句子具有较高的概率分布。另外，模型必须满足一个限制条件： \\sum_{i=1}^{|\\mathcal{V}|} f(i, w_{t-1}, \\cdots,w_{t-n+1})=1有了以上限制条件以后，Bengio 等人就设计出下面一个神经网络模型： 模型可以分成两部分： 一个映射 $C \\in \\mathbb{R}^{|\\mathcal{V}| \\times m}$，将词表中的词映射成分布式特征向量，$C(w_i) \\in \\mathbb{R}^m$。$C$ 是一个自由参数矩阵。 一个概率函数 $g$ 用来计算特征向量序列 $\\langle C(w_{t-n+1}), \\cdots, C(w_{t-1}) \\rangle$ 的条件概率。$g$ 的输出是句子中第 $t$ 个词出现的概率。既然是神经网络语言模型，那么 $g$ 肯定就是一个神经网络啦。 假设有一个句子 $\\langle w_1, w_2, …, w_T \\rangle$，整个模型的建模过程如下： 选取滑动窗口大小 $n$，对特征向量序列进行滑动切片，得到 $\\mathrm{ngrams}=[(w_1, w_2, \\cdots,w_n), (w_2, w_3, \\cdots, w_{n+1}), (w_3, w_4, \\cdots, w_{n+2}),\\cdots, (w_{T-n}, \\cdots, w_{T})]$。比如 $\\langle 我，爱， 北京，天安门 \\rangle, n=3$，滑动切片以后得到 $[(我，爱， 北京),(爱，北京，天安门)]$。 $\\langle w_{t-n+1}, \\cdots, w_{t-1} \\rangle$ 表示 $\\mathrm{ngrams}$ 中第 $t$ 项的前 $n-1$ 个词，比如 $t=1$，则 $\\langle w_{t-n+1}, \\cdots, w_{t-1} \\rangle$ 表示 $(我,爱)$。将其中每个词 $w_i$ 使用 $C$ 映射成特征向量，得到 $\\langle C(w_{t-n+1}), \\cdots, C(w_{t-1}) \\rangle$。比如 $(我，爱，北京)$，$C(我)=[0.1, 0.3, 0.12], C(爱)=[0.2, 0.23, 0.4]$，那么可以得到特征向量序列（其实就是个特征矩阵）： x_{\\mathrm{in}}=\\left[ \\begin{matrix} 0.1 & 0.2 \\\\\\\\ 0.3 & 0.23 \\\\\\\\ 0.12 & 0.4 \\end{matrix} \\right] 特征向量序列，就相当于神经网络的输入层。输入层的特征向量序列传递到隐藏层，在隐藏层经过 $\\tanh$ 变换： x_{\\mathrm{hidden}} = \\tanh(d+Hx_{\\mathrm{in}})其中 $H$ 和 $d$ 分别表示隐藏层的权重和偏置。 经过隐藏层变换之后，传入输出层，在输出层经过线性变换： x_{\\mathrm{out}} = b+Wx_{\\mathrm{in}} + Ux_{\\mathrm{hidden}}其中 $b,W,U$ 也是神经网络的参数。经过输出层的变换我们就可以得到一个 $x_{\\mathrm{out}} \\in \\mathbb{R}^{|\\mathcal{V}| \\times m}$ 的输出矩阵。矩阵的每一列都代表 $w_t$ 可能的分布。 神经网络输出一个 $C(w_t)$ 的候选集，要从这些候选集中选取正确的 $C(w_t)$，就需要将这些候选集转化成概率分布，选择概率最高的那一列对应的向量。最常见的方法是使用 $\\mathrm{softmax}$ 函数： \\mathrm{softmax}(x_{\\mathrm{out}}) = \\frac{\\exp(x_{\\mathrm{out}})}{\\sum_{w_i}\\exp(x_{\\mathrm{out}})}这样其实就是对 $(我，爱，北京)$ 的建模过程：输入 $(我，爱)$，输出 $(我，爱)$ 后面所有可能出现的词的概率分布。 有了这样一个过程以后，就可以对整个 $\\mathrm{ngrams}$ 进行相同的建模过程。我们的目标是模型每次预测出来的词都是正确的，即我们希望找到一套参数 $\\theta$，最大化对数似然函数： L=\\frac{1}{T} \\sum_t \\log f(w_t, _{t-1}, \\cdots, w_{t-n+1}; \\theta) + R(\\theta)其中 $R(\\theta)$ 表示正则项（只对权重做正则，不对偏置）。 要找到一套合适的参数，神经网络通常采用的方法是随机梯度下降方法： \\theta \\leftarrow \\theta + \\epsilon\\frac{\\partial \\log p(w_t|w_{t-n+1}, \\cdots, w_{t-1})}{\\partial\\theta}其中 $\\epsilon$ 表示学习率。 2.2 模型参数量分析模型参数来源于两部分： $C \\in \\mathbb{R}^{|\\mathcal{V}| \\times m}$ 是一个矩阵，$C(w_i)$ 表示矩阵第 $i$ 行对应的向量，即为 $w_i$ 对应的特征向量； $g$ 是一个神经网络，$\\pmb{\\omega}$ 表示神经网络的参数，从上面我们可以确定 $\\pmb \\omega = (b,d,W,U,H)$。 所以，整个模型的参数为 $\\theta = (C, b,d,W,U,H)$。 $C$ 是一个 $\\mathbb{R}^{|\\mathcal{V}|\\times m}$ 的矩阵，所以参数量为：$|\\mathcal{V}|\\times m$; 假设有 $h$ 个神经元，隐藏层的权重 $H$ 参数量为：$h \\times (n-1)m$； 从隐藏层到输出层的权重 $U$ 参数量为：$|\\mathcal{V}| \\times h$； 从输入层到输出层的权重 $W$ 参数量为：$|\\mathcal{V}| \\times (n-1)m$； 输出层偏置 $b$ 的参数量为：$|\\mathcal{V}|$； 隐藏层偏置 $d$ 的参数量为：$h$。 那么总的参数量为以上所有参数的数量相加得到：$|\\mathcal{V}|(1+mn+h)+h(1+(n-1)m)$。可以看到整个模型的参数随着词表 $\\mathcal{V}$ 线性增长，不像统计语言模型那样是指数型增长的。另外，模型参数量也与滑动窗口大小 $n$ 成正比。 3. 实验结果 4. 总结Bengio 等人提出一种使用神经网络训练 n-gram 模型的方法，该方法具有以下几个优点： 相比传统的统计语言模型，Ngram的N增加只带来线性提升，而非指数复杂的提升； 通过高维空间连续稠密的词向量解决统计语言模型中解决稀疏的问题，不用进行平滑等操作； 另外词向量的引入解决统计语言模型部分相似性的问题，为后续词向量时代的发展做铺垫； 相比传统的统计语言模型，神经网络的非线性能力获得更好的泛化能力，perplexity（困惑度下降） 但是不可避免的也存在一些缺点： 不能处理变长句子序列。由于输入层的神经元是固定的，因此模型必须输入固定长度的序列。 由于输入序列长度是固定的，因此，模型只能对固定长度的上下文进行建模，而不是对整段序列进行建模。 序列中的词没有包含位置信息，而实际上我们知道，对于相同的几个词，放在不同的位置整句话就会表达不同的意思。 尽管全接连神经网络需要学习的参数量远小于 n-gram 但是相比于其他结构的神经网络，其参数量还是过大。 语言模型的发展随着这篇文章的诞生进入了一个崭新的时代。 5. ReferenceA Neural Probabilistic Language Model. Yoshua Bengio， Réjean Ducharme，Pascal Vincent，Christian Jauvin，2003","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/tags/nlp/"},{"name":"Language Model","slug":"language-model","permalink":"https://rogerspy.gitee.io/tags/language-model/"},{"name":"FFNNLM","slug":"ffnnlm","permalink":"https://rogerspy.gitee.io/tags/ffnnlm/"}]},{"title":"预训练语言模型-对数线性语言模型","slug":"ptm-log-linear-language-model","date":"2021-03-16T15:46:29.000Z","updated":"2022-01-12T08:37:38.402Z","comments":true,"path":"2021/03/16/ptm-log-linear-language-model/","link":"","permalink":"https://rogerspy.gitee.io/2021/03/16/ptm-log-linear-language-model/","excerpt":"1. 前言回想语言模型问题，我们的任务是在给定前 $j-1$ 个词的情况下，预测第 $j$ 个词： p(W_j=w_j|W_1=w_1, W_2=w_2, ..., W_{j-1}=w_{j-1}) = p(w_j|w_1, w_2, ..., w_{j-1})在马尔科夫假设条件下： p(w_j|w_1, w_2, ..., w_{j-1}) \\approx p(w_j|w_{j-n+1:j-1})","text":"1. 前言回想语言模型问题，我们的任务是在给定前 $j-1$ 个词的情况下，预测第 $j$ 个词： p(W_j=w_j|W_1=w_1, W_2=w_2, ..., W_{j-1}=w_{j-1}) = p(w_j|w_1, w_2, ..., w_{j-1})在马尔科夫假设条件下： p(w_j|w_1, w_2, ..., w_{j-1}) \\approx p(w_j|w_{j-n+1:j-1}) 在进行参数估计的时候，为了避免因数据稀疏化造成的零词频问题，引入了各种平滑技术。在使用平滑技术的时候，有诸多限制，比如稍有不慎可能造成概率和不为 1 的情况，比如对于线性插值法来说，一旦 n-gram 过多引入的 $\\pmb{\\alpha}$ 超参数的搜索空间也会变大，找到一个合适的 $\\pmb{\\alpha}$ 会变得很困难，另外参数估计的复杂度也会变得很高；对于加性平滑和减值平滑来说，对于零词频词的概率分配引入过多的人为假设。 下面我们介绍一种新的解决数据稀疏带来的参数估计困难的方法——对数线性语言模型（log-linear language model）。实际上对数线性模型在自然语言处理领域有着广泛的应用，这里只介绍利用对数线性模型对语言进行建模，即所谓的对数线性语言模型。 2. 对数线性模型（Log-Linear Model）假设有一个模型可能的输入集 $\\mathcal{X}$ ，一个模型可能的有限输出集 $\\mathcal{Y}$，一个函数 $f:\\mathcal{X}\\times\\mathcal{Y}\\rightarrow\\mathbb{R}^d$ 可以将 $(x,y)$ 映射到一个特征向量，其中 $d$ 为向量的维度，另外还有一个参数向量 $v\\in\\mathbb{R}^d$。对于任意的 $\\{(x, y)|x\\in \\mathcal{X}, y\\in \\mathcal{Y}\\}$，我们定义： p(y|x; v) = \\frac{\\exp(v\\cdot f(x, y))}{\\sum_{y' \\in \\mathcal{Y}}\\exp(v \\cdot f(x, y'))}其中 $v \\cdot f(x,y) = \\sum_{k=1}^d v_k \\cdot f_k(x, y)$ 表示 $v$ 和 $f(x, y)$ 的内积。上式的意义是在模型参数为 $v$ 时，在 $x$ 的条件下，出现 $y$ 的概率。 既然模型的名字是线性对数模型，那么显然，我们要对上式求对数： \\log p(y|x;v) = v \\cdot f(x,y) -\\log \\sum_{y' \\in \\mathcal{Y}} \\exp(v \\cdot f(x, y'))令： g(x) = \\log \\sum_{y' \\in \\mathcal{Y}} \\exp(v \\cdot f(x, y'))上式得： \\log p(y|x;v) = v\\cdot f(x,y) -g(x)从上式可以看出，只要 $x$ 固定，那么 $\\log p(y|x, v)$ 就是一个线性方程，所以模型的名称是对数线性模型。 好了，我们已经给出了对数线性模型的定义了，那这样一个模型和语言模型有什么关系呢？假设我们有下面一段话： 我是中国少年先锋队队员，我在队旗下宣誓，我决心遵守队章，在中国共产党和共青团的领导下，做个好队员。好好学习，好好工作，好好劳动，准备着为共产主义和祖国的伟大事业，贡献出一切（ ）！ 我们首先令 $\\pmb{h}$ 表示 n-gram，$y$ 表示需要填入括号中的词，计算 $v \\cdot f(\\pmb{h}, y)$ 内积，可以得到： $v \\cdot f(\\pmb{h}, y=力量)$ $v \\cdot f(\\pmb{h}, y=小明)$ $v \\cdot f(\\pmb{h}, y=什么)$ $\\cdots$ $v \\cdot f(\\pmb{h}, y=这样)$ $8.1$ $0.5$ $-2.1$ $\\cdots$ $0.01$ 要计算表格中的数据，首先要确定 $v$ 和 $f(\\cdot)$，这个我们在后面的内容里详细介绍，现在先假定这两个是确定的，然后我们可以根据他们在给定 $\\pmb{h}$ 和 $y$ 的情况下计算出相应的内积值。我们计算出来的内积可以是任意实数，包括正数、负数等等。 然后将计算出来的内积取 $e$ 指数：$\\exp(v \\cdot f(x,y))$，这样就保证了结果是非负数的了。 然后我们对结果求和：$\\sum_{y’ \\in \\mathcal{Y}} \\exp(v \\cdot f(x, y’))$，再利用求和结果对计算出的每一项进行归一化，这样我们就得到了一个对数线性模型。而该模型表示模型参数 $v$ 确定后，给定历史词 $\\pmb{h}$ 的条件下，$y$ 出现的概率。 这样一个结果不就回到了 n-gram 语言模型 $p_{\\theta}(w_j|\\pmb{h})$，在确定参数 $\\theta$ 的情况下，给定历史词 $\\pmb{h}$ 的条件下，输出 $y$ 的概率吗？ 3. 对数线性语言模型（Log-Linear Language Model）为了和 n-gram 语言模型的符号保持一致，我们这里重写对数线性模型在语言模型上的定义： \\begin{equation} \\nonumber \\begin{aligned} p_\\theta(\\pmb{X}=\\pmb{x}) &= \\prod_{j=1}^l p_{\\theta}(W_j=w_j|W_{0:j-1}=w_{0:j-1}) \\\\\\\\ &= \\prod_{j=1}^l \\frac{\\exp(\\theta \\cdot f(w_{0:j-1}, w_j))}{\\sum_{w_j \\in \\mathcal{V}}\\exp(\\theta \\cdot f(w_{0:j-1}, w_j))} \\\\\\\\ &= \\prod_{j=1}^l \\frac{\\exp(\\theta \\cdot f(w_{j-n+1:j-1}, w_j))}{\\sum_{w_j \\in \\mathcal{V}}\\exp(\\theta \\cdot f(w_{j-n+1:j-1}, w_j))} (马尔科夫假设)\\\\\\\\ &= \\prod_{j=1}^l \\frac{\\exp(\\theta \\cdot f(\\pmb{h}, w_j))}{\\sum_{w_j \\in \\mathcal{V}}\\exp(\\theta \\cdot f(\\pmb{h}, w_j))} \\\\\\\\ \\end{aligned} \\end{equation}其中 $\\theta$ 为模型参数，$f(\\cdot)$ 表示特征投影。$\\theta$ 和 $f(\\cdot)$ 都是 $d$ 维向量。 3.1 特征对于任意 $\\{(x, y)|x\\in \\mathcal{X}, y\\in \\mathcal{Y}\\}$，$f(x, y) \\in \\mathbb{R}^d$ 就是一个特征向量，其中 $f_k(x, y), k=[1,2,…,d]$，表示特征。每一维上的特征是可以任意定义的，只要是可以只通过 $\\pmb{h}$ 和 $w_j$ 计算的。通常二元法进行定义，比如： n-gram 特征。比如对于三元组特征 “$\\langle 我,爱,北京 \\rangle$”，如果 $\\pmb{h} = \\langle 我, 爱 \\rangle，w_j=北京$，令 $f_k(\\pmb{h}, w_j)=1$，否则 $f_k(\\pmb{h},w_j)=0$； 空洞 n-gram 特征。比如 “$\\langle 我,爱,北京 \\rangle$”、“$\\langle我,讨厌,北京\\rangle$”、“$\\langle 我,在,北京 \\rangle$” 等等，只要 $\\pmb{h} $ 的倒数第二个词是 “我”，并且 $w_j=北京$ ，那么就令 $f_k(\\pmb{h}, w_j)=1$，否则 $f_k(\\pmb{h}, w_j)=0$； 拼写特征，通常在英文语言模型上比较常见。比如判断一个词是否以大写字母开头，是否在词中包含数字，是否以元音字母开头等等，如果答案是 “是”，那么就令 $f_k(\\pmb{h}, w_j)=1$，否则 $f_k(\\pmb{h}, w_j)=0$； 类别特征，使用外部资源判断一个词是不是某种类别。比如是不是地名、是不是组织机构名、是不是名词、是不是形容词等，如果答案是 “是”，那么就令 $f_k(\\pmb{h}, w_j)=1$，否则 $f_k(\\pmb{h}, w_j)=0$； $\\cdots$ n-gram 特征 空洞 n-gram特征 拼写特征 类别特征 … $\\times \\times$ 特征 $f_1=1$ $f_2=1$ $f_3=0$（$w_j=北京$ 不包含数字） $f_3=1$ （$w_j=北京$ 是地名） … $f_d(\\pmb{h}, w_j)=0$ 这样，我们对 “$\\langle 我，爱，北京 \\rangle$” 构建了一个 $f(x, y)=[1,1,0,1,…,0]$ 的特征向量。 总结一下我们构建某种特征的方式： f(\\pmb{h}, w_j) = \\begin{cases} 1 & 如果 \\pmb{h}，w_j 满足某种条件 \\\\\\\\ 0 & 否则 \\end{cases}在特征构建的时候，$d$ 作为超参数出现，特征过多容易造成过拟合，特征不足会造成欠拟合。在构造特征的时候有一个重要的原则是必须遵守的，那就是区分性。也就是说任意两个不同的 $(\\pmb{h}_i,w_i)$ 和 $(\\pmb{h}_j, w_j)$ 都必须有不同的特征向量。所以通常 $d$ 的选取不应该小于 $V^{n}$ ，$n$ 表示 n-gram。 3.2 特征稀疏上述方法构建特征向量有一个很严重的问题——特征稀疏化。通常自然语言处理任务用到的 $d$ 都会非常大。以 3-gram 为例，假设我们给每一个 $(w_{j-2}, w_{j-1}, w_j)$ 分配一个特征值（one-hot），那么 $d=V^3$。如此庞大的特征量，怎样使模型更有效率就成了一个问题。 对于任意给定的 $(\\pmb{h},w_j)$ ，定义特征向量 $[f_1(\\pmb{h}, w_j), f_2(\\pmb{h}, w_j), …, f_d(\\pmb{h}, w_j)]$ 中 $f_k(\\pmb{h}, w_j)=1$ 的个数： N(\\pmb{h}, w_j) = \\sum_{f(\\pmb{h}, w_j)=1}f_k(\\pmb{h}, w_j)通过实际观察我们会发现，通常 $N(\\pmb{h}, w_j) \\ll d$。最极端的情况，考虑 one-hot 特征向量，只有一个 1，其余全部是 0。 为了解决特征稀疏的问题，我们回过头去看对数线性语言模型的定义： p_\\theta(\\pmb{X}=\\pmb{x}) = \\prod_{j=1}^l \\frac{\\exp(\\theta \\cdot f(\\pmb{h}, w_j))}{\\sum_{w_j \\in \\mathcal{V}}\\exp(\\theta \\cdot f(\\pmb{h}, w_j))}通过观察我们会发现，上式的核心是 $\\theta \\cdot f(\\pmb{h},w_j)$ 的计算： \\theta \\cdot f(\\pmb{h}, w_j) = \\sum_{k=1}^d \\theta_k\\cdot f_k(\\pmb{h}, w_j)当 $f_k(\\pmb{h},w_j)=0$ 时，$\\theta_k \\cdot f_k(\\pmb{h}, w_j)=0$，所以内积最终的结果取决于 $f_k(\\pmb{h}, w_j) \\ne 0$ 的那些特征。 有了这样一个发现，我们就可以通过一些函数（比如哈希表）找到特征向量中的非零特征对应的索引： Z(\\pmb{h}, w_j) = \\{k: f_k(\\pmb{h},w_j)=1\\}有了 $Z(\\pmb{h},w_j)$ 以后，可以得到： \\sum_{k=1}^d \\theta_k\\cdot f_k(\\pmb{h}, w_j) = \\sum_{k\\in Z(\\pmb{h}, w_j)} \\theta_k计算复杂度从 $\\mathcal{O}(d)$ 降到 $\\mathcal{O}(|Z(\\pmb{h}, w_j)|)$。 3.3 Softmax得到特征向量以后，我们可以通过 softmax 将特征向量的分数映射到概率分布上: \\mathrm{softmax}([f_1, f_2, ..., f_d]) = \\left[\\frac{\\exp(f_1)}{\\sum_{k=1}^V\\exp(f_k)}, \\frac{\\exp(f_2)}{\\sum_{k=1}^V\\exp(f_k)}, ..., \\frac{\\exp(f_d)}{\\sum_{k=1}^V\\exp(f_k)} \\right]之所以使用 softmax 进行映射，是因为： 保持了原来向量的单调性，即原来的特征 $f_a&gt;f_b$，经过 softmax 映射以后仍然是 $f_a’&gt;f_b’$; softmax 将原来的特征向量映射到了概率分布上，即向量所有元素和为 1； 向量中的每个元素代表其对应的历史词 $\\pmb{h}$ 出现的概率。 3.4 系数/权重一旦我们将特征映射到特征向量以后，就可以计算 $\\theta \\cdot f(\\pmb{h}, w_j)$ 了，其中 $\\theta$ 我们称之为特征权重或者特征系数。我们可以将这样一个线性映射看成是 n-gram 的得分，特征权重 $\\theta$ 中的每一维决定了特征向量中的每一个向量对 n-gram 最终得分的影响力。假设 $f_k(\\pmb{h},w_j)=1$： 当 $\\theta_k &gt; 0$ 时，表明 $f_k(\\pmb{h}, w_j)$ 在 n-gram 中起到了正向作用，即 $(\\pmb{h},w_j)$ 出现的概率更高了； 当 $\\theta_k&lt;0$ 时，表明 $f_k(\\pmb{h}, w_j)$ 在 n-gram 中起到了反向作用，即 $(\\pmb{h},w_j)$ 出现的概率更低了； 当 $\\theta_k=0$ 时，表明 $f_k(\\pmb{h}, w_j)$ 在 n-gram 中没有任何影响，即 $(\\pmb{h},w_j)$ 出现的概率不变； 知道了 $\\theta$ 的意义，那么我们该怎么得到权重系数向量呢？还是靠验证集一个一个试吗？显然不靠谱，接下来就介绍一下 $\\theta$ 的估计方法。 3.4.1 对数似然函数之前我们定义了对数线性语言模型，每一个 n-gram 的对数概率是： \\log p(w_j|\\pmb{h},\\theta)那么每个句子的对数概率为： L_\\theta(\\pmb{X}=\\pmb{x}) = \\sum_{j=1}^l \\log p(w_j|\\pmb{h},\\theta)如果我们将 $\\theta$ 作为变量，即： L_{\\pmb{x}}(\\theta) = \\sum_{j=1}^l \\log p(w_j|\\pmb{h},\\theta)可以将此式理解为：参数 $\\theta$ 在多大程度上使语言模型接近训练数据。我们的目标是找到一套参数，使得语言模型最大程度接近训练数据： \\theta = \\arg \\max_{\\theta \\in \\mathbb{R}^d} L_{\\pmb{x}}(\\theta)在考虑如何对上式求解之前，我们思考这样一种情况：假设我们有一个三元组 $s = \\langle 我，爱，北京\\rangle$ 在训练集中只出现了一次，此时 $\\theta$ 应该是什么样的。 根据概率最大原则，因为 $s$ 只出现一次，没有其他三元组和它分割概率，那么它出现的概率最大应该是 1，也就意味着： p_\\theta(\\pmb{X}=\\pmb{我爱北京天安门}) = \\prod_{j=1}^l \\frac{\\exp(\\theta \\cdot f(\\pmb{h}, w_j))}{\\sum_{w_j \\in \\mathcal{V}}\\exp(\\theta \\cdot f(\\pmb{h}, w_j))}=1上式分子为（假设特征向量只有$f_k=1$，其余全部为零）： \\exp(\\theta_k)分母为： \\sum_{w_j \\in \\mathcal{V}}\\exp(\\theta_k)当且仅当 $\\theta_k \\rightarrow \\infty$ 时 \\lim_{\\theta_k \\rightarrow \\infty} \\frac{\\exp(\\theta_k)}{\\sum \\exp(\\theta_k)} = 1也就是说，这种情况会导致特征权重接近无穷，这显然是不对的。为了解决这个问题，通常采用的方法是加入正则化。 3.4.2 正则化正则化的方法有很多，比如 L1 正则化、L2 正则化等等。常用的正则化是 L2 正则化， 定义如下： ||\\theta||^2 = \\sum_k \\theta_k^2其中 $||\\theta||$ 表示向量 $\\theta$ 的欧拉长度，即 $||\\theta|| = \\sqrt{\\sum_k \\theta_k^2}$。经过正则化修正的目标函数为： L'(\\theta)=\\sum_{j=1}^l \\log p(w_j|\\pmb{h};\\theta) - \\frac{\\lambda}{2} \\sum_k\\theta_k^2其中 $\\lambda&gt;0$ 是一个超参数。 使用正则化避免出现参数过大的原理是这样的：上式第一项的意义是参数 $\\theta$ 能使语言模型在多大程度上接近训练数据；第二项的意义是对参数过大的惩罚项：它希望参数尽可能接近零，因为欧拉距离是大于等于零的，$\\lambda$ 也是一个大于零的数，也就是说第二项是一个大于零的数，要想使得 $L’(\\theta)$ 尽可能大，就需要上式中第一项尽可能大，而第二项尽可能小。 3.4.3 梯度下降有了目标函数以后，我们可以通过梯度下降算法对参数进行更新，直到参数收敛。 参数更新过程如下： 初始化 $\\theta=\\pmb{0}$ （元素全部是 0 的向量） 重复下面的过程： 计算 $\\delta_k=\\frac{dL’(\\theta)}{d\\theta}, k=[1,2,…,d]$; 计算 $\\beta^*=\\arg \\max_{\\beta \\in \\mathbb{R}}L’(\\theta+\\beta \\delta)$， 更新 $\\theta \\leftarrow \\theta + \\beta^*\\delta$ 其中 \\frac{dL'(\\theta)}{d_{\\theta_k}} = \\sum_{i=1}^n f_k(\\pmb{h}^{(i)}, w_j^{(i)})-\\sum_{i=1}^n\\sum_{w_j\\in\\mathcal{Y}} p(w_j|\\pmb{h}^{(i)};\\theta)f_k(\\pmb{h}_{(i)}, w_j)-\\lambda\\theta_k4. 小结对数线性模型的出现为我们打开了一条通往神经网络语言模型的道路，我们发现对数线性语言模型中蕴含的思想已经具备了神经网络语言模型的雏形。尤其是将 n-gram 扩展到了特征这一概念，为后来的特征向量分布式表示奠定了基础。这里使用的特征构建方法虽然简单，但是与分布式特征向量表示相比也存在着优点，那就是每一维上的特征都具有具体的含义，这就意味着，该模型是具有可解释性的。神经网络语言模型对特征的自动构建也有很多对数线性语言模型特征向量不具备的优势，比如无需人工参与、可以大幅度缩减参数维度、可计算词与词之间的语义关系等。总而言之，对数线性语言模型简约而不简单。","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/tags/nlp/"},{"name":"Log-Linear Language Model","slug":"log-linear-language-model","permalink":"https://rogerspy.gitee.io/tags/log-linear-language-model/"}]},{"title":"预训练语言模型-统计语言模型","slug":"ptm_probabilistic_language_model","date":"2021-03-16T12:32:36.000Z","updated":"2022-01-12T08:37:38.405Z","comments":true,"path":"2021/03/16/ptm_probabilistic_language_model/","link":"","permalink":"https://rogerspy.gitee.io/2021/03/16/ptm_probabilistic_language_model/","excerpt":"1. 简介1.1 词表/语料词表表示语言中包含的所有的词，比如对于中文来说：","text":"1. 简介1.1 词表/语料词表表示语言中包含的所有的词，比如对于中文来说： \\mathcal{V} = \\{我, 爱, 北京, 天安门, ...\\} ps: 实际上对于中文来说，词表可以分成两类：字表和词表。字表就是所有的汉字，词表指的是汉字组成的词。由于中文句子中不存在英文那种使用空格作为词与词之间的分割符的标志，因此怎样准确地进行分词也是中文自然语言处理的非常重要的工作。使用字作为句子的基本单位不存在分词的问题但是会丢失部分以词作为基本单位的语义信息。因此，以字和词作为句子的基本单位各有优劣。我们在这里讨论语言模型的时候以词作为基本单位。 令 $x = w_1w_2…w_n$ 表示一个句子，其中 $w_i \\in \\mathcal{V}$ 以及 $i \\in \\{ 1, …, (n-1)\\}, n\\ge 1$。令 $V$ 表示词表 $\\mathcal{V}$ 的大小，写作 $|\\mathcal{V}|$。 我们假设 $w_n$ 是一个特殊符号—— $STOP$ ，这个符号包含在词表中（在后面的内容中我们可以看到为什么要定义这样一个符号了），比如： 我爱北京天安门STOP 我爱吃苹果STOP 小狗好可爱STOP … 令 $\\mathcal{V}^+ = \\{x_1, x_2, …\\}$ 表示所有由词表中的词组成的句子集合。$\\mathcal{V}^+$ 是一个无限集，因为句子的长度是可以任意的（$\\ge 1$）。 一个理想的词表应该包含索要处理的语言的所有词汇，但实际上这是不可能的，因为： 每种语言（被广泛使用的）随时随刻都在产生新的词汇，有些是从别的语言借鉴而来，有些是随着新生事务的产生而产生的； 通常在构建词表的时候是通过训练语料，训练语料的数量是有限了，不可能包含该种语言的所有句子； 一个新词可以通过一些规则排列组合，而这样的组合可以产生的新词数量是无穷无尽的； 即使是同一个字/词在不同的时代都会有不同的拼写方式。 由于以上原因的限制，我们所用到的词表通常是有限的。而一个不能包含所有词汇的词表通常会遇到一个问题，当我们处理的句子中包含一个不在词表中的词时，我们称这个问题为 OOV（Out Of Vocabulary）问题，而这个不在词表中的词称之为“未登录词”。未登录词的出现会给自然语言处理任务带来很大的困扰，对于传统的统计方法来说，未登录词就意味着我们没有关于这个词的统计信息，无法将它纳入模型中；对于神经网络来说，我们没有办法对它进行向量化，也会对后续的模型训练和推理造成问题。 面对 OOV 问题通常有三种解决方式： 在词表中添加一个特殊符号，比如 “” ，用来表示所有未登录词。在训练数据中，将一些出现频率较低的词替换成 “”。 对于形态学上比较丰富的语言，可以训练一个模型将一个词分割成几个子串可以覆盖更多的词汇，比如对于英语来说，可以把 “starting” 分成 “start” 和 “ing” 两部分，这样即使词表中没有 “starting” 这个词，也不会遇到 OOV 问题。 使用字，而不是使用词来处理，或者字和词相互结合的方式。对于任何一种语言来说，它的最基本元素是字，而字的个数通常是有限的，任何一个词都可以使用字的组合来实现。比如英文只有26个字母，中文常用字也不过万。 最常用，成本最低的方式是将未登录词替换成 ，因此这里我们以这种方式为例介绍语言模型。 1.2 语言模型的定义语言模型是一个随机变量的概率分布，随机变量的值来源于 $\\mathcal{V}^+$ 中。因此语言模型可以定义为 $p:\\mathcal{V}^+ \\rightarrow \\mathbb{R}$： \\forall x \\in \\mathcal{V}^+, p(x) \\ge 0, \\\\\\\\ \\sum p(X=x) = 1建立一个语言模型可以分成以下几步： 收集训练语料 $x_{1:n}=\\{x_1, x_2, …, x_n\\}, x_i \\in \\mathcal{V}^+$； 从语料中构建一个词表 $\\mathcal{V}$； 定义概率分布 $p$ 的参数； 利用训练语料进行参数估计。 举例说明我们如何从训练语料中学习一个语言模型： 令 $c(x_i)$ 为训练语料中句子 $x_i$ 出现的次数，$N$ 为句子总数。我们可以令： p(x_i) = \\frac{c(x_i)}{N}这就是一个最简单的语言模型（ps：我们给这个模型取个名字叫 Creepy model 吧，其实这个名字是 Noah A. Smith 取的），他表示每个句子出现的概率。当然，这是一个非常简单的例子，因为对于没有出现在训练语料中的句子他会认为概率为 0，因此这个语言模型不能泛化到训练语料中不存在的句子上。而在接下来要介绍的统计语言模型就是为了尽可能的提升这种泛化性。 1.3 我们为什么要进行语言建模？从上面的介绍我们可以大致了解到，所谓语言模型其实就是判断一个句子出现的概率。一个经常被人们使用的句子出现的概率就会高，被人们使用频率较低的句子出现概率就会低，人们几乎不使用的句子出现的概率几乎为零。这实际上就是在判断一个句子是一个正常的为人所用的句子的概率，简而言之就是判断一句话是不是人话，比如，$p(我爱北京天安门) \\gt p(但是风格的歌)$” 说明前一句比后一句更像人话。 比如早期的语言建模动机来源于 “噪声通道范式” （noisy channel paradigm），该模型广泛应用于语音识别和机器翻译领域。比如语音识别先利用声学模型产生多个候选结果，然后利用语言模型判断哪一句话更像人话进行结果重排。 所谓的噪声通道是指，假设我们有两个随机变量，$O$ 和 $D$，$O$ 是系统输入（可观测量），$D$ 是我们希望系统的输出。我们可以认为 $O$ 的值是密文， $D$ 的值是 $O$ 解密后的源文本。解密过程需要： \\begin{equation} \\nonumber \\begin{aligned} \\pmb{d}^* &= \\arg \\max_{\\pmb{d}} p(\\pmb{d}|\\pmb{o}) \\\\\\\\ &= \\arg \\max_{\\pmb{d}} \\frac{p(\\pmb{o}|\\pmb{d})\\cdotp(\\pmb{d})}{p(\\pmb{o})} \\\\\\\\ &= \\arg \\max_{\\pmb{d}} \\underbrace{p(\\pmb{o}|\\pmb{d})}_{\\mathrm{channel\\ model}} \\cdot \\underbrace{p(\\pmb{d})}_{\\mathrm{source\\ model}} \\end{aligned} \\end{equation} 从上式可以看出，我们可以通过先验的明文（$p(\\pmb{d})$）和明文对应的密文（$p(\\pmb{o}|\\pmb{d})$）建模对密文进行解密。 \\mathrm{source} \\rightarrow D \\rightarrow \\mathrm{channel} \\rightarrow O 首先源分布随机生成一个明文值对应 $D$，然后通过在该明文中添加噪声（channel）生成观测值 $O$ 。而解码的过程就是将这个过程反过来，利用贝叶斯公式在给定观测值 $O=o$ 时得到最有可能的 $D$。 另一个很重要的原始是在语言建模过程中使用到的参数估计方法也可以被广泛应用于其他领域。 2. 语言模型前面我们举例介绍了一个非常简单的语言模型，但是这种语言模型几乎没有任何泛化性，为了使得我们的语言模型具有一定的泛化性，接下来介绍统计语言模型。 考虑一个随机变量序列 $ \\langle W_1, W_2, …, W_l \\rangle $，序列中每个随机变量可以从 $\\mathcal{V}$ 中取值。我们的目标是对于任意序列 $\\langle w_1, w_2, …, w_l \\rangle$ 对他们的联合概率进行建模，其中 $n \\ge 1, w_i \\in \\mathcal{V} (i=1, …, l)$： \\begin{equation} \\nonumber \\begin{aligned} p(W_1=w_1, ..., W_l=w_l) &= \\left( \\begin{matrix} p(W_1=w_1|W_0=w_0) \\times \\\\\\\\ p(W_2=w_2|W_0=w_0, W_1=w_1) \\times \\\\\\\\ p(W_3=w_3|W_0=w_0, W_1=w_1, W_2=w_2) \\times \\\\\\\\ \\cdots \\\\\\\\ p(W_n=w_n|W_0=w_0, W_1=w_1, W_2=w_2, ...W_{l-1}=w_{l-1}) \\end{matrix} \\right) \\\\\\\\ &= \\left( \\begin{matrix} p(W_1=w_1|W_0=w_0) \\times \\\\\\\\ p(W_2=w_2|W_{0:1}=w_{0:1}) \\times \\\\\\\\ p(W_3=w_3|W_{0:2}=w_{0:2}) \\times \\\\\\\\ \\cdots \\\\\\\\ p(W_n=w_n|W_{0:l-1}=w_{0:l-1}) \\end{matrix} \\right) \\\\\\\\ &= \\prod_{j=1}^l p(W_j=w_j|W_{0:j-1}=w_{0:j-1}) \\end{aligned} \\end{equation}我们令 $W_0=w_0=START$ 表示任意句子的起始符。 上式的 $l$ 并不是一个定值，任何语言中的句子都有不同的长度，在建模过程中我们怎么确定每个句子的长度呢？这个时候我们在介绍词表的时候介绍了一个特殊的符号——$STOP$ 就发挥作用了，当我们建模过程中遇到这个符号的时候就表明这个句子到此为止了，此时句子的长度就是 $l$。 以上的建模过程没有涉及任何假设，我们可以看到序列中每个词的产生都依赖于在它之前出现的所有的词。上式中的每一部分都是一个条件概率，对于条件概率我们可以用简单的统计方法进行估计： p(W_j=w_j|W_{0:j-1}=w_{0:j-1}) = \\frac{c(w_{0:j})}{c(w_{0:j-1})}其中 $c(\\cdot)$ 表示序列出现在语料中的次数。例如：序列 $\\langle 我， 爱， 北京， 天安门 \\rangle$ p(北京|我，爱) = \\frac{c(我，爱，北京)}{c(我，爱)}由此可得 \\begin{equation} \\nonumber \\begin{aligned} p(W_1=w_1, ..., W_l=w_l) &= \\prod_{j=1}^n \\frac{c(w_{0:j})}{c(w_{0:j-1})} \\\\\\\\ &= \\frac{\\prod_{j=1}^n c(w_{0:j})}{\\prod_{j=1}^n c(w_{0:j-1})} \\\\\\\\ &= \\frac{ \\qquad \\qquad c(w_{0:1})\\times c(w_{0:2}) \\times ... \\times c(w_{0:l-1}) \\times c(w_{0:l})}{c(w_0) \\times c(w_{0:1})\\times c(w_{0:2}) \\times ... \\times c(w_{0:l-1}) \\qquad \\qquad} \\\\\\\\ &= \\frac{c(w_{0:l})}{c(w_0)} \\\\\\\\ &= \\frac{c(\\pmb{x})}{n} \\end{aligned} \\end{equation}其中 $n$ 表示训练语料的句子数， $\\pmb{x}$ 表示由 $\\langle w_0, w_1, …, w_n \\rangle$ 构成的句子。 到了这一步我们会遗憾的发现，这样构建起来的语言模型又回到了原点，一切都未曾改变！ 2.1 Uni-Gram 模型上述建模过程我们没有涉及到任何假设，认为句子中每个词都依赖于在它之前的所有词，造成一个很尴尬的局面。现在我们走向另一个极端，给模型加入一个非常强的假设看看模型会变成什么样子：句子中的每个词都是相互独立互不依赖的。在这个假设下： p(W_j=w_j|W_{0:j-1}=w_{0:j-1}) = p_{\\theta}(W_j=w_j)那么 p_{\\theta} (\\pmb{W}=\\pmb{w})= \\prod_{j=1}^l p_{\\theta}(W_j=w_j)此时我们需要统计句子中每个词在语料中出现的概率： \\theta_w = \\frac{c(w)}{N}其中 $N$ 表示语料中所有的词的数量。注意在计算频率的时候 $START$ 符号是不进行计算的，因为它作为句子的起始符并不是由模型生成的；但是需要计算 $STOP$ 符号，因为他是作为模型生成的结果出现的，它的概率通常是 $n/N$。Uni-Gram 模型的参数量为 $V$，对应每个 $w \\in \\mathcal{V}$。 通常把 Uni-Gram 模型称之为“词袋模型”，因为它并不关注句子的顺序，只关注句子中每个词出现的概率。也就是说，对于相同的词组成的句子的概率是相同的。比如 $p(START我爱北京天安门STOP) = p(START天安门我爱北京STOP)$。 Uni-Gram 模型非常简单易于理解，建模也非常容易。虽然存在一些问题，但是在一些任务中却非常实用（比如信息检索）。 2.2 Bi-Gram 模型前面两种语言模型走了两个极端：一个过于精细导致模型不能泛化，另一个过于粗放导致模型缺乏准确。下面我们取个折中的假设：假设句子中每个词出现的概率只依赖于它前面的那个词。 p(W_j=w_j|W_{0:j-1}=w_{0:j-1}) = p_{\\theta}(W_j=w_j|W_{j-1}=w_{j-1}) \\\\\\\\ p_{\\theta}(\\pmb{X}=\\pmb{x}) = \\prod_{j=1}^l p_{\\theta} (W_j=w_j|W_{j-1}=w_{j-1})Bi-Gram 模型又叫一阶马尔科夫模型，因为这个假设是一阶马尔科夫假设。 经过前面的讨论，不难得出： \\theta_{w_j} = \\frac{c(w_{j-1}, w_j)}{c(w_{j-1})}Bi-Gram 模型参数量为词表中任意两个词的随机组合，即 $\\approx V^2$。 2.3 n-Gram 模型既然可以有一阶马尔科夫假设，那也可以有二阶马尔科夫假设，三阶马尔科夫假设等等。这些依赖马尔科夫假设的模型我们统称为 “n-Gram” 语言模型。其中 $n$ 表示当前词出现的概率依赖于前 $n-1$ 个词。 n-Gram 模型的通用形式是： p(W_j=w_j|W_{0:j-1}=w_{0:j-1}) = p_{\\theta}(W_j=w_j|W_{j-n+1:j-1}=w_{j-n+1:j-1}) \\\\\\\\ p_{\\theta}(\\pmb{X}=\\pmb{x}) = \\prod_{j=1}^l p_{\\theta}(W_j=w_j|W_{j-n+1:j-1}=w_{j-n+1:j-1})为了简化公式符号，我们令 $\\pmb{h}$ 为 $w_j$ 的历史词汇，比如对于 Bi-Gram 语言模型，$\\langle 我，爱，北京，天安门 \\rangle$ 中”北京“ 的历史词汇是”爱“，对于 Tri-Gram 语言模型来说，”北京“的历史词汇就是”我，爱“。此时，我们可以得到模型的参数： \\theta_{w_j|\\pmb{h}} = \\frac{c(\\pmb{h}, w_j)}{\\pmb{h}}n-Gram 模型中的 $n$ 值越大，模型越接近 Creepy model，$n$ 值越小模型越接近 Uni-Gram 模型。通常 $n$ 值的选取取决于训练数据，这里我们可以通过一些简单的步骤进行 $n$ 值的选取： 在构建训练数据的时候留出一部分作为验证集； 令 $\\mathcal{N}$ 为你期望的 $n$ 的取值范围集合，比如 $\\mathcal{N} = \\{1,2,3,4,5\\}$； 对于任意 $g \\in \\mathcal{N}$：（a）在训练数据集上构建 $g$-Gram 语言模型；（b）在验证集上计算 $g$-Gram 模型的困惑度（Perplexity，用来评估语言模型好坏的指标，后面会介绍）； 选择困惑度最低的 $g$-Gram 模型。 2.4 语言模型评估：困惑度（Perplexity, ppl）现在我们知道怎么样构建一个语言模型了，但我们应该怎样对我们构建的语言模型进行评估呢？目前通用的指标是困惑度（Perplexity），定义如下： \\begin{equation} \\nonumber \\begin{aligned} \\mathrm{perplexity}(p;\\bar{\\pmb{x}}) &= 2^{-\\left(\\frac{1}{M}\\log_2\\prod_{i=1}^m p(\\bar{\\pmb{x}}_i)\\right)} \\\\\\\\ &= 2^{-\\left(\\frac{1}{M}\\sum_{i=1}^m -\\log_2 p(\\bar{\\pmb{x}}_i)\\right)} \\end{aligned} \\end{equation}其中 $\\bar{\\pmb{x}}$ 是未参与训练的验证集（验证集不能参与训练这一点非常重要），$M$ 是验证集中词的数量。这个公式看起来好吓人哦，但是别着急，我们拆开了，掰碎了一点一点来看，这到底是个什么东西。 假设我们在训练数据集之外有一个验证数据集，$\\langle \\bar{\\pmb{x}}_1, \\bar{\\pmb{x}}_2, …, \\bar{\\pmb{x}}_m \\rangle$，其中每个 $\\bar{\\pmb{x}}_i, i \\in \\{1, 2, …, m\\}$ 都是一个句子，每个句子都是由 $\\langle w_{i1}, w_{i2}, …, w_{in} \\rangle$ 组成的序列，$w_{ij}, j \\in \\{1,2,…,n\\}$ 表示句子 $\\bar{\\pmb{x}}_i$ 中的第 $j$ 个词。 对于验证集中的每一句话我们都可以计算它的概率 $p(\\bar{\\pmb{x}}_i)$，那么对于整个验证集的所有句子出现的概率为： p(\\bar{\\pmb{x}})=\\prod_{i=1}^m p(\\bar{\\pmb{x}}_i)直观上来讲，语言模型的质量越高，那么 $p(\\bar{\\pmb{x}})$ 的值应该越大。困惑度指标就是基于这一基本假设提出的。 假设我们的验证集中包含 $N$ 个词，我们定义： \\frac{1}{N}\\log_2\\prod_{i=1}^mp(\\bar{\\pmb{x}}_i) = \\frac{1}{N} \\sum_{i=1}^m \\log_2p(\\bar{\\pmb{x}}_i) 这里先回答两个问题： 为什么要取对数？ ① 语言模型作为一种概率分布，对于每一个句子出现的概率一定是满足 $0&lt;p(\\pmb{x})&lt;1$ 的，即使每个句子出现的概率都能达到 0.99，当我们的验证语料包含 1 万个句子的时候，$\\prod_i p(\\pmb{x}_i) = 0.99^{10000} \\approx 2.2e^{-44}$。所以我们看到，我们直接相乘的时候很容易造成极小的数字，最后精度溢出。而如果我们取对数，最后的结果会是 $\\log_2(0.99^{10000})\\approx -145$，这样就不会造成精度溢出问题了 。 ② 对于计算机来说，乘法的效率要低于加法，因此，通过取对数将计算过程从乘法变成加法，提高了困惑度的计算效率。 为什么以 2 为底？ 首先，其实以几为底并不重要，因为通过下面的介绍我们会发现，最后还是会通过取 2 的指数来进行 “还原”，2 的作用相当于被抵消了。其次，以 2 为底可以使计算曲线更加平滑，不会造成大起大落的效果。 实际上对于这两个问题以上的解释并没有触及问题的本质，要真正理解这两个问题需要从信息熵的角度出发，具体可以看这里。 有了以上定义，我们就可以定义困惑度了： \\mathrm{perplexity} = 2^{-l} \\\\\\\\ l = \\frac{1}{N} \\sum_{i=1}^m \\log_2p(\\bar{\\pmb{x}}_i)困惑度取了负指数，说明困惑度值越低，语言模型越好。为什么要这样定义呢？我们以最简单的情形加以说明。 假设我们有一个词表 $\\mathcal{V}$ ，词表大小为 $V$，语言模型服从均匀分布，即对于语言模型来说词表中的每个词出现的概率是一样的，比如对于 Uni-Gram 来说 $p(w_i) = 1/V$，对于Bi-Gram 来说 $p(w_i|w_{i-1})=1/V$ 等等。我们将这样一个分布代入到上面的困惑度计算公式中会发现困惑度为 $V$，也就是词表的大小。 因此，我们可以认为，困惑度其实相当于一个等效词表，困惑度的值表明对于模型来说预测下一个词有多少种选择。比如困惑度为 120 时，当模型遇到“我爱”的时候需要从 120 个选择中准确找到“北京”这个词。（选择越多越困惑） 接下来我们一步一步解析困惑度的计算过程： 计算验证集中每个句子的概率：$p(\\bar{\\pmb{x}}_i), i \\in \\{1, 2, …m\\}$； 对每个句子的概率取对数：$\\log_2 p(\\bar{\\pmb{x}}_i), i \\in \\{1,2,…,m\\}$； 计算每个词出现的平均概率：$\\frac{1}{M} \\sum_{i=1}^m \\log_2p(\\bar{\\pmb{x}}_i), i \\in \\{1,2,…m\\}$； 将平均概率作为指数计算：$2^{-\\frac{1}{M} \\sum_{i=1}^m \\log_2p(\\bar{\\pmb{x}}_i)}, i \\in \\{1,2,…m\\}$。 需要注意的是困惑度并不是一个完美的指标，困惑度降低并不一定意味着语言模型质量的提升，影响困惑度的因素主要有以下几个： 训练数据集越大，困惑度会下降得更低，十亿数据量的语料和十万数据量的语料训练效果是很不一样的； 数据中的标点会对模型的困惑度产生很大影响，一个句号能让困惑度波动几十，标点的预测总是不稳定； 预测语句中的“的，了”等无意义词（通用词）也对困惑度有很大影响，可能“我借你的书”比“我借你书”的指标值小几十，但从语义上分析有没有这些停用词并不能完全代表句子生成的好坏。 因此，在对比两个 模型的困惑度的时候要记住两个原则： 使用不同词表的语言模型对比困惑度没有意义； 概率和不等于 1 的语言模型困惑度没有意义。 所以，评估语言模型时可以用困惑度大致估计训练效果，作出判断和分析，但它不是完全意义上的标准，具体问题还是要具体分析。 3. 语言模型参数估计中的稀疏化问题前面在介绍语言模型参数估计的时候是通过统计相对频率的方式，这种方式我们称之为最大似然估计。在实际情景中，我们直接用最大似然估计进行参数估计的时候会有一个问题——数据稀疏化。 随着 n-Gram 模型中 $n$ 的增大，模型参数量以 $\\approx V^n$ 的指数形式增长，如此大量的参数必然造成参数的稀疏，比如词表大小 $V=10000$，$n=3$ （这也是常见的语言模型），此时模型参数量为 $\\approx 10^{12}$。拥有如此大量的参数而训练集有限的情况下，必然有很多计数为零的情况出现： 当 $c(\\pmb{h},w_j)=0$ 时，会导致在训练集中没有出现的句子的概率为 0，这显然是不对的，因为训练集并没有包含所有的句子； 当 $c(\\pmb{h})=0$ 时，会导致参数没有意义，因为作为分母是不能为 0 的。 为了使语言模型达到可用状态，我们需要使用平滑技术（smoothing）来消除这些统计词频为零的情况。平滑的基本思想就是从高概率的句子中抽取微小的概率分配给零概率的句子，有点类似“劫富济贫”。在使用平滑技术的时候有一点要非常小心，那就是我们必须保证平滑完以后的语言模型概率和仍为 1。这里介绍三种平滑技术：线性插值平滑（Linear Interpolation Smoothing）、加性平滑（Additive Smoothing）和减值平滑（Discounting Smoothing）。 3.1 线性插值平滑前面介绍 Creepy 模型 和 Uni-Gram 模型的时候说这两个模型走了两个极端，然后通过调整 $n$ 来控制语言模型的精细度。由此可见，不同 $n$ 对应的语言模型的优缺点是不同的，比如 Uni-Gram 一定不会出现统计频率为零的情况出现，但忽略了词与词之间的依赖关系，而 Bi-Gram 模型可能出现零词频的情况，但比 Uni-Gram 多了对词之间依赖关系的考虑，如果我们将两个模型结合起来，既可以保留 Bi-Gram 的依赖关系，又可以保留 Uni-Gram 的非零词频的优点岂不是美哉。 \\hat{\\theta}(w_j|w_{j-1}) = \\alpha \\theta(w_j|w_{j-1}) + (1-\\alpha)\\theta(w_j)其中 $\\alpha \\in [0,1]$。利用 Uni-Gram 对 Bi-Gram 进行插值，只要 $\\alpha \\gt 0$，既保证了 Bi-Gram 不会出现零概率，也保证了 Uni-Gram 的词依赖。这就是线性插值的基本思想：利用低元 n-Gram 模型对高元 n-Gram 模型进行线性插值，取长补短。 将上面的例子扩展到一般情况： \\hat{\\theta}(\\pmb{h}, w_j) = \\sum_{k=1}^{n-1} \\alpha_{k}\\theta_k(\\pmb{h}, w_j), \\\\\\\\ \\sum_{k=1}^{n-1} \\alpha_k = 1, \\alpha_k \\in \\mathbb{R}_{+}^{n-1}那么我们如何选择 $\\alpha_k$ 的值呢？一个常用的方法和前面介绍 n-Gram 模型时，介绍选取 $n$ 值的方法一样，利用验证集找到最合适的 $\\alpha_k$ 值。但是无论怎么选，有一个大的原则：在高元语言模型分母遇到零词频的时候令对应的 $\\alpha_k=0$。 比如：Tri-Gram \\begin{equation} \\nonumber \\begin{aligned} \\hat{\\theta}(w_j|w_{j-1}, w_{j-2}) &= \\alpha_1\\theta(w_j|w_{j-1}, w_{j-2})+\\alpha_2\\theta(w_j|w_{j-1})+\\alpha_3\\theta(w_j) \\\\\\\\ &= \\alpha_1 \\frac{c(w_{j-2}, w_{j-1}, w_j)}{c(w_{j-2}, w_{j-1})} + \\alpha_2\\frac{c(w_{j-1}, w_j)}{c(w_{j-1})} + \\alpha_3 \\frac{c(w_j)}{N} \\end{aligned} \\end{equation}当 $c(w_{j-2}, w_{j-1})=0$ 或 $c(w_{j-1})=0$ 时，相应的令 $\\alpha_1=0$ 或 $\\alpha_2=0$ 。 3.2 加性平滑加性平滑又称拉普拉斯平滑，想法非常简单：只需要对每个统计单元词频加 $\\alpha$，比如： \\hat{\\theta}(w_j|w_{j-1}, w_{j-2}) = \\frac{\\alpha + c(w_{j-2}, w_{j-1}, w_j)}{\\alpha \\cdot V + c(w_{j-2}, w_{j-1})}假设 $c(我，爱)$ 在训练语料中的出现的次数是 100，经过拉普拉斯平滑以后就变成了 $100+\\alpha$，这样就一定能避免任意词频出现零的情况。而 $\\alpha$ 的选取仍然作为模型的超参数，通过验证集进行选取。在实际的语言模型中通常 $\\alpha \\lt 1$。 拉普拉斯平滑存在两个问题： 由于训练语料中零词频的词数量太多，通常会占据整个概率分布中的一个很大的比例。通过拉普拉斯平滑会给零词频的词分配了太多的概率空间。 给所有未出现的词的词频加上相同的数，即认为这些词出现的概率是相同的，这种假设是否合理其实也值得商榷。而且，对于非零词频的词都增加同样的频度值，这是否合理，我们并不能给出一个明确的答案。 3.3 减值平滑之所以会产生零词频，是因为那些非零词频的词出现的概率被模型高估了，占用了原本属于零词频词的概率份额，所以我们可以通过直接从非零词频对应的概率上扣除一部分概率还给零词频词，这就是减值平滑的基本思想。 以 Bi-Gram 为例，$\\theta(w_j|w_{j-1}) = c(w_{j-1}, w_j)/c(w_{j-1})$，对于任意 $c(w_{j-1}, w_j)&gt;0$ 的情况，我们都令 c^*(w_{j-1}, w_j) = c(w_{j-1}, w_j) - \\beta其中 $\\beta \\in [0,1]$（通常 $\\beta=0.5$），这个 $\\beta$ 就是我们从非零词频词的概率上抠下来的份额。 举个例子，假设 $c(w_{j-1}=我)=48$： $(w_{j-1}, w_j)$ $c(w_{j-1}, w_j)$ $c^*(w_{j-1}, w_j)$ $c^*(w_{j-1})/c(w_{j-1}=我)$ （我，爱） $15$ $15-0.5=14.5$ $14.5/48$ （我，吃） $13$ $13-0.5=12.5$ $12.5/48$ （我，喜欢） $10$ $10-0.5=9.5$ $9.5/48$ （我，在） $10$ $10-0.5=9.5$ $9.5/48$ \\sum_{c(w_{j-1}, w_j)} \\frac{c^*(w_{j-1}, w_j)}{c(w_{j-1})} = \\frac{14.5}{48} + \\frac{12.5}{48} + \\frac{9.5}{48} +\\frac{9.5}{48} = \\frac{46}{48}=\\frac{23}{24}由此可见，我们从非零词频的词身上抠下来 $1/24$ 的概率，我们称抠下来这部分概率为缺失质量（missing mass）。有了这部分缺失质量我们就可以将它分配给零词频的词了，通常采用的分配方法是平均分配。 以上过程我们用形式化的语言描述为： 定义 $\\beta \\in (0, 1)$，任意给定 $\\pmb{h}$，我们将训练数据分成两部分： \\mathcal{A}(\\pmb{h}) = \\{ w_j \\in \\mathcal{V}:c(\\pmb{h}, w_j) \\gt 0\\};\\\\\\\\ \\mathcal{B}(\\pmb{h}) = \\{ w_j \\in \\mathcal{V}:c(\\pmb{h}, w_j) = 0\\}对于 $w_{j} \\in \\mathcal{A}(\\pmb{h})$，定义： \\hat{\\theta}(\\pmb{h}, w_j) = \\frac{c(\\pmb{h}, w_j)-\\beta}{c(\\pmb{h})} \\\\\\\\ q(\\pmb{h}) = 1-\\sum_{w_j\\in\\mathcal{A}(\\pmb{h})} \\hat{\\theta}(\\pmb{h}, w_j)最后将 $q(\\pmb{h})$ 平均分配给所有 $w_j \\in \\mathcal{B}(\\pmb{h})$： \\hat{\\theta}(\\pmb{h}, w_j) = \\frac{q(\\pmb{h})}{\\sum_{w_j \\in \\mathcal{B}(\\pmb{h})}c(\\pmb{h}, w_j)}最终我们得到: \\begin{equation} \\nonumber \\hat{\\theta}(\\pmb{h}, w_j) = \\begin{cases} \\frac{c(\\pmb{h}, w_j)-\\beta}{c(\\pmb{h})} & \\mathrm{if}: w_j \\in \\mathcal{A}(\\pmb{h})\\\\\\\\ \\frac{q(\\pmb{h})}{\\sum_{w_j \\in \\mathcal{B}(\\pmb{h})}c(\\pmb{h}, w_j)} & \\mathrm{if}: w_j \\in \\mathcal{B}(\\pmb{h}) \\end{cases} \\end{equation}这种减去一个固定值 $\\beta$ 的减值法称为 “绝对减值平滑”，这种方法简单易操作，但缺点也很明显：在每个非零词频词上减去相同的词频，然后平均分配给不同的零词频词，其中蕴含的平权假设过于绝对。因此，针对这个问题人们又提出一个古德-图灵减值平滑，其基本思想是未出现的词的词频和只出现过一次的词的词频相同，然后再去调整只出现过一次的词频使整个概率和为 1。关于这种方法这里就不详细介绍了，有兴趣可以看这份资料。 除了以上三种平滑方法以外，还有很多其他平滑方法，比如 Kneser-Ney Smoothing、Jelinek-Mercer Smoothing 等等，更多资料看这里。 4. 总结 语言模型实际上就是一个概率分布，我们可以从中得到一个句子出现的概率或者可以根据之前出现的词推断下一个可能出现的词； 构建一个统计语言模型需要马尔科夫假设； 通常使用最大似然估计对模型参数进行估计； 在遇到词频为零的情况时可以使用平滑方法来解决； 使用困惑度对构建好的语言模型进行评估，语言模型质量越好困惑度就会越低。 统计语言模型存在几个缺点： 由于存在马尔科夫假设，尤其是通常使用的马尔科夫假设不会超过四阶，也就是通常的统计语言模型不会超过 5-gram，所以很难建立词与词之间的远距离依赖关系； 无法构建词与词之间的相似性关系。","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/tags/nlp/"},{"name":"Probabilistic Language Model","slug":"probabilistic-language-model","permalink":"https://rogerspy.gitee.io/tags/probabilistic-language-model/"}]},{"title":"预训练语言模型-前言","slug":"ptm-introduction","date":"2020-10-13T06:20:02.000Z","updated":"2022-01-12T08:37:38.401Z","comments":true,"path":"2020/10/13/ptm-introduction/","link":"","permalink":"https://rogerspy.gitee.io/2020/10/13/ptm-introduction/","excerpt":"自从 2017 年 Vaswani 等人提出 Transformer 模型以后 NLP 开启了一个新的时代——预训练语言模型。而 2018 年的 BERT 横空出世则宣告着 NLP 的王者降临。那么，什么是预训练？什么是语言模型？它为什么有效？","text":"自从 2017 年 Vaswani 等人提出 Transformer 模型以后 NLP 开启了一个新的时代——预训练语言模型。而 2018 年的 BERT 横空出世则宣告着 NLP 的王者降临。那么，什么是预训练？什么是语言模型？它为什么有效？ 在本系列文章中我们将会讨论跟预训练语言模型相关的技术。目前初步制定的计划如下： 一、前言 二、语言模型 三、NLP 中的迁移学习 四、预训练语言模型 五、预训练语言模型的应用 六、预训练语言模型的压缩 大体分成以上六个部分，本文为第一部分，将会对预训练语言模型的发展、技术路线做一个综述，使得我们能对这一领域有一个整体的认识。 1. 语言模型狭义上的语言模型就是对自然语言进行建模，自然语言指的是人类文明演化过程创造的用于人与人交流的语言，不包括编程语言等。自然语言通常包含语音和文字，语言模型指的是对文字进行建模。广义上来说，语言模型可以用来对任意的系列化结构进行建模。这里我们讨论的是狭义上的文字语言模型。 语言模型简单来讲就是让计算机判断一个词序是不是正常的句子，如果是则给出高概率，反之则给出低概率。本质上就是构建一个词序概率分布，一个序列的概率由序列中每个词出现的概率相乘得到，而每个词出现的概率由其前后出现的词来确定。用形式化语言描述为： 给定一个词表 $\\mathcal{V}$，对于序列 $s = w_1w_2…w_n$，其中 $w_i \\in \\mathcal{V}, i \\in {1, …, (n-1)}$ 以及 $n \\ge 1$，$w_n$ 通常是一个特殊符号，用于标志序列的结束。语言模型可以定义为： \\begin{equation}\\nonumber \\begin{aligned} p(s) &= p(w_1, w_2, ..., w_n)\\\\\\\\ &= p(w_1)p(w_2|w_1)...p(w_n|w_1,...,w_{n-1})\\\\\\\\ &= p(w_1)\\prod_{i=2}^np(w_i|w_1,...,w_{n-1}) \\end{aligned} \\end{equation}语言模型在 NLP 领域有广泛的用途，比如机器翻译过程中，模型给出几个候选翻译结果，然后再根据语言模型选出最符合自然语言的句子，使得翻译结果更加流畅。 1.1 统计语言模型在神经网络技术出现之前，人们通常是使用统计学方法从训练语料中去学习模型参数，因此此时的语言模型也称为统计语言模型（Statistical Language Model）。 标准的语言模型存在两个问题： 参数空间过大。假设序列中的词全部来自 $\\mathcal{V}$，那么对于一个长度为 $n$ 的序列来说，模型具有 $\\mathcal{V}^n$ 个自有参数。我们可以看出，模型的自由参数随着序列长度增加成指数级增长。 数据稀疏性。表面上看，序列中的每个词都具有 $\\mathcal{V}$ 种可能的取值，那么长度为 $n$ 的序列可以有 $\\mathcal{V}$ 种组合方式，但是实际上我们的语料不可能出现这么多种组合。 因此，直接对上面的语言模型进行求解几乎是不可能的，我们需要对问题进行一些合理的假设，从而简化模型。 n-gram 语言模型马尔科夫假设： 句子中第 $i$ 个词出现的概率只依赖于前面 $i-1$ 个词。 我们将这个假设再进一步弱化： 句子中第 $i$ 个词出现的概率只依赖于前面 $n-1$ 个词，其中 $n \\le i$。 基于这个假设，我们就能够理解 n-gram 中的 n 实际上就是前面 n-1 个词的意思。（为啥说是 n-1 个词呢，因为通常认为第 n 个词表示第 i 个词本身） 比如： $n=1$ uni-gram: $p(w_1, w_2, …, w_n) = p(w_i)$ $n=2$ bi-gram: $p(w_1, w_2, …, w_n) = p(w_1)\\prod_{i=2}^np(w_i|w_{i-1})$ $n=3$ tri-gram: $p(w_1, w_2, …, w_n) = p(w_1)\\prod_{i=2}^np(w_i|w_{i-2},w_{i-1})$ … $n=n$ n-gram: $p(w_1, w_2, …, w_n)=p(w_1)\\prod_{i=2}^np(w_i|w_(i-1),…,w_{i-n+1})$ 在实际应用中，$n$ 的选取通常从计算复杂度和模型效果两个方面去考虑，假设 $|\\mathcal{V}| = 2 \\times 10^5$, 下表给出了常见的 $n$ 的取值对应的计算复杂度和模型效果： n-gram order 模型参数量 perplexity $1$ $2 \\times 10^5$ $962$ $2$ $(2 \\times 10^5)^2=4 \\times 10^{10}$ $170$ $3$ $(2 \\times 10^5)^3 = 8 \\times 10^{15}$ $109$ $4$ $(2 \\times 10^5)^4=16 \\times 10^{20}$ $99$ 上表中 perplexity 表示语言模型的评估指标，值越小表明语言模型越好。 从表中我们可以看出，随着 $n$ 增大，模型参数量级是指数增加的，在实际应用中通常采用 $n=3$。 尽管 n-gram 模型将参数量大大降低，但是技术的发展，尤其是互联网技术的发展，我们可以轻松获得大量的语料。对于语言模型来说，一个基本的事实是语料越多模型效果越好，但是另一方面，模型的参数量也会随着词表的增大而剧增，这样就极大的限制了语言模型的发展。 1.2 神经网络语言模型为了解决上述问题，人们开始考虑使用神经网络技术将语言模型映射到连续空间中，我们称之为“语义空间”。 最早提出使用神经网络对语言进行建模思想的是百度徐伟，在其 2000 年的论文《Can Artificial Neural Networks Learn Language Models?》提出一种构建 2-gram 语言模型（$p(w_i|w_{i-1})$）的方法。该方法的基本思路与后来的神经网络语言模型的建模方法已经差别不大了，但是由于他采用的是只有输入层和输出层，而没有隐藏层的神经网络，且只是二元语言模型，因此限制了其模型泛化能力和上下文语义捕捉能力。 到 2003 年 Bengio 等人提出了真正意义上的神经网络语言模型（Feedforward Neural Network Language Model, FFNNLM），该模型采用四层神经网络来构建语言模型——输入层、投影层、隐藏层和输出层。该模型不仅解决了统计语言模型的维度灾难问题和稀疏性问题，同时还诞生了一个非常重要的副产物——词向量（word vector）。词向量我们会在下文详细介绍。 直到 2010 年，Mikolov 等人提出基于 RNN 的语言模型。自此，神经网络语言模型逐渐成为语言模型的主流并得到快速发展。 2012 年，Sundermeyer 等人提出使用 LSTM 构建语言模型，用来解决长程依赖问题。 随后的时间，各种神经网络语言模型如雨后春笋般涌现，用来解决各种各样的问题。直到 2018 年，以 ELMO、GPT 和 BERT 为代表的语言模型的出现，正式宣布预训练语言模型时代的到来。本小节先不讨论预训练语言模型的相关内容，留待下文讲解。这里我们先简单介绍一下 FFNN、RNN 、LSTM 三种里程碑式的语言模型的发展，为后续预训练技术在语言模型上的发展奠定基础。 1.2.1 FFNN 语言模型 Bengio 等人 2003 年提出的第一个 FFNN 语言模型结构如上图所示。图中最下方表示输入层，$w_{t-n+1}, …, w_{t-2}, w_{t-1}$ 表示前 $n-1$ 个词。上面一层表示投影层，$C(w)$ 表示将词投影到相应的词向量上，$C$ 表示一个大小为 $|\\mathcal{V}| \\times m$ 的词向量矩阵，矩阵中每一行对应词表中的一个词的词向量，$m$ 代表词向量的维度。实际上 $C(w)$ 就表示从 $C$ 矩阵中找到 $w$ 对应的向量。将词映射成词向量以后，将 $C(w_{t-n+1}),…,C(w_{t-2}), C(w_{t-1})$ 这 $n-1$ 个词向量首尾相接，得到一个 $(n-1)\\times m$ 维的向量，记为 $x$。第三层为隐藏层，通过下式计算得到： o = \\tanh(d + Hx)其中，$H \\in \\mathbb{R}^{h \\times (n-1)m}$。最后就是输出层： y = \\mathrm{softmax}(b+Wx+U\\cdot o)其中 $U \\in \\mathbb{R}^{|\\mathcal{V}|\\times h}$，$W \\in \\mathbb{R}^{|\\mathcal{V}| \\times ({n-1})m}$。 FFNN 语言模型存在以下几个问题： 不能处理变长句子序列。由于输入层的神经元是固定的，因此模型必须输入固定长度的序列。 由于输入序列长度是固定的，因此，模型只能对固定长度的上下文进行建模，而不是对整段序列进行建模。 序列中的词没有包含位置信息，而实际上我们知道，对于相同的几个词，放在不同的位置整句话就会表达不同的意思。 尽管全接连神经网络需要学习的参数量远小于 n-gram 但是相比于其他结构的神经网络，其参数量还是过大。 因此，Bengio 在论文最后提到，可以使用循环神经网络（RNN）来降低参数量。这就是后来 Mikolov 提出的 RNN 神经网络。 1.2.2 RNN 语言模型 Mikolov 等人提出的 RNN 语言模型，将一个 RNN 神经网络展开，得到如上图所示的结构。每个时间步，句子中的当前词经过隐层编码预测下一个词。注意 $h_0$ 通常是零向量进行初始化。由于隐层 $h_t$ 的传递性， RNN 语言模型实际上就相当于 n-gram 语言模型，而这个 n 是一个变量，即整个句子的长度。这样避免了马尔科夫假设，使得我们能够得到更加精准的语言模型。 我们将其中一个时间步展开可得到如下图所示的结构： 其中 $x_t$ 表示第 $t$ 个词，$y_t$ 表示第 $t$ 个词经过编码以后的输出，$h_t^{(i)}$ 表示第 $t$ 个隐藏层的第 $i$ 层，$p_t$ 表示通过第 $t$ 个词预测的第 $t+1$ 个词，$E$ 为词向量矩阵，$W_h$ 和 $W_o$ 分别表示隐层和输出层的权重矩阵。计算过程如下： 将词映射成词向量：$h_t^{(0)} = Ex_t$ 隐层编码：$h_t^{(1)} = \\tanh(W_h[h_t^{(0)};h_{t-1}^{(1)}]^T)$ 计算输出层：$y_t=W_oh_t^{(1)}$ 计算输出概率：$p_t=\\mathrm{softmax}(y_t)$ 注意：$[h_t^{(0)};h_{t-1}^{(1)}]^T$ 表示 $h_t^{(0)}, h_{t-1}^{(1)}$ 两个向量的首尾拼接。 相比于 FFNN 语言模型，RNN 语言模型能够处理变长序列，相当于对整个句子进行编码，即根据句子前面所有的词来预测当前词。这样我们能够获得更加准确的语言模型。另外由于隐层是共享权重的，因此语言模型的参数量被大大降低了。 虽然 RNN 语言模型有诸多优点，但是也存在严重缺陷。最棘手的问题是由于神经网络梯度消失或者爆炸导致模型在处理远程依赖问题上的无能为力。为了解决这个问题，Sundermeyer 等人提出了 LSTM 语言模型。 1.2.3 LSTM 语言模型 LSTM 是 RNN 的一种变体，包含了三个门结构：输入门，遗忘门和输出门。对于神经网络而言，造成梯度消失或者梯度爆炸的罪魁祸首是过深的连乘结构，而 LSTM 通过这三个门结构将原来的连乘结构，一部分连乘改成了加法形式，从而缓解了梯度消失或者爆炸问题。LSTM 语言模型就是利用这种特性对语言进行建模从而能够更好的处理长程依赖问题。 尽管 RNN 、LSTM 语言模型表现良好，但仍然存在一系列问题，比如训练慢、OOV 问题、softmax 需要考虑全部词表等等，后续的研究也在一步一步提出更加完善的语言模型。但无论如何，以这三种经典的神经网络语言模型为基础，神经网络语言模型正在蓬勃发展，这也为后来的预训练语言模型打下了坚实的基础。 2. 预训练自然语言处理技术的发展大体经历了：基于规则处理方法、基l于统计概率的处理方法和基于神经网络的处理方法三个阶段。尤其是随着神经网络技术的发展，自然语言处理在各项任务上也取得了突飞猛进的发展。然而 Jia and Liang, 2017 和 Belinkov and Bisk, 2018 的研究指出，基于神经网络的 NLP 算法在泛化性上仍然非常脆弱，模型只能对在训练数据中“见过”的特征进行建模，一旦遇到“未见过”的数据，模型就会失效。 为了解决（或者说缓解）这个问题，通常的做法是使用更大的数据集去训练模型，但是这样又带来一个问题，训练神经网络模型通常是需要大量的标注数据的，更多的训练数据意味着更多的人工标注，使得训练模型的成本大大增加。 我们希望训练好的模型能够将学习到的知识应用到具有相似性的问题上去，即使新的问题在训练数据中从来没有出现过，就像人类一样具有“举一反三”，“照猫画虎”的能力，这样模型的泛化能力将会得到大大的增强。而这正是迁移学习的思想，预训练则可以认为就是一种迁移学习。 预训练首先在图像领域发光发热，这就不得不提 ImageNet。 2.1 ImageNet早期的目标识别任务面临一个过拟合的问题，因为当时训练模型的数据集都非常小。斯坦福大学的李飞飞受到 George Miller 的 WordNet 的启发，决定构建一个能够”覆盖世界上所有物体”（map out the entire world of objects）的数据集。 ImageNet 项目正式启动于 2007 年，在短短三年的时间内构建了 300 多万张经过人工标注的图片，并将图片分成 5000 多个类别。2012 年，多伦多大学的 Hinton 研究小组发布了深度卷积神经网络（CNN）—— AlexNet，该网络在 ImageNet 上将错误率下降到 25%，这直接导致了深度学习的爆发。 研究人员很快发现，在 ImageNet 上训练好的最佳模型的权重参数可以被用来初始化新的模型，然后在新的数据集上进行训练，而且这种方法可以明显提升模型的能力。这一发现就为图像识别的打开了预训练方法的大门。 假设我们有一个任务 A，但是用于模型训练的数据十分匮乏并不能直接从头开始训练一个模型。但是我们有大量的其他类型的数据，这个时候我们可以先试用这些数据训练一个模型， 然后使用这个模型的权重来初始化我们的任务模型，然后在我们自己的任务数据上再训练模型，这样可以极大的加快模型收敛速度，同时提升模型效果。我们将在大数据集上训练模型的过程称之为“预训练（Pre-Training）”，将在我们自己的数据集上训练的过程称之为“微调（Fine-Tuning）”。 具体的做法如下： 假设我们想要一个图像分类器，用于区分“大象”和“狮子”，但是“大象”和“狮子”的图片很少，但是我们有大量的“斑马”和“猴子”的图片，这个时候我们可以使用 CNN 先在“斑马”和“猴子”的图片上训练一个分类器。将训练好的权重参数保存下来。 然后采用和上面相同结构的网络模型，在比较浅的几层采用上面预训练模型相应层的权重作为初始化权重，在接近任务端的较深的几层仍然采用随机初始化。 之后我们就可以训练这个“大象”和“狮子”的分类器了。通常有三种训练方法：① 浅层加载的参数在训练过程不参与训练，称之为 “Frozen”；② 浅层加载的参数也参与训练，但是学习率会小于深层随机初始化的参数，使得浅层参数在一个较小的范围内变化；③ 浅层参数与深层参数一起训练，后两种称之为 “Fine-Tuning”。（实际上，一般人们说的 Fine-Tuning 指的是目标任务模型整个训练过程） 这么做的好处是，首先我们可以在较少的任务数据下训练一个可用的模型。其次，预训练模型具有可复用性。比如，这次我们需要的是“大象狮子”分类器，下次我们需要“熊猫老虎”分类器，仍然可以使用预训练的模型参数。再次，加载预训练模型参数的目标模型在训练的时候收敛速度更快，效果更好。最后，随着开源社区的发展，很多大公司比如微软、谷歌都愿意将自己的模型开源。这些机构通常有海量的数据和计算资源，使得它们能够在完成海量数据的训练任务，这样它们开源出来的预训练模型本身就是一个非常优秀的模型，对于下游的任务而言有非常大的帮助。因此，这种 Pre-Training + Fine-Tuning 的模式在图像领域很快就流行起来了。 一个自然而然会产生的问题是：预训练方法为什么有效？ 这其实就是知识的成功迁移。以人脸识别为例，对于层级 CNN 模型来说，不同层的网络学习到了不同的特征：最底层学习到了线段特征；第二层学习到了人脸的五官轮廓；第三层学习到了人脸的轮廓……研究发现，越浅层的网络学习到的特征越基础，越具有通用性。 既然预训练方法具有如此神奇的功效，为什么只在图像领域有效？为什么没有引入到自然语言处理领域呢？实际上这两个问题是不成立的，因为预训练方法很早就有人用在了自然语言处理领域，但是并没有取得像图像领域那么大的成功。下面我们就聊一聊 NLP 领域的预训练。 2.2 Word Embedding语言是人类智慧的结晶，想要将计算机发展成一种具有通用智能的系统，对人类语言的理解是一个不可或缺的能力，由此诞生了自然语言处理（NLP）这门学科。对于自然语言来说，词 被认为是构成语言的有意义的最小单位，对于更高级的结构，比如词组、句子则是由词构成的，对于更低级的结构，比如单个字、字母通常是没有意义的。因此，如何将词转换成计算能够理解的表达（称之为“词向量”）就变成了一个非常重要的任务。 2.2.1 ASCII 码表示法一个最基础的想法是，计算集中的每个字（字母）都对应一个 ASCII 码，由于词是由字构成的，那么我们可以使用每个字对应的 ASCII 码组成的序列来表示词。比如：“desk“ 和 ”table“，可以分别表示成： 12desk: 01100100 01100101 01110011 01101011table: 01110100 01100001 01100010 01101100 01100101 但是这种表示法有一下几个缺陷： 变长。由于词是由不同个数的字组成的，使用这种方式表示的词的长度也是变化的，不利于矩阵运算； 稀疏。以英文为例，英文字母有26个，英文单词通常由 1-20 个字母组成，为了说明问题我们这里取 10 作为平均数。这 26 个字母有 $26^{10}$ 种排列组合方式，但实际上的英文单词个数远小于这个数。也就是说，真正的英文单词在这种排列组合情况下式非常稀疏的。这种稀疏化的表示方法会给后续的工作带来一系列问题，比如存储、计算等。 无法表达词与词之间的关联性。比如上面的 “desk” 和 “table” 都有 “桌子” 的意思，那么他们应该具有相似的语义。但是这种 ASCII 码表示法完全无法将这种语义关联性表示出来。 2.2.2 One-Hot 表示法给定一个固定的词表：$\\mathcal{V}=\\{w_1, w_2, …, w_{|\\mathcal{V}|}\\}$。我们使用一个维度为 $\\mathcal{|V|}$ 的向量对每个词进行编码，这个向量中对应该词在词表中的索引的维度为 1， 其余为 0： w_i = \\begin{cases} 1 & \\mathrm{if} ~ w = w_i\\\\\\\\ 0 & \\mathrm{otherwise} \\end{cases}举个例子， 假设我们的词表为 [desk, table, apple, orange]，那么词表中的每个词可以用 one-hot 表示成： 1234desk: [1, 0, 0, 0]table: [0, 1, 0, 0]apple: [0, 0, 1, 0]orange: [0, 0, 0, 1] 看起来 one-hot 的表示形式比 ASCII 码表示形式要好一些，至少每个词都有了固定的长度，而且不存在使用字母进行排列组合导致的词稀疏问题。在传统的机器学习算法上， 比如最大熵、SVM、CRF 等模型上，one-hot 表示法都是非常常见的。但是，这种表示法仍然存在问题： 稀疏。从上面的定义我们可以看出，词的维度和词表的大小是一致的，那么如果一个词表过大会造成词向量（简单理解为词的向量化表示）的维度过高，而一个词中只有一个维度的值是 1， 其余全部是 0，这样也会造成高维稀疏化问题； 同 ASCII 码表示法一样，无法表达词与词之间的关联性； 如果遇到新词需要添加到词表中，词表中的每个词的维度都需要相应的增加，这样在实际使用过程中是非常不方便的， 甚至有可能会导致一些问题。 2.2.3 向量空间模型Harris 和 Firth 分别在 1954 年和 1957 年提出了分布式假设（distributional hypothesis）： 对于语义词表示学习而言，具有相似分布的的语言对象具有相似的含义。 也就是说，如果两个词具有相似的分布，那么它们的语义也具有相似性。这个假设为后来的分布式词表示法奠定了基础。 这里的分布式词表示法指的是 distributed representation，另外还有一个术语叫做 distributional representation 指的是在上述分布式假设下学习到的词义。 Salton 等人于 1975 年提出向量空间模型（Vector Space Model），该模型最初是为了在信息检索中对文档进行建模，但是随着它的成功应用，逐渐扩展到其他领域。向量空间模型将词表示成一个连续向量，向量空间表示语义空间。 比如，[desk, table, apple, orange] 我们可以表示成： 1234desk: [0.1, 0.2, 0.5]table: [0.2, 0.4, 0.6]apple: [0.1, 0.5, 0.1]orange: [0.2, 0.9, 0.4] 这样做的好处是： 我们可以就算两个向量之间的距离，用于表示语义相似性； 向量维度可以大大降低； 由于是连续性分布，所以不存在稀疏性问题。 早期的向量空间模型主要是基于词频统计（共现矩阵）的方法，比如布朗聚类（Brown Cluster），潜在语义分析（Latent Semantic Analysis）等方法。然而这些方法通常会存在参数量过大以及需要某种程度的降维等问题。因此仍然具有一定的局限性。 2.2.4 词嵌入表示法Word Embedding 通常翻译为词嵌入，实际上也属于 distributed representation，这里特指使用神经网络训练得到的词向量。 随着神经网络技术的发展，深度学习掀起了机器学习的革命风潮，词向量的研究也迎来了新的转机。谷歌于 2013 年发表的 Word2Vec 模型可以说是词嵌入的里程碑式模型。它能够从大量的语料中高效的学习到词向量。Word2Vec 几乎解决了以上提到的所有问题。 在介绍 Word2Vec 之前，我们先回顾一下词向量的发展。 FFNNLM 词向量通常是在训练语言模型的时候得到的副产物。前面我们在介绍 FFNN 语言模型的时候说过，词向量最初就是在训练在该模型中第一次通过神经网络训练得到的。 在 FFNN 语言模型中，有一个 $C$ 矩阵，该矩阵就是词向量。开始训练之前，将矩阵中的参数随机初始化，利用梯度下降对模型进行训练，模型训练结束的时候也表明，$C$ 矩阵得到了充分的训练，即词向量训练完成。 SENNA Ronan Collobert 和 Jason Weston 在 2008 年提出了一种新的词向量训练方法，并开源了他们的方法——SENNA。实际上最初他们并不是想训练一份好的词向量，甚至不想训练语言模型，而是想要去完成 NLP 中的各种任务，比如词性标注、命名实体识别、语义角色标注等。 SENNA 的训练思路是对一个窗口中的 $n$ 个连续的词进行打分，而不是预测下一个词的概率。这实际上是直接尝试近似求解 $p(w_{t-n+1}, …, w_{t-1}, w_t)$，打分越高说明越接近正常的话，打分越低说明越不像一句正常的话。有了这个假设，就可以定义目标函数： \\sum_{x \\in \\mathcal{X}} \\sum_{w \\in \\mathcal{D}} \\max\\{0, 1-f(x)+f(x^{(w)})\\}其中 $\\mathcal{X}$ 为训练接中素有连续 $n$ 元短语，$\\mathcal{D}$ 表示整个词表。 第一个求和相当于选取训练语料中的所有 $n$ 元短语作为正样本，第二个求和相当于随机选择词表中的词构建负样本，构建方法就是将短语 $x$ 最中间的词替换为 $w$，即$x^{(w)}$。这样构建负样本的好处是，通常情况下，一个正常的 $n$ 元短语被替换掉中间的词之后确实会变成负样本，这样保证负样本的可靠性，即使出现替换掉之后仍然是正样本的情况，也属于少数情况，不影响大局；另一方面，由于负样本仅仅是修改了正样本中的一个词，不会让正负样本距离太大影响分类效果。最后希望正样本的打分要比负样本的打分至少高 1 分。 SENNA 模型的整体结构与 FFNNLM 类似，但是由于 SENNA 最后的输出是一个分数而不是下一个词的概率分布，因此输出层只有一个节点，这样大大降低了计算复杂度。 HLBL HLBL 是 “Hierarchical Log-BiLinear” 的简称，该模型是 Andriy Mnih 和 Geoffrey Hinton 于 2007 年和 2008 年连续两年致力于神经网络语言模型和词向量训练的研究成果。从最基本的受限玻尔兹曼机（RBM）逐步发展出来的模型。 2007 年的文章 《Three new graphical models for statistical language modelling》 提出 Log-Bilinear 模型： y_i = \\sum_{i=1}^{n-1}C(w_j)^TH_iC(w_i)通常我们将形如 $x^TWy$ 的模型称之为 “Bilinear”，上式中 $C(w)$ 表示词向量。 我们仔细看这个模型会惊喜的发现，这不就是注意力机制吗？$H_i$ 相当于是注意力权重，计算结果就是 $w_i$ 和 $w_j$ 的相似度。（关于注意力机制的介绍可以看这里） 受限于当时计算机的内存和算力，最终模型只考虑了 3-5 个词的上下文，然后通过最后的 softmax 得到下一个词的概率分布。 由于这个模型最后做预测的时候还是用的 softmax 获得下一个词的概率分布，计算复杂度仍然很高。因此， Andriy Mnih 和 Geoffrey Hinton 在 2008 年又发表一篇论文 《A scalable hierarchical distributed language model》引入层级结构做最后的预测，该层级结构将 softmax 的 $O(|\\mathcal{V}|)$ 复杂度降为 $O(\\log_2(|\\mathcal{V}|))$，大大提升了预测效率。 Goodman 在 2001 年的时候提出了一种加速预测下一个词的方法——基于分类的思想。简单来说，假设我们词表中有 10000 个词，在传统的方法是在这 10000 个词上做 softmax 获得每个词的概率分布，然后取出概率最大的词，这样我们需要计算 10000 次。如果我们将这 10000 个词进行分类，假设分成 100 个类别，每个类别 100 个词。这个时候我们的计算过程是，先用一个 softmax 计算下一个词是属于什么类别，然后再用一个 softmax 计算概率最大的类别中的词的概率分布，这样我们只需要两个 100 次的计算量，计算速度直接提升 50 倍。 基于这个思想，Frederic Morin &amp; Yoshua Bengio 于 2005 年提出使用平衡二叉树来构建这种分类关系，能够将计算复杂度降到 $O(\\log_2(|\\mathcal{V}|))$。但是在他们的模型中分类使用的是 WordNet 中的 IS-A 关系，最后虽然达到了加速预测的效果，但是模型效果较差。 Andriy Mnih 和 Geoffrey Hinton 希望从语料中学习并能自动构建一棵平衡二叉树。他们采用 bootstrapping 的方法，从随机树开始，根据分类结果不断调整迭代，最后得到一棵平衡二叉树。 值得一提的是，在他们的模型中，同一个词可能出现在多个不同的叶节点上，这实际上表示一词多义现象。歧义是自然语言处理中的一个非常重要的问题，也是早期限制预训练技术在自然语言处理领域发挥作用的重要阻碍。但是Mnih 和 Hinton 并没有重视模型中的这一细节。 MWP Bengio 2003 年的论文最后提到了多义词的问题，Eric H. Huang 等人在其 2012 年的论文《Improving Word Representations via Global Context and Multiple Word Prototypes》 中给出了一种解决方案。从论文题目我们可以看出，作者主要有两个贡献，首先是改进了 SENNA 模型，从局部信息扩展到全局信息，得到了更好的词向量，这一部分不过多介绍。另一个更重要的工作是创新的使用多个词向量来表示多义词。 他们提出的方法是将每个词的上下文各取 5 个词，对这 10 个词的词向量使用 idf 做加权平均，然后对得到的平均向量做 k-means 聚类，根据聚类的结果给每个词打上标签，不同类别中的同一个词当成不同词，然后重新训练词向量。思想很简单，但是最后的效果还不错。 Word2Vec 时间来到 2013 年，Mikolov 等人发表两篇开山之作—— Distributed Representations of Words and Phrases and their Compositionality 和 Efficient estimation of word representations in vector space 宣告着 Word2Vec 的到来。相比于之前的工作，Word2Vec 极大的降低了计算复杂度，从而使我们能够在超大规模的语料上学习更高维的词向量。 Word2Vec 提出了两种新的模型架构：CBOW 和 Skip-Gram。CBOW 的核心思想是从一个窗口中将中间的词扣掉，然后利用这个词的前后几个词来预测中间的词；Skip-gram 正好相反，利用中间的词来预测两边的词。 模型结构和 FFNN 语言模型的结构类似，不同点在于，FFNN 语言模型是利用上文预测下文，对于 FFNN 语言模型来说，词向量只是一个副产物，但对于 Word2Vec 来说，词向量才是主产物。 如之前讨论的那样，直接对预测输出使用 softmax 计算，计算复杂度非常高，因此，作者提出两种优化方案：层级 softmax（Hierarchical softmax） 和负采样（Negative Sampling）。关于 word2vec 的公开资料非常丰富，这里就不再赘述。 2.3 词向量怎么用？我们前面花了很大篇幅介绍了词向量，那么词向量和预训练有什么关系呢？实际上，对于 NLP 来说（至少在 2018 年之前）词向量对应 ImageNet 预训练的底层权重。 以分类任务为例，如果我们要从头开始训练一个分类模型，那么模型中的参数都是随机初始化的，模型的泛化能力很大程度上取决于数据量。如果我们能从海量的语料中学习一套词向量，在做分类任务的时候，使用预训练好的词向量对输入端的词向量矩阵做初始化，相当于我们在模型中注入了一定的先验知识。然后在后续的模型训练过程中，词向量矩阵不参与训练。这样有两个好处：1. 减少可训练参数，加快训练速度；2. 知识的迁移使得模型更具有泛化能力。 这个过程其实就是 NLP 中的预训练，与图像领域的预训练基本是一致的，只是 word embedding 只能初始化第一层，更高层就无能为力了，但通常 NLP 模型的深度也都比较浅。 既然采用的是基本相同的预训练方法，为什么在图像领域就取得巨大的成功，而在自然语言处理领域，不能说没有帮助，但是帮助非常有限呢？很显然，问题出在 word embedding 上。回想我们之前在介绍 Huang 等人提出的训练词向量的方法，一个非常重要的任务就是解决一词多义的问题。 在通常的 NLP 任务中，每个词对应的只有一个词向量，也就是只有一个语义。但一词多义在自然语言中是非常常见的现象，只用一个词向量是无法表达多个语义的。虽然 Huang 的方法是一个词训练多个词向量用来解决一词多义的问题，但是这种做法在 NLP 中并不常见，原因也很简单：1. 通常为了避免（缓解）OOV 问题，模型需要一个较大的词表，一般情况下，词向量的维度我们会选择 100-300 维。这样的话，单单是在词向量矩阵这部分就包含了几百上千万的参数，如果再考虑一个词对应多个词向量，那么这个数字还要大上几倍；2. 即使我们采用了一个词对应多个词向量的方法来解决一词多义的问题，那么每个词在具体的句子中要使用哪一个词向量呢？这也是一个问题。如果再在模型层面解决词向量选取的问题，那我们会发现，一个简单的分类模型的重点反而成了解决歧义问题，整个模型就显得头重脚轻。 2.4 Sentence Embedding既然词可以变成向量，那么句子是不是也可以变成向量呢？如果我们把句子变成向量是不是就不需要考虑词的多义性问题了呢？ 2.4.1 Paragraph vector2014 年，Mikolov 在提出 word2vec 不久之后就提出 paragraph vector 的设想，从论文题目《Distributed Representations of Sentences and Documents》就不难看出，他是想将句子和篇章也表达成固定维度的分布式向量。文章中他借鉴了 CBOW 和 Skip-gram，提出 PV-DM 和 PV-DBOW。 PV-DM PV-DBOW PV-DM PV-DM（Distributed Memory Model of Paragraph Vectors），通过上文预测下一个词，但是在输入层的时候不仅输入上文的词，还需要输入一个文档的 id，然后模型预测下一个词。由于输入多了一个文档 id, 因此我们还需要另外维护一个文档表（look-up table），用于通过 id 查找到对应的向量。训练结束后，对于现有的文档，便可以直接通过查表的方式快速得到该文档的向量，而对于新的一篇文档则需要将重新分配一个 id 给他，添加到 look-up table 中。然后重新训一遍模型，此时其他参数是固定的，只需要更新 look-up table 即可，收敛后便可以得到新文档对应的向量了。 PV-DBOW PV-DBOW（Distributed Bag of Words version of Paragraph Vector）是通过文档来预测文档中的词。首先先随机选取一个文档片段，然后随机从片段中选取一个词，然后让模型去预测这个词。和上面一样，如果此时有一个新的文档，要想获得它的向量，我们需要重新跑一遍模型。 由于上面两种方法都需要重新训练来获得新的文档向量，因此这两种方法并没有得到广泛应用。 2.4.2 Skip-thoughts2015 年，Kiros 等人借鉴 Skip-gram 的思想提出 Skip-thoughts 方法。Skip-gram 是根据一个词去预测它的上下文，这里的基本单位是词，而 Skip-thought 的基本单位是句子。具体来说就是，利用当前的句子预测前一句和后一句。 首先利用 RNN 对当前句子进行建模，然后再用一个 RNN 来生成上一个句子和下一个句子。本质上这其实就是 encoder-decoder 结构的 seq2seq 模型，只不过 Skip-thoughts 有两个 decoder。 2.4.3 Quick-thoughts 2018 年，Logeswaran 等人觉得 Skip-thoughts 的 decode 效率太低，且无法在大规模的语料上很好的训练。所以，他们把预测上下句的生成任务变成了分类任务，提出了 Quick-thoughts。具体来说就是，选取一个窗口，把窗口内的句子标记为正例，窗口外的句子标记为负例，将这些句子输入模型，让模型判断这些句子是否是同一个窗口的句子。（几个月后的 BERT 也借鉴了这一思路） 2.4.4 InferSent 除了上述的无监督任务，研究人员还在监督学习任务上进行了尝试。比如 Conneau 等人提出 InferSent 模型，基本思想是先在 SNLI （Stanford Natural Language Inference）数据集上训练一个特征提取器，然后利用这个特征提取器将句子转化成向量，再将句子向量应用于分类任务上，以此来判断句向量的质量。 2.4.5 General Purpose Sentence Representation除了单任务的预训练，Subramanian 等人在 2018 年还提出使用多任务来预训练模型。他们在 2018 年发表的论文《Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning》提出使用多任务联合学习来对模型进行预训练。论文中包含四种任务：Natural Language Inference, Skip-thougts, Neural Machine Translation 以及 Constituency Parsing，作者希望通过不同侧重点的任务，而不是特定任务来学习句子表征，达到 general 的目的。 具体的做法还是先在以上四个任务上做联合预训练，预训练好的模型保持不变，顶层添加一个全连接层作为分类器，然后训练一个新的分类器。在训练分类器的过程中，原来预训练的部分不参与训练，只训练顶层的全连接层。最后的实验结果也表明这种训练方式的有效性。 2.4.6 Universal Sentence Encoder同样在 2018 年，Daniel Cer 等人提出了和 General Purpose Sentence Representation 相同的方法，只是将其中的网络替换成了 Transformer。最后结果发现，利用 Transformer 作为特征提取器效果更好。 2.5 小结直到此时我们会发现，人们对于应该如何在 NLP 上进行预训练还是没有一个清晰的认知。比如，采用什么网络结构，在什么任务上进行预训练，怎样使用预训练的模型等等问题都还是处在一个摸索的阶段。我们也应该看到，虽然没有形成统一的认识，但是一个大致的发展脉络已经隐约可见了，从最初的只使用词向量，到后来开始考虑上下文，再到直接使用预训练模型进行特征抽取；从最初使用简单的 DNN，到后来使用 RNN 或 LSTM，再到 Transformer 的尝试等等，都逐渐呈现拨开云雾见光明的趋势。虽然经历了在不同的任务上进行预训练，但是在语言模型上的尝试也在快速发展，接下来就是预训练语言模型的舞台了。 3. 预训练语言模型在这部分，我们先简单介绍预训练语言模型的发展历史，随着预训练语言模型的发展，产生了不同的技术流派，我们也将对这些技术流派进行简单的梳理。 3.1 预训练语言模型发展简史首先我们将预训练语言模型的发展分成几个时期： 2015 年至 2017 年：技术探索期 2017 年至 2018 年：技术成长期 2018 年：技术爆发期 2019 年至今： 百家争鸣期 3.1.1 技术探索期2015 年，Andrew M. Dai 和 Quoc V. Le 首次尝试先使用语言模型在大规模无标注语料上进行预训练，然后以整个语言模型来初始化下游的分类模型的方法。 他们的提出两种预训练方法： 使用 LSTM 训练一个标准的语言模型，即根据上文预测下一个词； 使用 LSTM 作为序列自编码器，将整个序列输入到模型中，将序列编码成一个固定维度的向量，然后根据这个向量去预测输入序列本身。 然后使用训练好的 LSTM 权重去初始化一个 LSTM 分类模型，发现上述两种预训练方法不仅提升了模型的分类效果，而且在更多的相关数据集上进行预训练可以极大的提升泛化能力。 2017 年 4 月， AllenAI 研究小组提出了一个模型——TagLM，如下图所示： 可以看到，模型采用两段式训练方法（虽然写了三个步骤）：① 从无标记的数据中学习词向量和语言模型，② 将句子作为输入传递给训练好的语言模型，然后将语言模型的输出与 RNN 第一层输出拼接在一起作为序列标记任务模型的输入传递给下游序列标记模型，然后训练下游模型。这个思路与后来的 ELMO 模型是基本一致的，而且由于 ELMO 也是 AllenAI 小组的研究成果，因此我们可以认为 TagLM 模型是 ELMO 的一次初探。 2017 年 8 月，McCann 等人从机器翻译角度出发，训练了一个两层 Bi-LSTM 的 seq2sqe 翻译模型。然后，将训练好的 encoder 部分拿出来作为预训练的权重用于分类任务。 2018 年 1 月，Howard 等人提出的 ULMFiT 开始对 NLP 中的预训练方法展开了另一次新的尝试： 该模型采用的是三段式训练方法：① 在通用语料上训练词向量和语言模型；② 在专业领域语料上对词向量和语言模型进行 fine-tuning；③ 将训练好的语言模型作为句子特征提取器应用于下游分类任务。 可以看到，以上这些工作已经初现了现在的预训练方法：① 多段式训练，先在相关的数据上预训练一个模型，然后在具体任务数据上进行微调；② 不再只是单纯的使用预训练的词向量，而是开始考虑使用上下文。 这个时期的预训练更多的是尝试性的工作，比如应该如何训练语言模型，预训练的模型该怎么应用到下游任务等等。随着各种技术尝试的开展，从最开始的发散式尝试，逐渐开始有了一些技术聚焦点：从语言模型角度进行更多的尝试，采用双向 LSTM 网络结构，预训练方法在分类和序列标注任务上都有不俗的表现，这些都为后来的技术成长做好了铺垫。 3.1.2 技术成长期 EMLo ELMo 全称 “Embedding from Language Models”，其核心点在于它的论文名《Deep contextualized word representations》，即根据上下文（动态）生成词向量。比如：“我喜欢吃苹果”和“我喜欢苹果手机”，这两句话中的“苹果”分别表示两种含义，他们的词向量应该是不同的，那么 ELMo 可以根据这两句话表达的语义给“苹果”生成两个不同的词向量。 ELMo 是一个两段式训练模型：先在语料上训练一个语言模型，然后利用训练好的语言模型去动态生成词向量，应用于下游任务。第一阶段训练语言模型使用的是双向 LSTM 网络，所谓双向 LSTM 就是一个前向 LSTM 和 一个后向 LSTM，前向 LSTM 通过给定的前 $k-1$ 个词预测第 $k$ 个词，后向 LSTM 就是通过给定的反向的 $k-1$ 个词预测第 $k$ 个词。 假设模型有 $L$ 层双向 LSTM，那么我们可以得到 $2L+1$ 个向量：前向和后向各一个向量，加上输入层的词向量。 语言模型预训练好以后，在下游任务中我们怎么用这 $2L+1$ 个向量呢？首先是将每层的前向和后向的向量拼接在一起，然后对每层的向量进行加权求和，每层的权重可以通过学习得到。求和之后再进行一定程度的缩放，将缩放后的向量与输入层的词向量再进行加权求和。这样我们就将 $2L+1$ 个向量整合成了一个向量，然后将这个向量作为下游任务的输入，训练下游任务模型。 在实验中，作者使用的是两层的双向 LSTM，第一层学习到语法信息，第二层学习语义信息。从上面我们可以看到，ELMo 相比于之前的工作，并没有本质上的创新，基本上是对前人工作的引申和扩展，但是他的效果又是如此的惊艳，在 2018 年初的时候横扫了 NLP 中 6 大任务的最好结果。 那么 ELMo 有什么缺点呢？ 2017 年谷歌提出了 Transformer 模型，很多研究表明 Transformer 的特征提取能力是要强于 LSTM 的，比如我们上面提到的 Universal Sentence Encoder; ELMo 采用的特征融合方法还是比较传统的拼接加权求和等方式，相比于后来的 BERT 的一体化融合方式，融合能力弱了一些。 ELMo 是基于特征融合的方式来影响下游任务的，而从 ImageNet 的角度来看，也许 fine-tuning 的方式更适合下游任务（知识迁移）。 GPT GPT 全称 Generative Pre-Training，模型的大致结构如上图左侧所示。GPT 与之前的预训练模型一样，首先是预训练一个语言模型，然后将语言模型应用到下游任务。它与 ELMo 的不同点在于： 采用 Transformer 作为特征抽取器； 采用的是单向的语言模型； 将预训练和 fine-tuning 的结构进行统一，不再需要特征融合。 其中 Transformer 部分是经过改造的 decoder 层，如上图右侧所示。由于原始的 Transformer 是 encoder-decoder 结构的机器翻译模型，在 decoder 部分需要与 encoder 语义融合所以多了一个 multi-head attention 层，而在语言建模时，不需要语义融合，因此可以将其去掉。（更多关于 Transformer 的内容可参见【1】、【2】、【3】、【4】、【5】、【6】） 预训练好语言模型以后，怎么用到下游任务呢？以前的预训练语言模型在做下游任务的时候，可以任意设计自己的网络结构，而预训练语言模型只作为一个特征抽取器而已，在训练下游任务模型的时候，预训练的语言模型参数固定不变，只更新下游任务模型的参数。但是 GPT 说，我不要做配角，我要做主角！所以在利用 GPT 做下游任务的时候，我们需要把下游任务的网络结构设计成 GPT 的样子，利用预训练好的 GPT 初始化下游模型参数，然后利用任务数据对整个模型进行 fine-tuning。这样做的好处是，一来不需要特征融合（设计特征融合的方式也加入了过多的人工干预）；二是和 ULMFiT 一样的思路，先在通用领域的是语料上预训练语言模型，在下游任务 fine-tuning 的时候相当于在训练下游任务的同时，也在利用领域语料 fine-tuning 语言模型，相比于 ULMFiT，GPT 更加简洁明了。 那么问题来了， NLP 的各种任务花样百出，怎么改造才能靠近 GPT 的网络结构呢？ 论文给出的改造方案也很简单： 分类问题：直接在文本前后加上开始和结束符号； 判断句子关系问题：在两个句子之间添加一个分隔符即可； 文本相似性问题：将两个句子顺序颠倒做出两个输入，句子间仍然添加分隔符，之所以做成两个输入主要是告诉模型，句子的顺序不重要； 多选问题：制作多路输入，每一路是将文章和答案选项使用分隔符拼接在一起即可。 从图中我们可以看出，不同 NLP 任务的改造并不困难，只需要修改输入部分即可。而输出部分也是一个简单的全连接层。 GPT 最终的效果也是相当的惊艳，在实验涉及到的 12 项任务中，9 个达到了最佳效果！ 但是，由于 GPT 采用的是单向语言模型，使得 GPT 存在语言建模过程中信息不健全的固有缺陷，而正是这一缺陷给了后来者 BERT 的可乘之机。 3.1.3 技术爆发期时间来到 2018 年 10 月 11 日，这是一个本来平凡到不能再平凡的日子，一切都很平静。但是随着 Jacob Devlin 及其合作者在 Arxiv 上悄悄的放了一篇他们的最新论文 《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》，犹如一声惊雷彻底打破了宁静。首先是在 Twitter 上引发了巨大的浪潮，随后中文各大社区包括但不限于微信公众号、微博等几乎被刷屏。狂揽 11 项 NLP 任务的最佳效果，彻底宣告预训练语言模型的王者降临。 BERT 采用和 GPT 完全一致的两个阶段训练方式。与 GPT 最大的不同是采用了双向语言建模，为了防止双向语言建模时发生泄密，BERT 采用的是 Mask Language Model 方式训练语言模型。另外，BERT 还借鉴了 Skip-thoughts 的思想，通过预测下一个句子来获取句子信息（Next Sentence Prediction， NSP）。 输入层 BERT 的输入包含三种 Embedding：Token Embedding, Segment Embedding, Position Embedding。其中 Token Embedding 和 Position Embedding 分别对应词向量和位置向量，这个不难理解。那个 Segment Embedding 是用于区分两种句子的向量，正如我们上面说的， BERT 不仅是从语言模型中得到信息，还有一个 NSP 任务。BERT 对 NSP 任务的处理方式和 GPT 类似，将两个句子用一个分隔符拼接在一起，如下图所示。 Transformer Encoder 前面我们说，BERT 采用的是双向语言建模。我们知道 transformer encoder 是采用的自注意力机制，是一个并行结构，而不是像 LSTM 那样的串行结构。对于串行结构来说，我们将句子中的词按照正向顺序输入网络就得到正向模型，按照反向顺序输入模型就得到反向模型，将正向和反向的模型结合在一起就是双向模型。而对于并行结构来说，句子中的所有词是一起输入到模型中，并没有一个先后顺序，此时我们应该怎么理解 BERT 中的”双向“这个概念呢？ 如上左图，自注意力机制是将一句话中的每个词分别于其余的词计算点积（注意力权重），比如“我 爱 北京 天安门 。”，对于“北京”来说，当计算它与“我”、“爱”的注意力权重的时候即为前向，与“天安门”、“。”计算注意力权重的时候为后向。其实就是正常的自注意力的计算过程，被论文作者换了一个名字。 但是这里有一个问题，无监督的训练神经网络语言模型通常是使网络通过上文或者下文去预测当前的词，GPT 之所以用的是 Transformer decoder 很大程度考虑的也是通过 Mask multi-head attention 掩盖掉下文，避免下文信息泄露。而 BERT 直接采用 encoder 是对句子中的所有词都进行自注意力计算，这样就无可避免的会存在一个下文信息泄露。为了解决这个问题，Devlin 等人提出 Masked Language Model， 其核心思想就是随机将一些词替换成 “[Mask]” ，然后在训练过程中让模型利用上下文信息去预测被替换掉的词。其实它的本质和 CBOW 是一致的，只是说这里我们只预测 “[Mask]”。 但是这里会有一个问题：在训练的时候，训练数据中包含了大量的 “[Mask]”，但是在预测的时候，数据中是不包含 “[Mask]” 的，相当于认为地使在训练数据和真实数据产生了分布上的偏差，会使得模型在使用过程中出现问题。为了避免这个问题，BERT 的做法是： 随机挑选 15% 的词； 将选中的词中的 80% 替换成 [Mask]; 将选中的词中的 10% 随机替换成其他的词； 将选中的词中的 10% 不变。 将 80% 的词替换成 [Mask] 是为了防止泄密，这个正如我们上面所说的。将 10% 的词随机替换成其他词，这样做的目的是使模型不知道哪些词被 [Mask] 了，迫使模型尽量学习每一个词的全局表征，使得 BERT 能更好的的获得上下文相关的词向量。将 10% 的词不做替换，是为了使模型得到一定程度的 bias，相当于是额外的奖励，将模型对于词的表征能够拉向词的真实表征。 输出层 BERT 的下游任务主要有四种：句子关系分类、单句分类、阅读理解和序列标注。为了能适配这四种任务，BERT 设计了相应的输出层： 句子关系分类：输出序列的第一个位置后面链接一个 softmax 层用于分类； 单句分类：输出序列的第一个位置后面链接一个 softmax 层用于分类； 阅读理解：输出序列中每个词的分类，并将起始和终止位置中间的词取出即可； 序列标注：输出序列中每个词的分类，将对应列类别取出即可。 其实通过上面的介绍我们可以看出，BERT 本身的创新型并不强，算是一个前人工作的一个集大成者，类似于 Transformer 之于注意力。比如双向语言建模的特性是 Transformer encoder 自带的能力，Masked Language Model 实际上借鉴了 CBOW 的思想，而 NSP 则是借鉴 Skip-thoughts，在输出层的多任务适配更是借鉴了 GPT 的操作。 但是 BERT 的诞生也是具有划时代意义的： 明确了 NLP 的一个发展方向，两段式训练，双向语言模型，自注意力机制等都在后来的工作中大放异彩； 给了 NLP 一个做知识迁移的优雅的解决方案，单单是这一点就足以使 BERT 成为与计算机视觉中 ImageNet 相媲美的里程碑式成就，甚至可能比 ImageNet 更有意义，因为 BERT 预训练用的是无监督学习，无需人工标注，而 ImageNet 仍然是标注数据； 将 NLP 的发展推向了一个新的高度。在此之后，预训练语言模型迎来了爆发式的大发展，同时预训练语言模型也进入了百家争鸣的时代。 3.1.4 百家争鸣期BERT 诞生以后，彻底掀起了预训练语言模型的研究热潮，有针对性 BERT 的各种改进版，有提出新思路的创新版。在短短两年的时间内，预训练语言模型已经发展成了一个大家族，为了厘清家族成员之间的关系，复旦大学的邱锡鹏老师小组对两年来预训练语言模型进行了一下梳理，并根据不同视角将预训练语言模型进行了分类： 根据向量表示法将模型分成：上下文相关模型和非上下文相关模型； 根据模型结构将模型分成：使用 LSTM 模型；使用 Transformer encoder 模型；使用 Transformer deocder 模型；使用 Transformer 模型 根据预训练任务类型将模型分成：Language Model；Masked Language Model；Permuted Language Model；Denoising Autoencoder；Contrastive Learning； 根据模型的外围扩展：知识增强型；多语言型；特定语言；多模态；特定领域以及压缩模型等。 3.2 小结预训练语言模型在 NLP 各领域的强大能力令人兴奋，从 BERT 的提出到现在（2020.10.30）满打满算也不过两年的时间。预训练语言模型的发展也处于百花齐放的阶段，如同预训练技术在 NLP 的发展一样，经历了各种尝试，最后才发现了语言模型这条道路。预训练语言模型也一样，虽然现在每隔一段时间就会有一个新的模型出来刷榜，但是什么样的模型架构，以什么样的形式训练语言模型等等都还在处于探索阶段。在更高一层来看，目前的预训练语言模型并不能真正解决语言的认知能力问题。预训练语言模型的发展还远远没有达到成熟的阶段，但是基于这两年的发展，我们仍然能总结一些规律，也许能够使我们在往更强的模型发展上有迹可循。 首先，在保证数据质量的前提下，数据量越大，模型容量越大，训练越充分，预训练的模型效果越好； 其次，训练方式从传统的两段式扩展到四段式能达到更好的效果： 在大规模通用数据集上预训练大模型； 在预训练好的通用领域模型上利用领域数据再训练一个领域预训练模型； 在任务数据上，去掉标签，进行一次任务预训练； 最后再在具体任务上进行微调 再次，基于 Transformer 的架构往往能取得最佳效果，未来能否有新的架构取而代之我们拭目以待。 而目前预训练语言模型也存在着一些问题，比如有些新模型宣称能达到比 BERT 更好的效果，但实际上我们不能确定是因为新模型的模型结构在起作用还是由于它比 BERT 训练的更充分在起作用。也就是说，我们应该如何找到一个模型的能力上限是一个很重要的问题。另外，现在的预训练语言模型越来越大，训练数据越来越多，越来越考验计算硬件的能力，会将研究中心集中在一些资金充裕的地方，严重约束它的发展。 无论如何，预训练语言模型的成功使我们离 AI 更近了一步，目前存在的问题只有在一点一点的尝试、研究中去解决。 4. 为什么是语言模型？我们回过头来看，NLP 有众多任务分支：阅读理解、机器翻译、语法分析、自然语言推理、语言模型等等，为什么最后是语言模型成了 NLP 的 ImageNet？ 为了预测句子中下一个最可能的词，语言模型不仅需要学习到语法知识，还需要了解句子的语义。就像 ELMo 成功的关键就在于，他能从浅层获得句法特征，然后从深层获得语义特征一样。不仅如此，一个好的模型还要能从语料中学习到一些常识，比如 “The service was poor, but the food was”，为了预测下一个词，模型必须具备以下能力： 知道下一个词是用来描述 “food” 的； 知道 “but” 表示语义转折，并且知道对应的词是 “poor” 的反义词； 知道 “poor” 的反义词都有哪些。 语言模型能够获得与下游任务相关的信息，比如长程依赖、层级结构、感情信息等等。相比于 Skip-thoughts 和 autoencoding 等无监督的任务，语言模型更能获得语法信息（Kelly et al. 2018）。 而对于其他比如分类，机器翻译等任务来说，语言模型是无监督的。这样，语言模型的训练预料可以认为是无穷无尽的，而又无需人工标注。这一点对于 NLP 来说是至关重要的，目前世界上超过 1000 人使用的语言有 4500 多种，其中绝大多数的语言都是小语种，无论是直接获取语料资源还是进行人工标注，对于 NLP 任务来书都是巨大的挑战。有了无监督的语言模型，我们可以先在一些容易获取的，资源丰富的语言上先进性预训练，然后再在那些低资源（low-resource）语言上进行微调，对于小语种 NLP 的发展具有重要的意义。 从实际的发展来看，也印证了我们上面的说法，从 ELMo 到 BERT 正式开启了 NLP 的预训练时代，而这正是归功于预训练语言模型的发展。 Reference 02. 语言模型（language Model）发展历史 crazysnailer Can artificial neural network learn language models? W. Xu and A. Rudnicky A Neural Probabilistic Language Model Yoshua Bengio, Réjean Ducharme, Pascal Vincent, Christian Jauvin NLP’s ImageNet moment has arrived Sebastian Ruder, Andrey Kurenkov, Eric Wang, and Aditya Ganesh Recurrent neural network based language model T. Mikolov, M. Karafiat, L. Burget, ´J. Cernocky, and S. Khudanpur LSTM neural networks for language modeling M. Sundermeyer, R. Schluter, and H. Ney RNN Language Models Chainer 迁移学习简明手册 王晋东 Transfer Learning - Machine Learning’s Next Frontier Sebastian Ruder What is ImageNet and Why 2012 Was So Important GE Healthcare 从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史 张俊林 Embeddings in Natural Language Processing——Theory and Advances in Vector Representation of Meaning Mohammad Taher Pilehvar, Jose Camacho-Collados A synopsis of linguistic theory John R Firth Distributional structure Zellig S Harris Class-based n-gram models of natural language Peter F Brown, Peter V Desouza, Robert L Mercer, Vincent J Della Pietra, and Jenifer C Lai A vector space model for automatic indexing Gerard Salton, A. Wong, and C. S. Yang Representation Learning for Natural Language Processing Liu, Zhiyuan, Lin, Yankai, Sun, Maosong A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning Ronan Collobert, Jason Weston Natural Language Processing (Almost) from Scratch Ronan Collobert, Jason Weston, Leon Bottou, Michael Karlen, Koray Kavukcuoglu, Pavel Kuksa Three new graphical models for statistical language modelling Andriy Mnih, Geoffrey Hinton A scalable hierarchical distributed language model Andriy Mnih, Geoffrey Hinton Classes for fast maximum entropy training Goodman, J. Hierarchical probabilistic neural network language model Frederic Morin &amp; Yoshua Bengio Improving Word Representations via Global Context and Multiple Word Prototypes Eric Huang, Richard Socher, Christopher Manning, Andrew Ng NLP的巨人肩膀（中） weizier Distributed Representations of Sentences and Documents Quoc Le, Tomas Mikolov Skip-Thought Vectors Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio Torralba, Raquel Urtasun, Sanja Fidler AN EFFICIENT FRAMEWORK FOR LEARNING SENTENCE REPRESENTATIONS Lajanugen Logeswaran &amp; Honglak Lee Supervised Learning of Universal Sentence Representations from Natural Language Inference Data Alexis Conneau, Douwe Kiela, Holger Schwenk, Loic Barrault, Antoine Bordes Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning Sandeep Subramanian, Adam Trischler, Yoshua Bengio, Christopher J Pal Universal Sentence Encoder Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil Semi-supervised Sequence Learning Andrew M. Dai &amp; Quoc V. Le context2vec: Learning Generic Context Embedding with Bidirectional LSTM Oren Melamud, Jacob Goldberger, Ido Dagan Semi-supervised sequence tagging with bidirectional language models Matthew E. Peters, Waleed Ammar, Chandra Bhagavatula, Russell Power Universal Language Model Fine-tuning for Text Classification Jeremy Howard, Sebastian Ruder 放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较 张俊林 乘风破浪的PTM：两年来预训练模型的技术进展 张俊林 A Survey on Neural Network Language Models Kun Jing and Jungang Xu Pre-trained Models for Natural Language Processing: A Survey Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai &amp; Xuanjing Huang Deep Learning in NLP （一）词向量和语言模型 LICSTAR Neural Transfer Learning for Natural Language Processing Sebastian Ruder Adversarial Examples for Evaluating Reading Comprehension Systems Jia, R. and Liang, P. (2017) Synthetic and Natural Noise Both Break Neural Machine Translation Belinkov, Y. and Bisk, Y. (2018) Deep contextualized word representations Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer Language Modeling Teaches You More than Translation Does: Lessons Learned Through Auxiliary Task Analysis Kelly W. Zhang, Samuel R. Bowman Improving Language Understanding by Generative Pre-Training Alec Radford，Karthik Narasimhan，Tim Salimans，Ilya Sutskever BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova 后 BERT 时代的那些 NLP 预训练模型 李理","categories":[{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"}],"tags":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/tags/nlp/"},{"name":"Language Model","slug":"language-model","permalink":"https://rogerspy.gitee.io/tags/language-model/"}]},{"title":"Transformer家族之Deep Transformer","slug":"transformer家族-deep","date":"2020-05-23T02:24:01.000Z","updated":"2022-01-12T08:37:38.435Z","comments":true,"path":"2020/05/23/transformer家族-deep/","link":"","permalink":"https://rogerspy.gitee.io/2020/05/23/transformer家族-deep/","excerpt":"Transformer 的功能强大已经是学术界的共识，但是它难以训练也是有目共睹的。本身的巨大参数量已经给训练带来了挑战，如果我们想再加深深度可谓难上加难。这篇文章将会介绍几篇就如何加深 Transformer 的展开研究论文。从目前的研究来看 Transformer 之所以难训是由于梯度消失的问题，要对 Transformer 进行加深就必须要解决这个问题，今天我们介绍三种方法： Depth-Scaled Initialization Lipschitz Constrained Parameter Initialization Pre-Norm","text":"Transformer 的功能强大已经是学术界的共识，但是它难以训练也是有目共睹的。本身的巨大参数量已经给训练带来了挑战，如果我们想再加深深度可谓难上加难。这篇文章将会介绍几篇就如何加深 Transformer 的展开研究论文。从目前的研究来看 Transformer 之所以难训是由于梯度消失的问题，要对 Transformer 进行加深就必须要解决这个问题，今天我们介绍三种方法： Depth-Scaled Initialization Lipschitz Constrained Parameter Initialization Pre-Norm 1. Vanishing Gradient Analysis从目前的研究来看，影响 Transformer 收敛的主要因素是残差连接和 LayerNorm 部分的梯度消失问题，比如 Chen et al. (2018) ，Zhang et al. (2019)，Wang et al. (2019)，Xiong et al. (2020) 的研究都证实了这一假设。 Transformer 残差连接和 LayerNorm 如下： y_l = x_l+\\mathcal{F}(x_l;\\theta) \\\\\\\\ x_{l+1} = \\mathrm{LayerNorm}(y_l)令 $\\mathcal{E}$ 表示损失，$x_L$ 表示顶层 sub-layer 的输出，根据链式法则有： \\frac{\\partial\\mathcal{E}}{\\partial x_l} = \\frac{\\partial \\mathcal{E}}{\\partial x_L} \\frac{\\partial x_L}{\\partial x_l}一层一层分解得： \\frac{\\partial x_L}{\\partial x_l} = \\frac{\\partial x_L}{\\partial x_{L-1}} \\frac{\\partial x_{L-1}}{\\partial x_{L-2}} \\cdots \\frac{\\partial x_{l+1}}{\\partial x_l}将 $x_{l+1}$ 表达式代入得： \\frac{\\partial x_{l+1}}{\\partial x_l} = \\frac{\\partial x_{l+1}}{\\partial y_l}\\frac{\\partial y_l}{\\partial x_l}=\\frac{\\partial \\mathrm{LayerNorm}(y_l)}{\\partial y_l}\\left(1 + \\frac{\\partial \\mathcal{F}(x_l;\\theta_l)}{\\partial x_l}\\right)因此，我们可以得到： \\frac{\\partial \\mathcal{E}}{\\partial x_l} = \\frac{\\mathcal{E}}{\\partial x_L} \\times \\prod_{k=l}^{L-1}\\left[\\frac{\\partial \\mathrm{LayerNorm(y_k)}}{\\partial y_k}\\left(1+\\frac{\\partial \\mathcal{F}(x_k;\\theta_k)}{\\partial x_k}\\right) \\right]从上面的分析可以看出，损失函数在先后传播的时候是连乘形式的，这样很容易出现梯度消失或者梯度爆炸问题。另外，Xiong et al. (2020) 进一步证明随着损失梯度的向后传播的深度，其大小是以 $(2/3)^{L-l}$ 指数形式下降的。 实验上，下面两张图分别是 Zhang et al. (2019) 和 Xiong et al. (2020) 的独立实验结果。上图我们只看实线部分，下图只看橙色柱状图。我们会发现，实验结果所展示出来的原始的 Transformer 中损失梯度随层数的变化趋势和理论分析基本一致。因此，我们可以认为之前的理论分析是合理的。 现在，我们知道 Transformer 梯度消失之谜了，接下来我们就可以针对这个问题提出解决方案了。 2. Depth-Scaled Initialization and Merged Attention2.1 Depth-Scaled InitializationZhang 等人将 Transformer 的梯度消失问题归咎于残差连接输出的方差过大（方差过大会造成梯度消失可参考自注意力为什么scaled 的相关讨论）。 传统的 Transformer 所有参数都是通过均匀分布随机采样初始化的： \\mathbf{W} \\in \\mathbb{R}^{d_i \\times d_o} \\sim \\mathcal{U}(-\\gamma, \\gamma) \\\\\\\\ \\gamma = \\sqrt{\\frac{6}{d_i + d_o}}其中 $d_i$ 和 $d_o$ 分别表示输入和输出的维度。 作者定义了误差信号的变化比率 $\\beta$ 来表示在传播过程中误差信号是增强还是减弱。$\\beta = \\beta_{RC}\\cdot \\beta_{LN}$，其中 $\\beta_{RC}$ 和 $\\beta_{LN}$ 分别表示残差连接和 LayerNorm 对误差信号的影响。为了保证训练过程的稳定，理论上我们应该尽量让 $\\beta$ 保持在 $\\beta \\approx 1$。通过实验发现 LayerNorm 会削弱信号 $\\beta_{LN} \\lt 1$，残差连接会增强信号 $\\beta_{RC} \\gt 1$，并且而削弱的强度小于增强的强度，也就是说最终会导致 $\\beta \\gt 1$。 为了避免这种情况发生，作者提出一种新的初始化方法 —— DS-Init： \\mathbf{W} \\in \\mathbb{R}^{d_i \\times d_o} \\sim \\mathcal{U}(-\\gamma \\frac{\\alpha}{\\sqrt{l}}, \\gamma \\frac{\\alpha}{\\sqrt{l}}) \\\\其中 $\\alpha \\sim [0, 1]$ 是一个超参数，$l$ 表示网络层深度。 根据均匀分布的性质，使用 DS-Init 初始化后模型参数的方差会从 $\\frac{\\gamma^2}{3}$ 降到 $\\frac{\\gamma^2 \\alpha^2}{3l}$，也就是说，$l$ 越大其输出的方差会越小。 上面的图中虚线部分则展示了，使用 DS-Init 初始化方法后每层的误差梯度。从图中可以看出，该初始化方法是有效的。利用 DS-Init 初始化方法来解决梯度消失问题的另一大优势是，无需修改模型结构，只需要修改初始化方法即可，简单有效又方便。 2.2 Merged Attention Model随着模型深度的增加，计算量会变得很大，训练和推理时间都会大大增加。为了解决这个问题，作者提出 Merged Attention Model，该模型是 AAN（Average Attention Network） 的一种简化：移除了出了线性变换之外所有的矩阵运算: \\mathrm{SAAN}(\\mathbf{S}^{l-1}) = \\left[ \\mathbf{M}_a(\\mathbf{S}^{l-1}\\mathbf{W}_v)\\right]\\mathbf{W}_o其中 $\\mathbf{M}_a$ 表示 AAN 中的 mask 矩阵。然后通过如下方式将其与 cross-attention 相结合： \\mathrm{MATT}(\\mathbf{S}^{l-1}) = \\mathrm{SAAN}(\\mathbf{S}^{l-1}) + \\mathrm{ATT}(\\mathbf{S}^{l-1}, \\mathbf{H}^L) \\\\\\\\ \\bar{\\mathbf{S}}^l = \\mathrm{LN}(\\mathrm{RC}(\\mathbf{S}^{l-1}, \\mathrm{MATT}(\\mathbf{S}^{l-1})))其中 $\\mathbf{W}_o$ 在 SAAN 和 MATT 中共享， $\\mathbf{H}^L$ 为编码器的输出， $\\mathrm{ATT}$ 是 cross-attention。具体的结构图如下： 3. Pre-Norm for Deep Residual Network除了对参数的方差进行归一化之外，Wang 等人首次指出 Transformer 中的层正则化位置对于训练一个深层网络至关重要。通过重新定位层正则化的位置将其置于每个子层的输入之前，便能够有效解决深层网络当中容易出现的梯度爆炸或者梯度消失现象，这对训练深层网络的影响在之前并未被研究过。 3.1 Pre-Norm Transformer 的残差连接和 LayerNorm 组合方式称为 post-norm。具体的计算流程如图（a）所示：层输入-&gt;层计算-&gt;dropout-&gt;残差累加-&gt;层正则化。 这种方式可能出现的问题如第 1 节讨论，连乘形式的损失梯度很容造成梯度消失或者爆炸。因此，深层 Transformer 通常不容易收敛。 针对这个问题，作者提出 pre-norm 的组合方式，计算流程如图（b）所示：层输入-&gt;层正则化-&gt;层计算-&gt;dropout-&gt;残差累加。 我们来分析下这种组合方式的梯度形况。 x_{l+1} = x_l + \\mathcal{F}(\\mathrm{LN}(x_l); \\theta_l)=x_l+\\mathcal{F}(x_l;\\theta_l)我们仔细观察 pre-norm 会发现，它有一个重要的特性： \\begin{equation} \\nonumber \\begin{aligned} x_L &= x_{L-1} + \\mathcal{F}(x_{L-1};\\theta_{L-1}) \\\\\\\\ & = x_{L-2} + \\mathcal{F}(x_{L-2};\\theta_{L-2}) + \\mathcal{F}(x_{L-1};\\theta_{L-1})\\\\\\\\ & \\cdots \\\\\\\\ &= x_l +\\sum_{k=l}^{L-1} \\mathcal{F}(x_k;\\theta_k) \\end{aligned} \\end{equation}这样 $x_L$ 相对 $x_l$ 的导数可以写作： \\frac{\\partial x_L}{\\partial x_l} = 1+ \\sum_{k=l}^{L-1}\\frac{\\partial \\mathcal{F}(x_k;\\theta_k)}{\\partial x_l}将该式带入误差的导数公式： \\frac{\\partial \\mathcal{E}}{\\partial x_l} = \\frac{\\partial \\mathcal{E}}{\\partial x_L} \\times \\left( 1+ \\sum_{k=l}^{L-1}\\frac{\\partial \\mathcal{F}(\\mathrm{LN}(x_k);\\theta_k)}{\\partial x_l}\\right)对比一下 post-norm 的误差梯度： \\frac{\\partial \\mathcal{E}}{\\partial x_l} = \\frac{\\mathcal{E}}{\\partial x_L} \\times \\prod_{k=l}^{L-1}\\left[\\frac{\\partial \\mathrm{LayerNorm(y_k)}}{\\partial y_k}\\left(1+\\frac{\\partial \\mathcal{F}(x_k;\\theta_k)}{\\partial x_k}\\right) \\right]我们会发现，等号右边第二项从连乘变成了连加。这样就解决了连乘可能带来的梯度消失或者爆炸问题。同时，通过 pre-norm 的方式网络在反向更新时，底层网络参数可以直接获得顶层梯度的信息，而不经过其他的变换，使得误差信息更容易传递到底层。 3.2 Dynamic Linear Combination of Layers对于深层网络来说，残差连接的方式可能准确度还不够，一个可能的原因是，只用了前一步的信息来预测当前的值。机器翻译的 “单步”特性导致模型可能会 “忘记”距离比较远的层。这就会导致底层的网络训练不充分，针对这个问题作者提出动态线性组合（Dynamic Linear Combination of Layers, DLCL）的方式在信息传递至下一层时对之前所有层的输出进行线性聚合。 令 $\\{ y_0, …, y_l\\}$ 表示 $0 \\sim l$ 层的输出。定义 $l+1$ 层的输入： x_{l+1} = \\mathcal{G}(y_0, ..., y_l)其中 $\\mathcal{G}(\\cdot)$ 是是一个整合之前各层输出的线性函数，定义如下： \\mathcal{G}(y_0,...,y_l) = \\sum_{k=0}^l W_k^{(l+1)} \\mathrm{LN}(y_k)其中 $W_k^{(l+1)} \\in \\mathbb{R}$ 是一个可学习的标量，用来对每个输出层进行加权。 DLCL 可以看成一种普适的方法，如下图所示： （a）表示标准的残差网络：He et al. (2016)； （b）表示均匀权重的稠密残差网络：Britz et al. (2017)； （c）表示多层融合：Wang et al. (2018)； （d）表示表示本文的方法。 4. Experiments DS-Init 实验结果 Pre-norm 实验结果 5. Personal Thought本文介绍了两种加深 Transformer 的方法，一种是改变模型参数的初始化，一种是改变残差连接方式。无论哪一种目的都是解决深层 Transformer 的梯度消失/爆炸的问题。实际上还有几篇讨论加深 Transformer 的文章这里没有介绍，但是大致思路都差不多。 Kaiming 大神在2016年发表了一篇论文讨论 BN, activation 和 residual 之间的关系：Identity Mappings in Deep Residual Networks。结合关于加深 Transformer 的工作的各种方法来看，我们是不是可以大胆的猜测 Residual、LN、Initialization、Gradient 这四者之间，是否存在千丝万缕的联系？ Reference Improving Deep Transformer with Depth-Scaled Initialization and Merged Attention. Biao Zhang, Ivan Titov, Rico Sennrich. 2019. ACL Lipschitz Constrained Parameter Initialization for Deep Transformers. Hongfei Xu, Qiuhui Liu, Josef van Genabith, Deyi Xiong, Jingyi Zhang. 2020. arXiv: 1911.03179 Learning Deep Transformer Models for Machine Translation. Qiang Wang, Bei Li , Tong Xiao, Jingbo Zhu, Changliang Li, Derek F. Wong, Lidia S. Chao. 2019. arXiv: 1906.01787 On Layer Normalization in the Transformer Architecture Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Huishuai Zhang, Yanyan Lan, Liwei Wang, Tie-Yan Liu. ICLR 2020 (reject) 如何在NLP中有效利用Deep Transformer AI科技点评, 知乎 香侬读 | Transformer中warm-up和LayerNorm的重要性探究 香侬科技，知乎","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"Deep","slug":"deep","permalink":"https://rogerspy.gitee.io/tags/deep/"},{"name":"Initialization","slug":"initialization","permalink":"https://rogerspy.gitee.io/tags/initialization/"},{"name":"Norm","slug":"norm","permalink":"https://rogerspy.gitee.io/tags/norm/"}]},{"title":"Transformer家族之Guassian Transformer","slug":"transformer家族-guasssian","date":"2020-05-13T02:23:04.000Z","updated":"2022-01-12T08:37:38.438Z","comments":true,"path":"2020/05/13/transformer家族-guasssian/","link":"","permalink":"https://rogerspy.gitee.io/2020/05/13/transformer家族-guasssian/","excerpt":"我们仔细回想一下 Transformer 在计算自注意力的过程， 我们会发现，序列中每个词在与其他词计算注意力权重的时候是无差别计算的。也就是说，这里隐藏着一个假设：词与词之间的距离对语义依赖是没有影响的（抛开位置编码的影响）。然而，根据我们的直觉，距离越近的词可能依赖关系会更强一些。那么事实是怎样的呢？Guo 等人 2019 对这个问题进行了研究，并提出 Gaussian Transformer 模型。","text":"我们仔细回想一下 Transformer 在计算自注意力的过程， 我们会发现，序列中每个词在与其他词计算注意力权重的时候是无差别计算的。也就是说，这里隐藏着一个假设：词与词之间的距离对语义依赖是没有影响的（抛开位置编码的影响）。然而，根据我们的直觉，距离越近的词可能依赖关系会更强一些。那么事实是怎样的呢？Guo 等人 2019 对这个问题进行了研究，并提出 Gaussian Transformer 模型。 1. Motivation在我们日常生活经验中，句子中的一个词通常会与其周围的词关系更为紧密。传统的自注意力计算中，并没有考虑距离的影响。虽然在 Transformer 中使用了位置编码，但实际上自注意力对此并不敏感，这一点我们在最后讨论，这里简单考虑没有添加位置编码的情况。举个例子：I bought a new book yesterday with a new friend in New York. 句子中一共出现 3 次 “new”。对于 “book” 来说，只有第一个 “new” 是有意义的，其他两个对它没有任何影响，但是从下图 （a）我们可以看到，普通自注意力分配给了 3 个 “new” 以相同的注意力权重。 （b）是我c们考虑距离权重，距离越近权重越大，将这个先验的权重加入到自注意力计算过程，我们得到（c）的自注意力分布，从而更有效的对句子内部结构进行建模。 2. Gaussian Self-Attention 假设 $x_i$ 表示句子 $x$ 中的第 $i$ 个词，普通的注意力计算如上图（a）所示： \\tilde{x}_i = \\sum_j \\mathrm{softmax}(x_i \\cdot x_j) \\cdot x_j为了考虑词与词之间的距离对词义依赖关系的影响，作者考虑加入先验的高斯分布。由于我们很难去真实地统计到底什么样的分布最符合实际情况，所以作者对比了多种不同的分布，最后发现高斯分布的效果最好，所以选择了高斯分布。 为了简单起见，定义标准正态分布：$\\sigma^2=1/(2\\pi)$，概率密度函数：$\\phi(d) = e^{-\\pi d^2}$，其中 $d$ 表示词与词之间的距离。将 $\\phi(d_{i,j})$ 加入到上式当中： \\begin{equation} \\nonumber \\begin{aligned} \\tilde{x}_i &= \\sum_j \\frac{\\phi(d_{i.j}) \\cdot \\mathrm{softmax}(x_i \\cdot x_j)}{\\sum_k \\phi(d_{i, k})} \\cdot x_j\\\\\\\\ &= \\sum_j \\frac{e^{-\\pi d_{i, j}^2} \\cdot e^{(x_i \\cdot x_j)}}{\\sum_k e^{-\\pi d_{i, k}^2} \\cdot e^{(x_i \\cdot x_k)}} \\cdot x_j \\\\\\\\ &= \\sum_j \\frac{e^{- \\pi d^2_{i, j} + (x_i \\cdot x_j)}}{\\sum_k e^{-\\pi d_{i, k}^2 + (x_i \\cdot x_k)}} \\cdot x_j \\\\\\\\ &= \\sum_j \\mathrm{softmax}(-\\pi d_{i, j}^2 + (x_i \\cdot x_j)) \\cdot x_j \\end{aligned} \\end{equation}上式第一步中分母 $\\sum_k \\phi(d_{i, k}^2)$ 是为了归一化。上式第一个公式是我们直接将高斯分布插入到注意力计算的方式，如上图（b）所示，然后我们发现该式可以通过后续的一系列约化，转化成最后一行公式的形式，如上图（c）所示。这样的约化的好处是将高斯项从因子项转化成偏置项，省去了乘法操作，只需要加法操作即可，这样可以省去很大的计算开销。 由于上面我们假设了高斯的方差为 $1/(2\\pi)$，但实际情况不一定是这样的，所以引入一个 $w$ 因子用于弱化这个限制： \\tilde{x}_i = \\sum_j \\mathrm{softmax}(-w \\cdot \\pi d_{i, j}^2 + (x_i \\cdot x_j)) \\cdot x_j通过实验发现，我们再额外加入一个惩罚项 $b$ 用以减弱 $x_i$ 自身的影响效果会更好： \\tilde{x_i} = \\sum_j \\mathrm{softmax}(- |w\\cdot \\pi d_{i, j}^2 + b| + (x_i \\cdot x_j)) \\cdot x_j其中 $w&gt;0, b \\le 0$ 是标量。加入了二者的高斯分布分别如下图所示： 3. Gaussian Transformer Gaussian Transformer 模型面向的任务不是机器翻译，甚至不是序列生成任务，而是判别任务。具体来说是为了自然语言推断任务设计的模型。所谓自然语言推断（Natural Language Inference, NLI）又叫文本蕴含识别（Recognizing Textual Entailment, RTE），是研究文本之间的语义关系，含括蕴含（entailment）、矛盾（contradiction）和中性（neutral）。形式上，NLI 是一个文本分类的问题。 形式化描述为：输入一个句子对：$(\\{p_i\\}^{l_p}_{i=1}, \\{h_j\\}^{l_h}_{j=1})$ 分别表示前提（premise）和假设（hypothesis），其中 $p_i, h_j \\in \\mathbb{R}^V$，分别表示两个句子中第 $i$ 和第 $j$ 个词的 one-hot 向量，$l_p, l_h$ 分别表示两个句子的长度， $V$ 表示词表的大小。模型输出 $\\{entailment, contradiction, neutral\\}$ 代表的标签。 上图展示了 Gaussian Transformer 的整体结构。主要分为：Embedding Block、Encoding Block、Interaction Block 和 Comparison Block 四大部分，下面我们就详细介绍一下每一部分。 3.1 Embedding BlockEmbedding Block 的目的是将句子中的每个词转化成高维向量，主要包含三部分：字向量、词向量和位置向量。 字向量 字向量使用随机初始化的 $n-grams$ 字向量进行映射，然后对每个 token 进行 max-over-time pooling： x_i^{(c)} = \\max_t(\\{x_{i, t}^{(c)}E_c\\}_{t=1}^{l_{x_i}}) 词向量 词向量就使用预训练的词向量矩阵进行映射： x_i^{(w)} = x_iE_w 位置向量 位置向量使用 Transformer 中的位置向量： x_{i, 2k}^{(p)} = \\sin(i/10000^{2k/d_{model}}) \\\\\\\\ x_{i, 2k+1}^{(p)} = \\cos(i/10000^{2k/d_{model}}) 有了三个向量之后，将字向量和词向量拼接在一起，然后经过投影矩阵将拼接后的向量投影成 $d_{model}$ 维矩阵，然后与位置向量相加得到最终的 Embedding Block 输出。 x_i^{(e)} = x_i^{(p)} + [x_i^{(w)}: x_i^{(c)}] \\cdot W_e位置向量是不需要训练的，字向量和词向量在映射成高维矩阵之后还会经过一个投影矩阵 $W_e$ 将其维度变换成模型需要的 $d_{model}$ 维。字向量和词向量在模型训练过程是固定的，即不需要训练，需要训练的只是投影矩阵。 词向量不训练可以理解，但是字向量是随机初始化的，也不训练这样真的合适吗？ 3.2 Encoding Block在 Encoding Block 中包含了 $M$ 个子模块用来抽取句子特征，每个子模块都有相同的结构，除了计算多注意力的时候引入了高斯分布以外，其他都与 Transformer 保持一致。 因此，每个子模块包含两部分： 多头高斯自注意力层 FFN 层 层与层之间使用残差网络和 LayerNorm 连接。 这部分的核心是高斯自注意力，我们在上一章已经详细介绍过了，其他的和 Transformer 一致，因此不再赘述。 3.3 Interaction BlockInteraction Block 的作用是将两个句子进行信息交互。这一部分与原始的 Transformer 的 Decoder 部分类似， 区别是我们去掉了 Positional Mask 和解码的部分。 通过堆叠 $N$ 个 Interaction 模块，我们可以捕获高阶交互的信息。 3.4 Comparison BlockComparison Block 的作用就是模型最后的输出预测了。这个模块包含两部分： 聚合层 在聚合层，作者将 Encoding Block 以及 Interaction Block 的输出拼接到了一起，然后经过了两层带 relu 函数的全连接将维度从 $2d_{model}$ 变为 $d_{model }$。然后又经过了一个缩放的加法，后面就输入到了预测层： v_i = \\mathrm{Dense}(\\mathrm{Relu}(\\mathrm{Dense}([x_i:\\tilde{x}_i]))) \\\\\\\\ \\bar{x} = \\frac{1}{\\sqrt{l_x}}\\sum_{i=1}^{l_x}(v_i) 预测层 我们使用经典的 MLP 分类器对输出进行分预测： y = \\mathrm{softmax}(\\mathrm{Dense}(\\mathrm{Relu}(\\mathrm{Dense}([\\bar{p}: \\bar{h}])))) 4. Experiment 从实验结果可以看出，Gaussian Transformer 相比其他模型不仅参数量上非常少，而且效果也达到了最佳。另外在效率上，作者对比了 ESIM 模型，发现 GT 不仅准确率更高，而且训练速度提升了近 4 倍，推理效率提升了近8 倍。 5. 高斯假设的有效性问题之前我们在最开始讨论的时候，假设在计算自注意力的时候不考虑位置编码。那么高斯假设和加上位置编码后的自注意力相比究竟是不是有效呢？这里作者进行了讨论。 作者对比了原始 Transformer 与 GT 在 MultiNLI 数据集上的表现，发现 GT 的效果更优。另外，作者也对比了不同的分布假设以及 GT 的各种变种，最终发现上面的方法是最优的。 Reference Gaussian Transformer: A Lightweight Approach for Natural Language Inference, Maosheng Guo, Yu Zhang, Ting Liu. 2019. AAAI Gaussian Transformer论文解读, 宋青原，知乎 AAAI 2019 Gaussian Transformer: 一种自然语言推理的轻量方法","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"Gaussian","slug":"gaussian","permalink":"https://rogerspy.gitee.io/tags/gaussian/"}]},{"title":"Transformer家族之Universal Transformer","slug":"transformer家族-ut","date":"2020-05-11T02:30:11.000Z","updated":"2022-01-12T08:37:38.460Z","comments":true,"path":"2020/05/11/transformer家族-ut/","link":"","permalink":"https://rogerspy.gitee.io/2020/05/11/transformer家族-ut/","excerpt":"自从 2017 年谷歌提出 Transformer 模型以后，其在多个任务上的表现都超过了前辈 RNN, 但是在某些任务上表现却差强人意，比如复制字符串（输入 abc， 输出 abcabc）。随后谷歌对原始的 Transformer 进行了改进，提出了 Universal Transformer 模型使其具有更强的泛用性，同时该模型也是图灵完备的。","text":"自从 2017 年谷歌提出 Transformer 模型以后，其在多个任务上的表现都超过了前辈 RNN, 但是在某些任务上表现却差强人意，比如复制字符串（输入 abc， 输出 abcabc）。随后谷歌对原始的 Transformer 进行了改进，提出了 Universal Transformer 模型使其具有更强的泛用性，同时该模型也是图灵完备的。 1. IntroductionTransformer 解决了 RNN 的最大缺陷：无法并行处理输入序列以及最大长度依赖问题（梯度消失）。但是同时也放弃了 RNN 的两大优势：对迭代学习的归纳偏置（inductive bias towards learning iterative）和递归转换（recursive transformations），而这些优势在某些任务中起到了至关重要的作用。所以 Transformer 会在某些任务中被 RNN 轻易打败。 谷歌大脑的研究人员们针对这种情况，对 Transformer 进行了扩展，提出 Universal Transfomer 模型。该模型不仅保留了 Transformer 的并行能力和借助自注意力机制从距离较远的词中提取含义这两大优势，又引入时间并行的循环变换结构，相当于将 RNN 的两大优势也纳入其中。更重要的一点是：相比于 RNN 那种一个符号接着一个符号从左至右依次处理的序列处理方式，Universal Transformer 是一次同时处理所有的符号，而且 Universal Transformer 会根据自我注意力机制对每个符号的解释做数次并行的循环处理。 时间并行循环的大致计算过程如下： 在每个步骤中，每一个符号（比如句子中的一个词）的信息都可以借助自注意力机制与所有其他的符号进行沟通，就和原本的 Transformer 一样。不过，要对每个符号应用几次这种变换（也就是循环步骤的数目）可以预先手工设置为某个值（比如设置为定制，或者设置与输入长度相关），也可以由 Universal Transformer 自己在执行中动态地选择。为了能够达到后一种效果，研究人员为每个位置加入了一个自适应计算机制，它可以自定义在每个词上计算的次数。 举个例子：I arrived at the bank after crossing the river 句子中 “I“, “river“ 等词意义比较明显，不存在什么歧义，所以模型可能只在这些词上计算 1 次（循环一次），但 “bank“ 就不一样了，这个词是一个歧c义词，需要通过上下文才能确定词义，因此，模型可能会多次计算该词的词义（循环多次）。这样的设定理论上讲，可以让 UT 具有更强的能力。 2. 模型结构 对比 Universal Transformer 结构图和 Transformer 结构图可以发现，两者主要有三个区别： 循环结构 位置编码多了一个 Timestep embedding; FFN 变成了 Transition Function 在循环结构上，如上面讨论的，对于每个词的循环次数可以有两种方法确定：① 作为超参数人工设定，如同 Transformer 那样设成 6；② 模型自动设定，要实现这个功能，模型需要加入一个新的机制 —— 自适应计算时间 （Adaptive Computation Time，即 ACT） 下面我们针对这四个变化详细介绍一下。 2.1 Recurrent 机制2.1.1 Encoder给定输入序列长度 $m$，词向量维度 $d$，初始序列嵌入矩阵 $H^0 \\in \\mathbb{R}^{m \\times d}$。$H^t$ 表示经过 $t$ 次循环以后的序列嵌入矩阵。 \\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d}})V\\\\\\\\ \\mathrm{MultiHeadAttention}(H^t) = \\mathrm{Concat}(head_1, ..., head_k)W^O\\\\\\\\ head_i=\\mathrm{Attention}(H^tW_i^Q, H^tW_i^K, H^tW_i^V)其中 $W^Q \\in \\mathbb{R}^{d \\times d/k}$，$W^K \\in \\mathbb{R}^{d \\times d/k}$， $W^V \\in \\mathbb{R}^{d \\times d/k}$。 在第 $t$ 步时， $H^t \\in \\mathbb{R}^{m \\times d}$ 的计算如下： H^t = \\mathrm{LayerNorm}(A^t + \\mathrm{Transition}(A^t)) \\\\\\\\ A^t = \\mathrm{LayerNorm}((H^{t-1}+P^t) + \\mathrm{MultiHeadAttention}(H^{t-1}+P^t))其中 $\\mathrm{Transition}(\\cdot)$ 为 Transition Function；$P^t$ 为 Timestep embedding （或者 coordinate embedding），在后面详细介绍。 2.1.2 Decoder解码器与编码器的循环结构基本相同，只是多了一个接受编码器最终状态的另一个多头注意力，其输入的 $Q$ 来自解码器， $K$ 和 $V$ 来自编码器。 训练 训练的时候，对于一组输入输出序列样本解码器接受右移动一位的输出序列样本作为输入，相应解码器的自注意力机制也被修改成只能访问它左边的预测结果。每轮生成一个字符，通过 softmax 获得每个字符的输出概率： p(y_{pos}|y_{[1:pos-1]}, H^T)=\\mathrm{softmax}(OH^T)其中 $O \\in \\mathbb{R}^{d \\times V}$。这部分和 Transformer 是一致的，不再赘述。 推理 在生成时编码器只运行一次而解码器反复运行。解码器接受的输入为已经生成的结果，每次(一次可以有多轮)的输出为下一个位置的符号概率分布。我们选择出现概率最高符号作为修订后的符号。 2.1.3 parallel-in-time recurrent假设给定一个序列： $(a, b, c, d)$。UT 先将该序列经过 embedding 表示成 $(h^0_a, h^0_b, h^0_c, h^0_d)$ 初始化序列矩阵，然后经过 MultiHeadAttention 层和 Transition 层表示成 $(h^1_a, h^1_b, h^1_c, h^1_d)$。以此类推，经过 $t$ 次循环以后序列被表示成 $(h^t_a, h^t_b, h^t_c, h^t_d)$。 这个循环过程与 RNN 有着截然不同的计算方式。RNN 的循环计算过程是，先计算 $h^0_a$，然后依次计算$h^0_b, h^0_c, h^0_d$，然后进入下一个循环，直到 $t$ 步以后生成 $(h^t_a, h^t_b, h^t_c, h^t_d)$。也就是相当于对于 RNN 来讲，要循环计算 $t$ 次 $m$ 长度的序列，模型需要计算 $m \\times t$ 次运算，而 UT 只需要计算 $t$ 次。 2.2 Coordinate EmbeddingTransformer 中计算位置向量只需要考虑词的位置就好，这里又考虑了时间维度。 P^t_{i, 2j} = \\sin(i/10000^{2j/d}) + \\sin(t/10000^{2j/d}) \\\\\\\\ P^{t}_{i, 2j+1} = \\cos(i/10000^{2j/d}) + \\cos(t/10000^{2j/d})其中 $P^t \\in \\mathbb{R}^{m \\times d}$，维度与序列矩阵保持一致。 2.3 Transition Function根据任务的不同，作者使用两种不同的 transition function：可分离卷积或全连接神经网络。 2.4 Adaptive Computation Time (ACT)所谓自适应计算时间，是 Graves 等人 2016 年 提出的一种算法，该算法能自动学习 RNN 需要计算多少轮。用在 UT 中，使得模型能够对序列中不同的词有不同的循环次数，比如序列 $(a,b,c,d)$ 中 $a$ 只循环计算 1 次， $b$ 可能计算 2次，$c$ 会计算 5 次， $d$ 计算 8 次。而每个词的循环计算次数由 ACT 决定。当某个位置“停止”后，它的隐状态直接拷贝到下一步，直到所有位置都停止循环。 简单来说 ACT 会计算每个位置上的词需要停止的概率 （$p \\sim [0, 1]$），当 $p$ 大于某个阈值的时候该位置上的词及计算就会停止。为了避免死循环，还可以设置一个最大循环次数，当循环次数达到该值的时候，循环也会被强行停止。 3. Experiments 作者利用 bAbI 数据集和 WMT14 En-De 数据集在问答，语言模型，机器翻译等任务上做了充分的实验，实验结果表明 UT 的表现能达到更好的效果。上图我们只展示机器翻译的结果，更详细的实验可参看原文。 4. Personal Thought关于 Universal Transformer 的模型部分我们就介绍完了，总的来说 UT 具备了一些 Transformer 不具备的能力，解决了一些原有的缺陷。在问答、语言模型、翻译等任务上的表现都有所提升。 Weight sharing：归纳偏置是关于目标函数的假设，CNN 和 RNN 分别假设 spatial translation invariance 和 time translation invariance，体现为 CNN 卷积核在空间上的权重共享和 RNN 单元在时间上的权重共享，所以 Universal Transformer 也增加了这种假设，使 recurrent 机制中的权重共享，在增加了模型表达力的同时更加接近 RNN 的 inductive bias。 Conditional Computation Time：通过加入 ACT 控制模型的计算次数，比固定 depth 的 Universal Transformer 取得了更好的结果。 但是还是有一些问题文章中并没有说的很清楚，可能为接下来进一步的研究和优化留出了空间： 空间位置和时间位置向量的直接相加略显粗糙; 为什么需要不同的 Transition Function，它们分别起到什么作用？ 图灵完备对模型有什么用？ 5. UT with Dynamic Halting作者在附录中给出了 Tensorflow 实现的 ACT 代码，这里抄录一下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# while-loop stops when this predicate is False# i.e. all ((probability &lt; threshold) &amp; (counter &lt; max_steps)) are Falsedef should_continue(u0, u1, halting_probability, y2, n_updates, u3): return tf.reduce_any( tf.logical_and( tf.less(halting_probability, threshold), tf.less(n_updates, max_steps) ) )# do while loop iterations until predicate above is False(_, _, _, remainder, n_updates, new_state) = tf.while_loop( should_continue, ut_with_dynamic_halting, (state, step, halting_probability, remainders, n_updates, previous_state))# the computations in each stepdef ut_with_dynamic_halting( state, step, halting_probability, remainders, n_updates, previous_state): # Claculate the probablities based on the state p = common_layers.dense(state, 1, activation=tf.nn.sigmoid, use_bias=True) # Mask for inputs which have not halted yet still = tf.cast(tf.less(halting_probability, 1.0), tf.float32) # Mask for inputs which halted at this step new_halted = tf.cast( tf.greater( halting_probability + p * still_running, threshlod ), tf.float32 ) * still_running # Mask of inputs which haven't halted, and didn't halt this step still_running = tf.cast( tf.less_equal( halting_probablity + p * still_running, threshold ), tf.float32 ) * still_running # Add the halting prinbability for this step to the halting # pribabilities for those inputs which have not halted yet halting_probability += p * still_running # Compute remainders for the inputs which halteed at this step remaindes += new_halted * (1 - halting_probability) # Add the remainders to those inputs which halted at this step halting_probability += new_halted * remainders # Increment n_updates for all inputs which are still running n_updates += still_runnign + new_halted # Compute the weight to be applied to the new state and output # 0 when the input has already halted # p when the input hasn't halted yet # the remainders when it halted this step update_weights = tf.expand_dims( p * still_running + new_halted * remainders, -1 ) # Apply transformation to the state transformed_state = transition_function(self_attention(state)) # Interpolate transformed and prevous states for non-halted inputs new_state = ( transformed_state * update_weights\\ + previous_state * (1 - update_weights) ) step += 1 return (transformed_state, step, halting_probability, remainders, n_updates, new_state) Reference Universal Transformers, Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit Łukasz Kaiser, 2018, ICLR 2019 Moving Beyond Translation with the Universal Transformer, Google AI Blog (简介)Universal Transformers, wywzxxz, 知乎 【NLP】Universal Transformers详解，李如，知乎 Adaptive Computation Time for Recurrent Neural Networks, Alex Graves, 2016, arXiv: 1603.08983","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"parallel-recurrent","slug":"parallel-recurrent","permalink":"https://rogerspy.gitee.io/tags/parallel-recurrent/"}]},{"title":"Transformer家族之Insertion-Deletion Transformer","slug":"transformer家族-insertion-deletion","date":"2020-04-29T02:37:51.000Z","updated":"2022-01-12T08:37:38.441Z","comments":true,"path":"2020/04/29/transformer家族-insertion-deletion/","link":"","permalink":"https://rogerspy.gitee.io/2020/04/29/transformer家族-insertion-deletion/","excerpt":"Levenshtein Transformer 不仅具有序列生成的能力，还具有了序列修改的能力。然而我们会发现，整个模型实际上是很复杂的。从模型结构上讲，除了基础的 Transformer 结构，还额外增加了三个分类器：删除分类器、占位符分类器和插入分类器。从训练过程来讲，LevT 需要一个参考策略（expert policy），这个参考策略需要用到动态规划来最小化编辑距离。这样无论从训练还是才能够推理角度，我们都很难保证模型的效率。那么有没有一个既有 LevT 这样的强大的能力，又保持高效简洁的模型呢？Insertion-Deletion Transformer 就这样应运而生了（内心 os：你永远可以相信宋义进:joy:）。","text":"Levenshtein Transformer 不仅具有序列生成的能力，还具有了序列修改的能力。然而我们会发现，整个模型实际上是很复杂的。从模型结构上讲，除了基础的 Transformer 结构，还额外增加了三个分类器：删除分类器、占位符分类器和插入分类器。从训练过程来讲，LevT 需要一个参考策略（expert policy），这个参考策略需要用到动态规划来最小化编辑距离。这样无论从训练还是才能够推理角度，我们都很难保证模型的效率。那么有没有一个既有 LevT 这样的强大的能力，又保持高效简洁的模型呢？Insertion-Deletion Transformer 就这样应运而生了（内心 os：你永远可以相信宋义进:joy:）。 1. Abstract Framework Insertion-Deletion Transformer 实际上是 KERMIT 的扩展版，之前我们介绍过 KERMIT 是 Insertion Transformer 的泛化版，这里再次对模型进行进化。 Insertion-Deletion Transformer 只包含两个步骤：插入和删除。其中插入操作和 KERMIT 是一样的，之后将插入生成的序列传递给删除模块，进行删除操作。 $\\vec{y}_t$ —— 表示 $t$ 时刻的目标序列； $c \\in C$ —— $C$ 表示词表； $p(c, l|\\hat{y}_t)$ —— 表示在 $l \\in \\{1, …, |\\vec{y}_t|\\}$ 每个位置上插入 $c$ 的概率分布； $d \\in [0, 1]$ —— 表示删除操作的概率，$d=0$ 表示不删除， $d=1$ 表示删除； $p(d,l|\\vec{y}_t)$ —— 表示 $l \\in [0, |\\vec{y}_t|]$ 每个位置上的元素的删除操作的概率分布。 1.1 Training 采样生成步骤 $i \\sim \\mathrm{Uniform([1, n])}$; 采样前 $i-1$ 次插入操作的排列组合 $z_{1:i-1} \\sim p(z_{1:i-1})$； 将序列传入插入模型，按照 $p(c_i^z|x_{1:i-1}^{z, i-1})$ 概率分布进行插入操作（后续 $x_{1:i-1}^{z, i-1} $ 简写成 $\\hat{x}_t$）； 将上面经过插入操作后的序列传入删除模型； 删除模型按照 $p(d_l| l, \\hat{x}_t^\\star)$ 的删除概率分布进行元素删除，然后将删除操作后的序列输出。 实际上前面三步和 KERMIT 的过程是一致的。 1.2 Learning模型整体是将两个 Transformer 的解码器堆叠在一起，一个作为插入模型，另一个作为删除模型，同时训练各自的参数 $\\theta_i$ 和 $\\theta_d$。删除模型的信息依赖于插入模型的当前状态。我们的目标是通过并行解码最大化下式： \\hat{c}_l = \\mathop{\\arg \\max} \\limits_{c} p(c|l, \\hat{x}_t)需要注意的是，在计算梯度的时候，两个模型是分开的，也就是说删除模型的梯度没有传递给插入模型。这个其实也好理解，举个例子： 目标序列是 $[A, B, C, D, E, F, G]$，解码的顺序是： $[]$； $[D]$； $[B, D, F]$； $[A, B, C, D, E, F, G]$。 假设现在 $t=3$，$\\vec{y}_t=[B, D, F]$，这就是此时插入模型和删除模型的 target。由于并行解码用到的是平衡二叉树，那么每个时刻的 target 是固定的，我们就可以用这个 target 计算损失，然后计算删除模型和插入模型的各自梯度。 由于删除模型的信息依赖于插入模型，那么久有可能删除模型学习不到任何东西，即没有可删除的信息。有两方面原因会造成这个结果： 插入模型太好了，删除模型没有什么好删除的，这样删除模型没有损失，也就没有梯度，也就不能更新权重，造成什么也没学到； 插入模型什么也没插入，那么删除模型也就没有什么可删除的，也会造成什么也学不到。 为了解决这个问题，作者提出以 $p_{\\mathrm{adv}}$ 的概率 mask 掉目标序列中的一部分元素，这样会使插入模型错误率上升，这样删除模型就能学到新的权重了。 2. Experiments作者在这里没有做机器翻译的相关实验，而是做了另外两个实验： Learning shifted alphabetic sequences Alphabetic Sequence Shifting BLEU Insertion Model (KERMIT) 70.15 Insertion Deletion Model 91.49 Learning Caesar’s Cipher Caesar’s Cipher BLEU Insertion Model (KERMIT) 35.55 Insertion Deletion Model 37.57 这篇文章很短，所以有些细节可能没有讲的很清楚，期待作者放出源码，到时候跟着源码再看一遍，应该会有新的收获。另外，由于作者这里没有放出机器翻译相关的实验，所以还不太清楚其在机翻上的表现，但是个人比较期待。 ReferenceInsertion-Deletion Transformer, Laura Ruis, Mitchell Stern, Julia Proskurnia &amp; William Chan. 2020. arXiv: 2001.05540","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"},{"name":"insertion-deletion","slug":"insertion-deletion","permalink":"https://rogerspy.gitee.io/tags/insertion-deletion/"}]},{"title":"Transformer家族之Levenshtein Transformer","slug":"transformer家族-levt","date":"2020-04-27T09:52:57.000Z","updated":"2022-01-12T08:37:38.444Z","comments":true,"path":"2020/04/27/transformer家族-levt/","link":"","permalink":"https://rogerspy.gitee.io/2020/04/27/transformer家族-levt/","excerpt":"之前我们介绍了几个 Insertion-based 的序列生成的方法，使我们跳出传统的从左到右的生成顺序的思维定式。既然有 Insertion 操作，那么一个很自然的想法就是，我们能不能再加入一个 deletion 操作呢？这样我们不仅能生成序列，还可以修改生成的序列，岂不美哉？Gu et al. (2019) 就针对这种想法提出了 Levenshtein Transformer 的模型。Levenshtein Distance 我们不陌生，也就是编辑距离，这里面涉及到三种操作：insertion、deletion、replace，严格意义上来讲 replace 实际上就是 insertion 和 deletion 的组合，所以 LevT 模型只用到了插入和删除操作。","text":"之前我们介绍了几个 Insertion-based 的序列生成的方法，使我们跳出传统的从左到右的生成顺序的思维定式。既然有 Insertion 操作，那么一个很自然的想法就是，我们能不能再加入一个 deletion 操作呢？这样我们不仅能生成序列，还可以修改生成的序列，岂不美哉？Gu et al. (2019) 就针对这种想法提出了 Levenshtein Transformer 的模型。Levenshtein Distance 我们不陌生，也就是编辑距离，这里面涉及到三种操作：insertion、deletion、replace，严格意义上来讲 replace 实际上就是 insertion 和 deletion 的组合，所以 LevT 模型只用到了插入和删除操作。 1. Abstract FrameworkLevT 不同于一般的生成模型，它不仅可以生成序列，还可以修改序列。这样的话他应该算是 generation model 和 refinement model 的组合体，比如，如果 解码端初始化是一个序列，那么该模型就是普通的生成模型；而如果解码端初始化是一段低质量的序列，那么该模型可以通过插入和删除操作将输入序列修改成一段高质量的序列，比如翻译后编辑任务（translation post-editing）。 作者将 generation 和 refinement 两个任务当成一个马尔科夫决策过程（Markov Decision Process, MDP），使用一个五元组来表示：$(\\mathcal{Y, A, E, R}, y_0)$。 $\\mathcal{Y=V}^{N_{\\max}}$ —— 表示一个序列集合，其中 $\\mathcal{V}$ 表示词表； $\\pmb{a} \\in \\mathcal{A}$ —— 表示一个行为，$\\mathcal{A}$ 表示动作集合； $\\pmb{r} \\in \\mathcal{R}$ —— 表示回馈，$\\mathcal{R}$ 表示回馈函数； $\\mathcal{E}$ —— 表示一个主体（agent）; $\\pmb{y}_0$ —— 表示初始序列，要么为空，要么是由其他模型生成的序列。 马尔科夫决策过程如下：一个主体 $\\mathcal{E}$ 接受一个行为 $\\pmb{a}$，得到一个序列 $\\pmb{y}$， 然后反馈函数 $\\mathcal{R}$ 度量这个序列与真实的序列的误差：$\\mathcal{R(y)=-D(y, y^{\\star})}$。由于操作基于插入和删除，自然地，我们可以使用 Levenshtein Distance 去度量。主体要采取什么动作则由策略 $\\pi$ 决定：将目前的序列映射成行为概率分布，即 $\\pi: \\mathcal{Y \\rightarrow P(A)}$。 LevT 的任务就是给定一个序列 $\\pmb{y}^k = ( y_1, y_2, …, y_n)$，生成 $\\pmb{y}^{k+1} = \\mathcal{E(\\pmb{y}^k, \\pmb{a}^{k+1})}$，其中 $y_1$ 和 $y_n$ 分别为 $&lt; s &gt;$ 和 $&lt; /s &gt;$。 注意：在下面的描述中上角标 $k, k+1$ 省略，以及对于条件概率生成，比如机器翻译，源序列输入 $x$ 在下面的公式中也省略了。 删除 \\pi^{\\mathrm{del}}(d|i, \\pmb{y}) \\sim \\mathrm{Bernoulli}(0, 1)删除策略是一个 $n$ 重伯努利分布：输入一个序列 $y$，对于序列中的每一个元素 $y_i \\in \\pmb{y}$ 要么保留，要么删除，即 $d = 1(删除)$ 或者 $d = 0 (保留)$。为了避免 $&lt; s &gt;$ 和 $&lt; /s &gt;$ 被删除，这里强制令 $\\pi^{\\mathrm{del}}(0|0, \\pmb{y}) = \\pi^{\\mathrm{del}}(0|n, \\pmb{y}) = 1$。 插入 相对删除操作，插入就比较复杂了，因为你进要预测插入的词，还要预测插入的位置，我们还希望在同一个位置尽可能多的插入更多的词，这样就相当于模型具有并行的能力。这里作者将插入位置的预测称之为占位符预测（placeholder prediction）；将词的预测称之为词预测（token prediction）。 第一步：占位符预测 (y_i, y_{i+1}) = \\pi^{\\mathrm{plh}} (p|i, \\pmb{y})$(y_i, y_{i+1})$ 表示接下来的词插入到 $y_i, y_{i+1}$ 之间。注意这里可以预测多个插入位置。 第二步：词预测 tokens = \\pi^{\\mathrm{tok}}(t|i, \\pmb{y})每个位置可以有多个词。 这两个步骤可以看成是 Insertion Transformer 和 masked language model 的混合体。 删除和插入的综合 最后，作者将序列的生成分成三个阶段：① 删除词；② 插入占位符；③ 用词替换占位符。其中每一步都是可以并行处理的。 给定序列 $\\pmb{y}=(y_0, …, y_n)$，预测行为 $a = \\{\\underbrace{d_0, …, d_n}_{删除操作}; \\underbrace{p_0,…,p_{n-1}}_{占位符预测}; \\underbrace{t_0^1,…,t_0^{p_0},…,t_{n-1}^{p_{n-1}}}_{词预测}\\}$： \\pi(\\pmb{a}|\\pmb{y}) = \\prod_{d_1 \\in \\pmb{d}}\\pi^{\\mathrm{del}}(d_i|i, \\pmb{y})\\cdot \\prod_{p_i \\in \\pmb{p}}\\pi^{\\mathrm{plh}} (p_i|i, \\pmb{y'}) \\cdot \\prod_{t_i \\in \\pmb{t}}\\pi^{\\mathrm{tok}}(t_i|i, \\pmb{y''})其中 $\\pmb{y’}=\\mathcal{E}(\\pmb{y}, \\pmb{d})$，$\\pmb{y’’}=\\mathcal{E}(\\pmb{y’}, \\pmb{p})$。 2. Levenshtein Transformer2.1 Model 模型的整体结构仍然采用 Transformer，第 $l$ 个注意力层的状态如下： \\pmb{h}_0^{(l+1)}, ..., \\pmb{h}_n^{(l+1)} = \\begin{cases} E_{y_0}+P_0, ..., E_{y_n} + P_n, & l=0 \\\\\\\\ \\mathrm{TransformerBlock}_l(\\pmb{h}_0^{(l)}, ..., \\pmb{h}_n^{(l)})， & l \\ne 0 \\end{cases}其中 $E \\in \\mathbb{R}^{\\mathcal{|V|}\\times d_{model}}$ 表示词向量，$P \\in \\mathbb{R}^{N_\\max \\times N_\\max}$ 表示位置向量。 从图中我们可以看到，解码器的输出 $(\\pmb{h}_0,…,\\pmb{h}_n)$ 被传入到三个分类器中：删除分类器、占位符分类器和词分类器。 删除分类器 \\pi_\\theta^{\\mathrm{del}}(d|i, \\pmb{y}) = \\mathrm{softmax} (\\pmb{h}_i \\cdot A^T)其中 $A \\in \\mathbb{R}^{2 \\times d_{model}}$。对序列中除了 $&lt; s &gt;$ 和 $&lt; /s &gt;$ 之外的所有元素进行分类。 占位符分类器 \\pi_\\theta^{\\mathrm{plh}}(p|i, \\pmb{y}) = \\mathrm{softmax}(\\mathrm{concate}(\\pmb{h}_i,\\pmb{h}_{i+1}) \\cdot B^T)其中 $B \\in \\mathbb{R}^{(K_\\max+1)\\times (2d_{model})}$，$(0 \\sim K_\\max)$ 表示在当前位置上插入占位符的个数，本文中占位符用 [PLH] 表示。比如 $(A, D) \\rightarrow (A, [\\mathrm{PLH}], [\\mathrm{PLH}], D)$。 词分类器 \\pi_\\theta^{\\mathrm{tok}}(t|i, \\pmb{y}) = \\mathrm{softmax}(\\pmb{h}_i \\cdot C^T)其中 $C \\in \\mathbb{R}^{\\mathcal{|V|}\\times d_{model}}$。 2.2 Dual-policy Learning接下来一个关键的问题是，模型怎么学习？最简单的，我们可以用模仿学习。 假设我们现在有一个参考策略 $\\pi^{\\star}$，这个参考策略要么使用真值，要么可以加入少许噪声。我们的目标是最大化以下期望值： \\underbrace{\\mathop{\\mathbb{E}_{\\pmb{y}_{\\mathrm{del}} \\sim d_{\\tilde{\\pi}_{\\mathrm{del}}}}} \\limits_{\\pmb{d}^\\star \\sim \\pi^\\star} \\sum_{d_i^\\star \\in \\pmb{d}^\\star} \\log \\pi_\\theta^{\\mathrm{del}}(d^\\star_i|i, \\pmb{y}_{\\mathrm{del}})}_{删除操作的目标}+\\underbrace{\\mathop{\\mathbb{E}_{\\pmb{y}_{\\mathrm{ins}}\\sim d_{\\tilde{\\pi}_{\\mathrm{ins}}}}}\\limits_{\\pmb{p}^\\star, \\pmb{t}^\\star \\sim \\pi^\\star}\\left[\\sum_{p_i^\\star \\in \\pmb{p}^\\star} \\log \\pi_\\theta^{\\mathrm{plh}}(p_i^\\star|i, \\pmb{y}_{\\mathrm{ins}})+\\sum_{t_i^\\star \\in \\pmb{t}^\\star}\\log \\pi_\\theta^{\\mathrm{tok}}(t_i^\\star|i, \\pmb{y'}_{\\mathrm{ins}})\\right]}_{插入操作的目标}其中 $\\pmb{y’}_\\mathrm{ins}$ 表示在 $\\pmb{y}$ 上插入占位符以后的序列。$\\tilde{\\pi}_\\mathrm{del}, \\tilde{\\pi}_\\mathrm{ins}$ 是输入策略，我们不断从由它们导致的状态分布中抽样分布（序列），这些状态首先由参考策略运行，然后返回其行为，我们就是要去最大化这些行为概率。我们有两种方法定义输入策略：① 在真值上加噪； ② 使用对抗策略。如下图所示： 删除操作，我们可以定义： d_{\\tilde{\\pi}_\\mathrm{del}} = \\begin{cases} \\pmb{y}^0, & u< \\alpha \\\\\\\\ \\mathcal{E}(\\mathcal{E}(\\pmb{y'}, \\pmb{p}^\\star), \\tilde{\\pmb{t}}), & u \\ge \\alpha \\end{cases}其中 $\\pmb{y}^0$ 是初始输入，$\\alpha \\in [0, 1]$ 表示我们交替从 $\\pmb{y}^0$ 和 $\\pmb{y’}$ 中选取样本，$u \\sim U[0,1]$，$\\pmb{y’}$ 是任意准备插入的序列，$\\pmb{p}^\\star$ 取自参考策略， $\\tilde{\\pmb{t}}$ 取自当前策略。用这种方法，我们既可以学习对初始序列 $\\pmb{y}_0 $ 如何删除，也可以学习在整个过程中如何对序列删除。 插入操作，类似于删除操作： d_{\\tilde{\\pi}_\\mathrm{ins}} = \\begin{cases} \\mathcal{E}(\\pmb{y}^0, \\pmb{d}^\\star), & \\pmb{d}^\\star \\sim \\pi^\\star, & u < \\beta\\\\\\\\ \\mathcal{E}(\\pmb{y}^\\star, \\tilde{\\pmb{d}})， & \\tilde{\\pmb{d}} \\sim \\pi^{\\mathrm{RND}}, & u\\ge \\beta \\end{cases}这里 $u \\sim U[0,1]$，$\\beta \\in [0, 1]$，$\\pi^{\\mathrm{RND}}$ 是从真值序列中随机丢弃一个字符。 现在还剩最后一个问题：如何构建参考策略？ Oracle： \\pmb{a}^\\star = \\mathop{\\arg \\min} \\limits_{\\pmb{a}} \\mathcal{D}(\\pmb{y}^\\star, \\mathcal{E}(\\pmb{y, a}))其中 $\\mathcal{D}$ 表示 Levenshtein distance。 Distillation：我们首先训练一个 AR 模型，然后把真值序列 $\\pmb{y}^\\star$ 用 distillation 模型的 beam search 结果 $\\pmb{y}^{AR}$ 进行替换。实验结果表明这个方法是对上一个方法的大幅改进，既可以边生成边修改，又可以并行。 2.3 Inference 在进行推理的时候采用 贪婪解码。解码终止条件有两个： Looping：当两次连续的修改操作（插入和删除）返回相同的序列。可能有两个原因：① 没有可插入或者可删除的词了；② 插入和删除相互抵消了，解码过程陷入死循环。 Timeout：通过设置最大迭代次数保证模型不会在一个较差的结果上耗费过多时间。 另外为了防止不合理的空占位符的出现，作者这里和 Insertion Transformer 一样采取了惩罚措施：从占位符分类器的输出结果中剪掉 $\\gamma \\in [0,3]$ 项。 3. Experiments 可以看到，Levenshtein oracle 的效果堪比 Transformer，而加了Transformer distillation之后表现几乎总好于 Transformer，并且还快得多。 另外，由于 LevT 还可以进行 refinement， 因此作者还评估了模型的修改效果，下表 APE（automatic post-editing)） 是实验结果： 左边的结果是 BLEU 值，右边的结果是 TER 翻译错误率。可以看到，LevT 几乎承包了所有任务上的最优结果，表明了这种修改的可行性。 Reference Levenshtein Transformer, Jiatao Gu , Changhan Wang &amp; Jake Zhao (Junbo). 2019. arXiv: 1905.11006 香侬读 | 按什么套路生成？基于插入和删除的序列生成方法, 香侬科技, 知乎","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"},{"name":"insertion-deletion","slug":"insertion-deletion","permalink":"https://rogerspy.gitee.io/tags/insertion-deletion/"}]},{"title":"Transformer家族之Non-Monotonic Transformer","slug":"transformer家族-non-monotonic","date":"2020-04-21T08:14:10.000Z","updated":"2022-01-12T08:37:38.446Z","comments":true,"path":"2020/04/21/transformer家族-non-monotonic/","link":"","permalink":"https://rogerspy.gitee.io/2020/04/21/transformer家族-non-monotonic/","excerpt":"之前我们介绍的两种 insertion-based 文本生成方法预先规定了每次生成最中间的词，这样一来我们虽然利用树实现了并行，但是却丢失了其中的生成模式，我们不知道模型在生成的时候经历了什么。那么我们能不能让模型自动生成一棵树呢？比如，现在生成了一个根节点，然后再生成左右子节点，然后再生成子节点的子节点，以此类推，但不同的是，这棵树不一定平衡，甚至可能退化成一条链，但我们获得了模型的生成模式，如下图所示：","text":"之前我们介绍的两种 insertion-based 文本生成方法预先规定了每次生成最中间的词，这样一来我们虽然利用树实现了并行，但是却丢失了其中的生成模式，我们不知道模型在生成的时候经历了什么。那么我们能不能让模型自动生成一棵树呢？比如，现在生成了一个根节点，然后再生成左右子节点，然后再生成子节点的子节点，以此类推，但不同的是，这棵树不一定平衡，甚至可能退化成一条链，但我们获得了模型的生成模式，如下图所示： 可以从任意位置开始生成； 图中绿框中的数字表示生成顺序； 图中蓝筐中 的数字表示重构顺序； 传统的从左向右被做为二叉树的一种特殊情况。 1. Abstract Framework $Y=(w_1, …, w_N)$ ——表示生成的序列，其中 $w_i \\in V$，是一个词表; $\\tilde{V} = V \\bigcup \\{&lt; end &gt;\\}$ —— 表示所有可能生成的字符串； $S = \\tilde{V}^*$ —— 表示序列的状态空间； $s \\in S$ —— 表示状态空间中的一个序列，该序列中每个元素都来源于 $\\tilde{V}$。比如上图 $s_1=(are), s_2=(are, how),…,s_4=(are, how, ?, &lt; end &gt;)$； $a$ —— 表示将 $\\tilde{V}$ 中的一个元素添加到 $S$ 后面的操作； 所有的叶子结点都是 $&lt; end &gt;$ 时表示序列生成过程的结束，此时 $T=2N+1$，其中 $N$ 表示序列中非 $&lt; end &gt;$ 的元素， $T$ 表示整个序列的长度， $s_T$ 表示最终状态。 $\\tau(t)$ —— 表示按层序遍历树上的第 $t$ 的节点，则 $(a_{\\tau(1)},…,a_{\\tau(T)})$； 以上图为例，最终的序列是将图中蓝筐中的数字映射成绿框的顺序，然后删掉所有的 $&lt; end &gt;$。 $\\pi(a|s)$ —— 表示根据给定一个序列状态生成一个 $a$ 操作的策略。我们知道树的遍历有很多种方式，因此对于同一个序列，我们可以有不同的树，我们就有多种生成模式。 2. Learning for Non-Monotonic Generation我们考虑两种情况下的文本生成： 非条件生成：类似语言模型，没有额外信息输入； 条件生成：类似机器翻译，根据输入序列生成新的序列。 我们先考虑非条件生成的情况。这种情况比较复杂，因为我们只知道最终的序列是什么样的，但是生成这样的序列的那棵树长什么样子我们并不知道。因为我们是通过遍历树的叶子结点得到最终的序列，而树的遍历有很多种方法，要用不同的遍历方法得到同一个序列，此时树的结构就不尽相同。树的结构不同意味着每次生成都会有多种操作的可能性，这样我们就不能使用传统的监督学习方法了。为了解决这个问题我哦们可以使用 learning-to-search 和 imitation learning。 Key Idea 假定我们只有一个序列 $Y$。现在的想法是，在第一步我们首先生成任意一个单词 $w \\in Y$ 作为整棵树的根节点，然后类似快速排序的思想，在 $w$ 左边和右边递归地生成，由于我们希望树的中序遍历可以得到原始序列 $Y$，所以 $w$ 左边的字符必须在 $w$ 的左子树，同理对右子树。然后用 direct loss minimization 及相关的技术学习一个参考策略 $\\pi^{\\ast}$ 当成当前策略 $\\pi $ 的首选策略。 2.1 Unconditional Generation所谓 Learning-to-search，就是模仿一个参考策略 $\\pi^{\\ast}$ 来学习当前策略 $\\pi$。我们定义一个输入策略（roll-in）$\\pi^{in}$ 和一个输出策略（roll-out）$\\pi^{out}$。下面我们不断从 $\\pi^{in}$ 中抽样状态 $s$，然后在 $\\pi^{out}$ 下对每个行为 $a$ 计算一个运行代价，之后学到的 $\\pi $ 被训练去最小化这个运行代价。 用数学语言来说就是: \\mathbb{E}_{Y \\sim D}\\mathbb{E}_{t \\sim U([1, 2|Y|+1])}\\mathbb{E}_{s_t\\sim d_{\\pi^{in}}^t}\\left[C(\\pi;\\pi^{out}, s_t) \\right] $U(T)$ 表示 $[1,…,T]$ 的均匀分布； $d_\\pi^{in}$ 表示在 $\\pi$ 策略下进行 $t$ 步得到的状态分布； $C(\\pi;\\pi^{out}, s)$ 表示运行代价 通过选择不同的 $\\pi;\\pi^{out}, s$ 我们可以得到不同的 learning-to-search 算法，我们希望找到一个策略能够在获得 $s_t$ 上表现得和 $\\pi^*$ 一样好，甚至更好。 $\\pi^{in}$ 的选择 $\\pi^{in}$ 决定了我们要学习的策略 $\\pi$ 训练的状态分布。我们可以选择 $\\pi$ 与 $\\pi^{out}$ 的混合作为 $\\pi^{in}$，也可以选择仅使用 $\\pi^{out}$ 。后者更简单，我们本着从简的原则，使用后者。 $\\pi^{out}$ 的选择 $\\pi^{out}$ 就是我们要模仿的策略。由于 $\\pi^{out}$ 是参考策略，所以我们可以通过 $\\pi ^{out}$ 完全根据序列构建出树，于是我们可以把 $\\pi^{out} $ 视为树的生成过程，在每一步都对应一个状态 $s_t$ 和序列 $Y_t$ 。在每个 $s_t$ ，$Y_t$ 包含了合法行为，比如下图，在第一步，我们可以选择生成 $(a, b, c, d)$ 中的一个，比如我们选择了 $b$，之后，左节点的选择就只有 $a$ 了，右节点的选择就有 $(c,d)$，这些选择就是“合法”的。 给定一个连续子序列 $Y_t=(w_1’, …, w_{N^{‘}}’)$，$\\pi^{out}$ 可以定义为： 其中 $\\sum_{a \\in Y}p_a=1$。我们可以看到 $\\pi^{out}$ 策略主要由 $p_a$ 决定，这里作者预定义了三种不同的策略：均匀策略（或者任意顺序策略，uniform oracle）、指导策略（coaching oracle）和退火指导策略（annealed coaching oracle）。 均匀策略 令 $p_a = 1/n$，记为 $\\pi^{\\ast}_{\\mathrm{uniform}}$。 指导策略 任意顺序的策略会导致一个问题：难以使得 $\\pi $ 去模仿。为此，我们可以考虑加入当前学习的策略 $\\pi $： \\pi^{\\ast}_{\\mathrm{coaching}}(a|s) \\propto \\pi^*_{\\mathrm{uniform}}(a|s)\\pi(a|s)这样一来，既可以避免不合法的行为，也可以按照当前策略 $\\pi $ 继续学习。 退火指导策略 指导策略也有一个问题：它不会引导模型进行多样化的学习。因此，我们可以再适当加入$\\pi^{\\ast}_{\\mathrm{uniform}}$： \\pi^*_{\\mathrm{annealed}}(a|s) = \\beta \\pi^{\\ast}_{\\mathrm{uniform}}(a|s) | (1-\\beta) \\pi^{\\ast}_{\\mathrm{coaching}}(a|s)这里 $\\beta$ 随着训练从1线性递减到0。 $C$ 的选择 $C$ 度量的是经过输入策略的选择得到的状态与输出策略之间的误差，最常见的方法是使用平方误差。然而，有研究表明使用 RNN 时平方误差表现不佳，所以我们可以转而使用 KL 散度: C(\\pi, \\pi^{out}, s) = D_{KL}(\\pi^{out}(\\cdot|s)||\\pi(\\cdot|s)) = \\sum_{a \\in \\tilde{V}}\\pi^{out}(a|s)\\log \\pi(a|s)+C 2.2 Conditional Generation上面说的是给定单个句子 $Y$ ，如果我们要学习 $X \\rightarrow Y$ 怎么办呢？ 我们将条件输入 $X$ 编码成一组 $d_{enc}$ 维的向量，记为 $f^{enc}(X)$，然后经过神经网络，比如 LSTM 或者 Transformer，得到隐状态向量 $H \\in \\mathbb{R}^{|X| \\times d_{enc}}$，然后再送入该模型中即可。 3. 神经网络结构作者选择使用神经网络实现上面的二叉树生成策略，因为神经网络能有效的对不同尺寸的输入进行编码以及预测输出。这里作者选择两种神经网络：LSTM 和 Transformer，一个是老一代的 NLP 武林盟主，一个是新生代江湖俊杰。 3.1 LSTM Policy将二叉树的层序遍历节点 $(a_1, …, a_t)$ 作为序列输入到 LSTM ，然后 LSTM 将序列编码成向量 $h_t$，然后计算 $a_i$ 的概率分布： \\pi(a|s_t) \\propto \\exp(u_a^Th_t+b_a)3.2 Transformer Policy同样是将 $(a_1, …, a_t)$ 作为输入，然后使用多头注意力计算 $h_t$，再计算 $a_i$ 的概率分布。 3.3 Auxiliary $&lt; end &gt;$ Prediction作者将 $&lt; end &gt;$ 的预测和 $a_i$ 的预测分开进行，先利用伯努利分布判断是否是 $&lt; end &gt;$，设定一个阈值 $\\tau$ ，当概率大于 $\\tau$ 时，则认为 $a_t = &lt; end &gt;$，否则根据 $\\pi$ 计算 $a_t$。 4. Experiments作者最后在多个任务上进行了实验： 语言模型 句子补齐 词序重排 机器翻译 这里展示几个生成样例。 语言模型 机器翻译 从图中我们可以清晰地看到生成模式。更多详细的实验可以去看原文。 Reference Non-Monotonic Sequential Text Generation, Sean Welleck, Kiante Brantley, Hal Daume III, Kyunghyun Cho. 2019. arXiv: 1902.02192 Non-Monotonic Sequential Text Generation #121, kweonwooj. Github Pages. 2019 香侬读 | 按什么套路生成？基于插入和删除的序列生成方法, 香侬科技，知乎","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"},{"name":"LSTM","slug":"lstm","permalink":"https://rogerspy.gitee.io/tags/lstm/"}]},{"title":"Transformer家族之KERMIT","slug":"transformer家族-kermit","date":"2020-04-16T08:20:08.000Z","updated":"2022-01-12T08:37:38.442Z","comments":true,"path":"2020/04/16/transformer家族-kermit/","link":"","permalink":"https://rogerspy.gitee.io/2020/04/16/transformer家族-kermit/","excerpt":"我们注意到 Insertion Transformer 提出一种很有意思的文本生成框架：Insertion-based 。但是它仍然使用的是Encoder-Decoder 框架，这种框架有一个缺陷，就是 $(x, y)$ 无法对 联合概率 $p(x, y)$ 进行建模。对此 William Chan 等人于 2019 年提出一种新的架构：KERMIT，该模型抛弃了传统的 Encoder-Decoder 架构，使得我们能对 $p(x, y)$ 联合概率进行建模。训练阶段可以通过句子对 $(x, y)$ 获得联合概率 $p(x, y)$，也可以通过非句子对分别获得边缘概率 $p(x)$ 或者 $p(y)$。推理阶段我们可以获得条件概率 $p(x|y)$ 和 $p(y|x)$。","text":"我们注意到 Insertion Transformer 提出一种很有意思的文本生成框架：Insertion-based 。但是它仍然使用的是Encoder-Decoder 框架，这种框架有一个缺陷，就是 $(x, y)$ 无法对 联合概率 $p(x, y)$ 进行建模。对此 William Chan 等人于 2019 年提出一种新的架构：KERMIT，该模型抛弃了传统的 Encoder-Decoder 架构，使得我们能对 $p(x, y)$ 联合概率进行建模。训练阶段可以通过句子对 $(x, y)$ 获得联合概率 $p(x, y)$，也可以通过非句子对分别获得边缘概率 $p(x)$ 或者 $p(y)$。推理阶段我们可以获得条件概率 $p(x|y)$ 和 $p(y|x)$。 1. Abstract FrameworkKERMIT 算是 Insertion Transformer 的泛化版，损失函数用的是平衡二叉树，解码同样可以采用贪心解码和并行解码两种方式。 序列：$x=(x_1,…,x_n)$; 生成 $x$ 的顺序：$z \\in \\mathrm{permut}(\\{1,…,n\\})$，其中 $\\{1,…,n\\}$ 对应的是 $x$ 中每个词的绝对位置索引。$z$ 属于位置索引的排列组合，即 $x$ 中元素的生成顺序； 对应序列：$((c_1^z, l_1^z), …, (c_n^z, l_n^z))$，其中 $c_i^z \\in C$ 是词表中的词，$1 \\le l_i^z \\le i$ 是目前序列的插入相对位置。 $(x_1^{z, i}, …, x_i^{z, i})$，表示在 $\\{z_1, …, z_i\\}$ 顺序下 $x$ 的子序列。 KERMIT 对输出的词和词的位置进行建模： p(c, l|\\hat{x}) = \\mathrm{KERMIT}(\\hat{x})举个例子： 序列 $x = (A, B, C)$ 的生成顺序是 $() \\rightarrow (C) \\rightarrow (A, C) \\rightarrow (A, B, C)$，那么 $z = (3, 2, 1)$，对应序列为 $(c_1^z, l_1^z)=(C, 1), ~(c_2^z, l_2^z)=(A, 1), ~(c_3^z, l_3^z)=(B, 2)$。注意 $z$ 和 $l$ 都表示元素的索引，不同的是 $z$ 表示的是完整序列位置的索引，$l$ 表示的是序列生成过程中，当前序列的位置索引。此时 $(x_1^{z,2}, x_2^{z,2})=(A, C)$。 2. KERMIT有了以上定义，我们就可以得到： 最后一步使用了 Markov 假设：插入的顺序不重要，只是一个结果。对于 $p(z)$ 我们使用均匀分布，其他部分使用平衡二叉树（详见Transformer家族之Insertion Transformer）。 2.1 Learning上式要直接求解比较麻烦，但是可以用 Jensen 不等式得到 $p(x)$ 的下限： \\log p(x) = \\log \\sum_{z \\in S_n} p(z) p(x|z) \\ge \\sum_{z \\in S_n} p(z) \\log p(x|z) =: L(x)带入刚刚得到的 $p(x|z)$ 表达式： 下面将 $L(x)$ 分成是三部分：$(z_1,…,z_{i-1})$ 表示之前的插入，$z_i$ 表示下一步插入，$(z_{i+1}, …,z_n)$ 表示以后的插入： 最后一步是由于 $\\sum_{z_{i+1:n}}p(z_{i+1:n}|z_{1:i})=1$。 通过下面几个简单的采样过程就可以计算 $L(x)$： 采样生成步骤 $i \\sim \\mathrm{Uniform([1, n])}$; 采样前 $i-1$ 次插入操作的排列组合 $z_{1:i-1} \\sim p(z_{1:i-1})$; 计算 $\\log p\\left((c_i^z, l_i^z)|x_{1:i-1}^{z,i-1}\\right)$，$p(z_i|z_{1:i-1})$，二者相乘然后乘以 $n$。 前两步不多说，说下最后一步。 $i=1$，则 $\\log p\\left((c_1^z, l_1^z)|x_{1:0}^{z,0}\\right)=\\log p\\left((C, 1)|(&lt; BOS &gt;)\\right)$，$p(z_1|z_{1:0})=p(3|&lt; BOS &gt;)$; $i=2$，则 $\\log p\\left((c_2^z, l_2^z)|x_{1:1}^{z,1}\\right)=\\log p\\left((A, 1)|(&lt; BOS &gt;, C)\\right)$，$p(z_2|z_{1:1})=p(1|(&lt; BOS &gt;, 3))$; $i=3$，则 $\\log p\\left((c_3^z, l_3^z)|x_{1:2}^{z,2}\\right)=\\log p\\left( (B, 2)|(&lt; BOS &gt;, A, C)\\right)$，$p(z_3|z_{1:2})=p(2|(&lt; BOS &gt;, 3, 1))$; 2.2 Inference Greedy decoding (\\hat{c}_t, \\hat{l}_t) = \\arg \\max_{c, l} p(c, l|\\hat{x}) Parallel decoding \\hat{c}_{l} = \\arg \\max_{c} p(c | l,\\hat{x}_t)2.3 Pairs of Sequences目前为止我们讨论的都是单个序列。我们可以通过将两个序列拼接在一起实现对 $(x, y)$ 的直接建模，即： (x, y) = (x_1, ...,x_n, y_1, ..., y_m)比如，$x=(A,B,C,&lt; EOS &gt;),~y=(A’,B’,C’,D’,E’,&lt; EOS &gt;)$，拼接后成为 $(x, y)=(A,B,C,&lt; EOS &gt;, A’,B’,C’,D’,E’,&lt; EOS &gt;)$。相对于 Encoder-Decoder 结构，这样的好处是，$x, y$可以互为源序列和目标序列。 对于多模态数据，这种结构可能会成为未来的趋势。 通过这种结构我们可以很轻易的对 $p(x, y)$ 联合概率进行建模，同时还能获得边缘概率 $p(x),p(y)$ 以及条件概率 $p(x|y), p(y|x)$。我们还可以进行针对性的训练： 如果给出完整的 $x$ 或 $y$ （没有拼接成一个序列），则可以训练条件概率； 如果 $x$ 或 $y$ 有一个为空，则训练边缘概率。 2.4 Model KERMIT 的大致结构如图所示，采用 Transformer 的Decoder 部分，并且去掉了掩码注意力层。由于没有 Encoder ，所以注意力层是完全的自注意力层，不需要和 Encoder 进行 cross-attention。 另外，KERMIT 的损失函数用的是平衡二叉树，最后计算 $p(c, l)$ 的时候用的是 Insertion Transformer 中的因式分解方法。 所以我们可以认为 KERMIT 是 Insertion Transformer 的泛化版，很多后者不具备的能力都可以在它身上找到。尤其是在翻译领域，这种对称式的多模态训练很可能会成为未来的趋势。 比如：输入源序列 $(x, y)$ 分别是 $(en，zh)$，输出目标序列是 $(zh,en)$。这样我们相当于在一个模型上实现了两种语言的互相翻译。 3. Experiments Unidirectional 表示和传统方法一样，输入单一序列，输出单一序列； Bidirectional 表示输入单一序列，输出单一序列，但是在同一个模型中训练两种语言； Join 表示两种序列拼接在一起输入模型，另外使用 $p(x)，p(y)$ 进行改善，输出同样也是单一序列和两种序列。 Reference KERMIT: Generative Insertion-Based Modeling for Sequences, William Chan , Nikita Kitaev, Kelvin Guu , Mitchell Stern , Jakob Uszkoreit, 2019, arXiv: 1906.01604 香侬读 | 按什么套路生成？基于插入和删除的序列生成方法，香侬科技，知乎","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"},{"name":"insertion","slug":"insertion","permalink":"https://rogerspy.gitee.io/tags/insertion/"}]},{"title":"Transformer家族之Insertion Transformer","slug":"transformer家族-insert","date":"2020-04-09T07:45:55.000Z","updated":"2022-01-12T08:37:38.440Z","comments":true,"path":"2020/04/09/transformer家族-insert/","link":"","permalink":"https://rogerspy.gitee.io/2020/04/09/transformer家族-insert/","excerpt":"传统的文本生成，比如机器翻译无论是自回归或者半自回归的推理方式，都有一个特点：通常是自左向右依次生成文本序列。本文将介绍一篇文章，打破思维定式，突破自左向右的顺序生成。Insertion Transformer采用随机插入式序列生成： 以任意顺序生成； 支持自回归或者半自回归生成（同时在不同位置插入）。 Insertion Transformer不仅在效果上远超非自回归模型，而且能以$log(n)$的推理速度，效果上达到原始Transformer的水平。","text":"传统的文本生成，比如机器翻译无论是自回归或者半自回归的推理方式，都有一个特点：通常是自左向右依次生成文本序列。本文将介绍一篇文章，打破思维定式，突破自左向右的顺序生成。Insertion Transformer采用随机插入式序列生成： 以任意顺序生成； 支持自回归或者半自回归生成（同时在不同位置插入）。 Insertion Transformer不仅在效果上远超非自回归模型，而且能以$log(n)$的推理速度，效果上达到原始Transformer的水平。 1. Abstract Framework $x$ —— 源序列 $y$ —— 目标序列 $\\hat{y}_t$ —— $t$ 时刻的输出序列，由于我们只有插入操作，因此 $\\hat{y}_t$ 必须是最终输出序列的子序列，比如如果最终输出序列是$[A, B, C, D, E, F]$，那么$\\hat{y}_t=[B, C]$ 是合法的，而$[C, B]$则不可以 $\\hat{y}$ —— 最终输出序列 $C$ —— 词表 $c$ —— $c \\in C$，上下文 $l$ —— $l \\in [0, |\\hat{y}_t|]$，需要插入词的位置 Insertion Transformer 需要对输出的词和词的位置都要进行建模： p(c, l|x, \\hat{y}_t) = \\mathrm{InsertionTransformer}(x, \\hat{y}_t)举个例子： 假设$\\hat{y}_t = [B, D]$，$p(c, l| x, \\hat{y}_t) = (c=C, l=1)$，也就是说把 $C$ 插入到 $\\hat{y}_t$的 索引值为1的地方（从0开始计算索引），这就意味着$\\hat{y}_{t+1} = [B, C, D]$。 2. Insertion Transformer Full Decoder Self-Attention 将 Transformer 中的 causal self-attention 替换为 full self-attention。 Slot Representation via Concatenated Outputs 标准的 Transformer 是给输入 $n$ 个词，然后模型输出 $n$ 个向量，然后取最后一个词作为输出序列的下一个词。而为了实现插入操作，作者对 decoder 做了修改。因为插入需要的是在词与词之间插入，也就是说，decoder 需要对slot 进行编码，$n$ 个词就有 $n+1$ 个 slot，也就是说给定 $n$ 个词，decoder 输出必须是 $n+1$ 个向量：$n$ 个词之间有 $n-1$ 个slot，而序列开始和结束的地方还有两个 slot，一共 $n+1$ 个slot。 比如：$[A, C, E]$ 一共有3个词，$A, C$和$C, E$之间两个slot，模型下一个预测的词也有可能需要插入到$A$之前，或者 $B$ 之后，所以 $A$ 前和 $B$ 后还有两个slot，3个词4个 slot。 为了实现这一目标，我们在 decoder 的输入序列上加入特殊的开始和结束符，比如&lt;BOS&gt;或者&lt;EOS&gt;。这样我们就构造了一个 $n+2$ 的输入序列，最终 decoder 也将输出 $n+2$ 个向量。然后我们再将相邻的两个向量拼接在一起，这样就形成了 $n+1$ 个向量了。每个向量代表一个 slot。因此，每个 slot 相当于综合了该位置前后两个词的语义。 举个例子： 给定 $[A, C, E]$； 加入 &lt;BOS&gt; 和 &lt;EOS&gt;，成为 $[&lt; BOS &gt;, A, C, E, &lt; EOS &gt;]$； 输入给decoder； decoder 输出 $[[1,2,3], [2,3,4], [3,4,5], [4,5,6], [5,6,7]]$； 将相邻的两个向量拼接起来：$[[1,2,3,2,3,4],[2,3,4,3,4,5],[3,4,5,4,5,6],[4,5,6,5,6,7]]$; 2.1 Model Variants得到了 slot 向量，怎样得到最终的 $p(c, l)$，作者对此也进行了一番探索。 在继续介绍之前，我们先定义一些变量： $H$ —— $H \\in \\mathbb{R}^{(T+1) \\times d}$，表示上面我们得到的 slot 特征矩阵， 其中 $d$ 是向量维度，$T$ 是输入序列长度； $W$ —— $W \\in \\mathbb{R}^{d \\times |C|}$，是标准的 softmax 投影矩阵，其中 $|C|$ 表示词表大小。 好了，我们继续下面的介绍。 Content-Location Distribution 为了得到 $p(c, l|x, \\hat{y}_t)$，作者提出两种方法：第一种是直接对 $(\\mathrm{content}, \\mathrm{slot})$进行建模；另一种方式是因式分解。 直接建模 p(c, l) = \\mathrm{softmax}(\\mathrm{flatten}(HW))注意这里得到的是一个$(T+1) \\times |C|$ 的矩阵，其物理意义为：在$(T+1)$ 个slot 的每个位置上最可能出现的词。 因式分解 我们可以利用条件因式分解得到： p(c, l) = p(c|l) \\cdot p(l) \\\\\\\\ p(c|l) = \\mathrm{softmax}(h_l \\cdot W) \\\\\\\\ p(l) = \\mathrm{softmax}(H \\cdot q)其中 $h_l \\in \\mathbb{R}^{d}$ 表示 $H$ 的第 $l$ 行，$q \\in \\mathbb{R}^{d}$ 表示一个可学习的 query 向量。 这种方法的好处是相对直接建模的方式内存消耗要小得多。 Contextualized Vocabulary Bias 为了增加 slot 之间的信息共享，我哦们可以在 $H$ 上增加一个最大池化的操作，得到一个上下文向量 $g \\in \\mathbb{R}^d$，然后用一个可学习的投影矩阵 $V \\in \\mathbb{R}^{d \\times |C|}$ 将 $g$ 投影到词表空间: $b=g \\cdot V \\in \\mathbb{R}^{|C|}$，将 $b$ 作为偏置量添加到每个位置上。整个过程如下： g = \\mathrm{maxpool}(H) \\\\\\\\ b = g \\cdot V \\\\\\\\ B = \\mathrm{repmat}(b, [T+1, 1]) \\\\\\\\ p(c, l) = \\mathrm{softmax}(HW+B) Mixtrue-of-Softmaxes Output Layer (Optional) 讲道理，这部分我没有太想明白为什么需要 MoS。如果是从语言模型本身的复杂性来考虑，MoS 确实有可能会起到效果， 但是如果从同时编码 $(c, l)$ 的角度考虑的话，我就不太明白了。从文章的实验结果来看，这部分修改并没有使模型达到最佳效果（当然如果只考虑以上三种变种的话，加上 MoS 确实有提升效果，但是加上后续的一些 tricks 综合整个模型试验，它并没有达到最佳效果）。因此，这里对 MoS 做简单介绍吧，更详细的内容请去读原文。 假设我们有一个上下文矩阵 $H \\in \\mathbb{R}^{N \\times d}$，一个词向量矩阵 $W \\in \\mathbb{R}^{|C| \\times d}$，其中 $|C|$ 是词表大小。给定上下文，我们希望从矩阵 $A$ 中去预测下一个词 $p(x|c)$，其中 $A \\in \\mathbb{R}^{N \\times |C|}$。我们的模型是希望通过从真实的世界中采样 $N$ 个样本，训练出尽可能接近 $A$ 分布的 $A’$ 矩阵。 H = \\left[ \\begin{array}{c} \\mathbf{h}_{c1}^T\\\\\\\\ \\vdots \\\\\\\\ \\mathbf{h}_{cN}^T \\end{array} \\right]; W = \\left[ \\begin{array}{c} \\mathbf{w}_{x1}^T\\\\\\\\ \\vdots \\\\\\\\ \\mathbf{w}_{xM}^T \\end{array} \\right]; A = \\left[ \\begin{array}{ccc} \\log p(x_1|c_1), & \\cdots, & \\log p(x_M|c_1)\\\\\\\\ \\vdots , & \\ddots, & \\vdots\\\\\\\\ \\log p(x_1|c_N), & \\cdots, & \\log p(x_M|c_N), \\end{array} \\right]我们希望 $A’ = HW^T$，尽量接近 $A$ 的分布。 矩阵乘法有一个性质：两矩阵乘积的秩（rank）等于两个矩阵秩较小的那个： \\mathrm{rank}(A \\cdot B) = \\min(\\mathrm{rank}(A), \\mathrm{rank}(B))通常我们的训练样本 $N$ 会远远大于词向量的维度，也就是说 $A’$ 的秩的上限由词向量维度 $h$ 决定的。而真实世界的 $A$ 的秩很可能接近 $|C|$，通常 $|C| \\gg d$。这就造成一个问题，我们希望通过 $A’$ 来逼近 $A$ 的分布，但是实际上$A’$ 的秩是远低于 $A$ 的，也就是说我们的模型训练出来的矩阵表达能力是远低于真实世界的。 简单一句话就是：由于词向量维度的限制，我们训练出来的模型表达能力不足以完整的描述真实的世界。 要解决这个问题的最直接的方法就是让词向量的维度等于词表的大小，即 $d = |C|$。但这会引入另外一个问题，那就是参数量爆炸！。 因此，作者提出 Mixture of Softmax: [\\mathbf{h}_0, ..., \\mathbf{h}_K] = \\tanh(\\mathbf{h}P^T) [\\pi_0, ..., \\pi_K] = \\mathrm{softmax}(\\mathbf{h}M^T) P_{\\theta}(x|\\mathbf{h}) = \\sum_{k=1}^{K}\\pi_{c, k} \\frac{\\exp(\\mathbf{h}_{c, k}^T \\mathbf{w}_x)}{\\sum_{x' \\exp(\\mathbf{h}_{c, k}^T \\mathbf{w}_{x'})}}其中 $\\sum_{k=1}^K\\pi_{c, k}=1$。 这里引入了两个权重： $P \\in \\mathbb{R}^{Kd\\times d}$，它将 $\\mathbf{h}$ 映射成 $K$ 个不同的 $\\mathbf{h}$，每个 $\\mathbf{h_k} \\in \\mathbb{R}^d$； $M \\in \\mathbb{R}^{d \\times K}$，决定这 $K$ 个模型如何混合。 这个模型的基本原理就相当于使用 $K$ 个 softmax 将它们混合起来，既避免了参数量爆炸，又保持了模型的表达能力。这 $K$ 个不同的模型组合求加权平均效果往往比单一的模型要好， $K$ 个模型联合训练也能避免一些单模型的缺陷。 3. Training and Loss FunctionsInsertion Transformer的机制支持它以任何顺序来生成目标语句，因此在训练时，可以通过设计loss function来将先验的顺序信息施加给模型，从而使得模型在预测时也按照先验的顺序进行预测。 3.1 Left-to-Right文中将原始自回归模型从左到右的生成方式作为一个特例进行对比。固定每次插入的单词位置都在最右侧，就退化成了原始的序列生成方式。 \\mathrm{loss}(x, \\hat{y}) = - \\log p(y_{k+1}, k | x, \\hat{y})3.2 Balanced Binary Tree显然从左到右的解码方式不能做到并行。因此，作者提出使用平衡二叉树的方式最大化并行解码能力。基本思想是：每次生成目标序列最中间的词。 比如，目标序列是 $[A, B, C, D, E, F, G]$，解码的顺序是： $[]$； $[D]$； $[B, D, F]$； $[A, B, C, D, E, F, G]$。 为了达到这个目的，作者提出 soft binary tree loss： 随机挑选一个 $k$ 值，$k \\sim \\mathrm{uniform}(0, |y|)$； 打乱 $y$ 中每个词的索引顺序，选择其中前 $k$ 个索引对应的词，这样就得到了一个长度为 $k$ 的子序列； 这个长度为 $k$ 的子序列包含 $k+1$ 个slot，每个 slot 对应的位置为 $l = 0, 1, …, k$。令 $(y_{i_l}, y_{i_l+1}, …, y_{j_l})$为 $ y$ 中剩余的对应第 $l$ 个 slot 位置上的词。 以上图为例：解释$(y_{i_l}, y_{i_l+1}, …, y_{j_l})$是什么？$[A, C, D, I, M]$ 是随机挑选出来的子序列， $l=1$ 对应的 $(y_{i_1}, y_{i_1+1}, …, y_{j_1})=[B]$； $l=3$ 对应的 $(y_{i_3}, y_{i_3+1}, …, y_{j_3})=[E, F, G, H]$； $l=4$ 对应的 $(y_{i_4}, y_{i_4+1}, …, y_{j_4})=[J, K, L]$； $l=5$ 对应的 $(y_{i_5}, y_{i_5+1}, …, y_{j_5})=[N, O]$； 对于$l=0, 2$ 的情况在后面讨论。 注意 $i_l, j_l$ 分别是该词在原始 $y$ 中的索引。 得到了 $(y_{i_l}, y_{i_l+1}, …, y_{j_l})$ 列表以后，我们去计算每个 slot 与其对应的$(y_{i_l}, y_{i_l+1}, …, y_{j_l})$ 中每个词的距离： d_l(i) = \\left|\\frac{i_l+j_l}{2}-i\\right| $l=1$ : $d_1 = \\left|\\frac{1+1}{2}-i|_{i=1}\\right| = [0]$； $l=3$ : $d_3 = \\left|\\frac{4+7}{2}-i|_{i=4,5,6,7}\\right| = [1.5, 0.5, 0.5, 1.5]$； $l=4$ : $d_4 = \\left|\\frac{9+11}{2}-i|_{i=9,10,11}\\right| = [1,0,1]$； $l=5$ : $d_5 = \\left|\\frac{13+14}{2}-i|_{i=13,14}\\right| = [0.5, 0.5]$； 然后我们根据上面计算出来的距离，给每个距离一个权重： w_l(i) = \\frac{\\exp(-d_l(i)/\\tau)}{\\sum_{i^{'}}^{j_l}\\exp(-d_l(i^{'})/\\tau)} 有了上面的权重，我们就可以定义每个位置上的 slot loss 了： \\mathrm{SlotLoss}(x, \\hat{y}, l)=\\sum_{i=i_l}^{j_l} -\\log p(y_i, l|x, \\hat{y}) \\cdot w_l(i) 最后总的 loss 为： \\mathrm{loss} = \\frac{1}{k+1}\\sum_{l=0}^k \\mathrm{SlotLoss}(x, \\hat{y}, l) SlotLoss 中的 $\\tau$ 是一个温度超参数，用来控制 $w_l$ 的平滑程度的：当 $\\tau \\rightarrow 0$ 时，将会给最中间的位置以非常高的权重，两侧的位置权重几乎为 0；当 $\\tau \\rightarrow \\infty$ 时，每个位置的权重基本相等。 3.3 Uniform作者也做了不给模型施加约束，让模型自己探索生成方式的尝试，即鼓励模型uniform地生成每个slot中的各个单词。实现的方式很简单，将$\\tau \\rightarrow \\infty$ 即可。 3.4 Termination Condition选取解码时的停止条件也是一个很关键的问题。Insertion Transformer 提出了两种停止条件: Slot Finalization 在训练时引入了 end-of-slot token，来和 label 为空的 slot 计算损失函数。在推理时，当且仅当全部 slot 的预测都为 end-of-slot 时，停止继续解码。 上面我们在介绍 soft binary tree loss 的时候遗留了一个问题：$l=0, 2$ 时怎么办？我们看到当 $l=0, 2$ 时我们不需要插入任何词，这时候我们定义一个 end-of-slot token，这个时候 $l=0, 2$ 对应的 $(y_{i_1}, y_{i_1+1}, …, y_{j_1})=[\\mathrm{EndOfSlot}]$ ，然后我们用 $\\mathrm{EndOfSlot}$ 计算损失。推理的时候，当所有的 slot 对应的 $y_{i_l}$ 都是 $\\mathrm{EndOfSlot}$ 时停止解码。 Sequence Finalization 则还是用的传统的 end-of-sequence token，在全部单词都生成之后，将每个 slot 都和 end-of-sequence token 计算损失函数。在推理时，当任意一个 slot 的预测结果是 end-of-sequence token 时，停止解码。 回到上面那个 $l=0, 2$ 的问题，在上面使用 Slot Finalization 时，我们令 $(y_{i_1}, y_{i_1+1}, …, y_{j_1})=[\\mathrm{EndOfSlot}]$ 然后计算相关损失。当使用 Sequence Finalization 时，遇到 $l=0, 2$ 这种情况的时候，我们认为这里需要插入空字符串，跳过这两个位置的损失计算。直到所有的 slot 都不再产生损失（也就是所有 slot 都要插入空字符串）的时候，我们让每个 slot 都和 end-of-sequence token 计算损失。推理的时候，任意一个 slot 的预测是 end-of-sequence token 则停止解码。 4. Inference4.1 Greedy DecodingGreedy decoding 支持 Slot Finalization 和 Sequence Finalization 两种终止条件的训练模式。推理的时候选择概率最高的词和对应的位置： (\\hat{c}_t, \\hat{l}_t) = \\arg \\max p(c, l|x, \\hat{y})然后再 $\\hat{l}_t$ 位置上插入 $\\hat{c}_t$。 4.2 Parallel Decoding采用 Slot Finalization 方式支持并行训练和解码。具体来说，就是对于每个 slot 计算最高概率的词： \\hat{c}_{l, t} = \\arg \\max p(c | l,x,\\hat{y}_t)这样相当于每次推理我们能填满所有 slot，理论上，只需要 $\\log_2(n)+1$ 步就可以生成一个长度为 $n$ 的序列。 5. Tricks作者对模型做了非常充分的实验，也做了很多有意思的讨论。这里总结一些比较有用的小 tricks： 由于两种终止条件在训练的时候引入了过多的 $&lt; EOS &gt;$, 会导致模型在推理时很容易生成 $&lt; EOS &gt;$造成早停的问题。因此文章引入了 $&lt; EOS &gt;$ 惩罚来在推理时对 $&lt; EOS &gt;$ 人为地增加预测难度：仅当 $&lt; EOS &gt;$ 的概率大于第二可能单词的概率一个阈值 $\\beta$ 的时候才会真正生成 $&lt; EOS &gt;$。从实验中看来，这是一个很重要的 trick。 使用base Transformer 作为模型的 teacher model，来做知识蒸馏也会提升模型的能力。 6. Experiments 这个实验是分析 2.1 节讨论的模型的不同变种的效果。从结果上看，不加 $&lt; EOS &gt;$ 惩罚的时候，Contextual + Mixture 能达到最佳效果，但是加上惩罚之后这种效果提升就消失了。说明模型的核心结构在适当的调整下已经足够强大有效，无需做太大的调整。 这个实验室采用并行解码的方式进行推理。我们发现之前介绍的平衡二叉树损失是非常有效的，另外$&lt; EOS &gt;$ 惩罚带来的提升已经不太明显了。 最后，与其他模型相比较，Insertion Transformer 不仅在效率上提升巨大，而且在效果上也达到了与自回归模型相同的水准。这是一个非常令人兴奋的结果。 最后，下面这张图展示了 Insertion Transformer 的一个实际推理的例子。 Reference Insertion Transformer: Flexible Sequence Generation via Insertion Operations, Mitchell Stern, William Chan, Jamie Kiros, Jakob Uszkoreit, 2019, arXiv: 1902.03249 Breaking The Softmax Bottleneck: a High-Rank RNN Language Model, Zhilin Yang , Zihang Dai, Ruslan Salakhutdinov, William W. Cohen, 2018, arXiv: 1711.03953 Insertion Transformer: Flexible Sequence Generation via Insertion Operations #123, kweonwooj, Github Pages Non-Autoregressive NMT: Insertion Transformer, Leo Guo, 知乎 香侬读 | 按什么套路生成？基于插入和删除的序列生成方法, 香侬科技, 知乎 Understanding the Mixture of Softmaxes (MoS)","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"},{"name":"insertion","slug":"insertion","permalink":"https://rogerspy.gitee.io/tags/insertion/"}]},{"title":"Transformer家族之Sparse Transformer","slug":"transformer家族-sparse","date":"2020-03-30T01:50:11.000Z","updated":"2022-01-12T08:37:38.459Z","comments":true,"path":"2020/03/30/transformer家族-sparse/","link":"","permalink":"https://rogerspy.gitee.io/2020/03/30/transformer家族-sparse/","excerpt":"目前来看，自注意力机制有一统NLP的趋势，其凭借能够捕捉序列中任意两个元素的关联信息，且易于并行等优势，在与传统的NLP武林盟主RNN的较量中，几乎是全方位碾压。但是它也并不是没有弱点，之前我们介绍过在机器翻译过程中，它的推理过程是auto-regression的，严重制约了它的推理效率。因此，很多研究人员对它做了一定程度上的改善。今天我们继续来对它进行其他方面的优化，也就是变形金刚家族的另一成员 —— Sparse Transformer。","text":"目前来看，自注意力机制有一统NLP的趋势，其凭借能够捕捉序列中任意两个元素的关联信息，且易于并行等优势，在与传统的NLP武林盟主RNN的较量中，几乎是全方位碾压。但是它也并不是没有弱点，之前我们介绍过在机器翻译过程中，它的推理过程是auto-regression的，严重制约了它的推理效率。因此，很多研究人员对它做了一定程度上的改善。今天我们继续来对它进行其他方面的优化，也就是变形金刚家族的另一成员 —— Sparse Transformer。 在介绍 Sparse Transformer 之前我们要先思考一个问题：我们为什么要对它进行稀疏化改进？稀疏注意力能解决现有的什么问题？ 1. Why you need Sparsity?1.1 计算复杂度从理论上来讲，Self Attention的计算时间和显存占用量都是$O(n^2)$级别的（$n$是序列长度），这就意味着如果序列长度变成原来的2倍，显存占用量就是原来的4倍，计算时间也是原来的4倍。现在，AI 研究中的一项挑战是对长序列的精细相关性建模，比如图像、声音等。如果我们在每一层都构建一个$n \\times n$的注意力矩阵的话会消耗大量的内存。例如： 而目前用于深度学习的标准GPU显存是12-32G。因此全自注意力（full self-attention）严重制约了模型的编码长度。 1.2 注意力集中问题理解自然语言需要注意最相关的信息。例如，在阅读过程中，人们倾向于把注意力集中在最相关的部分来寻找他们心中问题的答案。然而，如果不相关的片段对阅读理解产生负面影响，就会出现检索问题。这种分心会阻碍理解过程，而理解过程需要有效的注意力。比如： 与tim相关度最高的是heart及周围的几个词，而传统的transformer也给了其他不相关的词很高的权重，这样造成了注意力的分散。Sparse Transformer可以将注意力集中在几个最重要的元素上，避免或者缓解这一问题。 2. Sparse Transformer这里我们呢主要介绍四种Sparse Transformer : Sparse Transformers Adaptive Span Transformers Adaptively Sparse Transformers Explicit Sparse Transformer 2.1 注意力模式既然要将注意力稀疏化，那么如何稀疏就是个需要思考的问题。为了更好的处理这个问题，Child等人在图像上探究了Transformer 的注意力模式发现其中许多模式表现出了可解释和结构化的稀疏模式。以下每幅图像都显示了哪个输入像素（白色高亮标出）由一个给定的注意力头处理，以预测图像中的下一个值。当输入部分集中在小的子集上并显示出高度规律性时，该层就易于稀疏化。以下是 CIFAR-10 图像上 128 层模型的样本： 左图是Layer 19的注意力模式（白色高亮），右图是Layer 20的注意力模式。可以看到Layer 19集中了当前行的注意力，Layer 20集中了当前列的注意力。 左图是Layer 6的注意力模式，右图是Layer 36的注意力模式。可以看到Layer 6无论输入是什么，注意力的集中点都具有相似的模式，Layer 36的注意力高度依赖具体的数据。 另外，Sukhbaatar等人也对比了两个Transformer注意力头的注意力模式： 可以看到，Head A的注意力主要在最近的20个token，前面的80个token注意力权重很低，Head B的注意力主要集中在最近的20个token，但前80个token的注意力是均匀分布的。 从上面两个实验可以看出，注意力通常是稀疏的，而且在不同的层有不同的模式。虽然许多层显示出稀疏的结构，但有些层清晰地显示出了动态注意力，这种注意力延伸到整个图像。这个结论和我们在《Transformer的每一个编码层都学到了什么？》)中讨论的结果基本一致。 由于注意力机制的稀疏模式，研究人员提出了不同的稀疏化方法，下面我们介绍其中几种。 2.2 Sparse Transformers2019年OpenAI研究人员研发出一种Sparse Transformers，该模型在预测长序列方面创造了新纪录——无论预测的是文本、图像还是声音，可以从长度可能是之前30倍的序列中提取模式。 对于图像这种具有周期性结构的数据来说，作者提出Strided Sparse Transformer。从上面的Layer 19和Layer 20可以看出注意力分为关注当前行和当前列。作者可以根据这两种注意力模式设计两个稀疏注意力矩阵。 2.2.1 Full Self Attention 在上图中，左边显示了注意力矩阵，右变显示了关联性。这表明每个元素都跟序列内所有元素有关联。注意力稀疏化一个基本的思路就是减少关联性的计算，也就是认为每个元素只跟序列内的一部分元素相关，这就是稀疏注意力的基本原理。 2.2.2 Atrous Self Attention首先考虑列性注意力。对于一张图片来说，我们如果把图片展开成一个一维序列，对于之前注意力只关注当前列实际上就意味着，在这个展开的长序列中，注意力的关注点是间隔的，不连续的。这样引入一个新概念——Atrous Self Attention： Atrous Self Attention 强行要求每个元素只跟它相对距离为$k,2k,3k,…$的元素关联，其中$k&gt;1$是预先设定的超参数。由于现在计算注意力是“跳着”来了，所以实际上每个元素只跟大约$n/k$个元素算相关性，这样一来理想情况下运行效率和显存占用都变成了$O(n^2/k)$，也就是说能直接降低到原来的$1/k$。 2.2.3 Local Self Attention再考虑行性注意力。当注意力只关注在一行的内容时相当于每个元素只与前后$k$个元素以及自身有关联，如下图： 其实Local Self Attention就跟普通卷积很像了，都是保留了一个$2k+1$大小的窗口，然后在窗口内进行一些运算，不同的是普通卷积是把窗口展平然后接一个全连接层得到输出，而现在是窗口内通过注意力来加权平均得到输出。对于Local Self Attention来说，每个元素只跟2k+12k+1个元素算相关性，这样一来理想情况下运行效率和显存占用都变成了$O((2k+1)n)∼O(kn)$了，也就是说随着$n$而线性增长，这是一个很理想的性质——当然也直接牺牲了长程关联性。 2.2.4 Stride Sparse Self Attention到此，就可以很自然地引入OpenAI的Sparse Self Attention了。OpenAI将Atrous Self Attention和Local Self Attention合并为一个，形成适用于图像的Strided Sparse Transformer: 这样一来Attention就具有局部紧密相关和远程稀疏相关的特性，这对很多任务来说可能是一个不错的先验，因为真正需要密集的长程关联的任务事实上是很少的。 2.2.5 Fix Sparse Self Attention对于文本这种非周期的数据，上面的Stride Sparse Transformer并不能很好的获取数据特征，作者认为是因为对于文本来说，元素的空间坐标和它所处的位置并没有必然的联系，它可能与未来的元素关联性更大，因此，作者提出另一种稀疏注意力模式——Fix Sparse Transformer。 Fix Sparse Transformer同样是由两个注意力机制合并组成的，一种如下图，相当于将完整序列划分成多个子序列，在每个子序列内部做full self attention。 另一种如下图，相当于只计算序列上固定几个位置的元素计算注意力权重。 两种注意力相结合同样保证了局部紧密相关和远程稀疏相关特性。 2.3 Adaptive Span Transformers上面的稀疏化方法是研究人员利用先验知识，人工设计的一种稀疏化方法。这些方法可以很好的处理明显具有稀疏化特征的注意力机制，比如Layer 19/20，但是对于具有全局注意力和依赖数据特征的注意力机制，利用上述的稀疏化方法会影响最后的效果。因此，我们就想能不能设计一种自适应的注意力稀疏化机制，让模型自己决定要怎样稀疏化，这样可以避免人工设计的缺陷。 针对这个问题，Facebook的研究人员提出一种新的方法，利用一个$M_z$函数自动过滤一定长度的子序列，不参与注意力计算。$M_z$函数定义如下： m_z(x)=\\min[\\max[\\frac{1}{R}(R+z-x), 0], 1]这个函数的大致形状如下： 其中$R$是超参数，用来控制斜率。$z$是一个需要训练的参数，$x$是相对距离。得到这样一个函数以后，计算注意力的方法如下： a = \\frac{m_z(t-r)\\exp(s_{tr})}{\\sum_{q=t-s}^{t-1}m_z(t-q)\\exp(s_{tq})}在损失函数中，给z添加一个L1惩罚项： L = -\\log P(w_1,...w_T)+\\frac{\\lambda}{M} \\sum_iz_i另外，我们也可以用动态方式来学习$z$，即$z$是基于当前输入的一个输出，称之为动态宽度。 z_t = S\\sigma(\\mathbf{v}^T\\mathbf{x}_t+b)从上面的函数图可以看出来， 当$z$大于两元素的相对距离时，最后的注意力相当于Full self attention; 当$z$小于两元素的相对距离时，注意力会更集中在近距离元素上，相当于Local self attention； 当$z$很小时，远距离的元素上不会有任何注意力 可以看出这样同样是既保留了局部的依赖，又处理了远程的稀疏性，而这样一个过程是模型自行决定，有效避免了人为设计的缺陷。 2.4 Adaptively Sparse Transformers回想前面的稀疏化方法，我们发现之前的两种稀疏化方法都存在一个问题就是，注意力是连续性的。比如Adaptive Span Transformer，会忽略掉远距离的元素；虽然Sparse Transformer中包含了Atrous Attention，但是这种不连续性是人为设计的，具有固定的模式，不能很好的适应不同的数据。因此，本文提出一种新的方法，既能处理不连续的注意力，又能使这种不连续的注意力做到自适应不同的数据。 纵观我们从介绍注意力机制开始，到Transformer，再到后来的各种变种，有一个东西是自始至终都和注意力形影不离，那就是Softmax。Softmax是将一个向量进行归一化，将向量中每一个元素赋予概率的意义，而这个概率本身就是连续的。因此，如果要处理不连续性的注意力机制，我们是否可以将softmax进行稀疏化呢？ 本文就引入一个新的Softmax函数，实现了注意力的不连续稀疏化——$\\alpha$-$\\rm{entmax}$： \\alpha - \\mathrm{entmax}(\\mathbf{z}) = \\arg \\max_{\\mathbf{p} \\in \\Delta^d} \\mathbf{p}^T\\mathbf{z}+\\mathbf{H}_\\alpha^T(\\mathbf{p})其中$\\Delta^d=\\{\\mathbf{p} \\in \\mathbb{R}^d:\\sum_i\\mathbf{p}_i=1\\}$，对于$\\alpha \\ge 1$，$\\mathrm{H}_\\alpha^T$是Tsallis广延熵族： \\mathbf{H}_\\alpha^T(\\mathbf{p})=\\begin{cases} \\frac{1}{\\alpha(\\alpha-1)}\\sum_j(p_j-p_j^\\alpha), \\alpha \\ne 1, \\\\\\\\ \\\\\\\\ -\\sum_jp_j\\log p_j, \\alpha =1. \\end{cases}可以看到，这样一个函数是非连续性的，面临一个凸优化的问题。实际上我们可以通过下面的公式对其进行优化： \\alpha-\\mathrm{entmax}(\\mathbf{z}) = \\left[ (\\alpha-1)\\mathbf{z}-\\tau\\mathbf{1}\\right]_+^{1/\\alpha-1}其中$\\mathbf{1}$表示元素全为1的向量，$\\tau$是一个拉格朗日乘子为了保证$\\sum_ip_i=1$，$[\\cdot]_+$表示$\\mathrm{ReLU}$的正数部分。 看公式实在头疼，看不出为啥这样一个公式能将注意力进行稀疏化，那我们就来看图： 左边是二维图像，右边的两幅图分别是softmax和$\\alpha=2$的$\\alpha$-$\\mathrm{entmax}$。可以看出当 $t$ 过小的时候，输出就会变成0；$t$ 过大的时候，输出就会变成1，这样也就相当于将注意力稀疏化了。 剩下的 工作就是为了确定 $\\tau$，以及为了自适应不同的注意力头（transformer是多注意头的）的 $\\alpha$ 值，作者将 $\\alpha$ 作为网络的参数，利用后向传播进行优化等一系列细节，这里就不做详细介绍了。 本文涉及到的数学原理和公式的推导在引文和文章附录中都有详细推导，这里就不搬上来了，有兴趣可以自己看。 2.5 Explicit Sparse TransformerExplicit Sparse Transformer虽然实现了不连续的自适应稀疏化自注意力，但是其实整个过程蛮复杂的，尤其是其中涉及到的数学，看了让人头秃（我边推公式边看着头发往下掉，内心毫无波动…）。有没有一种既简单易实现，又能做到不连续自适应的稀疏化自注意力呢？当然有咯，接下来就来介绍这样一个工作。 Explicit Sparse Transformer的想法非常简单：它认为在计算注意力的时候，只有注意力最高的$k$个词对信息的获取有作用，其他低注意力的属于噪声，非但不会帮助模型获取有效信息，还会干扰模型做出正确决策。因此，在计算自注意力的时候，每个词只取注意力权重最高的$k$个词，其他的全部设置成$-\\infty$。计算过程如下： 首先计算注意力矩阵$P$； 找出 $P$ 中每行的 $k$ 个最大元素，记录其位置，并得到一个阈值向量，$t=[t_1, t_2, …, t_{lQ}]$，$t_i$ 表示第 $i$ 行中$k$ 个元素中注意力最低的那个值； 得到一个$Masking$矩阵： M(P, k)_{ij} = \\begin{cases} P_{ij}, \\qquad P_{ij} \\ge t_i \\\\\\\\ \\\\\\\\ \\mathrm{-} \\infty, \\qquad P_{ij} \\lt t_i \\end{cases} 归一化 A = \\mathrm{softmax} (M(P, k)) 输出表示 C = AV整个流程如下： 根据作者的实验表明，序列长度与vanilla transformer一致时，$k=8$能得到最佳结果。 关于取$\\mathrm{top}-k$以后的后向传播问题，作者在论文的附录中给出了解释，有兴趣的可以看原文哟。 最后说几句吧，这个文章是投稿给了ICLR 2020，但是被拒稿了，拒稿的理由主要是效果没有达到SOTA，额，我觉得嘛，黑猫白猫，能抓老鼠就是好猫。 References 为节约而生：从标准Attention到稀疏Attention，苏剑林， 科学空间 Generative Modeling with Sparse Transformers, Rewon Child, Scott Gray, Alec Radford, Ilya Sutskever, 2019, Arxiv:1904.10509 Generative Modeling with Sparse Transformers, OpenAI’s blog EXPLICIT SPARSE TRANSFORMER: CONCENTRATED ATTENTION THROUGH EXPLICIT SELECTION, Guangxiang Zhao, Junyang Lin, Zhiyuan Zhang,Xuancheng Ren, Xu Sun, 2019, Arxiv:1912.11637 Adaptive Attention Span in Transformers, Sainbayar Sukhbaatar, Edouard Grave, Piotr Bojanowski, Armand Joulin, 2019，Arxiv:1905.07799 Transformer之自适应宽度注意力, 张雨石， 知乎 Adaptively Sparse Transformers, Goncalo M. Correia， Vlad Niculae，Andre F.T. Martins，2019，Arxiv:1909.00015","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"},{"name":"sparse","slug":"sparse","permalink":"https://rogerspy.gitee.io/tags/sparse/"}]},{"title":"Transformer家族之Blockwise Transformer","slug":"transformer家族-block","date":"2020-03-26T07:35:28.000Z","updated":"2022-01-12T08:37:38.435Z","comments":true,"path":"2020/03/26/transformer家族-block/","link":"","permalink":"https://rogerspy.gitee.io/2020/03/26/transformer家族-block/","excerpt":"本文将继续介绍关于transformer在 non-auto regression方面的研究，今天要介绍的是Google Brain的工作Blockwise Parallel Decoding for Deep Autoregressive Models。","text":"本文将继续介绍关于transformer在 non-auto regression方面的研究，今天要介绍的是Google Brain的工作Blockwise Parallel Decoding for Deep Autoregressive Models。 1. 简介对于seq2seq任务来说，decoding过程是影响推理速度的关键。效率和效果似乎是一个难以和平共处的老对手，纵观之前我们介绍的方法，大致分成三类：auto regression、semi-auto regression、non-auto regression。Auto regression是效果最好的，但是推理速度是最慢的；non-regression是推理速度最快的（可以比前者快甚至几十倍），但是效果就差了；而semi-auto regression介于两者之间，效果略差但速度较快。之前我们介绍的Share transformer在效率和效果上都有所提升，但是这种提升是来源于对模型结构的优化，以更小的计算量实现的，虽然我很喜欢，但是有没有一种更新的，在decoding上的创新方法，既能提升效果，又能提高效率呢？下面要介绍的这篇文章就完成了这样一个设想。 2.Blockwise Parallel Decoding 上面展示的是BPD的基本方法。 假设我们有一组模型$\\{p_1, p_2, …, p_k\\}$，其中$p_1$是 原始模型，$p_2, …, p_k$是辅助模型。从图中我们可以看到，推理过程分成三步： Predict: 使用 $p_1$ 预测一个长度为$k$的序列； \\hat{y}_{j+i}=\\arg max_{y_{j+i}} p_i(j_{j+i}| \\hat{y}_{\\le j}, x), ~~ i=1,2, ..., k Verify: 使用辅助模型找到$i$的最大值$\\hat{k}$，使得 \\hat{y}_{j+i}=\\arg max_{y_{j+i}} p_1(j_{j+i}| \\hat{y}_{\\le j+i-1}, x), ~~ 1 \\le i \\le k Accept: 扩展预测序列，从$\\hat{y}_{\\le j}$变成$\\hat{y}_{\\le j+\\hat{k}}$，同时设置$j \\leftarrow j +\\hat{k}$。 在读论文的时候感觉作者在对predict和verify过程进行详细描述的时候给搞反了，不知道是真的写反了还是我理解错了，已经给作者发邮件了，截止到现在作者还没有回我。这里暂时按照我的理解做介绍，如果是我理解错了，再做修改。 假设我们现在已经有一个种子序列： \\mathrm{I\\quad saw\\quad a\\quad dog\\quad ride} 预测阶段：将种子序列作为$p_1$的输入，使$p_1$并行输出一个候选序列： $\\rm{in \\quad the\\quad bus}$ 验证阶段： ① 将 $\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride}$作为$p_1$的输入去预测 $\\rm{in}$ ② 将 $\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride \\quad in}$作为$p_2$的输入去预测 $\\rm{the}$ ③ 将 $\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride}$作为$p_3$的输入去预测 $\\rm{bus}$ $p_1$模型的输入来源无需多说，就是原始的种子序列；$p_2$的输入是种子序列+在预测阶段$p_1$的输出的第一个词；$p_3$的输入是种子序列+预测阶段$p_1$的输出的前两个词，以此类推。在验证阶段每个模型都是以Greedy decoding模式进行推理的，即只预测下一个词。因为每个模型都是独立运行的，所以$p_1, p_2, p_3$是并行运算的。 验收阶段： 在前面的验证阶段我们的到了一个候选集： \\rm{I\\quad saw\\quad a\\quad dog\\quad ride\\quad in} \\\\\\\\ \\rm{I\\quad saw\\quad a\\quad dog\\quad ride\\quad in\\quad the} \\\\\\\\ \\rm{I\\quad saw\\quad a\\quad dog\\quad ride\\quad in\\quad the\\quad car}与预测阶段$p_1$的输出对比发现$p_1$的输出最后一个词是$\\rm{bus}$，而$p_3$输出的词是$\\rm{car}$，相当于$p_1$和$p_3$发生了冲突，那么在验收阶段我们只取验证阶段与预测阶段输出相同的结果的最长序列，即我们取$\\rm{I\\quad saw\\quad a\\quad dog\\quad ride\\quad in \\quad the}$作为这一轮预测的输出，同时也是下一轮的输入。 相比于传统的auto-regression每一轮预测只能生成一个词，这种Blockwise decoding每一轮可以产生多个词（上面的例子中，同时生成$\\rm{in\\quad the}$两个词，当然需要注意的是每一轮生成词序的长度并不是固定的），同时还能保证这些词是以auto-regression的方式产生的，因此在提升推理效率的同时，效果一定不会比auto-regression差。 这里再唠叨几句，为什么这种方法是合理的呢？因为我们先用$p_1$生成一个短序列，然后用$p_1, p_2, …,p_k$去验证的时候，相当于是将一个时序的推理过程并行化了。首先，我们先假设$p_1$生成的序列是合理的，在验证过程中用第一个模型去验证如果是在自回归模式下$p_1$是否会生成 $\\rm{in}$，用第二个模型验证自回归模式下$p_1$ 是否会在$\\rm{in}$后面生成$\\rm{the}$，以此类推，知道我们发现验证阶段的输出和验证阶段的输出不一致的时候，我们就认为并行化生成的序列在这个位置及以后的输出是不合理的，所以我们可以放心的使用之前的生成的序列。 前面我们是以已经存在一个种子序列作为初始条件介绍的，那么在模型推理的一开始还没有种子序列的时候其实也差不多。Auto-regression的时候第一步推理也是根据encoding生成第一个词，然后逐步生成我们想要的序列。在blockwise decoding的时候也是一样的，初始的时候$p_1$不是生成一个词，而是生成一个序列。这样我们就可以重复上面的三个步骤了。 文章中给出了一个实际的推理过程的例子： 另外，还有一个需要注意的细节，在文章当中并没有提及，我不太清楚作者是怎么处理的，这里我说下我个人的想法。还以上面的句子为例：初始序列是: $\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride}$ 假设预测阶段$p_1$生成的序列是$\\rm{in \\quad the \\quad bus}$，但是在验证阶段$p_1$生成的是$\\rm{on}$，也就是说，验证阶段的第一个模型输出就与预测阶段生成的第一个词不一致，这种情况该怎么办呢？当然需要指出的是，这种情况的概率应该是很低的，因为都是$p_1$模型的输出所以在最靠近输入序列的输出应该有相同的分布，但是在写代码的时候不得不考虑这种情况。我个人的想法是应该是以验证阶段$p_1$的输出为准，毕竟这个时候的模型推理模式是auto-regression式的。虽然文章没有确切提出这一处理方式，但是在下面的介绍中，我们可以看到作者实际上确实是采用了这种方法的。 3. Combined Scoring and Proposal Model从上面的推理步骤可以看出，每一步推理都需要至少两次模型调用：预测阶段调用$p_1$和验证阶段调用$p_1, p_2, …, p_k$。理想情况下，我们希望生成长度为$m$的序列，只调用$m/k$次模型，但是上面的步骤需要$2m/k$次模型调用。那么有没有什么办法尽可能接近$m/k$次呢？接下来我们就介绍对上面步骤的改进，使得调用次数从$2m/k$次下降到$m/k+1$次。 和之前一样预测阶段先由$p_1$生成一个短序列，但是在验证阶段就发生了变化：之前是每个模型生成一个词，现在我们令每个模型和预测阶段的$p_1$一样，都生成一个短序列，这个实际上就相当于是验证我那个阶段和预测阶段合二为一了。我们仍然通过对比生成序列的第一个词来进行验收，而下一个推理周期的预测序列采用刚刚验收的序列生成的短序列。 以上图为例： 第一步：使$p_1$并行输出一个候选序列： $\\rm{in \\quad the\\quad bus}$ 第二步： ① 将 $\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride \\quad in }$作为$p_1$的输入去预测 $\\rm{the \\quad car \\quad last}$ ② 将 $\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride \\quad in \\quad the }$作为$p_2$的输入去预测 $\\rm{car \\quad this \\quad week}$ ③ 将 $\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride \\quad in \\quad the \\quad bus}$作为$p_3$的输入去预测 $\\rm{last \\quad week \\quad when}$ 第三步：我们提取出 $\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride \\quad in \\quad the }$作为我们这一轮的推理的输出，同时将$\\rm{car \\quad this \\quad week}$作为下一轮推理的预测序列。这样我们就相当于每一轮推理只需要调用一次模型（时间）就完成了验证和预测两步。 我们可以看到，这种推理方法的核心点在于$p_1$必须具有并行生成序列的能力，不能是RNN一次生成一个词的模型，所以只能是CNN或者Transformer这种具有并行能力的模型。 4. Approximate Inference到目前为止，我们就介绍了BPD的基本方法，实际上我们还可以放松验证标准实现额外的加速推理。 4.1 Top-$k$ Selection 之前在验证阶段，我们要求辅助模型的输出必须和原始模型的输出高度一致才可以，但是实际上我们可以认为，只要原始模型的输出在辅助模型的输出的top-k个输出中就可以，即 \\hat{y}_{j+i} \\in \\mathrm{top}k ( p_1(y_{j+i}|\\hat{y}_{\\le j+i-1}, x))比如前面$\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride \\quad in \\quad the \\quad car \\quad this \\quad week}$ 其中 $\\rm{car}$ 与 $\\rm{bus}$ 不一致，所以我们的输出序列只取到$\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride \\quad in \\quad the}$。那么现在如果 $\\rm{car}$ 存在于输出概率的top-k候选里面，我们也认为它是正确的，那么我们这一轮的推理输出结果应该是$\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride \\quad in \\quad the \\quad car}$。 4.2 Distance-Based Selection如果两个词在语义空间中有相近的含义，那么我们也可以用近义词代替，即： d(\\hat{y}_{j+i}, \\arg max_{y_{j+i}} p_1(y_{j+i}|\\hat{y}_{j+i-1}, x)) \\le \\epsilon比如 $\\rm{car}$ 和 $\\rm{bus}$ 的意思相近， 因此我们任然可以得到 $\\mathrm{I \\quad saw \\quad a \\quad dog \\quad ride \\quad in \\quad the \\quad car}$。 4.3 Minimum Block Size在推理的时候有可能出现炎症阶段第一个词就不正确的情况（上面我们讨论过），这样的话我们就只能一次生成一个词，那么久退回到自回归的推理模式了，为了保证推理的加速，我们可以设置一个最小值$l$，$1\\le l \\le k$，无论对错，每次最小生成 $l$ 个词。当$l=1$时，模型退化到自回归；当 $l=k$ 时模型变成纯并行模型。 5. Traning从上面描述我们可以看到，这种推理方式是非常消耗内存的，因为需要同时存在多个模型，这样我们就不能计算全部模型的loss了，取而代之，我们可以随机选择其中一个模型的loss作为整体的loss。 6. Experiments 7. ReferenceMitchell Stern, Noam Shazeer, Jakob Uszkoreit, NeurIPS 2018, Blockwise Parallel Decoding for Deep Autoregressive Models.","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"}]},{"title":"Transformer家族之Share Attention Networks","slug":"transformer家族-share","date":"2019-09-30T06:36:44.000Z","updated":"2022-01-12T08:37:38.448Z","comments":true,"path":"2019/09/30/transformer家族-share/","link":"","permalink":"https://rogerspy.gitee.io/2019/09/30/transformer家族-share/","excerpt":"接下来我们介绍一下Sharing Attention Weights for Fast Transformer这篇文章。实际上这篇文章之前还有两个关于加速Transformer推理的文章，一个类似Latent Transformer的引入离散隐变量的类VAE的方法，另一个是引入语法结构达到non-auto regression的方法。个人感觉没什么意思，就直接跳过了。本文要介绍的这篇文章比较有意思，引入共享权重的概念。从近期关于Bert小型化的研究（比如DistilBERT，ALBERT，TinyBERT等）来看，实际上Transformer中存在着大量的冗余信息，共享权重的方法应该算是剔除冗余信息的一种有效的手段，因此这篇文章还是比较有意思的。","text":"接下来我们介绍一下Sharing Attention Weights for Fast Transformer这篇文章。实际上这篇文章之前还有两个关于加速Transformer推理的文章，一个类似Latent Transformer的引入离散隐变量的类VAE的方法，另一个是引入语法结构达到non-auto regression的方法。个人感觉没什么意思，就直接跳过了。本文要介绍的这篇文章比较有意思，引入共享权重的概念。从近期关于Bert小型化的研究（比如DistilBERT，ALBERT，TinyBERT等）来看，实际上Transformer中存在着大量的冗余信息，共享权重的方法应该算是剔除冗余信息的一种有效的手段，因此这篇文章还是比较有意思的。 1. Attention Weights我们在介绍Transformer的时候说过，Multi-Head Attention其实和Multi-dimension Attention是一回事。在多维注意力机制中，我们希望每一维注意力都能学到不同的含义，但是实际上Lin et al. 2017研究发现，多维注意力机制经常会出现多个维度学到的东西是相同的的情况，即不同维度的注意力权重分布是相似的。 本文做了一个类似的研究，发现不同层之间的注意力权重也有可能具有相似的分布，说明不同层之间的注意力权重也在学习相同的信息。作者分别计算了不同层之间的注意力权重的JS散度，用以说明不同注意力权重有多大的差异性，下图是作者的计算结果： 注意作者的意图是加速Transformer的推理速度，因此着重研究的是decoder部分，因此上图表示的decoder的JS散度矩阵。我们知道每个decoder block中包含两个注意力矩阵，一个是masked atteniton，一个是encoder-decoder attention，上图左图表示masked attnetion，右图表示encoder-decoder attention。图中颜色越深表示差异性越小，即两个注意力权重矩阵越相似。从图中可以看到self-attention部分的相似非常大，而encoder-decoder attention相似性虽然不如self-attention，但是1,2,3,4之间和5,6层之间的相似性也比较大。 由于不同层的注意力权重相似性较大，因此可以在不同层中共享同一个注意力权重，减少参数从而达到加速推理的目的。 这里作者只讨论了decoder的情况，还记得我们之前介绍过一篇论文An Analysis of Encoder Representations in Transformer-Based Machine Translation，讲的是在encoder的每一层注意力都学到了什么信息。这里我希望对比一下用本文的方法和上面的研究方法对比一下，看看得到结论是否能相互印证。因此我和本文的作者进行了交流，很遗憾的是作者并没有像decoder那样仔细研究encoder的情况，但是作者认为理论上encoder的情况应该是和decoder的self-attention的情况是一致的，因为encoder中的attention和decoder的self-attention层都是对单一的序列进行编码，不同的是前者是对源序列，后者是对目标序列，因此两者应该有相似的表现。虽然作者没有计算encoder注意力权重的JS散度，但是在实验过程中，尝试过对encoder的注意力进行共享，发现第1, 2层计算，3-6层使用第1层的权重，此种情况下对性能也未发现明显的下降趋势，因此作者认为encoder端不同层的注意力权重同样存在着较多的相似情况。 2. 模型结构 模型结构如上图。其实SAN的基本想法很简单，就是计算一次注意力权重，多次重复使用。具体的数学描述如下： Self-Attention 定义第$m$层的注意力自注意力权重矩阵为： S^m = s(Q^m, K^m)有了第$m$层的注意力权重，把它共享给第$m+1$层： S^{m+i} = s(Q^m, K^m), i \\in [1, \\pi-1]其中$\\pi$表示有多少层共享第$m$层的注意力权重，比如对于一个6层的decoder来说，我们可以让前两层共享一个权重矩阵$\\pi_1=2$，让后面的4层共享两一个权重矩阵$\\pi_2=4$，具体的共享策略在后面介绍。 Encoder-Decoder Attention 对于encoder-decoder注意力层来说，采取同样的操作。但是为了进一步加速推理，这里作者采用了一个小技巧，即$K, V$使用encoder的输出： A^{m+i} = A^m = S^m \\cdot V, i \\in [1, \\pi-1]其中$A^m$是第$m$层的 注意力输出，$V$是encoder的输出。 另外为了减少内存消耗，共享的注意力权重只需要拷贝给相应的层即可，不需要配置到在每一层的内存中去。 3. Learning to Share那么，现在的问题是，我们怎么知道那些层需要共享注意力权重呢？一个最简单的方法就是遍历测试，然后在development set上进行微调。显然这不是最优的方法，因为我们要在不同的程度上控制注意力权重的共享程度。 这里作者提出采用动态策略——利用JS散度计算层与层之间的相似度： \\mathrm{sim}(m,n) = \\frac{\\sum_{i=m}^n \\sum_{j=m}^n(1-\\delta(i,j))\\mu(i, j)}{(n-m+1)\\cdot (n-m)}其中$\\mu(i, j)$表示第$i$层和第$j$层的JS相似度，$\\delta(i,j)$表示Kronecker delta function。上式表示$m,n$层之间的相似性，当$\\mathrm{sim}(m,n) &gt; \\theta$时那么$m,n $层就共享注意力权重。 首先从第一层开始计算满足$\\theta$阈值的最大的$\\pi_n$，如此往复，直到所有的注意力层都计算完了。这个时候我们会得到一个注意力权重的共享策略$\\{\\pi_1, …, \\pi_N\\}$，$\\pi_i$实际上前面已经解释了表示什么，但是为了更直观的解释，这里我们还是举个例子吧： 假设deocder有6层注意力层，共享策略为$\\{\\pi_1=2,\\pi_2=4\\}$，表示第$1,2$层共享注意力权重，第$3,4,5,6$共享注意力权重。 一旦共享策略确定了下来之后，我们要重新训练模型，对注意力权重进行微调，直到模型收敛。 4. 实验结果 5. 参考资料Sharing Attention Weights for Fast Transformer Tong Xiao et al., 2019","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"}]},{"title":"Transformer家族之Semi-Autoregressive Transformer","slug":"transformer家族-sa","date":"2019-09-30T01:49:38.000Z","updated":"2022-01-12T08:37:38.447Z","comments":true,"path":"2019/09/30/transformer家族-sa/","link":"","permalink":"https://rogerspy.gitee.io/2019/09/30/transformer家族-sa/","excerpt":"从题目就可以看出来，本文将要介绍一种半自动回归的机器翻译解码技术。之前我们介绍了各种非自动回归的解码技术，其中有一个Latent Transformer是先用auto-regression生成一个短序列，然后用这个短序列并行生成目标序列。当时我们说这其实算是一种半自动回归的方法。今天我们要介绍另一种半自动回归的方法——SAT。","text":"从题目就可以看出来，本文将要介绍一种半自动回归的机器翻译解码技术。之前我们介绍了各种非自动回归的解码技术，其中有一个Latent Transformer是先用auto-regression生成一个短序列，然后用这个短序列并行生成目标序列。当时我们说这其实算是一种半自动回归的方法。今天我们要介绍另一种半自动回归的方法——SAT。 和Latent Transformer不同，Semi-Auto regressive Transformer （SAT）仍然是auto-regression的运行机制，但是不像auto-regression那样一次生成一个元素，SAT是一次生成多个元素。 1. 模型结构 模型结构如图。我们可以看到模型基本上和Transformer保持一致，只在图中红虚线框中有所改变。 1.1 Group-Level Chain Rule给定一个目标序列，通常的建模方式是词级别的链式法则： p(y_1, y_2, ..., y_n|X) = \\Pi_{t=1}^n p(y_t|y_1, ..., y_{t-1}, x)每个词都依赖之前的词。在SAT中，对序列进行分组 G_1, G_2, ..., G_{[(n-1)/K]+1} = y_1, ..., y_K, y_{K+1}, ..., y_{2K}, ...,y_{[(n-1/K)\\times K+1]}, ..., y_n其中$K$表示每组的大小，$K$越大 表示并行能力越强，除了最后一组其他每组中必须包含$K$个词。这样的话，上面的链式法则则变成： p(y_1, ..., y_n|X) = \\Pi_{t=1}^{[(n-1)/K]+1} p (G_t|G_1, ..., G_{t-1}, x)作者将之前的auto-regression称之为short-distance prediction，而将SAT称之为long-distance prediction。 1.2 Relaxed Causal Mask在Transformer中由于是连续的词矩阵，因此在做mask的时候直接使用下三角矩阵，但是在SAT中由于答对词进行了分组，再使用下三角矩阵就不合适了，作者这里提出一个粗粒度下三角矩阵（coarse-grained lower triangular matrix）的 mask矩阵。如图所示： 图中左边表示标准的下三角矩阵，右边表示粗粒度下三角矩阵。 数学形式： 2. 实验结果 3. 参考资料Semi-Autoregressive Neural Machine Translation","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"}]},{"title":"Transformer家族之NA Trasnsformer","slug":"transformer家族-nat","date":"2019-09-26T11:13:04.000Z","updated":"2022-01-12T08:37:38.445Z","comments":true,"path":"2019/09/26/transformer家族-nat/","link":"","permalink":"https://rogerspy.gitee.io/2019/09/26/transformer家族-nat/","excerpt":"本文继续介绍关于transformer在non-auto regression方面的研究，今天要介绍的是Gu et al. 2018 发表在ICLR 2018上的文章Non-autoregressive neural machine translation 。","text":"本文继续介绍关于transformer在non-auto regression方面的研究，今天要介绍的是Gu et al. 2018 发表在ICLR 2018上的文章Non-autoregressive neural machine translation 。 1. 简介之前我们介绍了由于transformer的auto-regression机制，导致模型在做推理的时候会变得非常慢。针对这个问题很多研究者都做了探索，之前介绍的几篇论文都没有真正做到non-auto regression，而今天我们要介绍的这篇文章则从根本上做到了non-auto regression。 1.1 Auto-Regressive Decoding给定一个源序列$X=\\{x_1, x_2, …, x_{T’}\\}$，翻译模型通过链式条件概率的方式预测输出序列$Y = \\{ y_1, y_2, …, y_T\\}$: p_{AR}(Y|X;\\theta) = \\Pi_{t=1}^{T+1} p(y_t|y_{0:t-1}, x_{1:T'};\\theta)其中$y_0$表示句子开始符，比如$BOS$；$y_{T+1}$表示句子结束符，比如$EOS$ 。 1.2 Maximum Likelihood training训练的时候直接使用Maximum Likelihood training方法对模型进行训练： L_{ML} = \\log P_{AR}\\{Y|X;\\theta\\} = \\sum_{t=1}^{T+1} \\log p(y_t|y_{0:t-1},x_{1:T'};\\theta)1.3 Non-Auto regressive Decoding从上面的$p_{AR}(Y|X;\\theta)$中可以看出，实际上要预测$Y=\\{y_t\\}$需要两个条件： 知道$Y$的长度$T$，虽然对于auto-regression来说，解码过程并不知道$T$显示的值，但是由于编码的开始和结束可以通过句子开始符（$&lt; BOS&gt;$）和句子结束符（$&lt; EOS&gt;$）来控制，编码过程是一个词一个词的生成 ，知道遇到结束符，则编码过程结束。因此，模型可以隐式的知道$T$的值。但是对于并行生成句子序列，我们必须提前知道句子的长度，才能一次性生成一个长度为$T$的序列，所以对于Non-auto reregression来说$T$必须是显式的； 第二点当然就是$Y$序列本身了，当知道了需要预测的序列长度，就可以根据输入预测输出了。 因此，我们可以把预测$Y=\\{y_t\\}$任务分为两部分，第一部分预测$T$的大小，第二部分生成长度为$T$的序列： p_{NA}(Y|X;\\theta) = p_L(T|x_{1:T'};\\theta)\\cdot \\Pi_{t=1}^{T} p(y_t|x_{1:T'};\\theta)这样我们就可以分别独立的训练这两部分，而在推理的时候 能并行计算。 1.4 多模态问题这种简单的方法虽然看起来合理，但是实际上有一个很大的问题：多模态问题 。具体来说就是同一句话有多种翻译方式，比如Thank you可以翻译成谢谢、感谢等。由于$p(y_t)$只与$X$有关，所以无法获得训练数据中谢谢、感谢 等不同翻译方式的分布。 当A B既可以翻译成1 2 3，又可以翻译成4 5 6时，实际上相当于 \\{A, B\\} => \\{1, 2, 3, 4, 5, 6\\}的一个映射，而最佳的映射组合是$\\{1,2,3\\}$和$\\{4,5,6\\}$，但是由于non-auto regression每个词都是独立的，所以无法获取到词与词之间的依赖关系，每种序列组合称为mode。 另外使用Maxium Likelihood进行训练的时候，模型倾向于使用在训练集中出现概率最大的mode覆盖掉其他小概率mode，这实际上是有一定问题的。 要解决多模态问题，一般有三种方法： 增强模型处理多模态的能力； 在训练集中减少mode的数量； 改变学习目标 实际上最有效的还是第一种方法，这篇论文提出了一种训练技术用来解决多模态问题。 2. Non-Autoregressive Transformer 模型结构图如上。模型包含四个部分：Encoder、Fertility predictor、Decoder和Translation Predictor。其中黑色实线箭头表示可微分操作，浅色虚线表示不可微分操作，每个sublayer也都包含LayerNorm和残差连接。 Encoder部分作者并没有做什么变化，与Transformer保持一致，因此这里我们不做介绍，主要介绍其他几部分，以及训练技巧。 2.1 Decoder Stack从图中可以看到，Decoder Stack包含了四部分： Multi-Head Self-Attention Multi-Head Positional Attention Multi-Head Inter-Attention MLP 其中MLP就是transformer中的position wise feed forward层。Multi-Head Inter-Attention就是transformer中decoder block的第二个multi-head attention层。这两个相比原来的transformer没有什么变化，这里就跳过不讲。下面主要介绍其余两个模块以及Decoder Stack的输入。 2.1.1 Decoder Inputs在进行解码之前，Non-Autoregressive Transformer（NAT）需要知道要生成的序列的长度。另一方面如果只输入位置编码的话最后的效果会很差，因此解码器的输入也是非常重要的。为此，作者设计了两种解码器的输入： Copy source inputs uniformly：根据下面的规则从源序列中拷贝一个序列出来作为解码器的输入 Round(T't/T)假设源序列长度是$T’$，目标序列长度是$T$，那么解码器的输入序列中第$t$个位置的元素为源序列中第$Round(T’t/T)$个元素。举个例子： 源序列：[Thank, you, !] 目标序列：[谢谢, ！] 源序列的长度是3，目标序列的长度是2。那么解码器的输入第0个位置的元素应该对应源序列中第 $3 \\times 0/2=0$，个元素，即Thank；解码器的输入序列的第1个元素，应该对应源序列中第$3 \\times 1/2=1.5$，四舍五入得2，即！。那么解码器的输入序列应该为$\\{Thank , !\\}$。 Copy source inputs using fertilities：同样是从源序列中拷贝一个序列出来作为解码器的输入，但是拷贝规则有了变化。如同结构图中显示的，编码器会在编码结束后除了输出注意力状态，还会输出一个长度与源序列长度相同的序列，序列中每个元素都是一个整数。将源序列中的每个位置上的元素拷贝相应的整数倍之后作为解码器的输入，而解码器的输入长度$T$则是编码器输出的整数序列之和。举个例子： 源序列：[Thank, you, !] encoder output: [1, 0, 1] 那么解码器的输入序列为： $\\{Thank \\times 1, you \\times 0, ! \\times 1 \\}$，即$\\{Thank, !\\}$为解码器的输入。 2.1.2 Non-causal self-attention由于这里是并行生成目标序列，因此不需要对注意力权重矩阵进行mask。但是在实际的测试过程中作者发现把元素自身所在的位置mask掉后会取得更好的结果，即（深色部分表示被mask掉的）： 2.1.3 Positional Attention作者还在每个decoder layer中加入了positional attention，使得模型获得序列位置向量的能力更强了。而所谓的positional attention顾名思义就是positional encoding + attention，分别对应transformer中的positional encoding和multi-head attention： p(j, k) = \\sin(j/10000^{k/d}), k为偶数 p(j,k) = \\cos(j/10000^{k/d}), k为奇数 Attention(Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_{model}}})V2.2 Modeling Fertility 解决多模态问题本文提出使用隐变量（Latent Variable）方法来解决这一问题。具体的想法如下图 左边代表可能的各种可能的组合元素，所有元素可以两两组合，也可以三三组合等等可以以任意方式组合，因为对于NA来说词与词之间存在一个独立假设。我们可以从大的组合集中进行采样得到小的组合集（如图中蓝色圈圈画出来的小样本集合），这样模型就相当于在一个小的样本空间中进行建模，这样就可以强化模型的多模态处理能力。而我们把采样得到的样本空间称之为隐变量$z$，引入$z$后多模态的翻译分布则变成了： p_{NA}(Y|X;\\theta) = \\sum_z\\left[ p_z(z|x_{1:T'};\\theta)\\cdot p_L(T|x_{1:T'};\\theta;z)\\cdot \\Pi_{t=1}^{T}p(y_t|x_{1:T'};\\theta;z)\\right]$z$需要满足以下条件： 需要比较简单的从端到端的训练中获得； $z$要尽可能的考虑到不同说出之间的关系，使得其余位置的输出尽可能条件独立性； $z$要很容易从平行语料中推理得到，又不能信息量过于丰富让$p$显得无关紧要。 所以，模型的关键是对$z$建模。本文中$z$就是decoder的输入——利用Fertility的思想从encoder输入中拷贝元素。所谓fertility指的是，源序列中每个元素会被翻译多少次。这种思想源于早期的统计机器翻译中，每个词被翻译的次数不同，则输出序列会不，比如Thank被翻译一次可能是谢谢，而如果翻译两次的话可能会输出多谢。每个词的翻译次数实际上是个隐藏的含义，并不具有显式意义，因此它是一种Latent Variable，可以用来表示一种translation mode。 因此根据fertitlity我们可以把方程写成： p_{NA}(Y|X;\\theta) = \\sum_{f_1, ..., f_T'\\in F}\\left( \\Pi_{t'=1}^{T'}p_F(f_{t'}|x_{1:T'};\\theta) \\cdot \\Pi_{t=1}^{T}p(y_t|x_1\\{f_1\\}, ...x_{T'}\\{f_{T'};\\theta\\})\\right)其中$F=\\{f_1, …, f_{T’} | \\sum_{t’=1}^{T’}f_{t’}=T, f_{t’}\\in \\mathbb{Z^*}\\}$。 Fertility序列中每个词重复的次数通过一个softmax层预测。 3. 训练由于模型中引入了离散的隐变量，是的整个模型不能直接使用后向传播进行训练。作者引入了一个外部的对齐函数——Fast-align。Fast-align能够将输入输出进行词对齐，即目标序列中的每个词对应源序列中的相应的词。这样我们就可以得到一个外部的Fertility序列。我们可以用这个外部的fertility序列当成fertility的监督项，这样整个模型的损失项来源于两部分：decoding和fertility： L_{ML}= \\log p_{NA}(Y|X;\\theta) = \\log \\sum_{f_{1:T'}\\in F} p_F(f_{1:T'}|x_{1:T'};\\theta)\\cdot p(y_{1:T}|x_{1:T'},f_{1:T'};\\theta) L_{ML} \\ge \\mathbb{E}_{f_{1:T'}\\sim q}(\\underbrace{\\sum_{t=1}^T\\log(y_t|x_1\\{f_1\\}, ...,x_{T'}\\{f_{T'}\\};\\theta)}_{\\mathrm{Translation Loss}}+\\underbrace{\\sum_{t'=1}^{T'}\\log p_F(f_{t'}|x_{1:T'};\\theta)}_{\\mathrm{Fertility~Loss}})+H(q)其中$q$表示外部对齐函数估计的Fertility序列分布。 这样的话整个模型就相当于由两部分监督学习组成，就可以直接使用后向传播进行训练了。 3.1 知识蒸馏之前我们提到解决多模态问题有三种方法：增强模型处理多模态的能力，减少mode数，改变学习目标。其中增强模型处理多模态的能力是核心，前面我们已经介绍过了。下面我们介绍一下后两种方法，注意这几种方法结合使用，而不是分别使用，也就是说是在同一个模型中一起使用者三种方法，fertility是核心。 知识蒸馏其实蒸馏的就是mode，通过减少mode数，从而提升模型的学习效果。这里使用的方法是先用一个标准的Transformer学习一个模型，将这个标准Transformer的推理结果作为NAT的目标序列。 3.2 Fune Tuning前面我们提到使用Maximum Likelihood本身更倾向于学习概率更大的mode，因此作者在这里引入一个微调项，用来做目标纠正——reverse K-L divergence: L_{RKL}(f_{1:T'};\\theta) = \\sum_{t=1}^{T}\\sum_{y_t} [\\log p_{AR}(y_t|\\hat{y}_{1:t},x_{1:T'})\\cdot p_{NA}(y_t|x_{1:T'},f_{1:T'};\\theta)]其中$\\hat{y}_{1:T}=G(x_{1:T’}, f_{1:T’};\\theta)$，所以最终的损失函数为： L_{FT} = \\lambda(\\underbrace{\\mathbb{E}_{f_{1:T'}\\sim p_F}(L_{RKL}(f_{1:T'})-L_{RKL}(\\overline{f_{1:T'}}))}_{L_{RL}}+\\underbrace{\\mathbb{E}_{f_{1:T'}}(L_{RKL}(f_{1:T'}))}_{L_{BP}})+(1-\\lambda)L_{KD}4. 推理推理阶段主要的任务是获取fertility序列，作者提出三种方法： Argmax decoding 由于在模型训练阶段，fertility序列随着模型的训练一起呗训练了 ，因此我们可以直接使用$\\mathrm{arg~max}$来得到fertility序列： \\hat{Y}_{argmax} = G(x_{1:T'},\\hat{f}_{1:T'};\\theta),其中\\hat{f}_{t'}=\\mathrm{arg}\\max p_F(f_{t'}|x_{1:T'};\\theta) Average decoding 也可以通过求对应的softmax的期望来得到fertility序列： \\hat{Y}_{average} = G(x_{1:T'}, \\hat{f}_{1:T'};\\theta), 其中\\hat{f_{t'}}=Round(\\sum_{f_{t'}}^{L}p_F(f_{t'}|x_{1:T'};\\theta)f_{t'}) Noisy parallel decoding (NPD) \\hat{Y}_{NPD} = G(x_{1:T'},\\mathrm{arg}\\max_{f_{t'}\\sim p_F} p_{AR}(G(x_{1:T'}, f_{1:T'};\\theta)|X;\\theta);\\theta)最后使用一个之前在做知识蒸馏的时候训练好的Transformer对输出的句子进行re-ranking，得到一个最佳的翻译结果： 5. 实验结果 6. 参考资料 Non-autoregressive neural machine translation Gu et al. 2018 直播实录 | 非自回归神经机器翻译 + ICLR 2018 论文解读","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"}]},{"title":"Transformer家族之Latent Transformer","slug":"transformer家族-latent","date":"2019-09-25T01:47:26.000Z","updated":"2022-01-12T08:37:38.443Z","comments":true,"path":"2019/09/25/transformer家族-latent/","link":"","permalink":"https://rogerspy.gitee.io/2019/09/25/transformer家族-latent/","excerpt":"之前提到Auto-regression的decoding方法使得transformer在推理上的表现很慢，所以很多研究者在这方面做了很多研究，本文就介绍一个使用Non-Auto Regression的方法——Discrete Latent Variable。该方法与Auto-regression方法相比，效果上要稍差 一些，但是取得了比其他Non-auto regression方法都好的结果，而效率上也有很大的提升。","text":"之前提到Auto-regression的decoding方法使得transformer在推理上的表现很慢，所以很多研究者在这方面做了很多研究，本文就介绍一个使用Non-Auto Regression的方法——Discrete Latent Variable。该方法与Auto-regression方法相比，效果上要稍差 一些，但是取得了比其他Non-auto regression方法都好的结果，而效率上也有很大的提升。 1. 简介1.1 Auto-RegressionRNN在机器翻译领域有着非常重要的应用，但是它本身由于不能进行并行计算，限制了它的效率，所以后来有些研究者希望能用CNN替代RNN。而Transformer的横空出世，使得机器翻译在训练效果和效率上都上了一个台阶，但是仍然存在一个问题。 Transformer在生成一个序列的时候，通常需要根据之前的序列来预测下一个词，即当预测$y_n$时，需要利用$y_1, y_2, …, y_{n-1}$作为模型的输入。所以transformer在生成序列的时候是一个词一个词的生成，每生成一个词就需要进行一次推理，因此造成效率很低。这也就是所谓的Auto-regression问题。而transformer的auto-regression问题比RNN和CNN更加严重，因为RNN是根据前一个状态预测下一个状态，CNN是根据前K（kernel大小）个状态预测下一个状态，而transformer则是利用之前的所有状态预测下一个状态。虽然transformer在训练的时候可以很高效的训练，这是因为训练时的输出序列都已知，所以不需要auto-regression；但在进行decoding的时候输出是未知的，必须进行auto-regression，所以效率反而更低。 1.2 Latent Transformer为了克服Auto-regression问题，Kaiser et al. 2018提出使用离散隐变量方法加速decoding推理。这种方法算不上真正解决了Auto-regression问题，但是算是对问题进行了优化吧，或者应该叫做Semi-auto regression。 这种方法简而言之就是，先用auto-regression生成一个固定长度的短的序列$l= \\{l_1, l_2, …, l_m\\}$，其中$m&lt;n$，然后再用$l$并行生成$y = \\{y_1, y_2, …, y_n\\}$。为了实现这种方法，我们需要变分自编码器。由于句子序列是离散的序列，在使用离散隐变量的时候会遇到不可求导的问题，因此如何解决这个问题就需要一些离散化的技术了。 2. 离散化技术我们主要介绍四种离散化技术： Gumbel-softmax (Jang et al., 2016; Maddison et al., 2016) Improved Semantic Hashing (Kaiser &amp; Bengio, 2018) VQ-VAE (van den Oord et al., 2017) Decomposed Vector Quantization 给定目标序列$y=\\{y_1, y_2, …, y_n\\}$，将$y$输入到一个编码器（自编码器中的编码器，并非机器翻译模型中的编码器，下文的解码器同理，如非特殊说明encoder和decoder指的都是自编码器中的编码器和解码器）中产生一个隐变量表示$enc(y) \\in \\mathbb{R}^D$，其中$D$是隐变量空间的维度。令$K$为隐变量空间的大小，$[K]$表示集合$\\{1, 2, …, K\\}$。将连续隐变量$enc(y)$传入到一个discretization bottleneck中产生离散隐变量$z_d(y) \\in [K]$，然后输入$z_q(y)$到解码器$dec$中。对于整数$i, m$我们使用$\\tau_m(i)$代表用$m$ bits表示的二进制$i$，即用$\\tau_m^{-1}$将$i$从二进制转换成 十进制。 下面我们主要介绍discretization bottleneck涉及到的离散化技术。 实际上离散化技术是一个在VAE、GAN、RL中都有很重要应用的技术，本文只简单介绍它在文本生成方向的应用，而涉及到技术细节以及数学原理等更加详细的内容，以后会专门讨论，这里只说怎么用不说为什么。 2.1 Gumbel-Softmax将连续隐变量$enc(y)$变成离散隐变量的方法如下： l = W enc(y) , W \\in \\mathbb{R}^{K\\times D} z_d(y) = \\mathrm{arg} \\max_{i\\in[K]}~ l_i 评估和推理时 z_q(y) = e_j其中$e \\in \\mathbb{R}^{K \\times D}$，类似词向量的查询矩阵；$j=z_d(y)$。这一步相当于编码器生成一个短句子序列，然后这个短句子序列作为解码器的输入，通过查询词向量矩阵将句子中的词变成向量。 训练时 使用Gumbel-softmax采样生成$g_1, g_2, …, g_K$个独立同分布的Gumbel分布样本： g_i \\sim -\\log(-\\log(u))其中$u \\sim U(0,1)$表示均匀分布。然后用下式计算softmax得到$w \\in \\mathbb{R}^K$: w_i = \\frac{\\exp((l_i+g_i)/\\tau)}{\\sum_i\\exp((l_i+g_i)/\\tau)}得到$w$以后我们就可以简单地用： z_q(y) = we来获得$z_q(y)$。 注意Gumbel-softmax是可导的，也就是说我们可以直接通过后向传播对模型进行训练。 2.2 Improved Semantic HashingImproved Semantic Hashing主要来源于Salakhutdinov &amp; Hinton, 2009提出的Semantic Hahsing算法。 \\sigma'(x) = \\max(0, \\min(1, 1.2\\sigma(x)-0.1))这个公式称为饱和sigmoid函数（Kaiser &amp; Sutskever, 2016; Kaiser &amp; Bengio, 2016）， 训练时 在$z_e(y) = enc(y)$中加入高斯噪声$\\eta \\sim \\mathcal{N}(0,1)^D$，然后传入给饱和sigmoid函数 f_e(y) = \\sigma'(z_e(y) + \\eta)使用下式将$f_e(y)$进行离散化： 解码器的输入用两个嵌入矩阵计算$e^1, e^2 \\in \\mathbb{R}^{K \\times D}$： z_q(y) = e^1_{h_{e(y)}}+e^2_{1-h_{e(y)}}其中$h_{e}$是从$f_e$或者$g_e$中随机选择的。 推理时 令$f_e=g_e$ 2.3 Vector QuantizationVector Quantized - Variational Autoencoder (VQ-VAE)是van denOord et al., 2017提出的一种离散化方法。VQ-VAE的基本方法是使用最近邻查找矩阵$e \\in \\mathbb{R}^{K\\times D}$将$enc(y)$进行数值量化。具体方法如下： z_q = e_k, k=\\mathrm{arg} \\min_{j\\in [K]} \\|enc(y) -e_j \\|_2对应的离散化隐变量$z_d(y)$是$e$矩阵中与$enc(y)$距离$k$索引最近的值。损失函数定义如下： L = l_r +\\beta\\|enc{y}-sg(z_q(y)) \\|_2其中$sg(\\cdot)$定义如下： $l_r$即为给定$z_q(y)$后模型的损失（比如交叉熵损失等）。 使用下面两个步骤获得exponential moving average (EMA)： 每个$j \\in [K]$都用$e_j$； 统计编码器隐状态中使用$e_j$作为最近邻量化的个数$c_j$。 $c_j$的更新方法如下： c_j \\leftarrow \\lambda c_j+(1-\\lambda)\\sum_l 1[z_q(y_l)=e_j]然后对$e_j$进行更新： e_j \\leftarrow \\lambda e_j +(1+\\lambda)\\sum_l \\frac{1[z_q(y_l)=e_j]enc(y_l)}{c_j}其中$1[\\cdot]$是一个指示函数，$\\lambda$是延迟参数，实验中设置为$0.999$。 2.4 Decomposed Vector Quantization当离散隐变量空间很大的时候VQ-VAE会有一个问题——index collapse：由于“富人越富，穷人越穷”效应，只有少数的嵌入向量能得到训练。 具体来说就是如果一个嵌入向量$e_j$距离很多编码器的输出$enc(y_1), enc(y_2), …, enc(y_i)$都很近，那么它就能通过上面$c_j$和$e_j$的更新更加靠近，到最后只有少数几个嵌入向量被用到。因此，本文提出了一个VQ-VAE的变种——DVQ使$K$值很大的时候也能做到充分利用嵌入向量。 2.4.1 Sliced Vector QuantizationSliced vector quantization顾名思义，就是将$enc(y)$切成$n_d$个小的切片： enc^1(y)\\odot enc^2(y)...\\odot enc^{n_d}(y)其中每一个$enc(y)$的维度为$D/N_d$，$\\odot$表示拼接。 2.4.2 Projected Vector Quantization另一个方法是，使用固定的随机初始化投影集合： \\{ \\pi^i \\in \\mathbb{R}^{D\\times D/n_d} | i \\in [n_d]\\}将$enc(y)$投影到$R^{D/n_d}$的向量空间中去。 3. Latent Transformer介绍了这么多离散化的技术，下面就需要将这些离散化的技术应用到模型中去。给定输入输出序列对：$(x, y) = (x_1, x_2, …, x_k, y_1, y_2, …, y_n)$，Latent Transformer包含下面三个部分： $ae(y, x)$函数用来对$y$进行编码成$l=l_1, l_2, …, l_m$； 使用Transformer （即$lp(x)$）对$l$进行预测 $ad(l, x)$函数并行化产生$y$ 损失函数分成两部分： $l_r = compare(ad(ae(y,x), x), y)$; $l = compare(ae(y, x), lp(x))$ L = l_r + l3.1 $ae(y,x)$函数 结构如图。其中bottleneck即为上面介绍的各种离散隐变量的方法。 3.2 $ad(y, x)$函数 结构如图。 4. 实验结果 图中作为baseline的NAT是Gu et al. 2017另一种Non-auto regression的方法。 5. 参考资料 Fast Decoding in Sequence Models Using Discrete Latent Variables Kaiser et al., 2018 Categorical reparameterization with gumbel-softmax Jang et al. 2016 The concrete distribution: A continuous relaxation of discrete random variables Maddison et al., 2016 Can active memory replace attention? Kaiser, Łukasz and Bengio, Samy. 2016 Discrete autoencoders for sequence models Kaiser, Łukasz and Bengio, Samy. 2018 Neural GPUs learn algorithms Kaiser, Łukasz and Sutskever, Ilya. 2016 Non-autoregressive neural machine translation Gu et al., 2017 Neural discrete representation learning van den Oord et al., 2017 Semantic hashing Salakhutdinov, Ruslan and Hinton, Geoffrey E. 2009","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"}]},{"title":"Transformer家族之Average Attention Network","slug":"transformer家族-average","date":"2019-09-24T01:54:06.000Z","updated":"2022-01-12T08:37:38.434Z","comments":true,"path":"2019/09/24/transformer家族-average/","link":"","permalink":"https://rogerspy.gitee.io/2019/09/24/transformer家族-average/","excerpt":"Transformer虽然在训练上比RNN和CNN快，但是在做推理（decoding）的时候由于采用的是Auto-regression不能做到并行计算，所以速度很慢（甚至可能比纯RNN还要慢），所以针对这种情况很多研究者提出了decoding时也能采用并行计算的改进方案，下面要介绍的这个transformer大家族的以为成员就是其中之一：Average Attention Network。","text":"Transformer虽然在训练上比RNN和CNN快，但是在做推理（decoding）的时候由于采用的是Auto-regression不能做到并行计算，所以速度很慢（甚至可能比纯RNN还要慢），所以针对这种情况很多研究者提出了decoding时也能采用并行计算的改进方案，下面要介绍的这个transformer大家族的以为成员就是其中之一：Average Attention Network。 1. Average Attention Network这篇论文作者认为造成transformer在decoding的过程慢的原因有两个： Auto-regression self-attention 是的，作者认为在decoder中，对目标句子编码时计算目标句子内部依赖关系的时候使用自注意力机制会造成解码速慢，因此作者提出使用AAN进行代替。 1.1 模型结构 从模型结构图中可以看到，基本结构和Transformer基本相同，唯一不同的点在于decoder layer中Masked Multi-head attention变成了Average Attention。那么下面我们就来看看这个Average Attention是何方神圣？ 1.2 Average Attention 结构如图所示，给定输入$\\mathbf{y = \\{y_1, y_2, …, y_m\\}}$ AAN首先计算累加平均： \\overline{\\mathbf{y}_j} = \\frac{1}{j} \\sum_{k=1}^j \\mathbf{y}_k假设模型auto-regression产生了$j=3$个词，“我，喜欢， 打”，对其中每个词进行累加平均得（average(我), average(我+喜欢), average(我+喜欢+打)）。 然后经过FFN层进行线性变换，其中FFN层即Point wise feeed forward： \\mathbf{g}_j = \\mathrm{FFN}(\\overline{\\mathbf{y}_j})这两部虽然很简单，但是却是AAN中最核心的部分: 每个位置上的向量都是通过之前的词计算得来，所以词与词之间并非独立的，而是存在依赖关系的； 无论输入向量有多长，之前的词都被融合进同一个向量中，也就是说词与词之间的距离是不变的，这就保证了AAN可以获得长距离依赖关系。 注意：在作者提供的源码中，FFN层是可以跳过的，即计算出平均值以后不经过FFN层，直接进行接下来的计算。 拼接原始的输入和累加平衡后的输出 c = \\mathrm{Concat}(\\mathbf{y}_j, \\mathbf{g}_j) 由于后面加入了LSTM的遗忘门机制， 因此这里先计算各个信息流所占的比例： \\mathbf{i}_j, \\mathbf{f}_j = \\sigma(Wc)其中，$\\mathbf{i}_j$表示原始输入在接下来的信息流中所占的比例，$\\mathbf{f}_j$表示在接下来的信息流中Average所占的比重。 遗忘门 \\widetilde{\\mathbf{h}}_j = \\mathbf{i}_j \\odot \\mathbf{y}_j + \\mathbf{f}_j \\odot \\mathbf{g}_j 残差连接 \\mathbf{h}_j = \\mathrm{LayerNorm}(\\mathbf{y}_j + \\widetilde{\\mathbf{h}}_j)至此，整个AAN就计算完成了，这也是original AAN。 1.2 Masked ANN之前我们介绍origin AAN时说到求累加平均的时候举了个例子，假设我们想要预测“我非常喜欢打篮球”， 在auto-regression时： 输入：$(我, 非常, 喜欢, 打)$ 计算累加平均的时候要分别计算：average(我)，average(非常)，average（喜欢），average(打)。也就是说我们要多次计算平均值，这样就不能实现并行化计算，所以我们希望能通过矩阵一次性求出这三个平均向量： \\left\\{ \\begin{array} {cccc} 1 & 0 & 0 & 0\\\\\\\\ 1/2 & 1/2 & 0 & 0 \\\\\\\\ 1/3 & 1/3 & 1/3 & 0 \\\\\\\\ 1/4 & 1/4 & 1/4 & 1/4 \\end{array} \\right\\} \\times \\left( \\begin{array} {c} y_1 \\\\\\\\ y_2 \\\\\\\\ y_3 \\\\\\\\ y_4 \\end{array} \\right) = \\left( \\begin{array} {c} y_1 \\\\\\\\ \\frac{y_1+y_2}{2} \\\\\\\\ \\frac{y_1+y_2+y_3}{3} \\\\\\\\ \\frac{y_1+y_2+y_3+y_4}{4} \\end{array} \\right)1.3 Decoding Acceleration不同于transformer中的自注意力机制，AAN可以以非常快的速度进行推理： \\widetilde{\\mathbf{g}}_j = \\widetilde{\\mathbf{g}}_{j-1} + \\mathbf{y}_j \\\\\\\\ \\mathbf{g}_j = \\mathrm{FFN}(\\frac{\\widetilde{\\mathbf{g}}_j}{j})即，在进行auto-regression的时候每次都只需要用之前的结果与本次的输入相加，然后求平均即可。注意$\\widetilde{\\mathbf{g}}_0=0$。我们只需要根据前一次的状态就可以确定当前的状态，而不需要像自注意力机制那样依赖之前所有的状态。 至此关于AAN的部分我们就介绍完了，模型其他部分的结构和transformer保持一致，在作者的实验中，虽然BLEU值较transformer略微降低，但是推理效率上提升很大， 尤其是对长句。 2. 实验结果 3. 核心代码3.1 pytorch123456class AAN(nn.Modules): def __init__(...): super(AAN, self).__init__() def forward(...): pass 3.2 tensorflow123456class AAN(tf.keras.layers.Layer): def __init__(...): super(AAN, self).__init__() def call(...): pass 4. 参考资料Accelerating Neural Transformer via an Average Attention Network","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"}]},{"title":"Transformer家族之Weighted Transformer","slug":"transformer家族-weighted","date":"2019-09-19T02:36:06.000Z","updated":"2022-01-12T08:37:38.461Z","comments":true,"path":"2019/09/19/transformer家族-weighted/","link":"","permalink":"https://rogerspy.gitee.io/2019/09/19/transformer家族-weighted/","excerpt":"之前我们介绍了擎天柱的工作原理以及内部构造。对擎天柱已经有了深入的了解，那么本文就来介绍一下汽车人家族中的其他成员——Transformer的各种变种。","text":"之前我们介绍了擎天柱的工作原理以及内部构造。对擎天柱已经有了深入的了解，那么本文就来介绍一下汽车人家族中的其他成员——Transformer的各种变种。 1. Weighted Transformer 1. Weighted Transformer为了更快的训练和更好的发挥Transformer的信息表示能力，Ahmed et al. 2017提出了这种新的结构。 1.1 模型结构 模型在整体结构上和Transformer差不多，不同点有两个： 使用Multi-branch代替Multi-Head； 在FFN上不是直接线性转换，而是Multi-branch线性转换后加权求和。 公式如下： head_i = Attention(QW_i^Q, KW_I^K, VW_I^V) \\overline{head_i} = head_i W^{O_i} \\times \\kappa_i BranchedAttention(Q, K, V) = \\sum_{i=1}^M \\alpha_i \\mathrm{FFN}_i(\\overline{head_i})1.2 Multi-branch Attention在Weighted Transformer中对Attention的计算和标准的Transformer计算过程是一致的，所以这里不做介绍。接下来对计算完的scaled dot-product attention的处理上，模型就在原始Transformer上做了修改。作为对比，我们把原始的Transformer在这一步的处理也列出来： \\overline{head_i} = head_iW^{Q_i}Transformer是直接将heads进行线性变换，而Weighted transformer在对每个head进行线性变换后还乘上一个$\\kappa$参数，这个参数是可训练的，而且必须满足条件：$\\sum_i \\kappa_i =1$。这个参数作者称之为concatenation weight。 我们知道Multi-head中的每一个head的作用是学习句子的不同信息，Transformer认为每个head学到的信息对任务来说是平权的，因此直接将多个head直接等权拼接，然后线性变换。而Weighted transformer认为每个head对任务的作用是不同的，因此为每个head分配一个权重，用于表明这个head对任务的重要性，而权重的大小令模型自动从任务中学习。这种假设显然应该比Transformer的平权假设要更加合理。 1.3 Weighted point wise feed forward network这一部分我认为作者要么是对Transformer的理解有误，要么是论文的表述不准确，在对比Transformer和Weighted Transformer的时候有点小冲突，比如作者说Transformer对应的FFN公式是$BranchedAttention(Q, K, V)=\\mathrm{FFN}(\\sum_i^M \\overline{head_i})$，先不纠结BranchedAttention的函数名问题，作者认为每个head是通过求和， 然后再经过FFN。但是Transformer原始论文写的很清楚head是通过Concat拼接在一起的，并非求和。造成作者在这里使用$\\sum_i^M\\overline{head_i}$，我个人猜测有两个可能的原因： 1. 作者使用$\\sum$的意图其实是Concat 2.作者可能把Transformer结构图中Add当成了对head求和 无论什么原因，下面的介绍我都会替换成Concat。另外，作者介绍Weighted transformer的FFN的时候使用的也是$\\sum$，但是从作者在其他的地方的表述来看，这里的求和应该指的也是Concat。比如作者将$\\kappa$命名为concatenation weight，另外作者认为weighted transformer的参数只比transformer多了$\\alpha$和$\\kappa $，所以总的参数量应该是相同的，但是如果在weighted transformer中这一步使用了求和的话，假设$h=8, d_k=d_v=64$， 那么FFN的输出维度应该是（batch_size, seq_len, 64），而Transformer的输出维度是（batch_size, seq_len, 512），这样参数量是不同的， 除非在weighted transformer中作者令$d_k=d_v=512$，但是如果是这样的话，每个head的参数又不同了，所以无论如何weighted trnasformer和transformer的参数都是不同的。因此，我认为这里应该是Concat。 刚开始的时候由于思考的不周全，以为是作者在论文中的表述不准确，所以自己瞎讨论半天，后来发现作者的表述没有任何问题，而是自己的问题，所以上面的内容只保留删除线，不把内容删除，用来提醒自己曾经犯过的错误。 这里解释一下为什么作者表述是正确的，而我的理解是错误的呢？首先说作者在描述transformer的时候用的公式$BranchedAttention(Q, K, V)=\\mathrm{FFN}(\\sum_i^M \\overline{head_i})$，我之前认为原始论文中这里应该是Concat而不应该是$\\sum$，但是我忽略了一点，就是在transformer原始论文中，是先进行Concat，这个时候输出tensor.shape == (batch_size, seq_len, d_model)，再进行线性变换的时候$W^{O_i}$的形状应该是（d_model, d_model），所以FFN的输出是(batch_size, seq_len, d_model)。但是本文中是先进行的线性变换，我原先想的是线性变换的tensor.shape == (batch_size, seq_len, d_v)，而$W^{Q_i}.shape == (d_v, d_v)$，这样得到的输出形状是(batch_size, seq_len, d_v)，然后平权求和，如果是这样的话就会出现我上面的错误，缺少Concat和输出维数对应不上的问题。但实际上这里的$W^{Q_i}.shape == (d_v, d_{model})$，这样会输出$M$个形状为(batch_size, seq_len, d_model)的tensor（这就是$\\overline{head_i}=head_iW^{O_i}$这一步做的事情），然后通过沿着head方向求和就可以得到一个形状为(batch_size, seq_len, d_model)的tensor（这就是$\\mathrm{FFN}(\\sum \\overline{head_i})$这一步做的事情），实际上本文作者的操作和transformer的原始论文的操作是等效的。我的思考主要问题出现在了线性变换这一步的输出上。下面我们继续跟随作者的脚步，看下他在FFN上做了什么文章。 Transformer在计算FFN的过程如下： MultiHeadAttention(Q, K, V) = \\mathrm{FFN}(\\sum_{i=1}^M \\overline{head_i})可以看到两者的区别仍然是对不同head信息的加权方式不同，transformer仍然认为是平权的，但是weighted transformer认为是各有不同的权重，和$\\kappa$一样，$\\alpha$是从任务中学习的，且满足$\\sum_i\\alpha_i=1$。作者给$\\alpha$取了一个名字叫做addition weight。 2. 模型细节除了以上两点修改以外，其他方面没有做任何修改。但是在训练的时候$\\alpha$和$\\kappa$的学习率由下式确定： lr = (d_{model}/N)^{-0.5}\\cdot \\min(steps^{-0.5}, steps \\cdot 400^{-1.5})也就是说将warmup_steps改成400。 3. 代码实现3.1 pytorch核心代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class MultiBranchAttention(nn.Module): def __init__(self, depth, d_model, d_ff, n_branches, dropout): super(MultiBranchAttention, self).__init__() self.depth = depth self.d_model = d_model self.d_ff = d_ff self.n_branches = n_branches # in practice, d_model == d_k * n_branches assert d_model == d_k * n_branches # Q, K, V Linear self.w_q = Linear([d_model, d_model]) self.w_k = Linear([d_model, d_model]) self.w_v = Linear([d_model, d_model]) # scaled dot-product attention self.attentions = nn.ModuleList([ # custom define ScaledDotProductAttention(depth, dropout) for _ in range(n_branches) ]) # additional parameters for BranchedAttention # custom define self.w_o = nn.ModuleList([Linear(depth, d_model) for _ in range(n_branches)]) self.w_kp = torch.rand(n_branches) self.w_kp = nn.Parameter(self.w_kp/self.w_kp.sum()) self.w_a = torch.rand(n_branches) self.w_a = nn.Parameter(self.w_a/self.w_a.sum()) # Position wise feed forward network self.ffn = nn.ModuleList([ # custom define PositionwiseFeedForwardNetwork(d_model, d_ff//n_branches, dropout) for _ in range(n_branches)]) self.dropout = nn.Dropout(dropout) # layer normalization # custom define self.layer_norm = LayerNormalization(d_model) init.xavier_normal(self.w_o) def forward(self, q, k, v, attn_mask): # q: (batch_size, len_q, d_model) # k: (batch_size, len_k, d_model) # v: (batch_size, len_v, d_model) note (len_k == len_v) residual = q # Linear Q = self.w_q(q) # (batch_size, len_q, d_model) K = self.w_k(k) # (batch_size, len_q, d_model) V = self.w_v(v) # (batch_size, len_q, d_model) # split Qs = Q.split(self.depth, dim=-1) # (b_size, len_q, depth) x n_branches Ks = K.split(self.depth, dim=-1) # (b_size, len_k, depth) x n_branches Vs = V.split(self.depth, dim=-1) # (b_size, len_v, depth) x n_branches # scaled dot product attention # scaled_attn: (batch_size, len_q, d_v) x n_branch scaled_attn = [ attn(Qs[i], Ks[i], Vs[i], mask) for i, attn in enumerate(self.attentions) ] # multi-branch attention # outputs: (b_size, len_q, d_model) x n_branches outputs = [self.w_o[i](scaled_attn[i]) for i in range(self.n_branches)] outputs = [kappa * output for kappa, output in zip(self.w_kp, outputs)] # FFN outputs = [ffn(output) for ffn, output in zip(self.ffn, outputs)] outputs = [alpha * output for alpha, output in zip(self.w_a, outputs)] # output: (b_size, len_q, d_model) output = self.dropout(torch.stack(outputs).sum(dim=0)) return self.layer_norm(residual + output) 3.2 tensorflow核心代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class MultiBranchAttention(tf.keras.layers.Layer): \"\"\" Implement Multi-branch attention layer. \"\"\" def __init__(self, depth, d_model, d_ff, n_branches, dropout): super(MultiBranchAttention, self).__init__() self.depth = depth self.d_model= d_model self.d_ff = d_ff self.n_branches = n_branches self.dropout = dropout # K, Q, V, linear self.wq = tf.keras.layers.Dense(d_model) self.wk = tf.keras.layers.Dense(d_model) self.wv = tf.keras.layers.Dense(d_model) # scaled dot product attention self.attentions = [ # custom define scaled_dot_product_attention(depth, dropout) for _ in range(n_branches) ] # additional parameters for BranchedAttention self.w_o = [tf.keras.layers.Dense(d_model) for _ in range(n_branches)] self.w_kp = np.random.random((n_branches,)) self.w_kp = tf.Variable(self.w_kp/self.w_kp.sum(), trainable) self.w_a = np.random.random((n_branches,)) self.w_a = tf.Variable(self.w_a/self.w_a.sum(), trainable) # Position wise feed forward network self.ffn = [ # custom define PositionwiseFeedForwardNetwork(d_model, d_ff//n_branches, dropout) for _ in range(n_branches)] self.dropout = tf.keras.layers.Dropout(dropout) # layer normalization self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6) self.dense = tf.keras.layers.Dense(d_model) def call(self, q, k, v, mask): residual = q # First linear transition step Q = self.wq(q) # (batch_size, seq_len, d_model) K = self.wk(k) # (batch_size, seq_len, d_model) V = self.wv(v) # (batch_size, seq_len, d_model # Split K, Q, V into multi-branch Qs = tf.split(Q, n_branches, axes=-1) # (batch_size, len_q, depth) x n_branches Ks = tf.split(K, n_branches, axes=-1) # (batch_size, len_k, depth) x n_branches Vs = tf.split(V, n_branches, axes=-1) # (batch_size, len_v, depth) x n_branches # Scaled Dot-Product Attention step # head_i = Atteniton(QW_Q, KW_K, VW_V) scaled_attention = [ attn(Qs[i], Ks[i], Vs[i], mask) for i, attn in enumerate(self.attentions) ] # scaled_attention.shape == (batch_size, len_q, depth) # multi-branch attention # outputs: (b_size, len_q, d_model) x n_branches outputs = [self.w_o[i](scaled_attention[i]) for i in range(self.n_branches)] outputs = [kappa * output for kappa, output in zip(self.w_kp, outputs)] # FFN outputs = [ffn(output) for ffn, output in zip(self.ffn, outputs)] outputs = [alpha * output for alpha, output in zip(self.w_a, outputs)] # output: (b_size, len_q, d_model) output = self.dropout(tf.stack(outputs).sum(dim=0)) return self.layer_norm(residual + output) 4. 参考资料 Weighted Transformer Network for Machine Translation, Ahmed et al., arxiv 2017","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"},{"name":"weighted-head","slug":"weighted-head","permalink":"https://rogerspy.gitee.io/tags/weighted-head/"}]},{"title":"Transformer的每一个编码层都学到了什么？","slug":"transformer编码层表示","date":"2019-09-18T09:32:47.000Z","updated":"2022-01-12T08:37:38.462Z","comments":true,"path":"2019/09/18/transformer编码层表示/","link":"","permalink":"https://rogerspy.gitee.io/2019/09/18/transformer编码层表示/","excerpt":"Transformer现在已经被广泛应用于NLP领域的各项任务中，并且都取得了非常好的效果。其核心层使用了自注意力机制，关于为什么使用自注意力机制，作者提出了三点原因：","text":"Transformer现在已经被广泛应用于NLP领域的各项任务中，并且都取得了非常好的效果。其核心层使用了自注意力机制，关于为什么使用自注意力机制，作者提出了三点原因： 计算复杂度：Transformer的计算复杂度比RNN和CNN都要低 并行计算：Transformer可以进行并行计算，这也是作者提出Transformer模型的初衷 远距离长程依赖的路径距离：Transformer有更短的路径距离，因此更容易学习到远程的依赖关系。 前两个原因我们不做过多的介绍，只要仔细思考就可以理解，而且这两个是属于确定性问题，是可以通过理论分析得出的结论。但是第三点却是Transformer有效性的决定因素，而且无法进行理论分析（现在深度学习中的模型可解释性仍然是个研究热点），只有通过实验进行分析。本文就通过解读An Analysis of Encoder Representations in Transformer-Based Machine Translation这篇论文来看下Transformer作者提出的第三点原因是否成立，并且深入理解Transformer每一层注意力都学到了什么。 本文通过不同方法分析了encoder层的注意力权重： 可视化注意力权重 注意力权重的树结构生成 将encoder作为不同预测任务的输入 将其中一个encoder的知识迁移到另一个里面 在研究Transformer中的注意力之前先训练一个Transformer模型，表1列出了训练模型的数据，表2列出了每组数据的bleu值： 表1：训练样本统计 # Training sentences English → Czech 51,391,404 English → German 25,746,259 English → Estonian 1,064,658 English → Finnish 2,986,131 English → Russian 9,140,469 English → Turkish 205,579 English → Chinese 23,861,542 表2：BLEU值 newstest 2017 newstest 2018 English → Czech 18.11 17.36 English → German 23.37 34.46 English → Estonian - 13.35 English → Finnish 15.06 10.32 English → Russian 21.30 18.96 English → Turkish 6.93 6.22 English → Chinese 23.10 23.75 1. 注意力权重可视化注意力权重可视化应该是最直接的一种研究方法。Transformer的encoder里面包含了6层注意力，每层注意力有8个head，要把这些权重全部可视化出来比较困难，所以作者选择了一些具有高视觉可解释性的注意力权重。 通过可视化他们发现这些注意力权重有四种模式： 在初始注意力层中，每个词的注意力会在自身上； 注意力层数增加后，注意力会集中在前几个词 或者注意力集中在后几个词 最后注意力会集中在句子的末尾 假设输入句子是“there is also an economic motive.”，Transformer中典型的注意力权重分布。可以看到layer 0中注意力都在词本身，后面基层的注意力会在词的前后几个词上，再到最后一层所有词的注意力全部放在句子末尾。这就预示着Transformer的高层注意力试图发现词与词之间的长程依赖关系，而低层注意力试图在局部发现依赖关系，这一发现很好的印证了Transformer作者的预想。 2. 树结构生成Transformer的权重矩阵可以看成是一个加权图：每个次都是一个节点，词与词之间的注意力是边。尽管模型没有任何生成树形结构的训练，但是我们可以使用这种图结构来抽取出一棵树来看看它是否能反应词之间的依赖关系。 作者在CoNLL 2017 Share Task的English PUD treebank上做实验。 上图展示了UAS F1-Score，实验中作为对比作者使用random baseline的得分是10.1，从上图我们可以看到虽然注意力层没有训练用于生成树结构，但是每一层的得分都好于随机，这说明模型可以学习到一些语法关系。 基本上得分最高的层都集中在前三层，说明前三层主要用于学习句子的语法结构的。 但是作者也通过在注意力权重可视化中发现的规律作为基准，计算UAS F1-Score得到最好的分数为35.08，而我们可以从上表中看到，表中最好的结果并没有比基准高多少，并且之前我们的结论是高层注意力用于学习远距离的依赖关系，但是这里我们看到主要是低层注意力学习到了有效的语法结构，这说明Transformer很难有效地处理更加复杂和长程的依赖。 总的来说，对于语料更丰富的数据来说，模型更能学习到语法结构（对比English-Turkish和其他），但是当语料达到一定程度的时候，模型并不能学到更多的语法知识了。 3. 探索序列标注任务作者通过四个序列标注任务对encoder进行研究： Part-of-Speech tagging （ the Universal Dependencies English Web Treebank v2.0数据集） Chunking（CoNLL2000 Chunking shared task数据集） Named Entity Recognition（ CoNLL2003 NER shared task数据集） Semantic tagging（Parallel Meaning Bank (PMB) for Semantic tagging数据集） 表3：各数据集统计结果 #labels #training sentences #testing sentences average sent.length POS 17 12543 1000 21.2 Chunk 22 8042 2012 23.5 NER 9 14987 3684 12.7 SEM 80 62739 4351 6.4 上图展示了测试结果。 对于POS和CHUNK任务来说，最高的结果基本出现在前三层，说明前三层用于学习语法结构，这一结论与之前的结果相吻合。 NER和SEM这种注重语义知识的任务， 在模型的高层注意力中表现的更好，说明高层注意力主要用于学习语义知识。 上表数据右侧展示的是句子长度匹配的错误率，从表中我们可以看出，前三层的句子长度错误率普遍低于高层的注意力层，这说明低层注意力不仅要学习语法结构，还会对句子长度进行编码， 但到了高层注意力，句子长度信息就会丢失。唯一例外的是SEM任务，但是我们看下训练集的数据统计列标可以发现，SEM数据集的句子普遍较短，对模型来说更容易预测。而模型低层注意力本身就是在学习短程依赖方面比较有优势，高层注意力处理远距离依赖的乏力可能和句子长度信息的丢失有一定关系。 对比BLEU值我们可以发现，BLEU值越高，在序列标注任务中的表现也越好，这说明encoder对句子语法的编码越好，翻译质量会越高。 4. Transfer Learning为了进一步研究编码进注意力层的知识是否对少语料的情景有所帮助，作者做了两个实验： 使用English-German训练好的编码层，初始化English-Turkish编码层，并且允许编码层权重微调（TL1） 使用English-German训练好的编码层，初始化English-Turkish编码层，并且保持权重不变（TL2） 上图展示了实验的结果。从结果中我们可以看到，效果很明显。 5. 总结本文主要研究了Transformer每层注意力都学到了什么，通过实验发现： 低层注意力能有效地获得句子的短程依赖关系 高层注意力尝试学习句子的远距离依赖关系，但是效果并不明显 低层注意力能够对句子长度进行编码，高层注意力可能丢失句子长度编码信息，这也可能是导致远距离依赖关系处理困难的原因 低层注意力主要学习句子语法结构 高层注意力主要学习句子语义信息 语料越多，模型越能学到足够多的语法信息，但是存在一个瓶颈 语法信息越丰富，翻译的效果越好 用大量语料学习到的知识可迁移到少量预料任务中去 6. 参考资料An Analysis of Encoder Representations in Transformer-Based Machine Translation","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"}]},{"title":"Transformer代码实现-Tensoflow版","slug":"Transformer代码实现-tensorflow","date":"2019-09-16T12:28:30.000Z","updated":"2022-01-12T08:37:38.321Z","comments":true,"path":"2019/09/16/Transformer代码实现-tensorflow/","link":"","permalink":"https://rogerspy.gitee.io/2019/09/16/Transformer代码实现-tensorflow/","excerpt":"前面介绍了Transformer的pytorch版的代码实现，下面我们再介绍一下tensorflow版的代码实现。","text":"前面介绍了Transformer的pytorch版的代码实现，下面我们再介绍一下tensorflow版的代码实现。 本文主要参考的是tensorflow官方教程，使用的是tensoflow 2.0，因此首先还是要先搭建代码环境，可以参考这里：简单粗暴 TensorFlow 2.0。 1. 前期准备1234567891011from __future__ import absolute_import, division, print_function, unicode_literalstry: %tensorflow_version 2.xexcept Exception: passimport tensorflow_datasets as tfdsimport tensorflow as tfimport timeimport numpy as npimport matplotlib.pyplot as plt 2. Scaled Dot-Product Attention 12345678910111213141516171819202122232425262728293031323334353637383940def scaled_dot_product_attention(q, k, v, mask): \"\"\" Calculate the attention weights. q, k, v must have matching leading dimension. k, v must have matching penultimate dimension, i.e.:seq_len_k = seq_len_v. The mask has different shapes depending on its type (padding or look ahead) but it must be broadcastable for addition. :params q: query shape == (..., seq_len_q, depth) :params k: key shape == (..., seq_len_k, depth) :params v: value shape == (..., seq_len_v, depth) :params mask: Float tensor with shape bradcastable to (None, seq_len_q, seq_len_k), Default is None. \"\"\" # MatMul step in above Fig matmul_qk = tf.matmul(q, k, transpose_b=True) # (..., seq_len_q, seq_len_k) # Scale step in above Fig # This is done because for large values of depth, the dot product grows # large in magnitude pushing the softmax function where it has small # gradients resulting in a very hard softmax. dk = tf.cast(tf.shape(k)[-1], tf.float32) scaled_attention = matmul_qk / tf.math.sqrt(dk) # Mask step in above Fig # This is done because the mask is summed with the scaled matrix # multiplication of Q and K and is applied immediately before a softmax. # The goal is to zero out these cells, and large negative inputs to # softmax are near zero in the output. if mask is not None: scaled_attention += (mask * -1e9) # SoftMax step in above Fig # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1 attention_weights = tf.nn.softmax(scaled_attention, axis=-1) # The last MatMul step in above Fig out = tf.matmul(attention_weights, v) # (..., seq_len_q, depth_v) return out, attention_weights 3. Multi-Head Attention Multi-Head Attention有四部分组成： 线性转换层和multi-head (Q, K, V) Multi-head Scaled dot-product attention Concatenation of heads 最后的线性转换层 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class MultiHeadAttention(tf.keras.layers.Layer): \"\"\" Implement Multi=head attention layer. \"\"\" def __init__(self, d_mode, num_heads): super(MultiHeadAttention, self).__init__() self.d_model= d_model self.num_heads = num_heads # after `Concat`, concatenated heads dimension must equal to d_model assert d_model % num_heads == 0 self.depth = d_model // num_heads self.wq = tf.keras.layers.Dense(d_model) self.wk = tf.keras.layers.Dense(d_model) self.wv = tf.keras.layers.Dense(d_model) self.dense = tf.keras.layers.Dense(d_model) def split_heads(self, x, batch_size): \"\"\" Split the last dimension (word vector dimension) into (num_heads, depth). Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth) \"\"\" x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth)) return tf.transpose(x, perm=[0, 2, 1, 3]) def call(self, q, k, v, mask): batch_size = tf.shape(q)[0] # First linear transition step in above Fig q = self.wq(q) # (batch_size, seq_len, d_model) k = self.wk(k) # (batch_size, seq_len, d_model) v = self.wv(v) # (batch_size, seq_len, d_model # Split K, Q, V into multi-heads q = self.split_heads(q, batch_size) # (batch_size, num_heads, seq_len_q, depth) k = self.split_heads(k, batch_size) # (batch_size, num_heads, seq_len_k, depth) v = self.split_heads(v, batch_size) # (batch_size, num_heads, seq_len_v, depth) # Scaled Dot-Product Attention step in above Fig scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask) # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth) # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k) # Concat step in above Fig scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) # scale_attention.shape == (batch_size, seq_len_q, num_heads, depth) concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model)) # concate_attention.shaoe == (batch_size, seq_len_q, d_model) # Final linear transition step in above Fig out = self.dense(concat_attention) # (batch_size, seq_len_q, d_model) return out, attention_weights 4. Point wise feed forward networkPoint wise feed forward network由两个全连接层组成，激活函数使用Relu： 123456def point_wise_feed_forward_network(d_model, d_ff): ffn = tf.keras.Sequential([ tf.keras.layers.Dense(d_ff, activation='relu'), # (batch_size, seq_len, d_ff) tf.keras.layers.Dense(d_model) # (batch_size, seq_len, d_model) ]) return ffn 5. Positional encoding PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}}) PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})12345678910def get_angles(pos, i, d_model): \"\"\" Get the absolute position angle from each word. :params pos: position index :params i: word embedding dimension index at each position :params d_model: model dimension \"\"\" angle_rates = 1 / np.power(10000, (2*(i//2)) / np.float32(d_model)) return pos * angle_rates 123456789101112131415161718192021def positional_encoding(position, d_model): \"\"\" Compute positional encoding. :params position: length of sentence :params d_model: model dimension \"\"\" angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model) # (position, d_model) # apply sin to even indices in the array; 2i angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2]) # apply cos to odd indices in the array; 2i+1 angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2]) # positional encoding positional_encoding = angle_rads[np.newaxis, ...] return tf.cast(positional_encoding, dtype=tf.float32) 6. Masking这里有两种Mask，一种用来mask掉输入序列中的padding，一种用来mask掉解码过程中“未来词”。 Mask每个batch中所有序列的padding token，使得模型不会把padding token当成输入： 1234567891011def create_padding_mask(seq): \"\"\" Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise. \"\"\" seq = tf.cast(tf.math.equal(seq, 0), tf.float32) # add extra dimensions to add the padding to the attention logits. return seq[:, tf.newaxis, tf.newaxis, :] # (batch_size, 1, 1, seq_len) Mask掉解码过程中的“未来词”： 1234567def create_look_ahead_mask(size): \"\"\" The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used. \"\"\" mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0) return mask # (seq_len, seq_len) 7. Encoder and Decoder Transformer和标准的seq2seq with attention模型一样，采用encoder-decoder结构，encoder / decoder都包含了6个结构相同的encoder layer和decoder layer。 7.1 EncoderEncoder layer由两个sub-layer组成： Multi-head attention Point wise feed forward network 每个sub-layer后面都接一个layer normalization，使用残差连接防止梯度消失。 12345678910111213141516171819202122232425262728293031class EncoderLayer(tf.keras.layers.Layer): \"\"\" Implements Encoder Layer. \"\"\" def __init__(self, d_model, num_heads, d_ff, rate=0.1): super(EncoderLayer, self).__init__() self.multihead_attention = MultiHeadAttention(d_model, num_heads) self.ffn = point_wise_feed_forward_network(d_model, d_ff) self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6) self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6) self.dropout1 = tf.keras.layers.Dropout(rate) self.fropout2 = tf.keras.layers.Dropout(rate) def call(self, x, training, padding_mask): # Multi-head attention sub-layer attention_out, _ = self.multihead_attention(x, x, x, padding_mask) # attention_out.shape == (batch_size, input_seq_len, d_model) attention_out = self.dropout1(attention_out, training=training) attn_norm_out = self.layernorm1(x + attention_out) # attn_norm_out.shape == (batch_size, input_seq_len, d_model) # point wise feed forward network sub-layer ffn_out = self.ffn(attn_norm_out) # (batch_size, input_seq_len, d_model) ffn_out = self.dropout2(ffn_out, training) ffn_norm_out = self.layernorm2(attn_norm_out + ffn_out) # ffn_norm_out.shape == (batch_size, input_seq_len, d_model) return ffn_norm_out Encoder由三部分组成： 输入Embedding Positional Encoding N个encoder layer 123456789101112131415161718192021222324252627282930313233343536class Encoder(tf.keras.layers.Layer): def __init__(self, num_layers, d_model, num_heads, d_ff, input_vocab_size, rate=0.1): super(Encoder, self).__init__() self.d_model = d_model self.num_layers = num_layers # Embedding layer self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model) # Positional encoding layer self.pos_encoding = positional_encoding(input_vocab_size, d_model) # encoder layers self.encoder_layers = [EncoderLayer(d_model, num_heads, d_ff, rate) for _ in range(num_layers)] self.dropout = tf.keras.layers.Dropout(rate) def call(self, x, training, padding_mask): \"\"\" The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder. \"\"\" seq_len = tf.shape(x)[1] # adding embedding and positional encoding x = self.embedding(x) # (batch_size, input_seq_len, d_model) x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) # ???? x += self.pos_encoding[:, :seq_len, :] x = self.dropout(x, training=training) # encoder layer for encoder in self.encoder_layers: x =encoder(x, training, padding_mask) return x # (batch_size, input_seq_len, d_model) 7.2 DecoderDecoder layer由三个sub-layer组成： Masked multi-head attention (with look ahead mask and padding mask) Multi-head attention (with padding mask)。其中Q（query）来自于前一层（或者输入层）的输出， K（key）和V（value）来源于Encoder的输出。 Point wise feed forward networks 与encoder layer类似，每个sub-layer后面会接一个layer normalization，同样使用残差连接。 12345678910111213141516171819202122232425262728293031323334353637383940414243class DecoderLayer(tf.keras.layers.Layer): def __init__(self, d_model, num_heads, d_ff, rate=0.1): super(DecoderLayer, self).__init__() self.multihead_attention1 = MultiHeadAttention(d_model, num_heads) self.multihead_attention2 = MultiHeadAttention(d_model, num_heads) self.ffn = point_wise_feed_forward_network(d_model, d_ff) self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6) self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6) self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6) self.dropout1 = tf.keras.layers.Dropout(rate) self.dropout2 = tf.keras.layers.Dropout(rate) self.dropout3 = tf.keras.layers.Dropout(rate) def call(self, x, encoder_out, training, look_ahead_mask, padding_mask): # enc_output.shape == (batch_size, input_seq_len, d_model) # Masked multi-head attention (with look ahead mask and padding mask) attention_out1, attn_weights1 = self.multihead_attention1(x, x, x, padding_mask) # attention_out.shape == (batch_size, target_seq_len, d_model) attention_out1 = self.dropout1(attention_out1, training=training) attn_norm_out1 = self.layernorm1(attention_out1 + x) # attn_nor_out.shape == (batch_size, target_seq_len, d_model) # Multi-head attention (with padding mask) attention_out2, attn_weights2 = self.multihead_attention2(attention_out1, encoder_out, encoder_out, padding_mask) # attention_out2.shape == (batch_size, target_seq_len, d_model) attention_out2 = self.dropout2(attention_out2, training=training) attn_norm_out2 = self.layernorm2(attention_out2 + attn_norm_out1) # attn_nor_out2.shape == # (batch_size, target_seq_len, d_model) # Point wise feed forward networks ffn_out = self.ffn(attn_norm_out2) # (Point wise feed forward networks) ffn_out = self.dropout3(ffn_out, training=training) ffn_norm_out = self.layernorm3(ffn_out + attn_norm_out2) return ffn_norm_out, attn_weights1, attn_weights2 Decoder由三部分组成： Output Embedding Positional Encoding N个decoder layer 1234567891011121314151617181920212223242526272829303132class Decoder(tf.keras.layers.Layer): def __init__(self, num_layers, d_model, num_heads, d_ff, target_vocab_size, rate=0.1): super(Decoder, self).__init__() self.d_model = d_model self.num_layers = num_layers self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model) self.pos_encoding = positional_encoding(target_vocab_size, d_model) self.decoder_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)] self.dropout = tf.keras.layers.Dropout(rate) def call(self, x, encoder_out, training, look_ahead_mask, padding_mask): seq_len = tf.shape(x)[1] attention_weights = &#123;&#125; x = self.embedding(x) # (batch_size, target_seq_len, d_model) x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) x += self.pos_encoding[:, :seq_len, :] x = self.dropout(x, training=training) for i in range(self.num_layers): x, block1, block2 = self.decoder_layers[i](x, encoder_out, training, look_ahead_mask, padding_mask) attention_weights['decoder_layer&#123;&#125;_block1'.format(i+1)] = block1 attention_weights['decoder_layer&#123;&#125;_block2'.format(i+1)] = block2 # x.shape == (batch_size, target_seq_len, d_model) return x, attention_weights 8. Create the Transformer1234567891011121314151617181920212223242526class Transformer(tf.keras.Model): def __init__(self, num_layers, d_model, num_heads, d_ff, input_vocab_size, target_vocab_size, rate=0.1): super(Transformer, self).__init__() self.encoder = Encoder(num_layers, d_model, num_heads, d_ff, input_vocab_size, rate) self.decoder = Decoder(num_layers, d_model, num_heads, d_ff, target_vocab_size, rate) self.final_layer = tf.keras.layers.Dense(target_vocab_size) def call(self, inputs, targets, training, encode_padding_mask, look_ahead_mask, decode_padding_mask): encoder_output = self.encoder(inputs, training, encode_padding_mask) # encoder_output.shape = (batch_size, inp_seq_len, d_model) decoder_output, attention_weights = self.decoder( targets, encoder_output, training, look_ahead_mask, decode_padding_mask ) # decoder_output.shape = (batch_size, tar_seq_len, d_model) final_output = self.final_layer(decoder_output) # final_output.shape = (batch_size, tar_seq_len, target_vocab_size) return final_output, attention_weights 9. 实验我们的实验还是将Transformer用于机器翻译——葡萄牙语翻译成英语。模型训练以后，我们输入葡萄牙语，模型返回英语。 9.1 优化器论文中使用的优化器是Adam， 使用下式自定义学习率： l_{rate} = d_{model}^{-0.5} \\cdot \\min(step\\_num^{-0.5}, step\\_num \\cdot warmup\\_steps^{-1.5})1234567891011121314class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule): def __init__(self, d_model, warmup_steps=4000): super(CustomSchedule, self).__init__() self.d_model = d_model self.d_model = tf.cast(self.d_model, tf.float32) self.warmup_steps = warmup_steps def __call__(self, step): arg1 = tf.math.rsqrt(step) arg2 = step * (self.warup_steps ** -1.5) return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2) 12learning_rate = CustomSchedule(d_model)optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)c 示例： 12345temp_learning_rate_schedule = CustomSchedule(d_model)plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))plt.ylabel(\"Learning Rate\")plt.xlabel(\"Train Step\") 9.2 Loss and Metrics由于target sentence被padding了，因此计算损失的时候使用padding mask也是至关重要的： 123loss_object = tf.keras.losses.SparseCategoricalCrossentropy( from_logits=True, reduction=\"none\") 12345678def loss_function(real, pred): mask = tf.math.logical_not(tf.math.equal(real, 0)) loss_ = loss_object(real, pred) mask = tf.cast(mask, dtype=loss_.dtype) loss_ *= mask return tf.reduce_mean(loss_) 12train_loss = tf.keras.metrics.Mean(name='train_loss')train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy') 9.3 模型超参数设置为了保证模型较小，训练速度相对够快，实验过程中的超参数不会和论文保持一致， num_layers，d_model，d_ff都会有所减小： 12345678num_layers = 4d_model = 128dff = 512num_heads = 8input_vocab_size = tokenizer_pt.vocab_size + 2target_vocab_size = tokenizer_en.vocab_size + 2dropout_rate = 0.1 9.4 数据pipeline 数据集 数据集使用TFDS从TED Talks Open Translation Project中加载 Portugese-English translation dataset。这个数据集包含大概5万训练数据，1100验证数据和2000测试数据。 123examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)train_examples, val_examples = examples['train'], examples['validation'] Tokenizer 12345tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus( (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus( (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13) 示例： 123456789sample_string = 'Transformer is awesome.'tokenized_string = tokenizer_en.encode(sample_string)print ('Tokenized string is &#123;&#125;'.format(tokenized_string))original_string = tokenizer_en.decode(tokenized_string)print ('The original string: &#123;&#125;'.format(original_string))assert original_string == sample_string Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]The original string: Transformer is awesome. Tokenizer会将不在词表中的词拆分成子字符串： 12for ts in tokenized_string: print('&#123;&#125;---&gt;&#123;&#125;'.format(ts, tokenizer_en.decode([ts]))) 7915 ——&gt; T1248 ——&gt; ran7946 ——&gt; s7194 ——&gt; former13 ——&gt; is2799 ——&gt; awesome7877 ——&gt; . 12BUFFER_SIZE = 20000BATCH_SIZE = 64 向输入和输出中添加开始和结束符 12345678def encode(lang1, lang2): lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode( lang1.numpy()) + [tokenizer_pt.vocab_size+1] lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode( lang2.numpy()) + [tokenizer_en.vocab_size+1] return lang1, lang2 12def tf_encode(pt, en): return tf.py_function(encode, [pt, en], [tf.float64, tf.float64]) 为了使模型不至于太大，且实验相对较快，我们过滤掉太长的句子 123MAX_LEN = 40def filter_max_len(x, y, max_len=MAX_LEN): return tf.logical_and(tf.size(x) &lt;= max_len, tf.size(y) &lt;= max_len) 123456789101112train_dataset = train_examples.map(tf_encode)train_dataset = train_dataset.filter(filter_max_length)# cache the dataset to memory to get a speedup while reading from it.train_dataset = train_dataset.cache()train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch( BATCH_SIZE, padded_shapes=([-1], [-1]))train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)val_dataset = val_examples.map(tf_encode)val_dataset = val_dataset.filter(filter_max_length).padded_batch( BATCH_SIZE, padded_shapes=([-1], [-1])) 12pt_batch, en_batch = next(iter(val_dataset))pt_batch, en_batch (, ) 9.5 Training and checkpointing12transformer = Transformer(num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, dropout_rate) 12345678910111213141516def create_masks(inp, tar): # Encoder padding mask encode_padding_mask = create_padding_mask(inp) # Used in the 2nd attention block in the decoder. # This padding mask is used to mask the encoder outputs. decode_padding_mask = create_padding_mask(inp) # Used in the 1st attention block in the decoder. # It is used to pad and mask future tokens in the input received by # the decoder. look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1]) decode_target_padding_mask = create_padding_mask(tar) combined_mask = tf.maximum(decode_target_padding_mask, look_ahead_mask) return encode_padding_mask, combined_mask, decode_padding_mask 管理checkpoint，每N轮保存一次 1234567891011checkpoint_path = \"./checkpoints/train\"ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)# if a checkpoint exists, restore the latest checkpoint.if ckpt_manager.latest_checkpoint: ckpt.restore(ckpt_manager.latest_checkpoint) print ('Latest checkpoint restored!!') target被分成两份：tar_inp和tar_real。其中tar_inp用于传入给decoder，tar_real是和输入一样的，只是向右移动一个位置，例如： sentence = &quot;SOS A lion in the jungle is sleeping EOS&quot; tar_inp = &quot;SOS A lion in the jungle is sleeping&quot; tar_real = &quot;A lion in the jungle is sleeping EOS&quot; 12345678910111213141516171819202122232425262728293031# The @tf.function trace-compiles train_step into a TF graph for faster# execution. The function specializes to the precise shape of the argument# tensors. To avoid re-tracing due to the variable sequence lengths or variable# batch sizes (the last batch is smaller), use input_signature to specify# more generic shapes.train_step_signature = [ tf.TensorSpec(shape=(None, None), dtype=tf.int64), tf.TensorSpec(shape=(None, None), dtype=tf.int64),]@tf.function(input_signature=train_step_signature)def train_step(inp, tar): tar_inp = tar[:, :-1] tar_real = tar[:, 1:] enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp) with tf.GradientTape() as tape: predictions, _ = transformer(inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask) loss = loss_function(tar_real, predictions) gradients = tape.gradient(loss, transformer.trainable_variables) optimizer.apply_gradients(zip(gradients, transformer.trainable_variables)) train_loss(loss) train_accuracy(tar_real, predictions) 1234567891011121314151617181920212223242526EPOCHS = 20for epoch in range(EPOCHS): start = time.time() train_loss.reset_states() train_accuracy.reset_states() # inp -&gt; portuguese, tar -&gt; english for (batch, (inp, tar)) in enumerate(train_dataset): train_step(inp, tar) if batch % 50 == 0: print ('Epoch &#123;&#125; Batch &#123;&#125; Loss &#123;:.4f&#125; Accuracy &#123;:.4f&#125;'.format( epoch + 1, batch, train_loss.result(), train_accuracy.result())) if (epoch + 1) % 5 == 0: ckpt_save_path = ckpt_manager.save() print ('Saving checkpoint for epoch &#123;&#125; at &#123;&#125;'.format(epoch+1, ckpt_save_path)) print ('Epoch &#123;&#125; Loss &#123;:.4f&#125; Accuracy &#123;:.4f&#125;'.format(epoch + 1, train_loss.result(), train_accuracy.result())) print ('Time taken for 1 epoch: &#123;&#125; secs\\n'.format(time.time() - start)) W0814 01:06:36.753235 140098807473920 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:455: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.Instructions for updating:Apply a constraint manually following the optimizer update step. Epoch 1 Batch 0 Loss 4.7365 Accuracy 0.0000Epoch 1 Batch 50 Loss 4.3028 Accuracy 0.0033Epoch 1 Batch 100 Loss 4.1992 Accuracy 0.0140Epoch 1 Batch 150 Loss 4.1569 Accuracy 0.0182Epoch 1 Batch 200 Loss 4.0963 Accuracy 0.0204Epoch 1 Batch 250 Loss 4.0199 Accuracy 0.0217Epoch 1 Batch 300 Loss 3.9262 Accuracy 0.0242Epoch 1 Batch 350 Loss 3.8337 Accuracy 0.0278Epoch 1 Batch 400 Loss 3.7477 Accuracy 0.0305Epoch 1 Batch 450 Loss 3.6682 Accuracy 0.0332Epoch 1 Batch 500 Loss 3.6032 Accuracy 0.0367Epoch 1 Batch 550 Loss 3.5408 Accuracy 0.0405Epoch 1 Batch 600 Loss 3.4777 Accuracy 0.0443Epoch 1 Batch 650 Loss 3.4197 Accuracy 0.0479Epoch 1 Batch 700 Loss 3.3672 Accuracy 0.0514Epoch 1 Loss 3.3650 Accuracy 0.0515Time taken for 1 epoch: 576.2345867156982 secs Epoch 2 Batch 0 Loss 2.4194 Accuracy 0.1030Epoch 2 Batch 50 Loss 2.5576 Accuracy 0.1030Epoch 2 Batch 100 Loss 2.5341 Accuracy 0.1051Epoch 2 Batch 150 Loss 2.5218 Accuracy 0.1076Epoch 2 Batch 200 Loss 2.4960 Accuracy 0.1095Epoch 2 Batch 250 Loss 2.4707 Accuracy 0.1115Epoch 2 Batch 300 Loss 2.4528 Accuracy 0.1133Epoch 2 Batch 350 Loss 2.4393 Accuracy 0.1150Epoch 2 Batch 400 Loss 2.4268 Accuracy 0.1165Epoch 2 Batch 450 Loss 2.4125 Accuracy 0.1182Epoch 2 Batch 500 Loss 2.4002 Accuracy 0.1196Epoch 2 Batch 550 Loss 2.3885 Accuracy 0.1209Epoch 2 Batch 600 Loss 2.3758 Accuracy 0.1222Epoch 2 Batch 650 Loss 2.3651 Accuracy 0.1235Epoch 2 Batch 700 Loss 2.3557 Accuracy 0.1247Epoch 2 Loss 2.3552 Accuracy 0.1247Time taken for 1 epoch: 341.75365233421326 secs Epoch 3 Batch 0 Loss 1.8798 Accuracy 0.1347Epoch 3 Batch 50 Loss 2.1781 Accuracy 0.1438Epoch 3 Batch 100 Loss 2.1810 Accuracy 0.1444Epoch 3 Batch 150 Loss 2.1796 Accuracy 0.1452Epoch 3 Batch 200 Loss 2.1759 Accuracy 0.1462Epoch 3 Batch 250 Loss 2.1710 Accuracy 0.1471Epoch 3 Batch 300 Loss 2.1625 Accuracy 0.1473Epoch 3 Batch 350 Loss 2.1520 Accuracy 0.1476Epoch 3 Batch 400 Loss 2.1411 Accuracy 0.1481Epoch 3 Batch 450 Loss 2.1306 Accuracy 0.1484Epoch 3 Batch 500 Loss 2.1276 Accuracy 0.1490Epoch 3 Batch 550 Loss 2.1231 Accuracy 0.1497Epoch 3 Batch 600 Loss 2.1143 Accuracy 0.1500Epoch 3 Batch 650 Loss 2.1063 Accuracy 0.1508Epoch 3 Batch 700 Loss 2.1034 Accuracy 0.1519Epoch 3 Loss 2.1036 Accuracy 0.1519Time taken for 1 epoch: 328.1187334060669 secs Epoch 4 Batch 0 Loss 2.0632 Accuracy 0.1622Epoch 4 Batch 50 Loss 1.9662 Accuracy 0.1642Epoch 4 Batch 100 Loss 1.9674 Accuracy 0.1656Epoch 4 Batch 150 Loss 1.9682 Accuracy 0.1667Epoch 4 Batch 200 Loss 1.9538 Accuracy 0.1679Epoch 4 Batch 250 Loss 1.9385 Accuracy 0.1683Epoch 4 Batch 300 Loss 1.9296 Accuracy 0.1694Epoch 4 Batch 350 Loss 1.9248 Accuracy 0.1705Epoch 4 Batch 400 Loss 1.9178 Accuracy 0.1716Epoch 4 Batch 450 Loss 1.9068 Accuracy 0.1724Epoch 4 Batch 500 Loss 1.8983 Accuracy 0.1735Epoch 4 Batch 550 Loss 1.8905 Accuracy 0.1745Epoch 4 Batch 600 Loss 1.8851 Accuracy 0.1757Epoch 4 Batch 650 Loss 1.8793 Accuracy 0.1768Epoch 4 Batch 700 Loss 1.8742 Accuracy 0.1779Epoch 4 Loss 1.8746 Accuracy 0.1780Time taken for 1 epoch: 326.3032810688019 secs Epoch 5 Batch 0 Loss 1.9596 Accuracy 0.1979Epoch 5 Batch 50 Loss 1.7048 Accuracy 0.1961Epoch 5 Batch 100 Loss 1.6949 Accuracy 0.1969Epoch 5 Batch 150 Loss 1.6942 Accuracy 0.1986Epoch 5 Batch 200 Loss 1.6876 Accuracy 0.1992Epoch 5 Batch 250 Loss 1.6827 Accuracy 0.1994Epoch 5 Batch 300 Loss 1.6776 Accuracy 0.2006Epoch 5 Batch 350 Loss 1.6740 Accuracy 0.2013Epoch 5 Batch 400 Loss 1.6706 Accuracy 0.2019Epoch 5 Batch 450 Loss 1.6656 Accuracy 0.2028Epoch 5 Batch 500 Loss 1.6599 Accuracy 0.2035Epoch 5 Batch 550 Loss 1.6558 Accuracy 0.2040Epoch 5 Batch 600 Loss 1.6519 Accuracy 0.2047Epoch 5 Batch 650 Loss 1.6510 Accuracy 0.2053Epoch 5 Batch 700 Loss 1.6453 Accuracy 0.2058Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1Epoch 5 Loss 1.6453 Accuracy 0.2058Time taken for 1 epoch: 307.13636589050293 secs Epoch 6 Batch 0 Loss 1.5280 Accuracy 0.2127Epoch 6 Batch 50 Loss 1.5062 Accuracy 0.2214Epoch 6 Batch 100 Loss 1.5121 Accuracy 0.2225Epoch 6 Batch 150 Loss 1.5051 Accuracy 0.2216Epoch 6 Batch 200 Loss 1.5014 Accuracy 0.2219Epoch 6 Batch 250 Loss 1.4984 Accuracy 0.2222Epoch 6 Batch 300 Loss 1.4966 Accuracy 0.2232Epoch 6 Batch 350 Loss 1.4929 Accuracy 0.2231Epoch 6 Batch 400 Loss 1.4900 Accuracy 0.2234Epoch 6 Batch 450 Loss 1.4836 Accuracy 0.2237Epoch 6 Batch 500 Loss 1.4792 Accuracy 0.2241Epoch 6 Batch 550 Loss 1.4727 Accuracy 0.2245Epoch 6 Batch 600 Loss 1.4695 Accuracy 0.2251Epoch 6 Batch 650 Loss 1.4659 Accuracy 0.2256Epoch 6 Batch 700 Loss 1.4625 Accuracy 0.2262Epoch 6 Loss 1.4619 Accuracy 0.2262Time taken for 1 epoch: 303.32839941978455 secs Epoch 7 Batch 0 Loss 1.1667 Accuracy 0.2262Epoch 7 Batch 50 Loss 1.3010 Accuracy 0.2407Epoch 7 Batch 100 Loss 1.3009 Accuracy 0.2400Epoch 7 Batch 150 Loss 1.2983 Accuracy 0.2414Epoch 7 Batch 200 Loss 1.2959 Accuracy 0.2428Epoch 7 Batch 250 Loss 1.2948 Accuracy 0.2436Epoch 7 Batch 300 Loss 1.2928 Accuracy 0.2439Epoch 7 Batch 350 Loss 1.2901 Accuracy 0.2442Epoch 7 Batch 400 Loss 1.2831 Accuracy 0.2448Epoch 7 Batch 450 Loss 1.2844 Accuracy 0.2458Epoch 7 Batch 500 Loss 1.2832 Accuracy 0.2463Epoch 7 Batch 550 Loss 1.2827 Accuracy 0.2469Epoch 7 Batch 600 Loss 1.2786 Accuracy 0.2470Epoch 7 Batch 650 Loss 1.2738 Accuracy 0.2473Epoch 7 Batch 700 Loss 1.2737 Accuracy 0.2480Epoch 7 Loss 1.2737 Accuracy 0.2480Time taken for 1 epoch: 314.8111472129822 secs Epoch 8 Batch 0 Loss 1.1562 Accuracy 0.2611Epoch 8 Batch 50 Loss 1.1305 Accuracy 0.2637Epoch 8 Batch 100 Loss 1.1262 Accuracy 0.2644Epoch 8 Batch 150 Loss 1.1193 Accuracy 0.2639Epoch 8 Batch 200 Loss 1.1210 Accuracy 0.2645Epoch 8 Batch 250 Loss 1.1177 Accuracy 0.2651Epoch 8 Batch 300 Loss 1.1182 Accuracy 0.2648Epoch 8 Batch 350 Loss 1.1200 Accuracy 0.2653Epoch 8 Batch 400 Loss 1.1212 Accuracy 0.2655Epoch 8 Batch 450 Loss 1.1207 Accuracy 0.2653Epoch 8 Batch 500 Loss 1.1222 Accuracy 0.2660Epoch 8 Batch 550 Loss 1.1219 Accuracy 0.2664Epoch 8 Batch 600 Loss 1.1229 Accuracy 0.2663Epoch 8 Batch 650 Loss 1.1211 Accuracy 0.2664Epoch 8 Batch 700 Loss 1.1206 Accuracy 0.2668Epoch 8 Loss 1.1207 Accuracy 0.2668Time taken for 1 epoch: 301.5652780532837 secs Epoch 9 Batch 0 Loss 0.8384 Accuracy 0.2751Epoch 9 Batch 50 Loss 0.9923 Accuracy 0.2793Epoch 9 Batch 100 Loss 0.9958 Accuracy 0.2796Epoch 9 Batch 150 Loss 0.9953 Accuracy 0.2787Epoch 9 Batch 200 Loss 0.9937 Accuracy 0.2790Epoch 9 Batch 250 Loss 0.9988 Accuracy 0.2800Epoch 9 Batch 300 Loss 0.9999 Accuracy 0.2801Epoch 9 Batch 350 Loss 1.0021 Accuracy 0.2800Epoch 9 Batch 400 Loss 1.0001 Accuracy 0.2800Epoch 9 Batch 450 Loss 1.0013 Accuracy 0.2800Epoch 9 Batch 500 Loss 1.0027 Accuracy 0.2805Epoch 9 Batch 550 Loss 1.0034 Accuracy 0.2804Epoch 9 Batch 600 Loss 1.0071 Accuracy 0.2810Epoch 9 Batch 650 Loss 1.0076 Accuracy 0.2810Epoch 9 Batch 700 Loss 1.0075 Accuracy 0.2806Epoch 9 Loss 1.0076 Accuracy 0.2806Time taken for 1 epoch: 304.53144931793213 secs Epoch 10 Batch 0 Loss 0.9130 Accuracy 0.3057Epoch 10 Batch 50 Loss 0.8950 Accuracy 0.2966Epoch 10 Batch 100 Loss 0.9066 Accuracy 0.2967Epoch 10 Batch 150 Loss 0.9128 Accuracy 0.2958Epoch 10 Batch 200 Loss 0.9099 Accuracy 0.2943Epoch 10 Batch 250 Loss 0.9131 Accuracy 0.2935Epoch 10 Batch 300 Loss 0.9155 Accuracy 0.2930Epoch 10 Batch 350 Loss 0.9144 Accuracy 0.2922Epoch 10 Batch 400 Loss 0.9148 Accuracy 0.2922Epoch 10 Batch 450 Loss 0.9170 Accuracy 0.2916Epoch 10 Batch 500 Loss 0.9164 Accuracy 0.2910Epoch 10 Batch 550 Loss 0.9175 Accuracy 0.2908Epoch 10 Batch 600 Loss 0.9193 Accuracy 0.2908Epoch 10 Batch 650 Loss 0.9229 Accuracy 0.2907Epoch 10 Batch 700 Loss 0.9245 Accuracy 0.2910Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2Epoch 10 Loss 0.9247 Accuracy 0.2910Time taken for 1 epoch: 308.50231170654297 secs Epoch 11 Batch 0 Loss 0.8796 Accuracy 0.3030Epoch 11 Batch 50 Loss 0.8186 Accuracy 0.3025Epoch 11 Batch 100 Loss 0.8268 Accuracy 0.3020Epoch 11 Batch 150 Loss 0.8422 Accuracy 0.3026Epoch 11 Batch 200 Loss 0.8453 Accuracy 0.3023Epoch 11 Batch 250 Loss 0.8472 Accuracy 0.3020Epoch 11 Batch 300 Loss 0.8478 Accuracy 0.3019Epoch 11 Batch 350 Loss 0.8488 Accuracy 0.3018Epoch 11 Batch 400 Loss 0.8509 Accuracy 0.3017Epoch 11 Batch 450 Loss 0.8505 Accuracy 0.3012Epoch 11 Batch 500 Loss 0.8505 Accuracy 0.3009Epoch 11 Batch 550 Loss 0.8514 Accuracy 0.3005Epoch 11 Batch 600 Loss 0.8541 Accuracy 0.3001Epoch 11 Batch 650 Loss 0.8568 Accuracy 0.2998Epoch 11 Batch 700 Loss 0.8581 Accuracy 0.2995Epoch 11 Loss 0.8586 Accuracy 0.2996Time taken for 1 epoch: 326.4959843158722 secs Epoch 12 Batch 0 Loss 0.8353 Accuracy 0.3318Epoch 12 Batch 50 Loss 0.7892 Accuracy 0.3161Epoch 12 Batch 100 Loss 0.7778 Accuracy 0.3134Epoch 12 Batch 150 Loss 0.7817 Accuracy 0.3132Epoch 12 Batch 200 Loss 0.7845 Accuracy 0.3132Epoch 12 Batch 250 Loss 0.7881 Accuracy 0.3124Epoch 12 Batch 300 Loss 0.7903 Accuracy 0.3122Epoch 12 Batch 350 Loss 0.7894 Accuracy 0.3107Epoch 12 Batch 400 Loss 0.7889 Accuracy 0.3097Epoch 12 Batch 450 Loss 0.7917 Accuracy 0.3089Epoch 12 Batch 500 Loss 0.7947 Accuracy 0.3089Epoch 12 Batch 550 Loss 0.7965 Accuracy 0.3087Epoch 12 Batch 600 Loss 0.7990 Accuracy 0.3082Epoch 12 Batch 650 Loss 0.8002 Accuracy 0.3077Epoch 12 Batch 700 Loss 0.8026 Accuracy 0.3076Epoch 12 Loss 0.8028 Accuracy 0.3076Time taken for 1 epoch: 306.4404299259186 secs Epoch 13 Batch 0 Loss 0.7718 Accuracy 0.3059Epoch 13 Batch 50 Loss 0.7275 Accuracy 0.3206Epoch 13 Batch 100 Loss 0.7308 Accuracy 0.3206Epoch 13 Batch 150 Loss 0.7317 Accuracy 0.3186Epoch 13 Batch 200 Loss 0.7342 Accuracy 0.3174Epoch 13 Batch 250 Loss 0.7349 Accuracy 0.3171Epoch 13 Batch 300 Loss 0.7374 Accuracy 0.3167Epoch 13 Batch 350 Loss 0.7397 Accuracy 0.3166Epoch 13 Batch 400 Loss 0.7410 Accuracy 0.3163Epoch 13 Batch 450 Loss 0.7415 Accuracy 0.3154Epoch 13 Batch 500 Loss 0.7434 Accuracy 0.3150Epoch 13 Batch 550 Loss 0.7466 Accuracy 0.3148Epoch 13 Batch 600 Loss 0.7490 Accuracy 0.3142Epoch 13 Batch 650 Loss 0.7522 Accuracy 0.3142Epoch 13 Batch 700 Loss 0.7552 Accuracy 0.3142Epoch 13 Loss 0.7554 Accuracy 0.3142Time taken for 1 epoch: 299.16382122039795 secs Epoch 14 Batch 0 Loss 0.6654 Accuracy 0.3193Epoch 14 Batch 50 Loss 0.6744 Accuracy 0.3277Epoch 14 Batch 100 Loss 0.6809 Accuracy 0.3237Epoch 14 Batch 150 Loss 0.6830 Accuracy 0.3238Epoch 14 Batch 200 Loss 0.6875 Accuracy 0.3235Epoch 14 Batch 250 Loss 0.6942 Accuracy 0.3238Epoch 14 Batch 300 Loss 0.6976 Accuracy 0.3231Epoch 14 Batch 350 Loss 0.7000 Accuracy 0.3230Epoch 14 Batch 400 Loss 0.7019 Accuracy 0.3222Epoch 14 Batch 450 Loss 0.7035 Accuracy 0.3212Epoch 14 Batch 500 Loss 0.7077 Accuracy 0.3207Epoch 14 Batch 550 Loss 0.7078 Accuracy 0.3201Epoch 14 Batch 600 Loss 0.7095 Accuracy 0.3196Epoch 14 Batch 650 Loss 0.7127 Accuracy 0.3197Epoch 14 Batch 700 Loss 0.7148 Accuracy 0.3193Epoch 14 Loss 0.7153 Accuracy 0.3194Time taken for 1 epoch: 294.01167726516724 secs Epoch 15 Batch 0 Loss 0.6159 Accuracy 0.3546Epoch 15 Batch 50 Loss 0.6416 Accuracy 0.3339Epoch 15 Batch 100 Loss 0.6477 Accuracy 0.3323Epoch 15 Batch 150 Loss 0.6480 Accuracy 0.3300Epoch 15 Batch 200 Loss 0.6518 Accuracy 0.3286Epoch 15 Batch 250 Loss 0.6536 Accuracy 0.3283Epoch 15 Batch 300 Loss 0.6576 Accuracy 0.3276Epoch 15 Batch 350 Loss 0.6618 Accuracy 0.3274Epoch 15 Batch 400 Loss 0.6657 Accuracy 0.3272Epoch 15 Batch 450 Loss 0.6689 Accuracy 0.3269Epoch 15 Batch 500 Loss 0.6693 Accuracy 0.3263Epoch 15 Batch 550 Loss 0.6711 Accuracy 0.3255Epoch 15 Batch 600 Loss 0.6740 Accuracy 0.3249Epoch 15 Batch 650 Loss 0.6775 Accuracy 0.3250Epoch 15 Batch 700 Loss 0.6796 Accuracy 0.3247Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3Epoch 15 Loss 0.6800 Accuracy 0.3247Time taken for 1 epoch: 296.7416775226593 secs Epoch 16 Batch 0 Loss 0.6764 Accuracy 0.3298Epoch 16 Batch 50 Loss 0.6024 Accuracy 0.3335Epoch 16 Batch 100 Loss 0.6089 Accuracy 0.3345Epoch 16 Batch 150 Loss 0.6135 Accuracy 0.3315Epoch 16 Batch 200 Loss 0.6191 Accuracy 0.3323Epoch 16 Batch 250 Loss 0.6214 Accuracy 0.3324Epoch 16 Batch 300 Loss 0.6230 Accuracy 0.3315Epoch 16 Batch 350 Loss 0.6268 Accuracy 0.3313Epoch 16 Batch 400 Loss 0.6294 Accuracy 0.3309Epoch 16 Batch 450 Loss 0.6325 Accuracy 0.3306Epoch 16 Batch 500 Loss 0.6350 Accuracy 0.3300Epoch 16 Batch 550 Loss 0.6385 Accuracy 0.3298Epoch 16 Batch 600 Loss 0.6405 Accuracy 0.3293Epoch 16 Batch 650 Loss 0.6434 Accuracy 0.3291Epoch 16 Batch 700 Loss 0.6472 Accuracy 0.3289Epoch 16 Loss 0.6476 Accuracy 0.3290Time taken for 1 epoch: 302.5653040409088 secs Epoch 17 Batch 0 Loss 0.7453 Accuracy 0.3696Epoch 17 Batch 50 Loss 0.5800 Accuracy 0.3427Epoch 17 Batch 100 Loss 0.5841 Accuracy 0.3422Epoch 17 Batch 150 Loss 0.5912 Accuracy 0.3409Epoch 17 Batch 200 Loss 0.5911 Accuracy 0.3384Epoch 17 Batch 250 Loss 0.5962 Accuracy 0.3389Epoch 17 Batch 300 Loss 0.5997 Accuracy 0.3389Epoch 17 Batch 350 Loss 0.6017 Accuracy 0.3383Epoch 17 Batch 400 Loss 0.6042 Accuracy 0.3376Epoch 17 Batch 450 Loss 0.6077 Accuracy 0.3375Epoch 17 Batch 500 Loss 0.6106 Accuracy 0.3369Epoch 17 Batch 550 Loss 0.6127 Accuracy 0.3361Epoch 17 Batch 600 Loss 0.6148 Accuracy 0.3352Epoch 17 Batch 650 Loss 0.6171 Accuracy 0.3346Epoch 17 Batch 700 Loss 0.6195 Accuracy 0.3339Epoch 17 Loss 0.6196 Accuracy 0.3339Time taken for 1 epoch: 303.3943374156952 secs Epoch 18 Batch 0 Loss 0.4733 Accuracy 0.3313Epoch 18 Batch 50 Loss 0.5544 Accuracy 0.3395Epoch 18 Batch 100 Loss 0.5637 Accuracy 0.3435Epoch 18 Batch 150 Loss 0.5625 Accuracy 0.3421Epoch 18 Batch 200 Loss 0.5686 Accuracy 0.3421Epoch 18 Batch 250 Loss 0.5714 Accuracy 0.3413Epoch 18 Batch 300 Loss 0.5727 Accuracy 0.3407Epoch 18 Batch 350 Loss 0.5770 Accuracy 0.3406Epoch 18 Batch 400 Loss 0.5759 Accuracy 0.3394Epoch 18 Batch 450 Loss 0.5779 Accuracy 0.3390Epoch 18 Batch 500 Loss 0.5810 Accuracy 0.3392Epoch 18 Batch 550 Loss 0.5836 Accuracy 0.3388Epoch 18 Batch 600 Loss 0.5870 Accuracy 0.3379Epoch 18 Batch 650 Loss 0.5905 Accuracy 0.3378Epoch 18 Batch 700 Loss 0.5945 Accuracy 0.3376Epoch 18 Loss 0.5947 Accuracy 0.3376Time taken for 1 epoch: 298.2541983127594 secs Epoch 19 Batch 0 Loss 0.5082 Accuracy 0.3261Epoch 19 Batch 50 Loss 0.5285 Accuracy 0.3451Epoch 19 Batch 100 Loss 0.5336 Accuracy 0.3472Epoch 19 Batch 150 Loss 0.5322 Accuracy 0.3440Epoch 19 Batch 200 Loss 0.5355 Accuracy 0.3439Epoch 19 Batch 250 Loss 0.5413 Accuracy 0.3441Epoch 19 Batch 300 Loss 0.5461 Accuracy 0.3443Epoch 19 Batch 350 Loss 0.5519 Accuracy 0.3441Epoch 19 Batch 400 Loss 0.5548 Accuracy 0.3436Epoch 19 Batch 450 Loss 0.5561 Accuracy 0.3427Epoch 19 Batch 500 Loss 0.5595 Accuracy 0.3423Epoch 19 Batch 550 Loss 0.5616 Accuracy 0.3416Epoch 19 Batch 600 Loss 0.5658 Accuracy 0.3412Epoch 19 Batch 650 Loss 0.5684 Accuracy 0.3407Epoch 19 Batch 700 Loss 0.5707 Accuracy 0.3405Epoch 19 Loss 0.5709 Accuracy 0.3406Time taken for 1 epoch: 297.59109830856323 secs Epoch 20 Batch 0 Loss 0.6551 Accuracy 0.3720Epoch 20 Batch 50 Loss 0.5086 Accuracy 0.3527Epoch 20 Batch 100 Loss 0.5160 Accuracy 0.3495Epoch 20 Batch 150 Loss 0.5196 Accuracy 0.3495Epoch 20 Batch 200 Loss 0.5210 Accuracy 0.3490Epoch 20 Batch 250 Loss 0.5241 Accuracy 0.3487Epoch 20 Batch 300 Loss 0.5287 Accuracy 0.3486Epoch 20 Batch 350 Loss 0.5312 Accuracy 0.3477Epoch 20 Batch 400 Loss 0.5337 Accuracy 0.3475Epoch 20 Batch 450 Loss 0.5369 Accuracy 0.3469Epoch 20 Batch 500 Loss 0.5377 Accuracy 0.3458Epoch 20 Batch 550 Loss 0.5400 Accuracy 0.3453Epoch 20 Batch 600 Loss 0.5441 Accuracy 0.3450Epoch 20 Batch 650 Loss 0.5469 Accuracy 0.3445Epoch 20 Batch 700 Loss 0.5507 Accuracy 0.3440Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4Epoch 20 Loss 0.5507 Accuracy 0.3440Time taken for 1 epoch: 303.6011939048767 secs 9.6 评估评估过程包含以下步骤： 使用Portuguese tokenizer对输入语句进行编码 解码输入start token == tokenizer_en.vocab_size 计算padding_mask和look_ahead_mask decoder输出预测结果 选择最后一个词，并且计算它的argmax 将之前输出的词拼接起来，作为deocder的输入，用于预测后面的词 最后的到最终的预测结果 这个评估过程非常重要，实际上这也是模型训练好以后，我们使用模型进行翻译的过程。我们可以看到这个过程是一步一步进行的，专业术语叫做Auto-Regression。虽然transformer的训练很快，但是推理却很慢，主要原因就是它做的是Auto-regression，不能进行并行化推理，所以后续很多对transformer的改进工作都是在这上面做的改进，我会在后续的博客中详细介绍相关模型。 123456789101112131415161718192021222324252627282930313233343536373839def evaluate(inp_sentence): start_token = [tokenizer_pt.vocab_size] end_token = [tokenizer_pt.vocab_size + 1] # inp sentence is portuguese, hence adding the start and end token inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token encoder_input = tf.expand_dims(inp_sentence, 0) # as the target is english, the first word to the transformer should be the # english start token. decoder_input = [tokenizer_en.vocab_size] output = tf.expand_dims(decoder_input, 0) for i in range(MAX_LENGTH): enc_padding_mask, combined_mask, dec_padding_mask = create_masks( encoder_input, output) # predictions.shape == (batch_size, seq_len, vocab_size) predictions, attention_weights = transformer(encoder_input, output, False, enc_padding_mask, combined_mask, dec_padding_mask) # select the last word from the seq_len dimension predictions = predictions[: ,-1:, :] # (batch_size, 1, vocab_size) predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32) # return the result if the predicted_id is equal to the end token if predicted_id == tokenizer_en.vocab_size+1: return tf.squeeze(output, axis=0), attention_weights # concatentate the predicted_id to the output which is given to the decoder # as its input. output = tf.concat([output, predicted_id], axis=-1) return tf.squeeze(output, axis=0), attention_weights 1234567891011121314151617181920212223242526272829303132def plot_attention_weights(attention, sentence, result, layer): fig = plt.figure(figsize=(16, 8)) sentence = tokenizer_pt.encode(sentence) attention = tf.squeeze(attention[layer], axis=0) for head in range(attention.shape[0]): ax = fig.add_subplot(2, 4, head+1) # plot the attention weights ax.matshow(attention[head][:-1, :], cmap='viridis') fontdict = &#123;'fontsize': 10&#125; ax.set_xticks(range(len(sentence)+2)) ax.set_yticks(range(len(result))) ax.set_ylim(len(result)-1.5, -0.5) ax.set_xticklabels( ['&lt;start&gt;']+[tokenizer_pt.decode([i]) for i in sentence]+['&lt;end&gt;'], fontdict=fontdict, rotation=90) ax.set_yticklabels([tokenizer_en.decode([i]) for i in result if i &lt; tokenizer_en.vocab_size], fontdict=fontdict) ax.set_xlabel('Head &#123;&#125;'.format(head+1)) plt.tight_layout() plt.show() 1234567891011def translate(sentence, plot=''): result, attention_weights = evaluate(sentence) predicted_sentence = tokenizer_en.decode([i for i in result if i &lt; tokenizer_en.vocab_size]) print('Input: &#123;&#125;'.format(sentence)) print('Predicted translation: &#123;&#125;'.format(predicted_sentence)) if plot: plot_attention_weights(attention_weights, sentence, result, plot) translate(“este é um problema que temos que resolver.”)print (“Real translation: this is a problem we have to solve .”) 10. 参考资料Transformer model for language understanding","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"tensorflow","slug":"tensorflow","permalink":"https://rogerspy.gitee.io/tags/tensorflow/"}]},{"title":"Transformer代码实现-Pytorch版","slug":"Transformer代码实现-pytorch","date":"2019-09-11T08:35:30.000Z","updated":"2022-01-12T08:37:38.314Z","comments":true,"path":"2019/09/11/Transformer代码实现-pytorch/","link":"","permalink":"https://rogerspy.gitee.io/2019/09/11/Transformer代码实现-pytorch/","excerpt":"前面介绍了Transformer的模型结构，最后也给出了pytorch版本的代码实现，但是始终觉得不够过瘾，有些话还没说清楚，因此，这篇文章专门用来讨论Transformer的代码细节。","text":"前面介绍了Transformer的模型结构，最后也给出了pytorch版本的代码实现，但是始终觉得不够过瘾，有些话还没说清楚，因此，这篇文章专门用来讨论Transformer的代码细节。 本文主要参考了：The Annotated Transformer。这篇文章是哈佛大学OpenNMT团队的工作，所以在正式进入话题之前要先把代码环境搭建好。Pytorch的安装网上有详细的教程这里不再赘述，只简单提一点，直接下载安装的话可能会速度比较慢，甚至下载失败，可以使用国内清华大学的镜像进行安装： 添加清华大学镜像： 123conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes 添加pytorch镜像： 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ 1. 前期准备导入相应的包 12345678910import numpy as npimport torchimport torch.nn as nnimport torch.nn.functional as Fimport math, copy, timefrom torch.autograd import Variableimport matplotlib.pyplot as pltimport seabornseaborn.set_context(context=\"talk\")%matplotlib inline 2. 模型结构大多数有竞争力的神经序列转换模型都有encoder-decoder结构，其中encoder部分将输入序列$(x_1, x_2, …, x_n)$映射到一个连续表示的序列$\\mathbf{z}=(z_1, z_2, …, z_n)$中。给定$\\mathbf{z}$，decoder再生成一个输出序列$(y_1, y_2, …, y_m)$。 12345678910111213141516171819202122232425class EncoderDecoder(nn.Module): \"\"\" A standard Encoder-Decoder architecture. Base for this and many other models. \"\"\" def __init__(self, encoder, decoder, src_embed, tgt_embed, generator): super(EncoderDecoder, self).__init__() self.encoder = encoder self.decoder = decoder self.src_embed = src_embed self.tgt_embed = tgt_embed self.generator = generator def forward(self, src, tgt, src_mask, tgt_mask): \"\"\" Take in and process masked src and target sequences. \"\"\" return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask) def encode(self, src, src_mask): return self.encoder(self.src_embed(src), src_mask) def decode(self, memory, src_mask, tgt, tgt_mask): return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask) 12345678910class Generator(nn.Module): \"\"\" Define standard linear + softmax generation step. \"\"\" def __init__(self, d_model, vocab): super(Generator, self).__init__() self.proj = nn.Linear(d_model, vocab) def forward(self, x): return F.log_softmax(self.proj(x), dim=-1) encoder和decoder都是由6个这样的结构堆叠而成的： 12345def clones(module, N): \"\"\" Produce N identical layers. \"\"\" return nn.ModuleList([copy.deepcopy(module) for _ in range(N)]) 2.1 Encoderencoder是由6个相同的模块堆叠在一起的： 12345678910111213141516class Encoder(nn.Module): \"\"\" Core encoder is a stack of N layers. \"\"\" def __init__(self, layer, N): super(Encoder, self).__init__() self.layers = clones(layer, N) self.norm = LayerNorm(layer.size) def forward(self, x, mask): \"\"\" Pass the input (and mask) through each layer in turn. \"\"\" for layer in self.layers: x = layer(x, mask) return self.norm(x) 每个encoder block由Multi-head Attention和Feed Forward两个sub-layer组成，每个sub-layer后面会接一个layer normalization： 123456789101112131415class LayerNorm(nn.Module): \"\"\" Construct a layer normalization module. See https://arxiv.org/abs/1607.06450 for detail \"\"\" def __init__(self, features, eps=1e-6): super(LayerNorm, self).__init__() self.a_2 = nn.Parameter(torch.ones(features)) self.b_2 = nn.Parameter(torch.ones(features)) self.eps = eps def forward(self, x): mean = x.mwan(-1, keepdim=True) std = x.std(-1, keepdim=True) return self.a_2 * (x - mean) / (std + self.eps) + self.b_2 sub-layer和layer normalization之间使用残差方式进行连接（进行残差连接之前都会先进行Dropout）： 12345678910111213141516class SublayerConnection(nn.Module): \"\"\" A residual connection followed by a layer norm. See http://jmlr.org/papers/v15/srivastava14a.html for dropout detail and https://arxiv.org/abs/1512.03385 for residual connection detail. \"\"\" def __init__(self, size, dropout): super(SublayerConnection, self).__init__() self.norm = LayerNorm(size) self.dropout = nn.Dropout(dropout) def forward(self, x, sublayer): \"\"\" Apply residual connection to any sublayer with the same size. \"\"\" return x + self.dropout(sublayer(self.norm(x))) 模型中，为了使x + self.dropout(sublayer(self.norm(x)))能够正常运行，必须保证x和dropout的维度保持一致，论文中使用的$d_{model}=512$（包括embedding层）。 12345678910111213141516171819class EncoderLayer(nn.module): \"\"\" Encoder block consist of two sub-layers (define below): - multi-head attention (self-attention) - feed forward. \"\"\" def __init__(self, size, self_attn, feed_forward, dropout): super(EncoderLayer, self).__init__() self.size = size self.self_attn = self_attn self.feed_forward = feed_forward self.sublayer = clones(SublayerConnection(size, dropout), 2) def forward(self, x, mask): \"\"\" Encoder block. \"\"\" x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask)) return self.sublayer[1](x, self.feed_forward) 2.2 DecoderDecoder同样是由6个相同的模块堆叠在一起的： 12345678910111213class Decoder(nn.module): \"\"\" Generic N layer decoder with masking. \"\"\" def __init__(self, layer, N): super(Decoder, self).__init__() self.layers = clones(layer, N) self.norm = LayerNorm(layer.size) def forward(self, x, memory, src_mask, tgt_mask): for layer in self.layers: x = layer(x, memory, src_mask, tgt_mask) return self.norm(x) 与encoder block不同的是，在decoder block的Multi-head attention和Feed forward之间还会插入一个Multi-head attention，这个attention中的key和value来源于encoder的输出。 1234567891011121314151617181920212223class DecoderLayer(nn.module): \"\"\" Encoder block consist of three sub-layers (define below): - multi-head attention (self-attention) - encoder multi-head attention - feed forward. \"\"\" def __init__(self, size, self_attn, src_attn, feed_forward, dropout): super(DecoderLayer, self).__init__() self.size = size self.self_attn = self_attn self.src_attn = src_attn self.feed_forward = feed_forward self.sublayer = clones(SublayerConnection(size, dropout), 3) def forward(self, x, memory, src_mask, tgt_mask): \"\"\" Decoder block. \"\"\" m = memory x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask)) x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask)) return self.sublayer[2](x, self.feed_forward) 为了保证解码过程中第$i$个位置的输出只依赖于前面已有的输出结果，在decoder中加入了Masking: 1234567def subsequent_mask(size): \"\"\" Mask out subsequent position. \"\"\" attn_shape = (1, size, size) subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8') return torch.from_numpy(subsequent_mask) == 0 下图的attention mask展示了每个目标词（行）可以看到的位置（列），黄色表示可以看到，紫色表示看不到。 3. 模型细节上面我们实现了模型的整体结构，下面我们来实现其中的细节。前面我们提到，每个encoder block有两个sub-layer：Multi-head attention和feed forward，虽然decoder block有三个sub-layer，但是两个都是Multi-head attention，说到底还是只有Multi-head attention和feed forward。 3.1 Multi-Head Attention之前我们介绍的时候讲到所谓Multi-Head Attention是有两部分组成：Multi-Head和Attention。 结构如下： \\mathrm{MultiHead}(Q, K, V) = Concat(head_1, ..., head_h)\\mathbf{W}^O其中$head_i$就是Attention，即$head_i=\\mathrm{Attention}(QW_i^Q, KW_i^K, VW_i^V)$具体结构如下图： 先来看下Scaled Dot-Product Attention得出具体实现： 123456789101112131415161718def attention(query, key, value, mask=None, dropout=None): \"\"\" Compute `Scale Dot-Product Attention`. :params query: linear projected query maxtrix, Q in above figure right :params key: linear projected key maxtrix, k in above figure right :params value: linear projected value maxtrix, v in above figure right :params mask: sub-sequence mask :params dropout: rate of dropout \"\"\" d_k = query.size(-1) scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k) if mask is not None: scores = scores.mask_fill(mask == 0, -1e9) p_attn = F.softmax(scores, dim=-1) if dropout is not None: p_attn = self.dropout(p_attn) return torch.matmul(p_attn, value), p_attn 下面我们就可以实现Multi-head Attention了： 123456789101112131415161718192021222324252627282930313233343536373839404142class MultiHeadAttention(nn.Module): \"\"\" Build Multi-Head Attention sub-layer. \"\"\" def __init__(self, h, d_model, dropout=0.1): \"\"\" :params h: int, number of heads :params d_model: model size :params dropout: rate of dropout \"\"\" super(MultiHeadAtention, self).__init__() assert d_model % h == 0 # According to the paper, d_v always equals to d_k # and d_v = d_k = d_model / h = 64 self.d_k = d_model // h self.h = h # following K, Q, V and `Concat`, so we need 4 linears self.linears = clones(nn.Linear(d_model, d_model), 4) self.attn = None self.dropout = nn.Dropout(p=dropout) def forward(self, query, key, value, mask=None): \"\"\" Implement Multi-Head Attention. :params query: query embedding matrix, Q in above figure left :params key: key embedding matrix, K in above figure left :params value value embedding matrix, V in above figure left :params mask: sub-sequence mask \"\"\" if mask is not None: # same mask applied to all heads mask = mask.unsequeeze(1) n_batch = query.size(0) # 1. Do all the linear projections in batch from d_model to h x d_k query, key, value = [l(x).view(n_batch, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))] # 2. Apply attention on all the projected vectors in batch x, self.attn = self.attention(query, key, value, mask=mask) # 3. `Concat` using a view and apply a final linear x = x.transpose(1, 2).contiguous().view(n_batch, -1, self.h * self.d_k) return self.linears[-1](x) Transformer中Multi-Head Attention有三种用法： 在decoder层中，中间的Multi-Head Attention模块中query来源于前置Masked Multi-Head Attention模块，而key和value来源于encoder层的输出， 这一部分模仿了典型的seq2seq模型中的encoder-decoder注意力机制； 在encoder层中，所有的query, key, value都来源于前一个encoder层的输出； 类似的在decoder层中，有一个Masked Multi-Head Attention模块，其中Masked是因为在进行解码的过程中，我们是从左向右一步一步的进行解码，对于模型来说右侧的信息是缺失的，因此不应该对左侧的信息产生干扰，因此在模型中我们令相应位置的值为$\\infty$。 3.2 Position-wise Feed-Forward NetworksFeed forward部分是由两个Relu线性变换组成的，在同一个block内的的不同位置使用相同的参数，但是不同block使用不同的参数。 \\mathrm{FFN(x)} = \\max(0, xW_1 + b_1)W_2 + b_2这个操作类似于卷积核大小为1的卷积操作。 123456789101112class PositionwiseFeedForward(nn.module): \"\"\" Implements FFN equation. \"\"\" def __init__(self, d_model, d_ff, dropout): super(PositionwiseFeedForward, self).__init__() self.w1 = nn.Linear(d_model, d_ff) self.w2 = nn.Linear(d_ff, f_model) self.dropout = nn.Dropout(dropout) def forward(self, x): return self.w2(self.dropout(F.relu(self.w1(x)))) 3.3 Embedding和SoftmaxTransformer中使用预训练的word embeddings，并且输入和输出的word embedding保持一致。和其他模型不同的是word embedding并不是直接进入模型，而是乘上一个缩放因子$\\sqrt{d_{model}}$： 12345678class Embeddings(nn.module): def __init__(self, d_model, vocab): super(Embeddings, self).__init__() self.d_model = d_model self.lut = nn.Embedding(vocab, d_model) def forward(self, x): return self.lut(x) * math.sqrt(self.d_model) 3.4 Position Encoding由于单纯的注意力机制没有有效的利用序列的顺序信息，因此作者在Transformer中加入了位置编码，用来抓住序列中的位置信息。 PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}}) PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})其中$pos$指得是位置索引，$i$是第$pos$个位置上对应向量的第$i$维。对序列的位置进行编码后，将输入序列和位置编码进行相加，得到一个新的输入序列。 12345678910111213141516171819202122class PositionEncoding(nn.module): \"\"\" Implements Position Encoding. \"\"\" def __init__(self, d_model, dropout, max_len=5000): super(PositionEncoding, self).__init__() self.d_model = d_model self.dropout = nn.Dropout(p=dropout) # Compute the position encodings once in log space pe = torch.zeros(max_len, d_model) position = torch.arange(0, max_len).unsqueeze(1) div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)) pe[:, 0::2] = torch.sin(position * div_term) pe[:, 1::2] = torch.cos(position * div_term) pe = pe.unsqueeze(0) self.register_buffer('pe', pe) def forward(self, x): x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False) return self.dropout(x) 至此， 整个模型各个模块我们已经搭建好了，最后进行总装。 4. Full Model123456789101112131415161718192021222324252627282930def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1): \"\"\" Construct Transformer model. :params src_vocab: source language vocabulary :params tgt_vocab: target language vocabulary :params N: number of encoder or decoder stacks :params d_model: dimension of model input and output :params d_ff: dimension of feed forward layer :params h: number of attention head :params dropout: rate of dropout \"\"\" c = copy.deepcopy attn = MultiHeadedAttention(h, d_model) ff = PositionwiseFeedForward(d_model, d_ff) position = PositionEncoding(d_model, dropout) model = EncoderDecoder( Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout),N), Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N), nn.Sequential(Embeddings(d_model, src_vocab), c(position)), nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)), Generator(d_model, tgt_vocab) ) # This was important from their code. # Initialize parameters with Glorot / fan_avg. for p in model.parameters(): if p.dim() &gt; 1: nn.init.xavier_uniform(p) return model 至此Transformer模型已经完成了，下面介绍是整个模型的训练过程以及机器翻译过程的一些技巧和常用工具的介绍，没有兴趣的话到这里就可以结束了。 5. 模型训练本节快速介绍一些在训练encoder-decoder模型过程中常用的工具，首先定义一个batch对象用来获取训练所需的源句子和目标句子，以及构建masking。 5.1 Batches and Masking1234567891011121314151617181920212223class Batch: \"\"\" Object for holding a batch of data with mask during training. \"\"\" def __init__(self, src, tgt=None, pad=0): self.src = src self.src_mask = (src != pad).unsequeeze(-2) if tgt is not None: self.tgt = tgt[;, :-1] self.tgt_y = tgt[:, 1:] self.tgtg_mask = self.make_std_mask(self.tgt, pad) self.ntokens = (self.tgt_y != pad).data.sum() @staticmethod def make_std_mask(tgt, pad): \"\"\" Create a mask to hide padding and future words. \"\"\" tgt_mask = (tgt != pad).unsequeeze(-2) tgt_mask = tgt_mask &amp; Variable( subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data) ) return tgt_mask 接下来我们创建一个通用的训练和计算得分的函数用于跟踪损失。我们传入一个通用的用于更新权重的损失函数。 5.2 Training Loop123456789101112131415161718192021222324def run_epoch(data_iter, model, loss_compute): \"\"\" Standard training and logging function. \"\"\" start_time = time.time() total_tokens = 0 total_loss = 0 tokens = 0 for i, batch in enumerate(data_iter): out = model.forward(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask) loss = loss_compute(out, batch.tgt_y, batch.ntokens) total_loss += loss total_tokens += batch.ntokens tokens += batch.ntokens if i % 50 == 1: elapsed = time.time() - start_time print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" % (i, loss / batch.ntokens, tokens / elapsed)) start_time = time.time() token = 0 return total_loss / total_tokens 5.3 Training Data and Batching论文使用的数据集： WMT 2014 English-German dataset： 4.5 million sentence pairs WMT 2014 English-French dataset： 36 M sentence pairs 由于Transformer本身训练需要的资源较多，而且上面的数据集过多，本文只是从原理上实现算法，不需要训练一个实际可用的模型，因此并没有在这两个数据集上进行训练。 1234567891011121314global max_src_in_batch, max_tgt_in_batchdef batch_size_fn(new, count, sofar): \"\"\" Keeping augumenting batch and calculate total number of tokens + padding. \"\"\" global max_src_in_batch, max_tgt_in_batch if count == 1: max_src_in_batch = 0 max_tgt_in_batch = 0 max_src_in_batch = max(max_src_in_batch, len(new.src)) max_tgt_in_batch = max(max_tgt_in_batch, len(new.tgt) + 2) src_elements = count * max_src_in_batch tgt_elements = count * max_tgt_in_batch return max(src_elements, tgt_elements) 5.4 Optimizer论文中使用Adam优化器，其中$\\beta_1=0.9, \\beta_2=0.98, \\epsilon=10^{-9}$；学习率根据公式$l_{rate} = d_{model}^{-0.5} \\cdot \\min(step_num^{-0.5}, step_num \\cdot warmup_steps^{-1.5})$来确定，该式意味着在开始的$warmup_steps$循环内学习率是线性增加的，达到一定程度后学习率开始下降， 论文中的$warmup_step=4000$，这是一个超参数。 123456789101112131415161718192021222324252627282930313233343536class NoamOpt: \"\"\" Optimizer warp that implements rate. \"\"\" def __init__(self, model_size, factor, warmup, optimizer): self.optimizer = optimizer self._step = 0 self.warmup = warmup self.factor = factor self.model_size = model_size self._rate = 0 def step(self): \"\"\" Update parameters and rate \"\"\" self._step += 1 rate = self.rate() for p in self.optimizer.param_groups: p['lr'] = rate self._rate = rate self.optmizer.step() def rate(self, step=None): \"\"\" Implement `lrate` above \"\"\" if step is None: step = self._step return self.factor * self.model_size ** (-0.5) * \\ min(step ** (-0.5), step * self.warmup ** (-1.5)) def get_std_opt(model): return NoamOpt(model.src_embed[0],d_model, 2, 4000, torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)) 下面给出了三组不同的优化器超参数的例子，直观的感受学习率的变化。 12345opts = [NoamOpt(512, 1, 4000, None), NoamOpt(512, 1, 8000, None), NoamOpt(256, 1, 4000, None)]plt.plot(np.arange(1, 20000, [[opt.rate(i) for opt in opts] for i in range(1, 20000)]))plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"]) 5.5 正则化训练过程中作者使用了label smoothing $\\epsilon_{ls}=0.1$， 虽然这样对Perplexity有所损伤， 但是提高了整体的BLEU值。这里我们用KL散度损失实现了label smoothing，并且使用分布式目标词分布用以替代one-hot分布。 1234567891011121314151617181920212223class LabelSmoothing(nn.Module): \"\"\" Implements label smoothing. \"\"\" def __init__(self, size, padding_idx, smoothing=0.0): super(LabelSmoothing, self).__init__() self.criterion = nn.KLDivLoss(size_average=False) self.padding_idx = padding_idx self.confidence = 1.0 = smoothing self.size = size self.true_dist = None def forward(self, x, target): assert x.size(1) == self.size true_dist = x.data.clone() true_dist.fill_(self.smoothing / (self.size - 2)) true_dist.scatter_(1, target.data.unsequeeze(1), self.confidence) true_dist[:, self.padding_idx] = 0 mask = torch.nonzero(target.data == self.padding_idx) if mask_dim() &gt; 0: true_dist.index_fill(0, mask.sequeeze(), 0.0) self.true_dist = true_dist return self.criterion(x, Variable(true_dist, requires_grad=False)) 下面给出一个例子说明基于置信度的词分布看起来是什么样的 123456789crit = LabelSmoothing(5, 0, 0.4)predict = torch.FloatTensor([ [0, 0.2, 0.7, 0.1, 0], [0, 0.2, 0.7, 0.1, 0], [0, 0.2, 0.7, 0.1, 0]])v = crit(Variable(predict.log()), Variable(torch.LongTensor([2, 1, 0])))plt.imshow(crit.true_dist) 如果模型对一个给定的选择给出非常大的置信度，Label smoothing就会开始对模型进行惩罚。 123456789crit = LabelSmoothing(5, 0, 0.1)def loss(x): d = x + 3 * 1 predict = torch.FloatTensor([ [0, x/d, 1/d, 1/d, 1/d] ]) return crit(Variable(predict.log()), Variable(torch.LongTensor([1]))).data[0]plt.plot(np.arange(1, 100), [loss(x) for x in range(1, 100)]) 6. 第一个例子在正式在真实的数据上做实验之前，我们可以先在一个随机生成的数据集上实验，目标是生成和源序列相同的序列，例如源序列是“I have a dream”，我们的目标是将序列输入到模型，然后输出这个序列。 6.1 合成数据12345678910def data_gen(V, batch, nbatches): \"\"\" Generate random data for src-tgt copy task. \"\"\" for i in range(nbatches): data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10))) data[:, 0] = 1 src = Variable(data, requires_grad=False) tgt = Variable(data, requires_grad=False) yield Batch(src, tgt, 0) 6.2 损失计算123456789101112131415161718class SimleLossCompute: \"\"\" A simple loss compute and train function. \"\"\" def __init__(self, generator, criterion, opt=None): self.generator = generator self.criterion = criterion self.opt = opt def __call__(self, x, y, norm): x = self.generator(x) loss = self.criterion(x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)) / norm loss.backward() if self.opt is not None: self.opt.step() self.opt.optimizer.zero_grad() return loss.data[0] * norm 6.3 Greedy Decoding12345678910111213V = 11criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)model = make_model(V, V, N=2)model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400, torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))for epoch in range(10): model.train() run_epoch(data_gen(V, 30, 20), model, SimpleLossCompute(model.generator, criterion, model_opt)) model.evel() print(run_epoch(data_gen(V, 30, 5), model, SimpleLossCompute(model.generator, criterion, None))) 实际的翻译模型一般使用beam search，这里为例简化代码，我们使用贪婪编码。 1234567891011121314151617181920def greedy_decode(model, src, src_mask, max_len, start_symbol): memory = model.encode(src, src_mask) ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data) for i in range(max_len-1): out = model.decode(memory, src_mask, Variable(ys), Variable(subsequent_mask(ys.size(1)) .type_as(src.data))) prob = model.generator(out[:, -1]) _, next_word = torch.max(prob, dim=1) next_word = next_word.data[0] ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1) return ys model.eval()src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]))src_mask = Variable(torch.ones(1, 1, 10))print(greedy_decode(model, src, src_mask, max_len=10, start_symbol=1)) 7. A Real World Example这里我们使用IWSLT German-English Translation 数据集，这个数据集比论文中使用的数据集小得多，但是能够检验整个模型。下面我们还会演示怎样在多GPU上进行训练。 123pip install torchtext spacypython -m spacy download enpython -m spacy download de 7.1 数据加载1234567891011121314151617181920212223242526272829from torchtext import data, datasetsif True: import spacy spacy_de = spacy.load('de') spacy_en = spacy.load('en') def tokenize_de(text): return [tok.text for tok in spacy.tokenizer(text)] def tokenize_en(text): return [tok.text for tok in spcy.tokenizer(text)] BOS_WORD = '&lt;S&gt;' EOS_WORD = '&lt;/S&gt;' BLANK_WORD = '&lt;blank&gt;' SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD) TGT = data.Field(tokenize=tokenize_en, init_token=BOS_WORD, eos_token=EOS_WORD, pad_token=BLANK_WORD) MAX_LEN = 100 TRAIN, VAL, TEST = datasets.IWSLT.splits( exts=('.de', '.en'), fields=(SRC, TGT), filter_pred=lambda x: len(vars(x)['src']) &lt;= MAX_LEN and len(vars(x)['trg']) &lt;= MAX_LEN ) MIN_FREQ = 2 SRC.build_vocab(train.src, min_freq = MIN_FREQ) TGT.build_vocab(train.trg, min_freq = MIN_FREQ) 7.2 Iterators12345678910111213141516171819202122232425class MyIterator(data.Iterator): def create_batches(self): if self.train: def pool(d, random_shuffler): for p in data.batch(d, self.batch_size * 100): p_batch = data.batch( sorted(p, key=self.sort_key), self.batch_size, self.batch_size_fn ) for b in random_shuffler(list(p_batch)): yield b self.batches = pool(self.data(), self.random_shuffler) else: self.batches = [] for b in data.batch(self.data(), self.batch_size, self.batch_size_fn): self.batches.append(sorted(b, key=self.sort_key)) def rebatch(pad_idx, batch): \"\"\" Fix order in torchtext to match ours. \"\"\" src, trg = batch.src.transpose(0, 1), batch.trg.transpose(0, 1) return Batch(src, trg, pad_idx) 7.3 Multi-GPU Training最后，为了加速训练，我们使用多GPU进行训练。方法就是在训练过程中将生成词的过程分成多份在多个GPU上并行处理。 我们使用pytorch的原生库来实现： replicate - 将模块分割放进不同的GPU上； scatter - 将不同的batch放进不同的GPU上； parallel_apply - 将不同的batch放到对应的GPU中的模块中； gather - 将分散的数据重新集合到同一个GU上； nn.DataParallel - 一个特殊的模块集合，用来在评估模型之前调度上面那些模块 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# Skip if not interested in multigpu.class MultiGPULossCompute: \"A multi-gpu loss compute and train function.\" def __init__(self, generator, criterion, devices, opt=None, chunk_size=5): # Send out to different gpus. self.generator = generator self.criterion = nn.parallel.replicate(criterion, devices=devices) self.opt = opt self.devices = devices self.chunk_size = chunk_size def __call__(self, out, targets, normalize): total = 0.0 generator = nn.parallel.replicate(self.generator, devices=self.devices) out_scatter = nn.parallel.scatter(out, target_gpus=self.devices) out_grad = [[] for _ in out_scatter] targets = nn.parallel.scatter(targets, target_gpus=self.devices) # Divide generating into chunks. chunk_size = self.chunk_size for i in range(0, out_scatter[0].size(1), chunk_size): # Predict distributions out_column = [[Variable(o[:, i:i+chunk_size].data, requires_grad=self.opt is not None)] for o in out_scatter] gen = nn.parallel.parallel_apply(generator, out_column) # Compute loss. y = [(g.contiguous().view(-1, g.size(-1)), t[:, i:i+chunk_size].contiguous().view(-1)) for g, t in zip(gen, targets)] loss = nn.parallel.parallel_apply(self.criterion, y) # Sum and normalize loss l = nn.parallel.gather(loss, target_device=self.devices[0]) l = l.sum()[0] / normalize total += l.data[0] # Backprop loss to output of transformer if self.opt is not None: l.backward() for j, l in enumerate(loss): out_grad[j].append(out_column[j][0].grad.data.clone()) # Backprop all loss through transformer. if self.opt is not None: out_grad = [Variable(torch.cat(og, dim=1)) for og in out_grad] o1 = out o2 = nn.parallel.gather(out_grad, target_device=self.devices[0]) o1.backward(gradient=o2) self.opt.step() self.opt.optimizer.zero_grad() return total * normalize 下面我们就可以构造模型了： 12345678910111213141516# GPUs to usedevices = [0, 1, 2, 3]if True: pad_idx = TGT.vocab.stoi[\"&lt;blank&gt;\"] model = make_model(len(SRC.vocab), len(TGT.vocab), N=6) model.cuda() criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=0.1) criterion.cuda() BATCH_SIZE = 12000 train_iter = MyIterator(train, batch_size=BATCH_SIZE, device=0, repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)), batch_size_fn=batch_size_fn, train=True) valid_iter = MyIterator(val, batch_size=BATCH_SIZE, device=0, repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)), batch_size_fn=batch_size_fn, train=False) model_par = nn.DataParallel(model, device_ids=devices) 7.4 训练模型1234567891011121314151617if False: model_opt = NoamOpt(model.src_embed[0].d_model, 1, 2000, torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)) for epoch in range(10): model_par.train() run_epoch((rebatch(pad_idx, b) for b in train_iter), model_par, MultiGPULossCompute(model.generator, criterion, devices=devices, opt=model_opt)) model_par.eval() loss = run_epoch((rebatch(pad_idx, b) for b in valid_iter), model_par, MultiGPULossCompute(model.generator, criterion, devices=devices, opt=None)) print(loss)else: model = torch.load(\"iwslt.pt\") 模型一旦训练好了我们就可以用来翻译了。这里我们以验证集的第一个句子为例，进行翻译： 123456789101112131415161718for i, batch in enumerate(valid_iter): src = batch.src.transpose(0, 1)[:1] src_mask = (src != SRC.vocab.stoi[\"&lt;blank&gt;\"]).unsqueeze(-2) out = greedy_decode(model, src, src_mask, max_len=60, start_symbol=TGT.vocab.stoi[\"&lt;s&gt;\"]) print(\"Translation:\", end=\"\\t\") for i in range(1, out.size(1)): sym = TGT.vocab.itos[out[0, i]] if sym == \"&lt;/s&gt;\": break print(sym, end =\" \") print() print(\"Target:\", end=\"\\t\") for i in range(1, batch.trg.size(0)): sym = TGT.vocab.itos[batch.trg.data[i, 0]] if sym == \"&lt;/s&gt;\": break print(sym, end =\" \") print() break 8. 注意力可视化尽管贪婪编码的翻译看起来不错，但是我们还想看看每层注意力到底发生了什么： 123456789101112131415161718192021222324252627tgt_sent = trans.split()def draw(data, x, y, ax): seaborn.heatmap(data, xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, cbar=False, ax=ax) for layer in range(1, 6, 2): fig, axs = plt.subplots(1,4, figsize=(20, 10)) print(\"Encoder Layer\", layer+1) for h in range(4): draw(model.encoder.layers[layer].self_attn.attn[0, h].data, sent, sent if h ==0 else [], ax=axs[h]) plt.show() for layer in range(1, 6, 2): fig, axs = plt.subplots(1,4, figsize=(20, 10)) print(\"Decoder Self Layer\", layer+1) for h in range(4): draw(model.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(tgt_sent)], tgt_sent, tgt_sent if h ==0 else [], ax=axs[h]) plt.show() print(\"Decoder Src Layer\", layer+1) fig, axs = plt.subplots(1,4, figsize=(20, 10)) for h in range(4): draw(model.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(sent)], sent, tgt_sent if h ==0 else [], ax=axs[h]) plt.show() Encoder Layer 2 Encoder Layer 4 Encoder Layer 6 Decoder Self Layer 2 Decoder Src Layer 2 Decoder Self Layer 4 Decoder Src Layer 4 Decoder Self Layer 6 Decoder Src Layer 6 9. 参考资料The Annotated Transformer","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"pytorch","slug":"pytorch","permalink":"https://rogerspy.gitee.io/tags/pytorch/"}]},{"title":"关于Transformer的分析","slug":"analyse-transformer","date":"2019-09-01T03:45:45.000Z","updated":"2022-01-12T08:37:38.322Z","comments":true,"path":"2019/09/01/analyse-transformer/","link":"","permalink":"https://rogerspy.gitee.io/2019/09/01/analyse-transformer/","excerpt":"Transformer 的模型框架我们已经介绍完了，接下来这篇文章我们讨论一下更多关于 Transformer 的模型细节。比如多头注意力的头越多越好吗？自注意力为什么要进行归一化？训练的时候 Warm-up 有什么用？","text":"Transformer 的模型框架我们已经介绍完了，接下来这篇文章我们讨论一下更多关于 Transformer 的模型细节。比如多头注意力的头越多越好吗？自注意力为什么要进行归一化？训练的时候 Warm-up 有什么用？ 1. 模型总览 在进入正题之前，我们先回顾一下 Transformer 的整体结构，大致包含以下几个部分： Input Embedding Positional Encoding Multi-head Attention Add &amp; Norm Feed Forward Masked Multi-head Attention Linear softmax 2. Input EmbeddingInput Embedding 实际上可以看成两部分：Input 和 Embedding。神经网络在处理自然语言问题的时候，一个基础的工作就是词向量化。要将自然语言问题转化成计算问题，首先就要将自然语言符号表示转化成数字表示，最简单的表示方法就是 one-hot ，但是 one-hot 有两个问题：① 数据稀疏；② 无法表示词语此之间的语义关系。所以后来人们发明了 embedding 表示法，就是将自然语言符号表示成低维连续的向量，这样可以同时解决上述两个问题。 向量化是自然语言处理的一个必不可少的工作，一般的词向量化有两种方式： 通过一些算法（比如，word2vec 或者 glov2vec）预训练一个词向量表，之后通过查表的方式将句子转化成词向量表示。然后在模型的训练的时候词向量不参与训练； 在模型输入阶段随机初始化一张词向量表，同样是通过查表的方式将句子表示成向量形式，而这张词向量表随着模型一起训练。 以上基本就是任意使用神经网络处理的自然语言问题的必经之路。其中的向量化过程我们不再赘述（在后续的系列文章中会专门讨论自然语言处理中的预训练技术），这里我们详细讨论一下 Input 部分。 上面我们说到我们需要一张词向量表将自然语言符号映射成向量，自然而然地我们同样需要一张词表，这张词表包含的元素就是自然语言符号。在训练模型的时候我们是使用一张固定大小的词表，也就是说模型只能处理词表中出现过的词。一个显然的问题是，大千世界，我们人类发明的自然语言符号虽然不是无穷无尽的，但是却是数量非常庞大的，而且还在不断的增长中，所以我们不可能将所有的符号都纳入到词表中。即使我们将当前所有的符号都纳入到词表中也会面临两个问题： 过于庞大的词表就意味着庞大的词向量表，如此庞大的词向量表会使模型参数量爆炸，大参数量不仅意味着大计算量，同时还有可能意味着较高的错误率。比如机器翻译过程中最后的输出由 softmax 挑选最合适的词进行输出，一个简单的直觉就是从更大的词表中选择会有更大的概率出错； 在所有的符号中，有些是常用的，有些是非常罕见的。对于常用的符号，模型可以得到充分的训练，但对于稀有的符号模型得不到充分训练，实际的效果也不会好。 这就意味着我们的模型只能使用一个有限的词表进行训练，但是当我们的模型训练好了以后，让它去处理实际问题的时候，它面临的却是开放的世界，它需要处理的也是所有的自然语言符号，一旦遇到词表之外的符号，模型就无能为力了。这就是自然语言处理过程中的 OOV（out-of-vocabulary） 问题。 为了解决 OOV 问题，研究人员展开了大量的研究工作，研究的核心就在于以什么样的方式表示自然语言符号。 以词为单位。通常，我们认为一个句子的基本元素是词（word），所以我们通常是使用一个个词组成一个序列，用来表示句子。而使用词作为自然语言符号表示法的话，就会面临上述的所有问题。而且以词为单位不利于模型学习词缀之间的关系，比如模型学到的“old”, “older”, and “oldest”之间的关系无法泛化到“smart”, “smarter”, and “smartest”。 以字为单位。后来人们想到用字（character）来表示。虽然真实世界的词浩如烟海，但是组成词的字却是非常有限的，比如英文只有 26 个字母。但是这种处理方法粒度太细，丢失了词带给句子的潜藏语义关联，因此通常效果不如以词为基础单元的模型。 以子词为单位。什么是子词（sub-word）？就是将一般的词，比如 older 分解成更小单元，old+er，这样这些小单元可以几个词共用，减小了词表大小，同时还能使模型学习到词缀之间的关系。因此子词可以很好的平衡 OOV 问题。所以下面我们详细介绍一下子词技术。 2.1 Byte Pair EncodingByte Pair Encoding（BPE） 算法最早是由 Gage 于1994 年提出的一种用于数据压缩的算法，而在 2015 年被 Sennrich 等人推广到了自然语言处理领域。 算法过程 算法过程如下： 1234561. 准备足够大的训练语料;2. 确定期望的子词表大小；3. 将单词拆分为字符序列并在末尾添加后缀“&lt;/w&gt;”，统计单词频率；4. 统计每一个连续字节对的出现频率；5. 选择最高频者合并成新的子词；6. 重复 4 ~ 5 步直到达到第2步设定的子词表大小或下一个最高频的字节对出现频率为 1。 举个例子： 假设我们准备了一份语料，语料中包含：$(low, lower, newest, widest)$ 这几个词; 将单词拆分成字符，并在后面添加 “&lt;/w&gt;”，然后统计词频，得到： vocab = {‘l o w &lt;/w&gt;’: 5, ‘l o w e r &lt;/w&gt;’: 2, ‘n e w e s t &lt;/w&gt;’: 6, ‘w i d e s t &lt;/w&gt;’: 3} 统计连续字符对出现的频率： {(‘l’, ‘o’): 7, (‘o’, ‘w’): 7, (‘w’, ‘&lt;/w&gt;’): 5, (‘w’, ‘e’): 8, (‘e’, ‘r’): 2, (‘r’, ‘&lt;/w&gt;’): 2, (‘n’, ‘e’): 6, (‘e’, ‘w’): 6, (‘e’, ‘s’): 9, (‘s’, ‘t’): 9, (‘t’, ‘&lt;/w&gt;’): 9, (‘w’, ‘i’): 3, (‘i’, ‘d’): 3, (‘d’, ‘e’): 3} 最高频连续字节对 (“e”, “s”)，合并成 “es”，得到： {‘l o w &lt;/w&gt;’: 5, ‘l o w e r &lt;/w&gt;’: 2, ‘n e w es t &lt;/w&gt;’: 6, ‘w i d es t &lt;/w&gt;’: 3} 重复以上步骤 注意：停止符”&lt;/w&gt;”的意义在于表示subword是词后缀。举例来说：”st”字词不加”&lt;/w&gt;”可以出现在词首如”st ar”，加了”&lt;/w&gt;”表明改字词位于词尾，如”wide st&lt;/w&gt;”，二者意义截然不同。 代码实现 123456789101112131415161718import re, collectionsdef get_stats(vocab): pairs = collections.defaultdict(int) for word, freq in vocab.items(): symbols = word.split() for i in range(len(symbols)-1): pairs[symbols[i],symbols[i+1]] += freq return pairsdef merge_vocab(pair, v_in): v_out = &#123;&#125; bigram = re.escape(' '.join(pair)) p = re.compile(r'(?&lt;!\\S)' + bigram + r'(?!\\S)') for word in v_in: w_out = p.sub(''.join(pair), word) v_out[w_out] = v_in[word] return v_out 训练示例： 1234567891011121314vocab = &#123;'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w e s t &lt;/w&gt;': 6, 'w i d e s t &lt;/w&gt;': 3&#125;num_merges = 1000for i in range(num_merges): pairs = get_stats(vocab) if not pairs: break best = max(pairs, key=pairs.get) vocab = merge_vocab(best, vocab) print(best) print(vocab) print('='*20) 输出： 123456789101112131415161718192021222324252627282930313233343536373839404142434445('e', 's')&#123;'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w es t &lt;/w&gt;': 6, 'w i d es t &lt;/w&gt;': 3&#125;====================('es', 't')&#123;'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est &lt;/w&gt;': 6, 'w i d est &lt;/w&gt;': 3&#125;====================('est', '&lt;/w&gt;')&#123;'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3&#125;====================('l', 'o')&#123;'lo w &lt;/w&gt;': 5, 'lo w e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3&#125;====================('lo', 'w')&#123;'low &lt;/w&gt;': 5, 'low e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3&#125;====================('n', 'e')&#123;'low &lt;/w&gt;': 5, 'low e r &lt;/w&gt;': 2, 'ne w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3&#125;====================('ne', 'w')&#123;'low &lt;/w&gt;': 5, 'low e r &lt;/w&gt;': 2, 'new est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3&#125;====================('new', 'est&lt;/w&gt;')&#123;'low &lt;/w&gt;': 5, 'low e r &lt;/w&gt;': 2, 'newest&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3&#125;====================('low', '&lt;/w&gt;')&#123;'low&lt;/w&gt;': 5, 'low e r &lt;/w&gt;': 2, 'newest&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3&#125;====================('w', 'i')&#123;'low&lt;/w&gt;': 5, 'low e r &lt;/w&gt;': 2, 'newest&lt;/w&gt;': 6, 'wi d est&lt;/w&gt;': 3&#125;====================('wi', 'd')&#123;'low&lt;/w&gt;': 5, 'low e r &lt;/w&gt;': 2, 'newest&lt;/w&gt;': 6, 'wid est&lt;/w&gt;': 3&#125;====================('wid', 'est&lt;/w&gt;')&#123;'low&lt;/w&gt;': 5, 'low e r &lt;/w&gt;': 2, 'newest&lt;/w&gt;': 6, 'widest&lt;/w&gt;': 3&#125;====================('low', 'e')&#123;'low&lt;/w&gt;': 5, 'lowe r &lt;/w&gt;': 2, 'newest&lt;/w&gt;': 6, 'widest&lt;/w&gt;': 3&#125;====================('lowe', 'r')&#123;'low&lt;/w&gt;': 5, 'lower &lt;/w&gt;': 2, 'newest&lt;/w&gt;': 6, 'widest&lt;/w&gt;': 3&#125;====================('lower', '&lt;/w&gt;')&#123;'low&lt;/w&gt;': 5, 'lower&lt;/w&gt;': 2, 'newest&lt;/w&gt;': 6, 'widest&lt;/w&gt;': 3&#125;==================== 2.2 WordPieceWordPiece 算法可以看作是 BPE 的变种。不同点在于，WordPiece 基于概率生成新的子词而不是最高频字节对。 算法过程 1234561. 准备足够大的训练语料;2. 确定期望的子词表大小;3. 将单词拆分成字符序列;4. 基于第3步数据训练语言模型;5. 从所有可能的子词单元中选择加入语言模型后能最大程度地增加训练数据概率的单元作为新的单元;6. 重复第5步直到达到第2步设定的子词表大小或概率增量低于某一阈值; 注意：因为加入每个可能的词对都需重新训练语言模型，这样需要的计算资源会很大，因此作者通过以下策略降低计算量： 只测试语料中出现的词对； 只测试有很大可能（高优先）是最好词对的候选； 同时测试几个词对，只要它们互不影响； 重训语言模型（并不需要是神经网络型），只重新计算受影响的部分。 2.3 Unigram Language ModelULM 是另外一种子词分隔算法，它能够输出带概率的多个子词分段。它引入了一个假设：所有子词的出现都是独立的，并且子词序列由子词出现概率的乘积产生。 ULM 和 WordPiece 一样都是利用语言模型建立子词表。与前两者都不相同的是，前两者构建词表的时候是增量的，而 ULM 是减量的。 算法过程 12345671. 先建立一个足够大的种子词表，可以用所有字符的组合加上语料中常见的子字符串。 对于种子词表，也能用 BPE 法来生成。2. 固定词表，用 EM 算法来最优化当前词表在语料上的概率；3. 之后计算每个子词的 loss，对应的 loss 相当于该子词有多大可能使总的 loss 降低；4. 接着按照每个子词 loss 大小来排序，保留最大一定比例（比如说80%）的子词， 为了避免OOV，建议保留字符级的单元；6. 不断重复 2 ~ 4，直到词表量减少到限定范围。 子词采样 相比于之前的两种方法，分词结果是确定的，ULM 会使用一定的概率对分词结果进行采样。这样给训练过程带来了随机性。结果表明相比起只用一种方案的确定性分词法，子词正则能够获得很大的提升。但同时也正如看到的，子词正则加上 ULM 法过于复杂，所以应用难度也相应增大，不像 BPE 应用广泛。 2.4 BPE-Dropout该方法非常简单，采取和子词正则相同思路，对 BPE 算法训练做了些改进，加入了一定的随机性。具体在每次对训练数据进行处理分词时，设定一定概率（10%）让一些融合不通过，于是即使是相同词，每次用 BPE dropout 生成出来的子词也都不一样。 算法过程 121. 用 BPE 生成所有的融合候选子词；2. 根据一定的概率 p 删除一部分候选子词； 2.5 小结 子词可以平衡词汇量和对未知词的覆盖。 对于包括中文在内的许多亚洲语言，单词不能用空格分隔。 因此，初始词汇量需要比英语大很多。 另外需要注意一点的是，对于中文这种不以空格分隔的语言，在应用子词技术的时候，需要先用分词算法进行分词。 3. Positional Encoding3.1 What, why and when？所谓位置编码指的是，在训练深度模型的时候，在输入训练数据的时候添加一种编码，使得模型的输出可以表征输入数据的时序特征。对于文本数据，词与词之间的顺序关系往往影响整个句子的含义。因此，在对文本进行建模的时候，词序是一个必须考虑的问题。但是否是所有的文本建模都需要使用位置编码呢？ 答案是：No! 只有当我们使用对位置不敏感（position-insensitive）的模型对文本数据建模的时候，才需要额外使用位置编码。那么什么是位置敏感模型？什么是位置不敏感模型呢？ 如果模型的输出会随着输入文本数据顺序的变化而变化，那么这个模型就是关于位置敏感的，反之则是位置不敏感的。 用形式化的语言描述为：假设模型函数 $y = f(x)$，其中 $x = (x_1, …, x_n)$ 为输入序列，$y$ 为输出。如果将 $x$ 找那个任意元素的位置进行了置换， $x’ = (x_{k_1}, …x_{k_n})$。此时，如果 $f(x) = f(x’)$，那么我们称模型是位置不敏感的；反之则为位置敏感的。 传统的 RNN 模型是关于位置敏感的模型，我们在使用 RNN 相关模型进行文本建模的时候是不需要位置编码的。只有使用位置不敏感的模型进行文本建模的时候才需要位置编码。 3.2 How?从直观上来讲，我们可以给序列中的第一个词的位置编码为 1，第二个词位置编码为 2 …… 依此类推。但是这种方法会带来两个问题：① 句子比较长的话，位置编码数字会变得很大；② 模型在推理的时候会遇到比训练数据更长的句子，这种编码会削弱模型的泛化性。 我们直接能想到的第二种方法是，将序列长度归一化到 $[0, 1]$ 范围内，0 表示第一个词， 1 表示最后一个词。但是这种编码方式也是有问题的：句子是变长的，我们不知道模型遇到的句子的长度是多少，对于不同长度的句子，每个词对应的位置编码是不一样的，也就是说这样的位置编码是无效编码。举个例子： I love you I love you! 这两句话，实际上意思相同，只不过第二句话多了一个句号，在用上面的方式进行位置编码的时候，两句话中对应的词的位置编码是不一样的，最后模型输出的结果也很难表征出相同的意思。因此，这种方式同样不可取。 理想的位置编码应该具备以下几个特征： 每一个词的位置都有一个唯一的编码； 不同长度的句子中任意两个词之间的距离应该是相同的； 编码值应该是有界的，而且可以轻松泛化到更长的句子中； 必须具有确定性。 目前主流的位置编码有三种： 可学习的位置编码（Learned Positional Embedding）； 正余弦位置编码（Sinusoidal Position Encoding）； 相对位置编码（Relative Position Representations）。 3.2.1 可学习的位置编码这种编码方式相对简单也容易理解。它的做法是，随机初始化一个位置矩阵，然后加到（或者拼接）词向量矩阵上，输入给模型作为模型参数参与模型训练。 3.2.2 正弦位置编码这种位置编码方式就是 Transformer 中使用的位置编码。假设 $t$ 是输入序列的位置，$\\vec{p}_t \\in \\mathbb{R}^d$ 表示其对应的编码。$\\vec{p}_t$ 定义如下： \\vec{p}_t^{(i)} = \\begin{cases} \\sin(\\omega_k \\cdot t), i=2k \\\\\\\\ \\cos(\\omega_k \\cdot t), i=2k+1 \\end{cases}其中 $\\omega_k = 1/10000^{2k/d}$。 有了位置编码以后，将词向量与位置向量相加得到带有位置信息的新序列。注意为了相加操作的正确，要保证此项来那个维度和位置向量维度一致： \\psi'(\\omega_t) = \\psi(\\omega_t) + \\vec{p}_t正弦位置编码的优势是，对于任意固定的偏移量 $k$，$\\vec{p}_{t+k}$ 可以表示成 $\\vec{p }_t$ 的线性函数。也就是说，模型可以很容易通过先验绝对位置编码学习到相对位置编码。通常对于句子中的词序，我们更关注的是词与词之间的相对位置。我们来证明一下吧。 问题描述 令 $ \\vec{p}_t$ 表示第 $t$ 个位置的位置编码： \\vec{p}_t=\\begin{bmatrix} \\sin(\\omega_1 \\cdot t)\\\\\\\\ \\cos(\\omega_1 \\cdot t)\\\\\\\\ \\sin(\\omega_2 \\cdot t)\\\\\\\\ \\cos(\\omega_2 \\cdot t)\\\\\\\\ \\vdots \\\\\\\\ \\sin(\\omega_{d_{model}/2} \\cdot t)\\\\\\\\ \\cos(\\omega_{d_{model}/2} \\cdot t) \\end{bmatrix}_{d_{model} \\times 1}我们希望能找到一个与 $t$ 无关的矩阵，使得 $\\vec{p}_t$ 通过线性变换成为 $\\vec{p}_{t+k}$。（因为如果是关于 $t$ 的矩阵， 那这个变换就是非线性的了） 证明 我们令 \\vec{p}_t=\\begin{bmatrix} \\begin{bmatrix} \\sin(\\omega_1 \\cdot t)\\\\\\\\ \\cos(\\omega_1 \\cdot t) \\end{bmatrix}\\\\\\\\ \\begin{bmatrix} \\sin(\\omega_2 \\cdot t)\\\\\\\\ \\cos(\\omega_2 \\cdot t) \\end{bmatrix}\\\\\\\\ \\vdots \\\\\\\\ \\begin{bmatrix} \\sin(\\omega_{d_{model}/2} \\cdot t)\\\\\\\\ \\cos(\\omega_{d_{model}/2} \\cdot t) \\end{bmatrix} \\end{bmatrix} 我们希望找到一个 $M \\in \\mathbb{R}^{2 \\times 2}$ ，使得 M \\cdot \\begin{bmatrix} \\sin(\\omega_i \\cdot t)\\\\\\\\ \\cos(\\omega_i \\cdot t) \\end{bmatrix}= \\begin{bmatrix} \\sin(\\omega_i \\cdot (t+k))\\\\\\\\ \\cos(\\omega_i \\cdot (t+k)) \\end{bmatrix} 令 $M = \\begin{bmatrix}u_1 &amp; v_1 \\\\\\ u_2 &amp; v_2\\end{bmatrix}$，代入上式，并分解等式右边得 \\begin{bmatrix} u_1 & v_1 \\\\\\\\ u_2 & v_2 \\end{bmatrix} \\cdot \\begin{bmatrix} \\sin(\\omega_i \\cdot t)\\\\\\\\ \\cos(\\omega_i \\cdot t) \\end{bmatrix}= \\begin{bmatrix} \\sin(\\omega_i \\cdot t)\\cos(\\omega_i \\cdot k) + \\cos(\\omega_i \\cdot t)\\sin(\\omega_i \\cdot k)\\\\\\\\ \\cos(\\omega_i \\cdot t)\\cos(\\omega_i \\cdot k) - \\sin(\\omega_i \\cdot t)\\sin(\\omega_i \\cdot k) \\end{bmatrix} 由此可得： u_1\\sin(\\omega_i \\cdot t) + v_1 \\cos(\\omega_i \\cdot t) = \\quad \\cos(\\omega_i \\cdot k)\\sin(\\omega_i \\cdot t) + \\sin(\\omega_i \\cdot k)\\cos(\\omega_i \\cdot t)\\\\\\\\ u_2\\sin(\\omega_i \\cdot t) + v_2 \\cos(\\omega_i \\cdot t) = -\\sin(\\omega_i \\cdot k)\\sin(\\omega_i \\cdot t) + \\cos(\\omega_i \\cdot k)\\cos(\\omega_i \\cdot t)\\\\\\\\ 通过对比等式两边，我们可以得到 $u_1, v_1, u_2, v_2$ 的一组解： u_1 = \\quad \\cos(\\omega_i \\cdot k) \\quad v_1 = \\sin(\\omega_i \\cdot k) \\\\\\\\ u_2 = -\\sin(\\omega_i \\cdot k) \\quad v_2 = \\cos(\\omega_i \\cdot k) 也就是说 M = \\begin{bmatrix} \\cos(\\omega_i \\cdot k) & \\sin(\\omega_i \\cdot k) \\\\\\\\ -\\sin(\\omega_i \\cdot k) & \\cos(\\omega_i \\cdot k) \\end{bmatrix} 我们可以看到 $M$ 是一个与 $t$ 无关的矩阵。最后，我们令 T^{(k)} = \\begin{bmatrix} M_1^{(k)} & 0 & \\cdots & 0 \\\\\\\\ 0 & M_2^{(k)} & \\cdots & 0 \\\\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\ 0 & 0 & 0 & M_{d_{model}/2}^{(k)} \\end{bmatrix} 其中 $0$ 表示 $2 \\times 2$ 的全零矩阵。$T^{(k)}$ 即为我们想要的线性变换矩阵。 正弦位置编码的性质 在计算自注意力的时候， Transformer 是计算序列中任意两个元素的注意力权重。因此，我们这里探究一下正弦位置编码的内积的性质。 ① 内积随相对位置递增而减小 \\begin{equation} \\nonumber \\begin{aligned} \\vec{p}_t \\cdot \\vec{p}_{t+k} &= \\sum_{i=0}^{\\frac{d_{model}}{2}-1} \\mathrm{sin}(\\omega_1\\cdot t)\\cdot \\mathrm{sin}(\\omega_i\\cdot (t+k))+\\cos(\\omega_i\\cdot t)\\cdot \\cos(\\omega_i\\cdot(t+k))\\\\\\\\ &= \\sum_{i=0}^{\\frac{d_{model}}{2}-1} \\cos(\\omega_i\\cdot(t-(t+k)))\\\\\\\\ &= \\sum_{i=0}^{\\frac{d_{model}}{2}-1} \\cos(\\omega_i\\cdot -k)\\\\\\\\ &= \\sum_{i=0}^{\\frac{d_{model}}{2}-1} \\cos(\\omega_i\\cdot k) \\end{aligned} \\end{equation} 由此我们可以发现，随着相对位置的递增，正弦位置编码的内积会减小。如上图所示，点积的结果是对称的，并且随 $|k|$ 增加而减少（但并不单调）。 但是在 Transformer 中，由于需要经过映射，即两者间的点积实际是 $\\vec{p}_t \\cdot W \\cdot \\vec{p}_{t+k}$，下图展示了经过映射之后的位置向量点积： 我们可以看到，此时位置向量的点积并没有展现出明确的趋势。 ② 对称性 \\begin{equation} \\nonumber \\begin{aligned} \\vec{p}_t \\cdot \\vec{p}_{t-k} &= \\sum_{i=0}^{\\frac{d_{model}}{2}-1} \\sin(\\omega_1\\cdot t)\\cdot \\mathrm{sin}(\\omega_i\\cdot (t-k))+\\cos(\\omega_i\\cdot t)\\cdot \\cos(\\omega_i\\cdot(t-k))\\\\\\\\ &= \\sum_{i=0}^{\\frac{d_{model}}{2}-1} \\cos(\\omega_i\\cdot(t-(t-k)))\\\\\\\\ &= \\sum_{i=0}^{\\frac{d_{model}}{2}-1} \\cos(\\omega_i\\cdot k) \\end{aligned} \\end{equation}由此我们发现，$ \\vec{p}_t \\cdot \\vec{p}_{t+k} = \\vec{p}_t \\cdot \\vec{p}_{t-k} $，这说明正弦位置编码无法区分词与词的前后关系。 词向量和位置向量直接相加是否合理？ Transformer 对模型输入的词向量和位置向量的处理是直接相加，作者并没有给出一个理论解释，为什么要直接相加。但是如果我们读过足够多的的 NLP 论文，我们会发现，对位置向量的处理通常只有两种方法：相加和拼接。这两种处理方式在不同的模型中有不同的表现，但总体上并没有太大的差别。Transformer 之所以使用相加的方式，可能主要是考虑减少模型参数，毕竟自注意力矩阵的参数已经足够多了。 但是我们仔细考虑一下，无论是直接相加还是拼接，都隐含了一个假设：词向量和位置向量都是独立分布的。这个假设对词向量来说是成立的，因为词向量的 index 与我们使用的字典排序有关，而这个排序是任意的，任意的 index 与 index+k 或者 index-k 都没有任何依赖关系，所以这个假设是成立的。但是对于位置向量却并不满足这一假设，其顺序关系对模型理解文本有着重要的影响。我们称之为位置不敏感问题（position-insensitive problem）。 为了解决这一问题 Wang 等人提出关于位置的连续函数来表征词在位置上的表示，即： f(j, t) = \\pmb{g}_j(t) \\in \\mathbb{R}^D其中 $\\pmb{g}_j(t) = [g_{j,1}(t), g_{j, 2}(t), …, g_{j, D}(t)]$，$g_{j, d}(t)$ 是一个关于 $t$ 的函数。为了让这个函数更好的表征位置信息，$g_{j, d}(t)$ 必须要满足一下两个性质： Position-free offset transformation 存在一个线性函数 $\\mathrm{Transform}_k(\\cdot)=\\mathrm{Transform}(g(t))$ 使得 g(t+k) = \\mathrm{Transform}(g(t))也就是说在位置 $t+k$ 上的词 $w_{j,t+k}$ 可以通过位置 $t$ 上的词 $w_{i, t}$ 通过一个只和 $k$ 相关的变换得到，而与具体这个词无关。有点类似正弦位置编码的线性变换，只是这里不仅是位置的变换，还有词的变换。 Boundedness 这个线性函数必须是有界的。这是一个非常合理的限制，不做过多解释。 最后，作者提出了 $g(t)$ 的函数形式： g(t) = r \\cdot e^{i(\\omega \\cdot t +\\theta)}我们可以看到这是一个复数形式的函数，其中 $r$ 为振幅， $\\omega$ 为角频率，$\\theta$ 为初相，都是需要学习的参数。 3.2.3 相对位置编码无论是可学习位置编码还是正弦位置编码都是将位置编码作为额外的信息输入给模型，相对位置编码是将位置信息作为模型本身的属性，使模型不需要额外输入位置编码即可处理序列的位置信息。 这部分因为涉及到的都是模型架构的修改，因此我们会在后续的论文解读中解读相关的论文，这里不做解释。有兴趣的话可以看以下几篇论文（这几篇论文都会在后面详细解读）： Self-Attention with Relative Position Representations Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Gaussian Transformer: A Lightweight Approach for Natural Language Inference 4. Multi-head Attention4.1 为什么需要 K、Q、V，只用K、Q/K、V/Q、V行不行？实际上这个问题，我们在 NLP中的注意力机制简介（一） 这篇文章中介绍过了。最初的注意力机制实际上是只用了两个值的，直到 Sukhbaatar et al., 2015 将注意力机制引入到对话系统模型中才出现了 $k, q, v$ 三值的注意力形式。这样的注意力形式有两个好处： 可复用性 灵活性 更详细的内容可以参考上面的博客以及论文，这里不赘述。 4.2 自注意力为什么scaled?知乎上关于这个问题有很详细的讨论与解释，我就不自由发挥了，照抄过来。原文地址：transformer中的attention为什么scaled? 4.2.1 为什么比较大的输入会使得 softmax 的梯度变得很小？对于输入向量 $\\pmb{x} \\in \\mathbb{R}^d$，softmax 函数将其映射/归一化到一个 $\\pmb{\\hat{y}} \\in \\mathbb{R}^d$。这个过程中，softmax 先用一个自然底数 $e$ 将输入的元素距离先拉大，然后归一化为一个分布。假设某个输入 $\\pmb{x}_k$ 表示最大的元素，如果输入的数量级变大（每个元素都很大），那么 $\\pmb{x}_k$ 对应的 $\\pmb{\\hat{y}}_k$ 会非常接近 1。 我们可以用一个小例子来看看。假定输入 $\\pmb{x} = [a, a, 2a]^T$， $a = 1$ 时，$\\hat{y}_2=0.5761168847658291$； $a=10$ 时，$\\hat{y}_2 = 0.999909208284341$； $a = 100$ 时，$\\hat{y}_2 \\approx 1$ （计算机精度限制）。 我们不妨把不同的 $a$ 对应的 $\\hat{y}_2$ 绘制成一条曲线，更能清晰的看出问题。 12345678from math import expfrom matplotlib import pyplot as pltimport numpy as np f = lambda x: exp(x * 2) / (exp(x) + exp(x) + exp(x * 2))x = np.linspace(0, 100, 100)y_3 = [f(x_i) for x_i in x]plt.plot(x, y_3)plt.show() 可以看到，数量级对 softmax 得到的分布影响非常大。在数量级较大时，softmax 将几乎全部的概率分布都分配给了最大值对应的标签。这里的数学证明请参考文章：浅谈Softmax函数（见A.补充）。 然后我们来看 softmax 的梯度。不妨简记 softmax 函数为 $g(\\cdot)$，$\\pmb{\\hat{y}} = g(\\pmb{x})$ 对 $\\pmb{x}$ 的梯度为： \\frac{\\partial g({\\pmb{x}})}{\\partial \\pmb{x}} = \\begin{bmatrix} \\hat{y}_0 & 0 & \\cdots & 0 \\\\\\\\ 0 & \\hat{y}_1 & \\cdots & 0 \\\\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\ 0 & 0 & \\cdots & \\hat{y}_{d-1} \\end{bmatrix}-\\begin{bmatrix} \\hat{y}_0^2 & \\hat{y}_0 \\hat{y}_1 & \\cdots & \\hat{y}_0\\hat{y}_{d-1} \\\\\\\\ \\hat{y}_1 \\hat{y}_0 & \\hat{y}_1^2 & \\cdots & \\hat{y}_1\\hat{y}_{d-1} \\\\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\ \\hat{y}_{d-1} \\hat{y}_0 & \\hat{y}_{d-1} \\hat{y}_1 & \\cdots & \\hat{y}_{d-1}^2 \\end{bmatrix}根据前面的讨论，当输入 $ \\pmb{x}$ 的元素均较大时，softmax 会把大部分概率分布分配给最大的元素。假设我们的输入数量级很大，最大的元素是 $\\pmb{x}_1$，那么就将产生一个接近 one-hot 的向量 $\\pmb{\\hat{y}} = [1, 0, \\cdots, 0]^T$，此时此时上面的矩阵变为如下形式： \\frac{\\partial g({\\pmb{x}})}{\\partial \\pmb{x}} = \\begin{bmatrix} 1 & 0 & \\cdots & 0 \\\\\\\\ 0 & 0 & \\cdots & 0 \\\\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\ 0 & 0 & \\cdots & 0 \\end{bmatrix}-\\begin{bmatrix} 1 & 0 & \\cdots & 0 \\\\\\\\ 0 & 0 & \\cdots & 0 \\\\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\ 0 & 0 & \\cdots & 0 \\end{bmatrix} = \\pmb{0}也就是说，在输入的数量级很大时，梯度消失为0，造成参数更新困难。 4.2.2 维度与点积大小的关系是怎么样的，为什么使用维度的根号来放缩？假设向量 $\\pmb{q}$ 和 $\\pmb{k}$ 的各个分量是相互独立的随机变量，均值是 $0$，方差为 $1$，则点积 $\\pmb{q \\cdot k}$ 的均值为 $0$，方差为 $d_k$，$d_k$ 表示向量维度。这里给出一点详细的推导： $\\forall i = 1, …, d_k$，$q_i$ 和 $k_i$ 都是随机变量。为方便书写，不妨记 $X = q_i, Y=k_i$。已知：$D(X) = D(Y) = 1$ ， $E(X)=E(Y)=0$。 则有： $E(XY)=E(X)E(Y) = 0 \\times 0 = 0$ \\begin{equation} \\nonumber \\begin{aligned} D(XY) &= E(X^2Y^2)-[E(XY)]^2 \\\\\\\\ &= E(X^2)E(Y^2) - [E(X)E(Y)] \\\\\\\\ &= E(X^2 - 0^2)E(Y^2-0^2) - [E(X)E(Y)]^2 \\\\\\\\ &= E(X^2-[E(X)]^2)\\cdot E(Y^2-[E(Y)]^2) - [E(X)E(Y)]^2 \\\\\\\\ &= D(X)D(Y)-[E(X)E(Y)]^2 \\\\\\\\ &= 1 \\times 1 - (0 \\times 0)^2 \\\\\\\\ &= 1 \\end{aligned} \\end{equation} 由期望和方差的性质， 对相互独立的分量 $Z_i$ 有： E(\\sum_i Z_i) = \\sum E(Z_i) \\\\\\\\ D(\\sum_i Z_i) = \\sum D(Z_i)所以 $\\pmb{q} \\cdot \\pmb{k}$ 的均值 $E(\\pmb{q \\cdot k}) = 0$，方差 $D(\\pmb{q \\cdot k}) = d_k$。方差越大也就说明，点积的数量级越大（以越大的概率取大值）。那么一个自然的做法就是把方差稳定到 1，做法是将点积除以 $\\sqrt{d_k}$： D(\\frac{\\pmb{q \\cdot k}}{\\sqrt{d_k}}) = \\frac{d_k}{(\\sqrt{d_k})^2} = 1将方差控制为 1，也就有效地控制了前面提到的梯度消失的问题。 4.2.3 为什么在其他 softmax 的应用场景，不需要做 scaled?参考：Massive Exploration of Neural Machine Translation Architectures 具体来说，分为以下两个层面： 为什么在普通形式的 attention 中，使用非 scaled 的 softmax？ 最基础的注意力机制有两种形式， 一种是加性的，另一种是乘性的。数学描述为： \\mathrm{score}(\\pmb{v}_i, \\pmb{u}) = \\pmb{w}^T \\tanh(\\pmb{W}[\\pmb{v}_i; \\pmb{u}]) \\\\\\\\ \\mathrm{score}(\\pmb{v}_i, \\pmb{u}) = \\pmb{u}^T \\pmb{v}_i在计算自注意力的时候之所以用乘性注意力机制，主要是为了计算更快。因为虽然矩阵加法的计算更简单，但是加性注意力包含 $\\tanh$ ，相当于是一个完整的神经网络层。在整体计算复杂度上两者接近，但是矩阵乘法已经有了非常成熟的加速实现。在 $d_k$ 较小的时候两者效果接近，但随着 $d_k$ 增大，加性效果开始明显超越乘性注意力。 作者分析乘性注意力效果不佳的原因，认为是极大的点积值将整个 softmax 推向梯度平缓区，使得收敛困难。也就是上面讨论的梯度消失。这才有了 scaled。所以加性注意力机制天然不需要 scaled，在乘性注意力中，$d_k$ 较大的时候必须要做 scaled。 那么，极大的点积值是从哪里来的呢？ 乘性注意力的极大点积值的来源上面讨论过，是由于两向量点积方差会从 $[0, 1]$ 范围扩散到 $[0, d_k]$ 范围。而加性的注意力，由于存在 $\\tanh$ 将值限制在 $[-1, 1]$ 范围内，整体的方差和 $d_k$ 没有关系。 为什么在分类层（最后一层），使用非 scaled 的 softmax？ 同上面部分，分类层的 softmax 也没有两个随机变量相乘的情况。此外，这一层的 softmax 通常和交叉熵联合求导，在某个目标类别 $i$ 上的整体梯度会变成 $\\pmb{y}’_i-\\pmb{y}_i$，即预测值与真值的差。当出现某个极大值时，softmax 的输出概率会集中在该类别上。如果预测正确，整体梯度接近于 0，如果类别错误，整体梯度会接近于 1，给出最大程度的负反馈。 也就是说，这个时候的梯度形式改变，不会出现极大值导致梯度消失的情况。 4.3 Transformer 为什么要用 Multi-head？Multi-head 应该是借鉴的 Multi-dimension attention 的思想。最早由 Wang et al., 2017 提出 2D-attention，希望模型能在不同的语境下，关注句子中不同的点。后来由 Lin et al. 2017 将 2D-attention 扩展到 Multi-dimension attention 。多维注意力的初衷是使注意力形成多个子空间，可以让模型去关注不同方面的信息，多头注意力也继承了这一想法。但是在实际的训练中，模型真的如我们的预期那样，去学习了不同方面的特征吗？ 现在的研究表明，Transformer 的底层更偏向于关注语法，顶层更偏向于关注语义。虽然在同一层中多数头的关注模式是一样的，但是总有那么一两个头与众不同。这种模式是很普遍的，为什么会出现这种情况？目前还不清楚。 针对不同的头，我们思考以下几个问题： 同一层中，不同头之间的差距有多少？（用 $h_i$ 度量） 同一层中，不同头的数量是否对 $h_i $ 有影响？ $h_i$ 是否随层数的变化而变化？ 我们能否使用 single-head 达到 multi-head 的效果？ 另外，初始化对 $h_i$ 的影响也是一个值得探究的问题，这个我们专门开一篇文章讲解，这里略过。 论文 What Does BERT Look At? An Analysis of BERT’s Attention 研究指出，头之间的差距随着所在层数变大而减少。换句话说，头之间的方差随着所在层数的增大而减小。 而在论文 Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned 中，作者研究了翻译的质量在何种程度上依赖单个头以及能否去掉一些头而不失效果等问题。研究结果表明，只有一小部分头对翻译而言是重要的，其他的头都是次要的（可以丢掉）。 这说明注意力头并非越多越好，但要足够多，single-head attention 目前来看还是无法取代 multi-head attention。 另外，其实还有一个有意思的问题是，不同头之间的差距有什么作用？在 Lin et al. 2017 的这篇文章中，通过引入一个正则化项，将不同头之间的注意力差距变大。他给出的解释是，是模型尽可能多的关注到不同的点上。那么拉大注意力头之间的差距在 Transformer 中有什么效果，目前还没有相关的实验。 更多关于 Multi-head attention 的探讨可以参考： Are Sixteen Heads Really Better than One? （博客） Are Sixteen Heads Really Better than One? （论文） How Much Attention Do You Need? A Granular Analysis of Neural Machine Translation Architectures 5. Add &amp; Norm还记得我们在介绍 Transformer 的时候，模型训练的初期我们使用了 warm-up 的小技巧。那么问题就来了，warm-up 为什么有效？ On Layer Normalization in the Transformer Architecture 就试图从 LayerNorm 的角度去解释。 首先我们先思考：为什么 warm-up 是必须的？能不能把它去掉？本文的出发点是：既然 warm-up 是训练的初始阶段使用的，那肯定是训练的初始阶段优化有问题，包括模型的初始化。顺着这个思路，作者发现在训练的初始阶段，输出层附近的期望梯度非常大，如果没有 warm-up，模型优化过程就会炸裂，非常不稳定。使用 warm-up 既可以保持分布的平稳，也可以保持深层的稳定。 作者发现这一现象与 LayerNorm 的位置有关。在原始的 Transformer 中，LayerNorm 在跟在 Add 之后的（也就是跟在残差之后），我们把这个称为 Post-LN Transformer。那我们很自然的想到，如果我们把 LayerNorm 换个位置，比如放到残差计算过程中（称为Pre-LN Transformer）会怎么样呢？ 下图是两种结构的示意图： 作者通过理论证明了： Post-LN Transformer的梯度范数在输出层附近很大，因此很可能随着后向传播的进行梯度越来越小； Pre-LN Transformer在每层的梯度范数都近似不变。 因此， warm-up 对 Post-LN Transformer 来说是必不可少的，实验结果也证实了这一点。而对于 Pre-LN Transformer 来说，理论上 warm-up 是可有可无的。然后作者通过实验证明 Pre-LN Transformer 似乎的确不再需要 warm-up 了。 6. Masked Multi-head AttentionMask 在 NLP 中是一个很常规的操作，也有多种应用的场景和形式。那么 Mask 到底有什么用呢？先上结论： 处理非定长序列 防止标签泄露 总的来说 Mask 无非就是这两种用途，下面我们详细解释一下。 6.1 处理非定长序列在 NLP 中，文本一般是不定长的，所以在进行训练之前，要先进行长度的统一，过长的句子可以通过截断到固定的长度，过短的句子可以通过 padding 增加到固定的长度，但是 padding 对应的字符只是为了统一长度，并没有实际的价值，因此希望在之后的计算中屏蔽它们，这时候就需要 Mask。 上图中的 1 表示有效字，0 代表无效字。 RNN 中的 Mask 对于 RNN 等模型，本身是可以直接处理不定长数据的，因此它不需要提前告知序列长度。但是在实践中，为了 批量训练，一般会把不定长的序列 padding 到相同长度，再用 mask 去区分非 padding 部分和 padding 部分。做这样区分的目的是使得 RNN 只作用到它实际长度的句子，而不会处理无用的 padding 部分，这样 RNN 的输出和隐状态都会是对应句子实际的最后一位。另外，对于 token 级别的任务，也可以通过 mask 去忽略 padding 部分对应的 loss。 Attention 中的 Mask 在 Transformer 中，有两种不同的 Mask。其中作用在序列上的 Mask 同样是为了忽略 padding 部分的影响。 6.2 防止标签泄露在一些任务中，模型输入的序列中可能包含需要预测的一些信息，为了防止模型“提前看答案”，我们需要将输入序列中的一些信息 mask 掉。 Transformer 中的 mask Transformer 中 masked multi-head attention 中的 mask 目的就是掩盖输入序列中的一些信息。在进行机器翻译的时候，模型 decoder 的输入是目标序列（已经预测的部分），比如 $t$ 时刻，模型是不可能知道 $t+1$ 时刻的输入的，因此，在训练的时候我们要模拟这一过程。至于怎么样进行 mask 这个在 Transformer 的介绍中已经详细介绍过了，不再赘述。 BERT 中的 Mask BERT 实际上是 Transformer 的 Encoder，为了在语言模型的训练中，使用上下文信息又不泄露标签信息，采用了 Masked LM，简单来说就是随机的选择序列的部分 token 用 [Mask] 标记代替。至于这么做为什么有效，实际上 Data Noising as Smoothing in Neural Network Language Models 就首次提出了此方法，而且给出了理论解释。这种替换其实本质上属于语言建模里面基于 interpolation 的平滑方式。 XLNet 中的 Mask XLNet 通过 Permutation Language Modeling 实现了不在输入中加 [Mask]，同样可以利用上下文信息。 为了更直观的解释，我们举个例子： 假设输入的序列是[1,2,3,4], 排列共有 4x3x2=24 种。 选其中的四种分别为[3,2,4,1],[2,4,3,1],[1,4,2,3],[4,3,1,2]。 在预测位置3的单词时， 第一种排列看不到任何单词，第二种排列能看到[2,4] 第三种排列能看到[1,2,4],第四种排列能看到[4], 所以预测位置 3 的单词时，不仅能看到上文[1,2],也能看到下文的[4]。 关于 Mask 的讨论也就到此为止了。 同时关于 Transformer 中的一些细节，以及引申出来的一些讨论，我们也就介绍到这。 7. AppendixAppendix A： BPE 初始版本假设有一段序列 $aaabdaaabac$，我们想对其进行编码。通过观察我们会发现 $aa$ 的出现概率最高（只考虑字符对），那么我们用一个序列中没有出现过的字符 $Z$ 来代替 $aa$ ： Z = aa \\\\\\\\ aaabdaaabac \\rightarrow ZabdZabac得到新序列之后我们会发现 $ab$ 字符对出现的概率最高，同样的我们使用一个新序列中没有出现过的字符 $Y$ 来代替 $ab$ ： Y = ab \\\\\\\\ Z = aa \\\\\\\\ ZabdZabac \\rightarrow ZYdZYac继续重复上面的步骤，我们得到： X=ZY \\\\\\\\ Y=ab \\\\\\\\ Z=aa \\\\\\\\ ZYdZYac \\rightarrow XdXac最后，序列中的所有字符对出现的频率都是 1，BPE 编码结束。解码的时候按照相反的顺序更新替换即可。 Reference Neural machine translation of rare words with subword units. Rico Sennrich, Barry Haddow, Alexandra Birch. 2015. arXiv: 1508.07909 Japanese and Korean Voice Search. Schuster, Mike, and Kaisuke Nakajima. 2012. IEEE BPE-Dropout: Simple and Effective Subword Regularization. Ivan Provilkov, Dmitrii Emelianenko, Elena Voita. 2019. arXiv:1910.13267 Subword regularization: Improving neural network translation models with multiple subword candidates. Taku Kudo. 2018. arXiv: 1804.10959 深入理解NLP Subword算法：BPE、WordPiece、ULM Luke. 知乎 子词技巧：The Tricks of Subword Andy Yang. 知乎 一分钟搞懂的算法之BPE算法 Transformer Architecture: The Positional Encoding Linear Relationships in the Transformer’s Positional Encoding Timo Denk’s Blog Encoding Word Oder In Complex Embeddings Benyou Wang, Donghao Zhao, Christina Lioma, Qiuchi Li, Peng Zhang, Jakob Grue Simonsen. 2020. ICLR 如何优雅地编码文本中的位置信息？三种positioanl encoding方法简述 小鹿鹿 lulu, 微信公众号 How Much Attention Do You Need? A Granular Analysis of Neural Machine Translation Architectures Tobias Domhan. 2018. ACL Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich, Ivan Titov. 2019. arXiv: 1905.09418 Are Sixteen Heads Really Better than One? Paul Michel, Omer Levy, Graham Neubig. 2019. arXiv: 1905.10650 On Layer Normalization in the Transformer Architecture Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Huishuai Zhang, Yanyan Lan, Liwei Wang, Tie-Yan Liu. 2020. ICLR (rejected) NLP中的Mask全解，海晨威 PaperWeekly 关于Transformer的若干问题整理记录 Adherer 知乎 香侬读 | Transformer中warm-up和LayerNorm的重要性探究 香侬科技， 知乎 transformer中的attention为什么scaled? Massive Exploration of Neural Machine Translation Architectures, Denny Britz, Anna Goldie, Minh-Thang Luong, Quoc Le. 2017. arXiv: 1703.03906 TENER: Adapting Transformer Encoder for Named Entity Recognition Hang Yan, Bocao Deng, Xiaonan Li, Xipeng Qiu. 2019. arXiv:1911.04474","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Attention","slug":"attention","permalink":"https://rogerspy.gitee.io/tags/attention/"},{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"}]},{"title":"NLP中的注意力机制简介（二）","slug":"NLP中的注意力机制简介（二）","date":"2019-08-27T03:53:17.000Z","updated":"2022-01-12T08:37:38.290Z","comments":true,"path":"2019/08/27/NLP中的注意力机制简介（二）/","link":"","permalink":"https://rogerspy.gitee.io/2019/08/27/NLP中的注意力机制简介（二）/","excerpt":"——Transformer专题篇 1. 前言之前我们介绍了各种各样的注意力机制，如果仔细回想一下就可以发现无论是哪种注意力机制都不是单独出现的，都是伴随着RNN或者其他RNN的变种。这种基于RNN的注意力机制会面临一个问题就是，难以处理长序列的句子，因为无法实现并行计算，所以非常消耗计算资源。","text":"——Transformer专题篇 1. 前言之前我们介绍了各种各样的注意力机制，如果仔细回想一下就可以发现无论是哪种注意力机制都不是单独出现的，都是伴随着RNN或者其他RNN的变种。这种基于RNN的注意力机制会面临一个问题就是，难以处理长序列的句子，因为无法实现并行计算，所以非常消耗计算资源。 CNN虽然可以实现并行计算，但是它无法获得序列的位置信息，这样它也就难以获得远距离信息上的依赖关系。后来虽然有人提出了完全基于CNN的seq2seq模型，但是却非常消耗内存。 由于基于RNN的注意力机制遇到了计算资源上的瓶颈，Vaswani et al., 2017提出了一个新的模型——Transformer！从目前的发展来看，这个模型对得起这个名字，因为它真的很能打，自从2018年基于Transformer的BERT预训练语言模型的横空出世到今天，几乎每一次NLP的重大进展都与它息息相关。因此，我们专门开一个专题篇来详细介绍一下这个模型。 Transformer的创新点在于抛弃了之前传统的基于CNN或者RNN的encoder-decoder模型的固有模式，只用Attention实现encoder-decoder。Transformer的主要目的在于减少计算量和提高并行效率的同时不损害最终的实验结果。 2. 模型结构2.1 模型结构总览在初始的论文中Transformer仍然是被用于机器翻译任务上： 下面我们来打开擎天柱，看下它到底是怎么构成的？ 可以看到Transformer仍然采用了encoder-decoder结构，原始论文中encoder是由6个相同的编码模块堆叠而成（这里的相同指的是结构相同，但是其中的权重却是不共享的， 下面的解码器与之相同），而decoder同样也是用6个解码器堆叠而成的。6这个数字并没有什么特殊之处，只是原始论文使用的层数，我们可以在实验过程中任意设置层数。如下图所示： 注意一个细节，encoder和decoder的链接方式是encoder的最后一层输出与decoder的每一层相连。下面我们打开其中一个编码器和解码器看下里面是什么结构： encoder的输入先经过一个自注意力层对句子进行编码获取词的注意力权重，然后将自注意力输入给一个全连接层。 对于decoder中自注意力层和全连接层和encoder相同，但是在自注意力输出后要经过一个注意力编码层与encoder进行联合编码，然后再传入给全连接层。这个联合编码其实就类似于在seq2seq模型中解码过程中，decoder隐状态和注意力联合编码然后再输出的过程是类似的。 下面我们继续拆解擎天柱的零件，看看这个自注意力和全连接层下面埋藏着什么秘密。 原来所谓的Self-attention是一个叫做Multi-Head Attention的东西，这个就是擎天柱的核心部件了。其他的小零件比如Add, Norm, Linear, softmax, Feed Forward等等都是在五金店都能买到的小玩意儿。下面我们就详细看下这个能量块到底隐藏着什么秘密吧。 2.2 Multi-Head Attention从字面上就可以看出所谓Multi-Head Attention是由两部分组成——Multi-Head和Attention，而实际情况也是如此。其实严格来讲这是一个一般化的名称，如果具体到论文使用的自注意力机制的话，应该叫做Self-Multi-Head Attention。应该有三部分组成，除了上面提到的两个，还应该加上一个自注意力。 还记得我们上一篇介绍注意力机制的文章中提到一种使用$\\mathbf{k}, \\mathbf{q}, \\mathbf{v}$计算注意力的注意力机制。而Scaled Dot-Product也是我们之前提到的一种计算Alignment score function的方法。也就是说，图中下半部分是在计算Scaled-Dot Product Attention，而图中上半部分的Concat操作就是拼接操作，拼接什么？仔细看下半部分计算注意力的时候，不是只计算一个Scaled-Dot Product Attention，而是在同时计算h个Scaled-Dot Product Attention。而Concat拼接的的就是这h个Scaled-Dot Product Attention。这就是所谓的Multi-Head Attention，每一个Head就是一个Scaled-Dot Product Attention。 形式化描述如下： MultiHead(Q, K, V) = Concat(head_1, head_2, ..., head_h)W^O head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)其中$W_i^Q \\in \\mathbb{R}^{d_{model}\\times d_q}$，$W_i^K \\in \\mathbb{R}^{d_{model}\\times d_k}$，$W_i^V \\in \\mathbb{R}^{d_{model}\\times d_v}$，$W_i^O \\in \\mathbb{R}^{d_{model}\\times d_o}$。在原始论文中$h=8$，$d_k=d_v=d_{model}/h=64$。由于对每一个Head进行了降维，所以总的计算量和使用一个单独的不降维的Head是一样的。本文涉及到的公式所用标记都与原论文保持一致，避免混淆。 我们仔细思考一下这个Multi-Head Attention，和我们提到的Multi-dimensional Attention有异曲同工之妙。论文里提到，相对于使用单个注意力而言，使用Multi-Head能获得更好的效果。但是论文并没有解释为什么。我们这里结合Multi-dimensional Attention做一个大胆的猜想：Transformer的强大之处正是由于这个Multi-Head！因为多维注意力机制能够获得一句话中在不同语境下的不同理解。而在语言模型中，词语和句子的歧义性一直是自然语言处理的难点，而Transformer在多维注意力机制的作用下能够很好的获取句子的多重含义，并且能根据上下文信息自动获取正确的语义，因此Transformer能够在预训练语言模型中大放异彩。 下面我们就应该看一下这个核心中的核心——Scaled-Dot Product Attention了。 2.3 Scaled-Dot Product AttentionScaled-Dot Product Attention结构如图所示： 首先我们先给出其形式化定义： Attention(K, Q, V) = softmax(\\frac{QK^T}{\\sqrt {d_k}})V我们把图中结构分解开来，一步一步解释清楚： 第一步MatMul：计算Alignment score function MatMul(Q, K_i) = QK_i^T 第二步Scale：调节Alignment score function分数 Scale(Q, K_i) = \\frac{Q,K_i^T}{\\sqrt{d_k}} 第三步Mask（可选）：encoder不需要这一步，decoder需要这一步。 这里的masked就是要在训练语言模型的时候，不给模型看到未来的信息， 让模型自己预测下一个词。 第四步Softmax：相似度归一化 \\alpha_i = Softmax(Q, K_i) =softmax(\\frac{QK_i^T}{\\sqrt {d_k}}) 第五步MatMul：通过计算出来的权重与$V$加权求和得到最终的Attention向量 Attention(K_i, Q, V_i) = \\sum_i \\alpha_i V_i下面我们从序列输入开始详细解释一下每一步到底是在做什么。 第一步：计算K, Q, V 将输入的每一个词转化成词向量，词向量可以是预训练好的（比如用word2vec）词向量，在网络训练过程中固定词向量矩阵不参与训练，也可以是随时初始化，然后随着网络的训练不断更新词向量矩阵。 将序列中每个元素对应的词向量分别与$W^Q, W^K, W^V$相乘计算得到queries, keys, values。计算得到的queries, keys, values的维度为64，当然维度缩减并非必须。 第二步：计算自注意力的alignment score function 所谓自注意力就是计算序列中两两元素之前的依赖关系，这个分数表示当前这个词需要把多少注意力放在句子中的其他部分上。 以上图举例，Thinking的得分是$\\mathbf{q}_1\\cdot \\mathbf{k}_1=112$，Machines的得分是$\\mathbf{q}_1\\cdot \\mathbf{k}_2=96$，后面的以此类推。 第三步和第四步：对上一步的得分进行缩放，然后计算softmax 上一步的得分除以8（因为前面我们提到queries, keys, values的维度为64，开方之后就是8）。之所以要做这个缩放论文给出的解释是防止这个得分过大或者过小，在做softmax的时候不是0就是1，这样的话就不够soft了。 得到放缩后的得分之后就是计算softmax了。 第五步：在decoder中对句子进行Mask。比如输入是一句话 “i have a dream” 总共4个单词，这里就会形成一张4x4的注意力机制的图： 这里的mask就是要在做语言建模的时候，不给模型看到未来的信息，让模型自己预测后面的信息。比如上图中，“I”作为第一个词，只能和自己进行Attention；“have”作为第二个词，可以和“I”和“have”本身进行Attention；“a”作为第三个单词，可以和“I”，“have”，“a” 三个单词进行Attention；到了最后一个单词“dream”的时候，才有对整个句子4个单词的attention。 第六步：用上面计算出来的softmax与values进行加权求和 至此Scaled-Dot Product Attention就计算完了。 2.4 矩阵计算 Scaled-Dot Product Attention前面我们说过，Transformer的初衷就是并行计算，所谓并行计算就是矩阵计算，上面的例子是通过一个一个向量进行计算的，如果我们把向量堆叠成矩阵，就可以实现并行运算了： 2.5 矩阵计算 Multi-Head 2.6 Position Encoding到目前为止，擎天柱的能量核心结构我们介绍完了，但是我们还忽略了一个问题：句子是一个有序的序列，句子中两个词的位置互换的话，这个句子的意思完全不同了，因此在处理自然语言的时候词与词的绝对位置或者相对位置也是一个非常重要的信息。 为了解决位置信息的问题，Transformer在每一个输入向量中增加了一个位置向量，这个位置向量的维度为$d_{model}$，这样输入向量和位置向量就可以 直接相加了。 在NLP的很多模型中都有位置向量的使用，比如前面我们提到基于CNN的seq2seq模型（Gehring et al., 2017）。但是通常其他模型中的位置向量都是通过学习得来的，本文采用的是直接通过函数构造出来的： \\left\\{ \\begin{aligned} PE_{(pos, 2i)} & = \\sin(pos/10000^{2i/d_{model}}) \\\\\\\\ PE_{(pos, 2i+1)} & = \\cos(pos/10000^{2i/d_{model}}) \\end{aligned} \\right.其中$pos$表示位置索引，$i$表示维度索引。也就是说位置向量中的每一维都是一个余弦曲线，波长是一个从$2\\pi$到$10000 \\cdot 2\\pi$的等比数列。之所以选择这个函数，是因为它允许模型能很容易的学习到相对位置信息，因为对于任意固定的偏置$k$，$PE_{pos+k}$能通过一个$PE_{pos} $的线性函数推理得到： \\begin{aligned} \\sin(\\alpha+\\beta) &= \\sin(\\alpha) \\cos(\\beta) + \\cos(\\alpha)\\sin(\\beta)\\\\\\\\ \\cos(\\alpha+\\beta) &= \\cos(\\alpha) \\cos(\\beta) - \\sin(\\alpha)\\sin(\\beta) \\end{aligned}另外，作者也做过实验，使用通过学习得到的位置向量，最后发现两者的效果差别不大。在效果差别不大的情况下使用直接构造的方法能够避免训练过程的权重更新，这样可以加速训练。另外一个很重要的原因就是，选择这个余弦版本的位置向量还可以处理比训练时遇到的更长的序列。 2.6 残差结构如果我们仔细看模型结构图就会发现，数据的流向并不是从一层单项流向下一层的这种简单的串联结构，而是采用了类似残差网络的残差式连接。 第一步：计算Multi-Head Attention 第二步：原始的输入+Multi-Head Attention 第三步：使用LayerNorm进行正则化 第四步：正则化后的数据经过全连接层，全连接层的激活函数使用ReLU函数。注意这里面的全连接层是每个位置每个位置单独进行计算的，其实更像是卷积核大小为1的卷积层。 第五步：第三步正则化的数据与全连接层后的数据相加 第六步：第五步相加后的数据再次正则化 这就是Transformer的残差网络计算过程。 到目前为止，擎天柱身上的主要零部件我们都已经介绍完了，接下来就该把这些零部件再组装回去了。 3. 模型组装3.1 EncoderEncoder包含6个相同的层 每一层包含2个sub-layer：Multi-Head Attention和全连接层。 每个sub-layer都要正则化 sub-layer内部通过残差结构连接 每一层的输出维度为$d_{model}=512$ 3.2 DecoderDecoder也是6层 每层包含3个sub-layer：Multi-Head Attention，Encoder-Decoder Attention和全连接层 其中Encoder-Decoder Attention的结构和其他的注意力相同，但是不同的是这一层的$K, V$都是来源于Encoder，而$Q$来源于上一层注意力产生的。 Decoder中的Multi-Head Attention层需要进行修改，因为只能获取到当前时刻之前的输入，因此只对时刻 t 之前的时刻输入进行Attention计算，这也称为Mask操作 3.3 最后的Linear层和Softmax层Decoder输出一个向量，我们怎么把这个向量转化成单词呢？这就是最后的Linear和Softmax层做的事情。 线性变换层是一个简单的全连接层，将Decoder输出的向量转化成一个logits vector。假设模型的词表中有10000个词，这个logits vector的维度就是10000，每一维对应词表中的一个词的得分。 然后softmax将这些得分进行归一化，将得分变成每个词的概率，然后选出概率最大的那个位置对应到词就是最后的输出了。 4. Transformer在机器翻译中的应用 5. 关于K, Q, V的讨论到这里我们关于整个Transformer的介绍就结束了，我们先从整体上介绍了Transformer也是一个基于encoder-decoder的结构，然后抽丝剥茧般的一层一层的剥开模型，看看它的每一部分到底长什么样子，然后我们了解了每个零件之后又重新把每个零件组装回去。但是还是有两个问题我们可以再细致的讨论一下的，比如为什么需要$V$？为什么$K, Q$使用不同的权重获得？ 5.1 我们为什么需要V？注意力权重矩阵可以表示序列中任意两个元素的相似性，但是不能用来表示原始的序列，因为它缺少了词向量。注意力的作用是给原始序列中的不同位置上的元素以不同的权重，这样可以更好的获取到这个句子中哪一部分重要哪一部分不那么重要，或者说对于句子中的某个词来说，哪个词对它更有依赖关系，哪些词跟它关系没那么密切。所以说，注意力有两个重要的组成部分，一个是注意力权重，也就是词与词之间的相似性，另一个就是原始的句子序列。从模型结构就可以看出来，$K, Q$是用来计算相似性的，那么$V$其实就是用来表征句子序列特征的。 我们可以认为注意力权重矩阵是一个过滤矩阵 ，把更多的注意力给重要的词，给那些不那么重要的词以更少的注意力。 5.2 为什么使用两个不同的权重获得K, Q?另一个问题就是，我们为什么要用两个不同的矩阵来获得$K, Q$？换句话说，就是我们为什么要用两个不同的矩阵来计算注意力呢？ 正如我们前面所说的，注意力实际上是在计算两个词的相似度，如果使用相同的矩阵的话那就相当于计算自己与自己的相似度了，最后我们会得到一个对称矩阵，这样最后的模型的泛化性会大打折扣。 5.3 Transformer是如何实现All You Need的？回顾一下前一篇文章，我们介绍了各种各样的注意力机制： 用于seq2seq的注意力机制 用于多语义理解的多维注意力机制 用于文本分类和语法纠正的层级注意力机制 用于阅读理解的基于记忆力的注意力机制 用于语言模型的自注意力机制 用于排序的指针网络 其他基于特定任务的注意力机制等等 而Transformer本身就是基于encoder-decoder的结构，由于才用了Multi-Head这种类似多维度注意力机制，所以也能在多维度理解语义，另外由于本身是完全基于注意力的网络所以类层级注意力和类指针网络的的特性应该是Transformer的内秉属性。最后重要的两点：自注意力和基于记忆力的注意力机制在Transformer中表现尤为明显。所以说Transformer可以说是注意力机制的集大成者。 6. 代码实现（Pytorch）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256import numpy as npimport torchimport torch.nn as nnimport torch.nn.functional as Fimport math, copy, timefrom torch.autograd import Variableclass EncoderDecoder(nn.Module): \"\"\" A standard Encoder-Decoder architecture. Base for this and many other models. \"\"\" def __init__(self, encoder, decoder, src_embed, tgt_embed, generator): super(EncoderDecoder, self).__init__() self.encoder = encoder self.decoder = decoder self.src_embed = src_embed self.tgt_embed = tgt_embed self.generator = generator def forward(self, src, tgt, src_mask, tgt_mask): \"Take in and process masked src and target sequences.\" return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask) def encode(self, src, src_mask): return self.encoder(self.src_embed(src), src_mask) def decode(self, memory, src_mask, tgt, tgt_mask): return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask) class Generator(nn.Module): \"Define standard linear + softmax generation step.\" def __init__(self, d_model, vocab): super(Generator, self).__init__() self.proj = nn.Linear(d_model, vocab) def forward(self, x): return F.log_softmax(self.proj(x), dim=-1) def clones(module, N): \"Produce N identical layers.\" return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])class Encoder(nn.Module): \"Core encoder is a stack of N layers\" def __init__(self, layer, N): super(Encoder, self).__init__() self.layers = clones(layer, N) self.norm = LayerNorm(layer.size) def forward(self, x, mask): \"Pass the input (and mask) through each layer in turn.\" for layer in self.layers: x = layer(x, mask) return self.norm(x) class LayerNorm(nn.Module): \"Construct a layernorm module (See citation for details).\" def __init__(self, features, eps=1e-6): super(LayerNorm, self).__init__() self.a_2 = nn.Parameter(torch.ones(features)) self.b_2 = nn.Parameter(torch.zeros(features)) self.eps = eps def forward(self, x): mean = x.mean(-1, keepdim=True) std = x.std(-1, keepdim=True) return self.a_2 * (x - mean) / (std + self.eps) + self.b_2 class SublayerConnection(nn.Module): \"\"\" A residual connection followed by a layer norm. Note for code simplicity the norm is first as opposed to last. \"\"\" def __init__(self, size, dropout): super(SublayerConnection, self).__init__() self.norm = LayerNorm(size) self.dropout = nn.Dropout(dropout) def forward(self, x, sublayer): \"Apply residual connection to any sublayer with the same size.\" return x + self.dropout(sublayer(self.norm(x))) class EncoderLayer(nn.Module): \"Encoder is made up of self-attn and feed forward (defined below)\" def __init__(self, size, self_attn, feed_forward, dropout): super(EncoderLayer, self).__init__() self.self_attn = self_attn self.feed_forward = feed_forward self.sublayer = clones(SublayerConnection(size, dropout), 2) self.size = size def forward(self, x, mask): \"Follow Figure 1 (left) for connections.\" x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask)) return self.sublayer[1](x, self.feed_forward) class Decoder(nn.Module): \"Generic N layer decoder with masking.\" def __init__(self, layer, N): super(Decoder, self).__init__() self.layers = clones(layer, N) self.norm = LayerNorm(layer.size) def forward(self, x, memory, src_mask, tgt_mask): for layer in self.layers: x = layer(x, memory, src_mask, tgt_mask) return self.norm(x) class DecoderLayer(nn.Module): \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\" def __init__(self, size, self_attn, src_attn, feed_forward, dropout): super(DecoderLayer, self).__init__() self.size = size self.self_attn = self_attn self.src_attn = src_attn self.feed_forward = feed_forward self.sublayer = clones(SublayerConnection(size, dropout), 3) def forward(self, x, memory, src_mask, tgt_mask): \"Follow Figure 1 (right) for connections.\" m = memory x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask)) x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask)) return self.sublayer[2](x, self.feed_forward) def subsequent_mask(size): \"Mask out subsequent positions.\" attn_shape = (1, size, size) subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8') return torch.from_numpy(subsequent_mask) == 0def attention(query, key, value, mask=None, dropout=None): \"Compute 'Scaled Dot Product Attention'\" d_k = query.size(-1) scores = torch.matmul(query, key.transpose(-2, -1)) \\ / math.sqrt(d_k) if mask is not None: scores = scores.masked_fill(mask == 0, -1e9) p_attn = F.softmax(scores, dim = -1) if dropout is not None: p_attn = dropout(p_attn) return torch.matmul(p_attn, value), p_attnclass MultiHeadedAttention(nn.Module): def __init__(self, h, d_model, dropout=0.1): \"Take in model size and number of heads.\" super(MultiHeadedAttention, self).__init__() assert d_model % h == 0 # We assume d_v always equals d_k self.d_k = d_model // h self.h = h self.linears = clones(nn.Linear(d_model, d_model), 4) self.attn = None self.dropout = nn.Dropout(p=dropout) def forward(self, query, key, value, mask=None): \"Implements Figure 2\" if mask is not None: # Same mask applied to all h heads. mask = mask.unsqueeze(1) nbatches = query.size(0) # 1) Do all the linear projections in batch from d_model =&gt; h x d_k query, key, value = \\ [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))] # 2) Apply attention on all the projected vectors in batch. x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout) # 3) \"Concat\" using a view and apply a final linear. x = x.transpose(1, 2).contiguous() \\ .view(nbatches, -1, self.h * self.d_k) return self.linears[-1](x) class PositionwiseFeedForward(nn.Module): \"Implements FFN equation.\" def __init__(self, d_model, d_ff, dropout=0.1): super(PositionwiseFeedForward, self).__init__() self.w_1 = nn.Linear(d_model, d_ff) self.w_2 = nn.Linear(d_ff, d_model) self.dropout = nn.Dropout(dropout) def forward(self, x): return self.w_2(self.dropout(F.relu(self.w_1(x)))) class Embeddings(nn.Module): def __init__(self, d_model, vocab): super(Embeddings, self).__init__() self.lut = nn.Embedding(vocab, d_model) self.d_model = d_model def forward(self, x): return self.lut(x) * math.sqrt(self.d_model) class PositionalEncoding(nn.Module): \"Implement the PE function.\" def __init__(self, d_model, dropout, max_len=5000): super(PositionalEncoding, self).__init__() self.dropout = nn.Dropout(p=dropout) # Compute the positional encodings once in log space. pe = torch.zeros(max_len, d_model) position = torch.arange(0, max_len).unsqueeze(1) div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)) pe[:, 0::2] = torch.sin(position * div_term) pe[:, 1::2] = torch.cos(position * div_term) pe = pe.unsqueeze(0) self.register_buffer('pe', pe) def forward(self, x): x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False) return self.dropout(x) def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1): \"Helper: Construct a model from hyperparameters.\" c = copy.deepcopy attn = MultiHeadedAttention(h, d_model) ff = PositionwiseFeedForward(d_model, d_ff, dropout) position = PositionalEncoding(d_model, dropout) model = EncoderDecoder( Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N), Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N), nn.Sequential(Embeddings(d_model, src_vocab), c(position)), nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)), Generator(d_model, tgt_vocab)) # This was important from their code. # Initialize parameters with Glorot / fan_avg. for p in model.parameters(): if p.dim() &gt; 1: nn.init.xavier_uniform(p) return model 7. 参考资料 Attention is all you need The Illustrated Transformer 细讲 | Attention Is All You Need 《Attention is All You Need》浅读（简介+代码） The Annotated Transformer Convolutional Sequence to Sequence Learning","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Attention","slug":"attention","permalink":"https://rogerspy.gitee.io/tags/attention/"},{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"}]},{"title":"NLP中的注意力机制简介（一）","slug":"NLP中的注意力机制简介（一）","date":"2019-08-26T09:54:30.000Z","updated":"2022-01-12T08:42:29.349Z","comments":true,"path":"2019/08/26/NLP中的注意力机制简介（一）/","link":"","permalink":"https://rogerspy.gitee.io/2019/08/26/NLP中的注意力机制简介（一）/","excerpt":"1. 简介传统的注意力机制是与encoder-decoder架构相结合的，其中编码器和解码器都是RNN。首先是一段文本序列输入到编码器当中，然后将编码器的最后一个隐状态单元作为解码器的初始状态，然后一个接一个地产生目标序列，如下所示：","text":"1. 简介传统的注意力机制是与encoder-decoder架构相结合的，其中编码器和解码器都是RNN。首先是一段文本序列输入到编码器当中，然后将编码器的最后一个隐状态单元作为解码器的初始状态，然后一个接一个地产生目标序列，如下所示： encoder-decoder结构在机器翻译任务中被广泛使用，尽管这种方法相较之前的统计翻译方法对翻译效果有很大的提升，但是这种基于RNN的结构也存在两个非常严重的问题： RNN是可遗忘的（forgetful），这就意味着随着信息的传递，在经历了多个时间步长之后，旧的信息可能会丢失；（长程依赖问题） 在解码过程中没有利用词对齐信息，也就是说在产生目标序列的过程中每产生一个词是基于整个源序列的信息的，由于注意力分散，所以在产生目标序列的过程中也容易出错。（注意力分散问题） 为了解决以上两个问题， Bahdanau et al., 2014和 Luong et al., 2015提出了注意力机制。论文中仍然使用基于RNN的encoder-decoder结构，但是在解码过程中每个时间步长都会计算注意力得分，然后再生成该隐状态下对应的输出。下面我们以seq2seq with attention模型为例，介绍传统注意力机制过程： 加入了注意力机制的encoder-decoder模型与标准的encoder-encoder有两点区别： 传入decoder的数据不再是单纯的encoder的最后一个隐状态，而是encoder的所有隐状态； decoder在产生输出之前还会有额外的计算，用于确定当前decoder的隐状态应该对应到哪个encoder的隐状态，这样相当于集中注意力来产生与之对应的输出，这也是注意力机制得名的由来。 注意力得分的计算过程如下所示： 准备好输入到decoder的所有encoder隐状态$\\mathbf{h}_1,\\mathbf{h}_2,\\mathbf{h}_3$； 对每一个隐状态给定一个得分； 对得分使用softmax进行归一化，即为注意力得分； 使用注意力得分和每个decoder隐状态相乘，得到隐状态在当前decoder下的重要性； 最后对加权后的encoder隐状态进行求和，求和后的隐状态即相当于原始encoder-decoder中的单一隐状态。 以上步骤在decoder中的每一个时间步长上都进行一次计算，仍然以翻译模型为例，对整个过程进行简单的介绍： 首先是encoder中对输入的句子序列进行编码，得到$h_1, h_2, h_3$三个隐状态待用； 第一个decoder单元接收到源序列中的终止符开始进行解码，decoder单元首先初始化一个隐状态权重，此时与接收到的源序列终止符相互作用，但并不产生输出，而是产生一个新的隐状态$\\mathbf{h}_4$； 利用上述计算注意力得分的方法对$\\mathbf{h}_1,\\mathbf{h}_2,\\mathbf{h}_3$，进行注意力计算得到$C_4$； 将$C_4$和$\\mathbf{h}_4$进行拼接得到一个新的向量； 将新向量传入到一个全连接层，全连接层的输出则是第一个decoder的输出，即目标序列的第一个元素； 将上述$\\mathbf{h}_4$隐状态作为第二个decoder单元的初始隐状态，第一个decoder的输出向量（即全连接层的输出）作为第二个decoder的输入，再次重复上面的步骤$3-5$。 从上面的过程可以看出，注意力机制的核心点在于注意力权重的计算，下面呢我们对这个计算过程进行公式化描述： e_{ji} = a(\\mathbf{h}_i^{in}, \\mathbf{h}_j^{out}) \\alpha_{ji} = \\frac{exp(e_{ji})}{\\sum_iexp(e_{ji})} \\mathbf{c}_j = \\sum_i\\alpha_{ji}\\mathbf{h}_i^{in}其中$\\mathbf{h}_i^{in}$表示decoder单元的输入隐状态（即encoder第$i$个隐状态），$\\mathbf{h}_j^{out}$表示当前decoder单元的输出，$e_{ji}$表示第$i$个encoder隐藏层对当前decoder单元输出的影响权重（$j$表示第$j$个decoder时间步长，为了方便这里指当前step）,此即为上述注意力全忠计算过程中的步骤$2$。公式$(2)$即使用softmax进行权重的归一化，$\\alpha_{ji}$就是归一化后的注意力权重，即为注意力权重计算过程步骤$3$。公式$(3)$表示的就是注意力权重计算过程步骤$4-5$。 得到注意力权重以后，与当前的decoder隐状态$h_j$和输入$y_{j-1}$结合最终输出目标元素（注意：这里当前decoder的输入是上一个decoder的输出，可参考前面的seq2seq模型的整个过程的介绍。） \\mathbf{y}_j = f_y(\\mathbf{h}_j^{out}, \\mathbf{y}_{j-1},\\mathbf{c}_j) \\mathbf{h}_{j+1}^{out} = f_h(\\mathbf{h}_j^{out}, \\mathbf{y}_j)其中$f_y$和$f_h$表示RNN的输出层和隐状态层。 将上述计算过程对每一个RNN时间步长进行重复计算就能解决最开始我们提出的单纯基于RNN的encoder-decoder模型所带来的问题： 对于长程依赖问题，由于计算注意力过程每次都会通过输入序列的隐状态来计算，因此$\\mathbf{c}_j$不会受到源序列长度的影响； 对于注意力分散的问题，由于我们在每一次进行decode的时候都会进行注意力加权，注意力只会集中在对当前影响较大的部分序列上，而不是把注意力分散到整个序列中，因此有效的解决了注意力分散的问题。 注意力机制自从被提出来以后，在机器翻译领域取得了非常打的成功，随后注意力机制被广泛应用于NLP各个领域中，并且为了解决不同领域中各种问题，注意力机制也出现了各种各样的变种，下图总结了最近几年关于注意力机制的一些比较重要的研究。 下面我们就介绍一些比较重要的注意力模型。 2. 注意力模型的基本形式前面我们介绍了注意力机制在神经机器翻译中的应用，为了更一般化、形式化注意力机制，首先定义$V=\\{\\mathbf{v}_i\\} \\in \\mathbb{R}^{n\\times d_v}$，其中$\\mathbf{v}_i$表示序列元素对应的向量（这里实际上应该是经过编码后的隐状态向量即前文所说的$\\mathbf{h}_i$），重写之前的注意力模型： e_i = a(\\mathbf{v}_i, \\mathbf{u}) \\alpha_i = \\frac{exp(e_i)}{\\sum_i exp(e_i)} c = \\sum \\alpha_i \\mathbf{v}_i其中$\\mathbf{u} \\in \\mathbb{R}^{d_v}$表示序列$\\{\\mathbf{v}_i\\}$对应的输出（pattern vector）， 而$e_i$则表示序列$\\{\\mathbf{v}_i\\}$中第$i$个元素对输出的影响，多数情况下$d_u=d_v=d$，而$a(\\cdot)$函数（又叫Alignment score function）通常有一下几种选择： Name Alignment score function $a(\\cdot )$ Notes Citation Content-base $a(\\mathbf{v}_i, \\mathbf{u})=cosine([\\mathbf{v}_i, \\mathbf{u}])$ — Graves2014 Additive $a(\\mathbf{v}_i, \\mathbf{u}) = \\mathbf{w}_2^{T}tanh(W_1[\\mathbf{v}_i;\\mathbf{u}])$ — Bahdanau2015 Location-base $\\alpha_i=softmax(W\\mathbf{u})$ 只依赖目标输出，直接计算注意力权重 Luong2015 General $ a(\\mathbf{v}_i, \\mathbf{u}) = \\mathbf{u}^TW\\mathbf{v}_i$ — Luong2015 Dot-product $a(\\mathbf{v}_i, \\mathbf{u}) = \\mathbf{u}^T\\mathbf{v}_i$ — Luong2015 Scaled Dot-product $a(\\mathbf{v}_i, \\mathbf{u}) = \\frac{\\mathbf{u}^T\\mathbf{v}_i}{\\sqrt{n}}$ 其中$n$是$\\mathbf{v}_i$的向量维度 Vaswani2017 以Content-base为例，计算出$e_i$在进行归一化，实际上可以认为这是一个相似性计算（类似$cos(\\cdot)$）的操作，也就是说这里是在计算$\\mathbf{v}_i$与输出之间的相似性。 为了避免混淆，我们先解释一下本文所采用的符号： 小写符号表示标量，如$e_i$; 小写加粗符号表示向量， 如$\\mathbf{v}_i$; 大写符号表示矩阵， 如$W$； 大写加粗符号表示张量，如$\\mathbf{W}$； $W, b$默认为待学习的权重矩阵和偏置 3. 注意力机制的变种前面我们讨论了注意力机制的基本形式，由于其简单且有效使得注意力机制在NLP领域被广泛使用，但是通常在一些复杂性况下，这种简单形式的注意力机制仍然不够强大。随着注意力机制在不同场景下的应用，各种各样与之相关的注意力机制被提出来，总结起来可以概括为：基础注意力（Basic Attention），多维注意力（Multi-dimensional Attention），层级注意力（Hierarchical Attention），自注意力（Self-Attention），基于记忆的注意力（Memory-based Attention），指针网络（Pointer Network），特定任务下的注意力（Task-specific Attention）。 注意我们是根据不同的NLP任务应用场景对注意力机制进行分类的，在一些论文或者博客中通常见到的注意力模型分类将注意力分成soft attention, hard attention, global attention, local attention, self-attention等，与本文的分法不太相同，这是因为分类的依据不同。这里对这种分类方法的注意力机制做简单的介绍： soft/hard attention的区别类似于word embedding和one-hot的区别。soft attention的优势在于注意力平滑可微分，也就是说可以利用梯度下降进行权重更新，缺点就是如果输入较大（输入序列过长）比较消耗计算资源。hard attention的优势就是计算资源消耗少，但缺点就是不能微分，在进行权重更新的时候需要比较复杂的技术来处理这个问题。 global attention 类似于soft attention将整个序列的信息融合进一个向量中，local attention类似于hard attention，它是在一个选定的窗口内进行soft attention，而在窗口之外仍然是hard attention。在特定任务下的注意力机制中我们会介绍一个local attention在机器翻译中的应用。 表1总结了不同注意力模型各自的特点： 注意力机制类型 特点 Basic Attention 从一个序列中抽取出重要的元素 Multi-dimensional Attention 获得元素之间的多种操作类型 Hierarchical Attention 抽取全局和局部的重要信息 Self-Attention 抽取序列中隐含的上下文信息 Memory-based Attention 获取NLP任务中的隐藏的依赖关系 Pointer Network 对输入序列进行排序 Task-specific Attention 获取特定任务中的重要信息 3.1 多维注意力机制前面我们介绍的基础注意力模型可以认为是一维的注意力机制（1D-attention），因为对于序列$V=\\{\\mathbf{v}_i\\}$中的每一个元素计算出来的注意力权重$\\alpha_i$都是一个标量，即$V=\\{\\mathbf{v}_i\\}$对应的注意力权重为$\\mathbf{\\alpha}=\\{\\alpha_i\\} \\in \\mathbb{R}^n$。但是在需要提取多种信息表示的情况下1D-attention就显得无能为力了，比如： Fish Burger is the best dish it tastes fresh. 这样一句很简单的话，我们可以有不同的理解方式： 晚餐之中哪道菜是最好的？ 晚餐中Fish Burger这道菜和其他菜比起来怎么样？ 对于第一个理解方式，那么注意力应该在Fish Burger；而对于第二种理解方式，注意力应该在the best上面。也就是说针对不同语境（representation space），同一句话的注意力重点也是不同的。因此，我们需要多个注意力来处理这类情况，即所谓的Multi-dimensional attention。 最简单的方式就是多个1D-attention堆积成一个Multi-dimensional attention。例如Wang et al., 2017提出的2D-attention：给定一个输入序列$V=\\{\\mathbf{v}_i\\}$，两个representation space $U = \\{\\mathbf{u}^a, \\mathbf{u}^p\\}$，权重张量$\\mathbf{W}=\\{W_a, W_p\\}$，注意力权重的计算变为： \\mathbf{e}_i = tanh([\\mathbf{v}_i^TW_a\\mathbf{u}^a:\\mathbf{v}_i^TW_p\\mathbf{u}^p])其中$[:]$表示两个向量的拼接，$E = \\{\\mathbf{e}_i\\}$， 经过softmax归一化之后得到注意力矩阵$\\Lambda = \\{\\alpha_i\\}$。结果如图所示： Aspect attention和Opinion attention表示两个representation space，Aspect attention能把注意力集中在Fish Burger上，而Opinion attention能把注意力集中在best上，这样就解决了上面提到的问题。 然而这种多维注意力机制存在一个问题： 如果每一维注意力都有相似的注意力，那么最后得到的信息会存在信息冗余的问题。 针对这个问题Lin et al. 2017提出一种惩罚机制，即 P = \\|(\\Lambda \\Lambda^T-I)\\|_F^2其中$\\Lambda$ 表示注意力矩阵，$I$表示单位矩阵，$|\\cdot|_F$表示Frobenius范数。类似于添加一个$L_2$正则项，这个惩罚项会乘以一个系数（超参数）然后和原始的损失函数一同计算最小化。 下面我们讨论一下这个惩罚项的有效性（原始论文中作者最先考虑的是KL散度，但是在实际测试过程中发现效果并不理想，所以才考虑添加这样一个惩罚项）。 考虑 $\\Lambda = \\{\\alpha_a, \\alpha_p\\}$，由于$\\alpha_a$和$\\alpha_p$都经过了softmax，因此$\\alpha_a$和$\\alpha_p$可以被认为是离散概率分布中的概率质量（probability mass），对于$\\Lambda \\Lambda^T$矩阵中任意非对角的元素$\\alpha_{ij}(i\\neq j)$，对应于两个分布的元素级乘积求和： 0 \\lt \\alpha_{ij}=\\sum_{k=1}^n\\alpha_k^i\\alpha_k^j \\lt 1其中$\\alpha_k^i$和$\\alpha_k^j$分别对应$\\mathbf{\\alpha}_a$和$\\mathbf{\\alpha}_p$的第$k$个元素。最极端情况下假设$\\mathbf{\\alpha}_a$和$\\mathbf{\\alpha}_p$没有任何交叉点，即$\\alpha_{ij}=0$，否则$\\alpha_{ij} \\gt 0$；另一个极端情况是假设$\\mathbf{\\alpha}_a$和$\\mathbf{\\alpha}_p$完全相等，即两个注意力全部在同一个词上面，此时$\\alpha_{ij}=1$。我们从$\\Lambda \\Lambda^T$中减去一个单位矩阵，相当于强迫$\\Lambda \\Lambda^T$的对角元素都约等于1，当$\\alpha_{ij}=1(i=j)$时，$\\alpha_{ij}=0(i \\neq j) $，而我们的目的就是使每个维度上的注意力都不相同，所以我们需要$\\alpha_{ij}=0(i \\neq j)$，满足第一种极端假设。 实际上我们最小化这个惩罚项的时候是在将注意力矩阵$\\Lambda $进行正交化，每一行都与其他行正交，即每一行都与其他行的注意力不同。 3.2 层级注意力机制3.2.1 自下而上的层级注意力机制（Bottom-up Hierarchical Attention）下面我们考虑文本分类任务。文本分类可以说是NLP中最基础的任务之一了。文本具有典型的层级结构： character =&gt; word =&gt; sentence =&gt; document document的类别取决于构成它的sentence，而sentence的意思又取决于word以及词序，也就是说要想对文本很好的进行分类，需要抓住其中的关键词和关键句子（语序可以通过RNN等网络结构来解决，这里不讨论语序的问题）。 针对这个问题Yang et al., 2016提出了Hierarchical Attention Networks (HAN)，也就是层级注意力神经网络。HAN使用双向GRU网络对序列进行编码。给定一个序列$V_j=\\{\\mathbf{v}_i\\}$表示文档中第$j$个句子，$\\mathbf{v}_i$则表示句子中第$i$个词。给定一个序列集$\\mathbf{D} = \\{V_i\\}$表示一篇文档。 Word Encoder \\mathbf{h}_i^{word} = BiGRU(\\mathbf{v}_i) \\mathbf{u}_i^{word} = tanh(W_w\\mathbf{h}_i^{word}+b_w)这里encoder编码后的隐状态又经过了一层全连接层进行编码。 Word Attention e_i^{word} = a(\\mathbf{u}_i^{word}, \\mathbf{u}_w) = \\mathbf{u}_w{^T}\\mathbf{u}_i{^{word}} \\alpha_i^{word} = softmax(e_i^{word}) \\mathbf{s}_i = \\sum_t \\alpha_i^{word}\\mathbf{h}_i^{word}其中$\\mathbf{s}_i$表示$V_i$经过编码后的句向量，$t$表示句子长度，$\\mathbf{u}_w$是随机初始化的可学习参数。 Sentence Encoder \\mathbf{h}_i^{sent} = BiGRU(\\mathbf{s}_i) \\mathbf{u}_i^{sent} = tanh(W_s\\mathbf{h}_i^{sent}+b_s) Sentence Attention e_i^{sent} = a(\\mathbf{u}_i^{sent}, \\mathbf{u}_s) = \\mathbf{u}_s{^T}\\mathbf{u}_s^{sent} \\alpha_i^{sent} = softmax(e_i^{sent}) \\mathbf{d} = \\sum_i \\alpha_i^{sent}\\mathbf{h}_i^{sent}其中$\\mathbf{d}$就是document对应的向量。 3.2.2 自上而下的层级注意力机制（Top-down Hierarchical Attention）HAN是一种bottom-up类型的层级注意力机制，除此之外还有top-down类型的层级注意力机制，比如Ji et al., 2017提出使用层级注意力机制进行语法错误改正（grammatical error correction）。在这篇文章中，在编码阶段使用GRU进行编码，但是为了解决OOV (out-of-vocabulary)问题，作者提出了所谓的Hybrid encoder，即对于不在词表中的词（UNK），使用字母编码向量代替UNK，这个并非本文讨论的重点，因此下面我们集中讨论这篇文章中top-down层级注意力机制：word-level attention和character-level attention。 语法错误改正的特点正好和文本分类相反，文本分类是需要从词到句再到文档一层一层抓住文本所描述的语义，而语法错误改正是需要先理解文本的语义，然后根据语义对其中的词进行修改。词的修改也并不是修改全词，有可能只是其中几个字母的错误，因此需要用top-down层级注意力机制。 目标词的确定是通过以下两种方式： 如果目标词在词表内，则使用word-level attention 如果目标词不在词表内，则使用character-level attention 具体来说就是： 以词为基础利用GRU进行句子编码（此处的编码指的是Hybrid encoder），得到隐状态$\\mathbf{h}_1, \\mathbf{h}_2, …, \\mathbf{h}_T$； 对于源词和目标词都在词表中的情况，直接使用word-level注意力权重进行解码，生成目标序列； 对于目标词不在词表的情况（模型预测出来的目标词为UNK），$p(UNK|\\mathbf{x}_c)\\cdot p(char_seq|\\mathbf{x}_c)$； 其中character-sequence的生成方法如下： 初始化character-decoder隐状态：$\\mathbf{d}_s^\\sim = Relu(W[\\mathbf{c}_s;\\mathbf{d}_s])$，其中$\\mathbf{c}_s=\\sum_T\\alpha_j\\mathbf{h}_j$，$\\mathbf{d_s}$表示当前word-decoder的隐状态； 若目标词对应的源词在词表中，直接使用character-decoder生成一个词； 若目标词对应的源词也不在此表中（即源词和目标词都为UNK），首先使用character-decoder生成一个词，然后利用编码时使用的character-encoder得到的UNK源词编码与生成的词进行加权求和即得到目标词 \\mathbf{d}_n^{cc} = Relu(W_c[\\mathbf{c}_n^c;\\mathbf{d}_n^c]) 另外，这种自上而下的注意力机制还被应用于为唱片挑选合适的海报Yu et al., 2017以及文本生成，这里就不详细介绍了。总的来说想这种需要先从全局信息来确定局部信息的场景都可以使用这种从上而下的层级注意力机制。 3.3 自注意力机制回顾一下基础的注意力机制：给定一个序列$V=\\{\\mathbf{v}_i\\}$和模式向量$\\mathbf{u}$，对于每一个$\\mathbf{v}_i$我们都可以计算一个注意力权重$\\alpha_i=softmax(a(\\mathbf{v}_i, \\mathbf{u}))$。实际上这种注意力机制是一种外部注意力，正如前面我们讨论的，这种注意力实际上有点类似于计算$\\mathbf{v}_i$与外部模式向量$ \\mathbf{u}$的匹配度（或者相似度），注意力权重依赖于外部模式。 所谓自注意力机制指的是$\\mathbf{u}$是输入序列自身的一部分，即： e_{ij} = a(\\mathbf{v}_i, \\mathbf{v}_j) \\alpha_{ij} = softmax(e_{ij})通常情况下， \\alpha_{ij} = softmax(tanh(\\mathbf{w}^T[\\mathbf{v}_i;\\mathbf{v}_j]+b))那么自注意力机制通常在什么场景下使用呢？ 获取序列内部元素之间的相互依赖关系。比如”Volleyball match is in progress between ladies“，这句话中其他词都是在围绕match进行描述的。从上面的形式描述也可以看出，自注意力机制是在计算序列内部元素之间的匹配度，因此当我们需要获取序列内部的依赖关系的时候自注意力机制就可发挥作用。 通过语义获取词义，类似于词义消歧。举个例子： I arrived at the bank after crossing the street. I arrived at the bank after crossing the river. 其中bank再第一句中最可能的意思应该是银行， 而第二句中的bank最可能的语义应该是岸边。因为自注意力能使第一句中的bank注意到street，而第二句中的bank注意到river。 自注意力机制最成功的的案例应该属于最近大火的Transformer了，下面我们会对Transformer进行单独的介绍，这里就先跳过。 3.4 基于记忆力的注意力机制为了介绍基于记忆力的注意力机制，我们重新构建旧的注意力机制。 假设有一组键值对$V =\\{(\\mathbf{k}_i, \\mathbf{v}_i)\\}$和一个检索向量（query vector）$\\mathbf{q}$，重新定义注意力权重计算过程： e_i = a(\\mathbf{k}_i, \\mathbf{q}) \\alpha_i = softmax(e_i) \\mathbf{c} = \\sum_i \\alpha_i \\mathbf{v}_i这种注意力机制有点类似信息检索，给定一些文本和一个检索词，根据这些文本与检索词之间的匹配度（注意力权重$\\{\\alpha_i\\}$）提取文本中的信息。当然信息检索是根据文本与检索词之间的匹配度进行文本排序，这里不做讨论。需要注意的是，如果所有的$\\mathbf{k}_i=\\mathbf{v}_i$的话，基于记忆力的注意力机制又转化成基础的注意力机制。更多关于$\\mathbf{k}$和$\\mathbf{v}$的内容我们会在Transformer专题里面进行讨论。 下面我们从两个方面详细讨论基于记忆力的注意力机制相对于基础记忆力机制的优势： 可复用性（Reusability） 对于问答系统来说，一个基本的问题是答案与问题并不是直接相关的，举个例子： Sam walks into the kitchen. Sam picks up an apple. Sam walks into bedroom. Sam drops the apple. Q: Where is the apple? 上面四个句子与apple匹配度比较高的应该是第2和第4句话，在用基础注意力机制的时候，注意力权重会集中在这两句话上，但是我们知道正确答案却在第3句话。因此，基础注意力机制没有办法解决这种间接相关（或者说需要进行一定程度上的推理）的任务。 但是如果我们通过迭代更新记忆信息来模拟时序推理的话，这个问题就可以得到解决。Sukhbaatar et al., 2015通过结合记忆神经网络和注意力机制，为这类问题提出了一种解决方案。这里我们只讨论Sukhbaatar et al., 2015的论文中的注意力机制和记忆力神经网络结合的部分，其他的细节问题不做讨论，过程如下： 初始化$\\mathbf{q}_t=\\phi_q(question)$； 计算句向量$\\mathbf{k}_i=\\phi_k(x_i )$； $e_i=\\mathbf{q}_t^T\\mathbf{k}_i$； $\\alpha_i=softmax(e_i)$； $\\mathbf{v}_i=\\phi_v(x_i)$； $\\mathbf{c}_i=\\sum_i \\alpha_i \\mathbf{v}_i$； 更新问题向量$\\mathbf{q}_{t+1}=\\mathbf{q}_{t}+\\mathbf{c}_i$； 重复$2-7$ 我们对上面的过程做一个解释： 第一步：初始化问题，将问题转化成向量，需要注意这里是一个一维向量，不是多个词向量序列构成的句矩阵，包括下面$x_i$指的是一个句子而不是词。$\\phi_q, \\phi_k, \\phi_v$都是将句子转化成一维的向量，具体怎么转化的在文章中有具体的介绍，这里不是我们讨论的重点。 第二步：将第$i$个句子转化成句向量。 第三至第六步：就是标准的注意力加权求和。 第七步：更新问题向量。 整个推理过程如下： 另外有很多人在这方面也做了很多工作，比如Kumar et al. 2016，Graves et al., 2014这里不详细介绍了。下面我们继续介绍第二点优势。 灵活性（Flexibility） 由于键 和值 有不同的向量表示，我们就可以自由的设计相应的嵌入层更好的获得相应的信息，比如分别设计针对问题和答案的向量表示，比如Miller et al., 2016提出的key-value memory network：设计一个窗口结构，窗口中心的词为值向量，而窗口周围的词为键向量，用上面的例子则apple和bedroom为值向量，他们周围的词为键向量。 如果我们希望使用基础的注意力机制只需要令$\\mathbf{k}=\\mathbf{v}$即可，这也是其灵活性的表现。另外还有一些其他的键值向量的设计方式，这里我们不再过多介绍了。 3.5 指针网络对于一些排序的问题（sorting）或者“巡回推销员”（travelling salesman）问题输出并不是确定的，而是随着输入的变化输出也随之改变。面对这类问题前面提到的各种注意力模型都无能为力了，因此 Vinyals, et al. 2015提出了指针网络的方法。不同于其他注意力模型将上下文信息糅合进一个向量里面，指针网络是在解码阶段通过注意力机制一个一个从输入序列中选择元素进行输出。 给定一个输入序列$V=\\{\\mathbf{v}_i\\}$，指针网络输出一个序列$\\mathbf{c}=\\{c_i\\}$，其中$c_i$是$V$中元素的索引。 \\begin{align} y_i &= p(c_i|c_1,...c_{i-1}, V) \\nonumber\\\\ &= \\sigma(a(\\mathbf{v}_i, \\mathbf{u})) \\nonumber\\\\ &= \\sigma(\\mathbf{w}_2^{T}tanh(W_1[\\mathbf{v}_i;\\mathbf{u}])) \\nonumber \\end{align}3.6 特定任务下的注意力机制 文本摘要 Tan et al., 2017在文本摘要任务中提出了一种类似于PageRank的graph-based attention。给定一篇文档$V=\\{\\mathbf{v}_i\\}$，其中$\\mathbf{v}_i$表示句子向量， 假设注意力分布为$\\mathbf{\\alpha}=\\{\\alpha_i\\}$，则$\\mathbf{\\alpha}$满足一下条件： \\mathbf{\\alpha}(t+1)=\\lambda WD^{-1}\\mathbf{\\alpha}(t)+(1-\\lambda)\\mathbf{y}其中$W$表示方阵$W(i,j)=\\mathbf{v}_i^TM\\mathbf{v}_j$，其中M是一个待学习的权重矩阵。$D$是一个对角矩阵，对角线上的元素$d_i=W(i,i)$，这是为了保证$WD^{-1}=1$，$\\lambda$是一个阻尼系数，$\\mathbf{y} \\in \\mathbb{R}^n$，并且$\\mathbf{y} $中的所有元素都是$1/n$。 我们来考虑下这个注意力的物理意义是什么？忽略阻尼系数$\\lambda$，我们来看下$WD^{-1}$表示什么： WD^{-1} =(\\mathbf{v}_i^TM\\mathbf{v}_j)D^{-1}其中的$W$与之前的$e_i$何其相似（公式$(9) $），而$D^{-1}$的存在是为了保证这一项能各元素相加为$1$，这又与$softmax(e_i)$何其相似。也就是说$WD^{-1}$我们也可以看成是一个注意力权重，而这个注意力权重是把注意力放在另一个注意力上。从公式$(32)$我们可以看出$\\alpha_i(t)$注意力越大$\\alpha_i(t+1)$也就会越大。也就是说，如果一个句子与其他重要的句子有更多的关联性的话，那么这个句子也会更重要。这个思想如同我们前面提到的和PageRank非常相似。 机器翻译 Luong et al., 2015为了解决机器翻译过程中，对长序列的所有元素都计算注意力太过消耗资源，因此提出一个叫做局部注意力机制（local attention）的方法。 所谓局部注意力机制其实很简单，就是从整个序列中设定一个窗口$D$，选取$[p_t-D, p_t+D]$范围内的序列计算注意力。其中$p_t$有两种确定方法： 假设源序列和目标序列是一一对应的，则$p_t=t$，即以步长为1沿着序列依次向后滑动窗口取子序列； 假设源序列和目标序列并不是一一对应的，则$p_t=S\\cdot sigmoid(\\mathbf{v}_p^Ttanh(W_p\\mathbf{h}_t))$，其中$S$表示序列的源总长度。然后计算注意力权重，最后视同高斯平滑得到输出。 其他 除了以上介绍的各种各样的注意力机制以外，Kim et al., 2017还提出一种叫做结构化注意力机制的方法。这种注意力机制可用于处理序列选择性问题，例如从一个序列中选出一个子序列，或者从语法树中选取一个子树。基本方法是将注意力模型看成是条件随机场（CRF），引入一个隐变量$Z={\\mathbf{z}_i}$，然后对序列进行编码-解码。这里不再详细介绍这种方法了，如有兴趣可以看论文原文。 4. 小结从上面的介绍我们可以看到，注意力机制的强大之处几乎在NLP领域的各个任务中都有相当出色的发挥： 机器翻译，作为最先引入注意力机制的任务，注意力机制使得机器翻译的水平比之前有一个大的飞跃； 多模式理解，使用多维注意力机制使我们能从不同角度理解自然语言 文本分类，使用自下而上的层级注意力机制提升文本分类的能力 语法纠正，自上而下的注意力机制帮助我们完成这类人物 语言模型，自注意力机制，尤其是Transformer的横空出世，使得语言模型的水准达到了前所未有的高度 阅读理解，基于记忆力的注意力机制使得注意力机制具有了推理能力，帮助我们完成阅读理解的任务 文本摘要，在基于图的注意力机制下，完成了类似PageRank的抽取式文本摘要，虽然目前没有看到其在信息检索方面的研究，但是我相信把它应用于信息检索领域也会有不俗的表现 序列排序，指针网络的出现补足了注意力机制在排序方面的应用空白 另外对于分词，分块，语法解析等基础任务同样有相关的注意力机制的研究成果 从上面的总结我们不难得出一个结论：Attention is all you need 此言非虚！ 5. 参考资料 An Introductory Survey on Attention Mechanisms in NLP Problems, Dichao Hu, 2018 Neural Machine Translation by Jointly Learning to Align and Translate, Bahdanau et al., 2014 Effective Approaches to Attention-based Neural Machine Translation, Luong et al., 2015 Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention), Jay Alammar Neural Turing Machines, Graves et al., 2014 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE, Bahdanau et al., 2015 Attention is all you need, Vaswani et al., 2017 Coupled multi-layer attentions for co-extraction of aspect and opinion terms, Wang et al., 2017 A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING, Lin et al., 2017 Hierarchical attention networks for document classification, Yang et al., 2016 A nested attention neural hybrid model for grammatical error correction, Ji et al., 2017 Hierarchicallyattentive rnn for album summarization and storytelling, Yu et al., 2017 End-toend memory networks, Sukhbaatar et al., 2015 Ask me anything: Dynamic memory networks for natural language processing, Kumar et al., 2016 Key-value memory networks for directly reading documents, Miller et al., 2016 Pointer Networks, Vinyals, et al., 2015 Abstractive document summarization with a graph-based attentional neural model, Tan et al., 2017 Structured attention networks, Kim et al., 2017","categories":[{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Attention","slug":"attention","permalink":"https://rogerspy.gitee.io/tags/attention/"}]}],"categories":[{"name":"博客转载","slug":"博客转载","permalink":"https://rogerspy.gitee.io/categories/博客转载/"},{"name":"语言模型","slug":"语言模型","permalink":"https://rogerspy.gitee.io/categories/语言模型/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://rogerspy.gitee.io/categories/数据结构与算法/"},{"name":"知识图谱","slug":"知识图谱","permalink":"https://rogerspy.gitee.io/categories/知识图谱/"},{"name":"NL2SQL","slug":"nl2sql","permalink":"https://rogerspy.gitee.io/categories/nl2sql/"},{"name":"论文解读","slug":"论文解读","permalink":"https://rogerspy.gitee.io/categories/论文解读/"},{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/categories/nlp/"}],"tags":[{"name":"Dijkstra's Algorithm","slug":"dijkstra-s-algorithm","permalink":"https://rogerspy.gitee.io/tags/dijkstra-s-algorithm/"},{"name":"Graph Algorithm","slug":"graph-algorithm","permalink":"https://rogerspy.gitee.io/tags/graph-algorithm/"},{"name":"Language Model","slug":"language-model","permalink":"https://rogerspy.gitee.io/tags/language-model/"},{"name":"CVT","slug":"cvt","permalink":"https://rogerspy.gitee.io/tags/cvt/"},{"name":"pre-trained seq2seq","slug":"pre-trained-seq2seq","permalink":"https://rogerspy.gitee.io/tags/pre-trained-seq2seq/"},{"name":"data noising","slug":"data-noising","permalink":"https://rogerspy.gitee.io/tags/data-noising/"},{"name":"einsum","slug":"einsum","permalink":"https://rogerspy.gitee.io/tags/einsum/"},{"name":"MHSA","slug":"mhsa","permalink":"https://rogerspy.gitee.io/tags/mhsa/"},{"name":"context2vec","slug":"context2vec","permalink":"https://rogerspy.gitee.io/tags/context2vec/"},{"name":"半监督语言模型","slug":"半监督语言模型","permalink":"https://rogerspy.gitee.io/tags/半监督语言模型/"},{"name":"数据结构","slug":"数据结构","permalink":"https://rogerspy.gitee.io/tags/数据结构/"},{"name":"queue","slug":"queue","permalink":"https://rogerspy.gitee.io/tags/queue/"},{"name":"stack","slug":"stack","permalink":"https://rogerspy.gitee.io/tags/stack/"},{"name":"KG","slug":"kg","permalink":"https://rogerspy.gitee.io/tags/kg/"},{"name":"knowledge-modelling","slug":"knowledge-modelling","permalink":"https://rogerspy.gitee.io/tags/knowledge-modelling/"},{"name":"词向量","slug":"词向量","permalink":"https://rogerspy.gitee.io/tags/词向量/"},{"name":"ontology","slug":"ontology","permalink":"https://rogerspy.gitee.io/tags/ontology/"},{"name":"双数组前缀树","slug":"双数组前缀树","permalink":"https://rogerspy.gitee.io/tags/双数组前缀树/"},{"name":"数组","slug":"数组","permalink":"https://rogerspy.gitee.io/tags/数组/"},{"name":"ROC-AUC","slug":"roc-auc","permalink":"https://rogerspy.gitee.io/tags/roc-auc/"},{"name":"Data Structure","slug":"data-structure","permalink":"https://rogerspy.gitee.io/tags/data-structure/"},{"name":"survey","slug":"survey","permalink":"https://rogerspy.gitee.io/tags/survey/"},{"name":"算法","slug":"算法","permalink":"https://rogerspy.gitee.io/tags/算法/"},{"name":"divide-conquer","slug":"divide-conquer","permalink":"https://rogerspy.gitee.io/tags/divide-conquer/"},{"name":"评估方法","slug":"评估方法","permalink":"https://rogerspy.gitee.io/tags/评估方法/"},{"name":"时间复杂度","slug":"时间复杂度","permalink":"https://rogerspy.gitee.io/tags/时间复杂度/"},{"name":"nl2sql","slug":"nl2sql","permalink":"https://rogerspy.gitee.io/tags/nl2sql/"},{"name":"推荐系统","slug":"推荐系统","permalink":"https://rogerspy.gitee.io/tags/推荐系统/"},{"name":"CNNLM","slug":"cnnlm","permalink":"https://rogerspy.gitee.io/tags/cnnlm/"},{"name":"text2viz","slug":"text2viz","permalink":"https://rogerspy.gitee.io/tags/text2viz/"},{"name":"nl2infographic","slug":"nl2infographic","permalink":"https://rogerspy.gitee.io/tags/nl2infographic/"},{"name":"NLP","slug":"nlp","permalink":"https://rogerspy.gitee.io/tags/nlp/"},{"name":"隐式正则化","slug":"隐式正则化","permalink":"https://rogerspy.gitee.io/tags/隐式正则化/"},{"name":"LSTMLM","slug":"lstmlm","permalink":"https://rogerspy.gitee.io/tags/lstmlm/"},{"name":"RNNLM","slug":"rnnlm","permalink":"https://rogerspy.gitee.io/tags/rnnlm/"},{"name":"FFNNLM","slug":"ffnnlm","permalink":"https://rogerspy.gitee.io/tags/ffnnlm/"},{"name":"Log-Linear Language Model","slug":"log-linear-language-model","permalink":"https://rogerspy.gitee.io/tags/log-linear-language-model/"},{"name":"Probabilistic Language Model","slug":"probabilistic-language-model","permalink":"https://rogerspy.gitee.io/tags/probabilistic-language-model/"},{"name":"Transformer","slug":"transformer","permalink":"https://rogerspy.gitee.io/tags/transformer/"},{"name":"Deep","slug":"deep","permalink":"https://rogerspy.gitee.io/tags/deep/"},{"name":"Initialization","slug":"initialization","permalink":"https://rogerspy.gitee.io/tags/initialization/"},{"name":"Norm","slug":"norm","permalink":"https://rogerspy.gitee.io/tags/norm/"},{"name":"Gaussian","slug":"gaussian","permalink":"https://rogerspy.gitee.io/tags/gaussian/"},{"name":"parallel-recurrent","slug":"parallel-recurrent","permalink":"https://rogerspy.gitee.io/tags/parallel-recurrent/"},{"name":"NMT","slug":"nmt","permalink":"https://rogerspy.gitee.io/tags/nmt/"},{"name":"insertion-deletion","slug":"insertion-deletion","permalink":"https://rogerspy.gitee.io/tags/insertion-deletion/"},{"name":"LSTM","slug":"lstm","permalink":"https://rogerspy.gitee.io/tags/lstm/"},{"name":"insertion","slug":"insertion","permalink":"https://rogerspy.gitee.io/tags/insertion/"},{"name":"sparse","slug":"sparse","permalink":"https://rogerspy.gitee.io/tags/sparse/"},{"name":"weighted-head","slug":"weighted-head","permalink":"https://rogerspy.gitee.io/tags/weighted-head/"},{"name":"tensorflow","slug":"tensorflow","permalink":"https://rogerspy.gitee.io/tags/tensorflow/"},{"name":"pytorch","slug":"pytorch","permalink":"https://rogerspy.gitee.io/tags/pytorch/"},{"name":"Attention","slug":"attention","permalink":"https://rogerspy.gitee.io/tags/attention/"}]}